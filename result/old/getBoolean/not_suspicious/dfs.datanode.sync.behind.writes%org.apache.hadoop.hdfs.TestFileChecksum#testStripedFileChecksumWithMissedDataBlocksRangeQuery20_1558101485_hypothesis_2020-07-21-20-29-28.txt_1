reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130935002-172.17.0.21-1595363381786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-6cf54629-b462-429c-92f2-c274dda29e98,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-daf23cd0-047c-4c6e-9e01-534ede0ff78d,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-4da5a41d-d838-4c50-88cd-9b1b4f9e9694,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-0aafe47d-1818-47ae-b471-9470578619e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-ab66c715-7f49-4aff-b971-f221bc60ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-154ee0ce-8a9a-486d-b746-75a695d710b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b05a05ca-4419-4455-bdfd-0a5d974b1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-aaa65a1f-d683-425c-80cb-d4dd324a9c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130935002-172.17.0.21-1595363381786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-6cf54629-b462-429c-92f2-c274dda29e98,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-daf23cd0-047c-4c6e-9e01-534ede0ff78d,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-4da5a41d-d838-4c50-88cd-9b1b4f9e9694,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-0aafe47d-1818-47ae-b471-9470578619e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-ab66c715-7f49-4aff-b971-f221bc60ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-154ee0ce-8a9a-486d-b746-75a695d710b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b05a05ca-4419-4455-bdfd-0a5d974b1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-aaa65a1f-d683-425c-80cb-d4dd324a9c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073568594-172.17.0.21-1595363862307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33109,DS-5e3b0a19-4414-41c7-8707-df6a678889bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-32b3fe9d-fdb3-4bda-8655-ab74d10ebec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-db3543b6-1db6-47f4-89ae-1af7aeb91bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-7ba14142-e368-4239-abca-565492dcd56f,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-390e32d3-2c47-4e9b-8c7d-f711f18b7b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-bdda4225-07f5-4521-95b8-fb518f3d9b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b1287d98-af2a-4883-8550-a7857cec5aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-488bcce3-da0f-481d-94be-5595b7b6cb40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073568594-172.17.0.21-1595363862307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33109,DS-5e3b0a19-4414-41c7-8707-df6a678889bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-32b3fe9d-fdb3-4bda-8655-ab74d10ebec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-db3543b6-1db6-47f4-89ae-1af7aeb91bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-7ba14142-e368-4239-abca-565492dcd56f,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-390e32d3-2c47-4e9b-8c7d-f711f18b7b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-bdda4225-07f5-4521-95b8-fb518f3d9b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b1287d98-af2a-4883-8550-a7857cec5aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-488bcce3-da0f-481d-94be-5595b7b6cb40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531016648-172.17.0.21-1595364333469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39932,DS-d6943639-d2f2-4ab7-b4e8-1acfe4f57ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-e921f610-c09e-488a-b13b-00206e58410c,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-e91ed930-4c87-472e-9db7-fbe19ec8d398,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-6094b346-e9f4-4469-89a0-f952b7869016,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-8093e2ab-c319-4ece-97f0-a77531b0991f,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-e32239e4-34d0-4bd9-9917-d2d4d7829ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-bf81d143-ce2d-43fb-9628-182453e06835,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-6b4d587e-a0ab-416f-8c6e-6abc9af20696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531016648-172.17.0.21-1595364333469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39932,DS-d6943639-d2f2-4ab7-b4e8-1acfe4f57ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-e921f610-c09e-488a-b13b-00206e58410c,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-e91ed930-4c87-472e-9db7-fbe19ec8d398,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-6094b346-e9f4-4469-89a0-f952b7869016,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-8093e2ab-c319-4ece-97f0-a77531b0991f,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-e32239e4-34d0-4bd9-9917-d2d4d7829ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-bf81d143-ce2d-43fb-9628-182453e06835,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-6b4d587e-a0ab-416f-8c6e-6abc9af20696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132957909-172.17.0.21-1595364582983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-9d6e5b14-ce91-4533-b148-1cd1d357f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-8f774476-1bec-4c04-b747-004ca6476d91,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-fbcad352-d8a8-404f-a38d-c78d88ab4f46,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-10a19468-7a2f-454e-b8f5-0114bfc83a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-0336d83e-4d3f-4a20-8d8f-1dec07d60029,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-ba38738e-d15f-49f4-a3ca-efbaefa9a714,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-0e64feac-668e-4744-be64-5c4c446ddb73,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-abbf65ef-4a4c-4cb8-b517-992a7b6e43ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132957909-172.17.0.21-1595364582983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-9d6e5b14-ce91-4533-b148-1cd1d357f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-8f774476-1bec-4c04-b747-004ca6476d91,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-fbcad352-d8a8-404f-a38d-c78d88ab4f46,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-10a19468-7a2f-454e-b8f5-0114bfc83a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-0336d83e-4d3f-4a20-8d8f-1dec07d60029,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-ba38738e-d15f-49f4-a3ca-efbaefa9a714,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-0e64feac-668e-4744-be64-5c4c446ddb73,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-abbf65ef-4a4c-4cb8-b517-992a7b6e43ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813669349-172.17.0.21-1595365004686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-6b76b5f7-36db-47e3-9fce-464520f164b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-dbe5f5c0-ef5b-433d-9e3e-31e37be7b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-b46f3db8-012d-45ca-aad9-d802de0f38bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-18a9c861-18ee-45a4-87aa-a8c695bae558,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-3e01e79e-b821-47b8-88f9-9df95758994d,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-74da5f5b-fd61-4226-a22d-8263a4e3d3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-cd5cf8d7-05aa-4435-a4d0-02b28d42164e,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-ae73a501-3619-4d70-82d8-7352e7562b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813669349-172.17.0.21-1595365004686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-6b76b5f7-36db-47e3-9fce-464520f164b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-dbe5f5c0-ef5b-433d-9e3e-31e37be7b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-b46f3db8-012d-45ca-aad9-d802de0f38bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-18a9c861-18ee-45a4-87aa-a8c695bae558,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-3e01e79e-b821-47b8-88f9-9df95758994d,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-74da5f5b-fd61-4226-a22d-8263a4e3d3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-cd5cf8d7-05aa-4435-a4d0-02b28d42164e,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-ae73a501-3619-4d70-82d8-7352e7562b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093037598-172.17.0.21-1595365389271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39879,DS-85a87228-b03b-4a5c-9fdd-636e00c5d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-978382eb-3dd3-4522-854b-cd13b95ba5db,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-f1e310a3-0d92-4a4b-91c8-08adad2597d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-f96d00f3-73dd-46c5-b385-a04ef75f21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-ed48dcce-69ba-436a-9dd1-556c49fea31c,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-f1d85183-1f73-4402-962d-539ee657f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-052186f4-2a7a-4b7c-bb0b-e99d8e3f449a,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-a2e744c3-74f4-4813-bf4e-9a1214e7cd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093037598-172.17.0.21-1595365389271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39879,DS-85a87228-b03b-4a5c-9fdd-636e00c5d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-978382eb-3dd3-4522-854b-cd13b95ba5db,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-f1e310a3-0d92-4a4b-91c8-08adad2597d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-f96d00f3-73dd-46c5-b385-a04ef75f21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-ed48dcce-69ba-436a-9dd1-556c49fea31c,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-f1d85183-1f73-4402-962d-539ee657f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-052186f4-2a7a-4b7c-bb0b-e99d8e3f449a,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-a2e744c3-74f4-4813-bf4e-9a1214e7cd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733881117-172.17.0.21-1595365673712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-b7b032fe-e8c3-4fc2-9664-9f865dcaed00,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-f92c772e-3bab-48a3-8271-ee93b83136d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-2ffaf14f-dc26-4aa3-85cd-96d48c0871a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-e1f49c7e-bde0-486c-9056-b3b95a2c0811,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-373d4ff1-dac0-4c85-ac52-612ea41173ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-4b760e96-13f8-47d0-b121-a83f55d78ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-482d11b8-451f-4dc1-9b00-7fb8fbdd2ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-b93432a8-cc56-4325-8ddd-bf4d6a208e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733881117-172.17.0.21-1595365673712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-b7b032fe-e8c3-4fc2-9664-9f865dcaed00,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-f92c772e-3bab-48a3-8271-ee93b83136d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-2ffaf14f-dc26-4aa3-85cd-96d48c0871a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-e1f49c7e-bde0-486c-9056-b3b95a2c0811,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-373d4ff1-dac0-4c85-ac52-612ea41173ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-4b760e96-13f8-47d0-b121-a83f55d78ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-482d11b8-451f-4dc1-9b00-7fb8fbdd2ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-b93432a8-cc56-4325-8ddd-bf4d6a208e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337806418-172.17.0.21-1595365894847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-d5926022-a789-4ea3-b197-53cf547e6831,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-d022dd33-6a44-45fc-8d5a-b8f5813dc4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-0dfdf71e-9ab0-4561-83f1-c5ca64579dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-7beae565-a67d-4d1f-939a-c3e04684b2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-45af9248-6ceb-40f5-b43a-4b6b227bf39a,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-ab6abea7-b44b-4171-b3c1-7e2457dddf87,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-abe64f47-8047-47b5-8d31-95002b3b1e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-854dba34-a123-4151-902f-ce549df3d35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337806418-172.17.0.21-1595365894847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-d5926022-a789-4ea3-b197-53cf547e6831,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-d022dd33-6a44-45fc-8d5a-b8f5813dc4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-0dfdf71e-9ab0-4561-83f1-c5ca64579dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-7beae565-a67d-4d1f-939a-c3e04684b2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-45af9248-6ceb-40f5-b43a-4b6b227bf39a,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-ab6abea7-b44b-4171-b3c1-7e2457dddf87,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-abe64f47-8047-47b5-8d31-95002b3b1e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-854dba34-a123-4151-902f-ce549df3d35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769370508-172.17.0.21-1595366069085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-4b64b963-f38e-4006-a9f5-f4abf706bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-5d026b25-3c1f-40dc-baf3-3f70f6dbc251,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-0d4187c2-4da7-4e0d-8569-b4925e5b7b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-e24a8d68-2f1f-43de-97ae-ce966e0bbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-7574b319-5577-40b7-a6cf-972583158ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-b2a378b5-436f-44cc-b8a6-618735d4eaad,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-f0092292-5e9f-451c-8721-7e8c928ffb09,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-27d35465-1b29-4ee6-b62f-410ad1a28f36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769370508-172.17.0.21-1595366069085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-4b64b963-f38e-4006-a9f5-f4abf706bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-5d026b25-3c1f-40dc-baf3-3f70f6dbc251,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-0d4187c2-4da7-4e0d-8569-b4925e5b7b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-e24a8d68-2f1f-43de-97ae-ce966e0bbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-7574b319-5577-40b7-a6cf-972583158ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-b2a378b5-436f-44cc-b8a6-618735d4eaad,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-f0092292-5e9f-451c-8721-7e8c928ffb09,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-27d35465-1b29-4ee6-b62f-410ad1a28f36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213910280-172.17.0.21-1595366140184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43606,DS-4b76d604-499c-4629-8311-ac4ec2a772ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-0caa8ac1-1451-498d-a856-3626bde0911a,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-09ae9599-3a38-4dba-a899-5a0987421dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-0165dc23-9b05-4c3c-9b99-4b688ffa1feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-d62efd2d-aae1-46f7-bca0-ee585e68dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-be97ad77-2e75-45e4-9816-a53589438c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-6f5a60fd-8af8-4277-a6db-f77ca742b5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-2427f15e-ca67-423e-babe-42691b6dc9ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213910280-172.17.0.21-1595366140184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43606,DS-4b76d604-499c-4629-8311-ac4ec2a772ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-0caa8ac1-1451-498d-a856-3626bde0911a,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-09ae9599-3a38-4dba-a899-5a0987421dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-0165dc23-9b05-4c3c-9b99-4b688ffa1feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-d62efd2d-aae1-46f7-bca0-ee585e68dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-be97ad77-2e75-45e4-9816-a53589438c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-6f5a60fd-8af8-4277-a6db-f77ca742b5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-2427f15e-ca67-423e-babe-42691b6dc9ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524374373-172.17.0.21-1595366565916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-393c8ca3-4d40-4967-81b9-285b7acdf9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-05cce442-120b-4ed6-9234-ea3663545239,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-7093f847-a93b-4eff-9072-4cae0f91cb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-10eed7fb-dca6-4145-bdfa-ae85fdbe5777,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-02a8a036-2e7c-4d82-9cca-8497a38cd51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-67f36e3a-2cde-4e17-90b4-5091228097fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-36026748-1bb5-48b2-8a2e-797e1e2ada7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-198ec569-7f8f-4e94-9cfb-336b26b9d277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524374373-172.17.0.21-1595366565916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-393c8ca3-4d40-4967-81b9-285b7acdf9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-05cce442-120b-4ed6-9234-ea3663545239,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-7093f847-a93b-4eff-9072-4cae0f91cb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-10eed7fb-dca6-4145-bdfa-ae85fdbe5777,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-02a8a036-2e7c-4d82-9cca-8497a38cd51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-67f36e3a-2cde-4e17-90b4-5091228097fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-36026748-1bb5-48b2-8a2e-797e1e2ada7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-198ec569-7f8f-4e94-9cfb-336b26b9d277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519367642-172.17.0.21-1595366920855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33435,DS-447144ac-8011-4b6c-b18d-c04c2b27bc78,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-a5914cb3-a5a9-4023-9329-53461dd67010,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-99e25527-eb8d-4526-889b-fef1542ecbac,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-1084a30e-70c1-4fc5-9faa-5c36765912e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-2ac9c130-e0d1-4990-9e68-5e1af33a71d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-4df8d357-edfb-408b-9e6f-0266f0c918db,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-0c278a38-900f-4250-85d6-0674e72bb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-00ea3775-433a-40df-9859-7d20eceb7fc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519367642-172.17.0.21-1595366920855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33435,DS-447144ac-8011-4b6c-b18d-c04c2b27bc78,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-a5914cb3-a5a9-4023-9329-53461dd67010,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-99e25527-eb8d-4526-889b-fef1542ecbac,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-1084a30e-70c1-4fc5-9faa-5c36765912e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-2ac9c130-e0d1-4990-9e68-5e1af33a71d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-4df8d357-edfb-408b-9e6f-0266f0c918db,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-0c278a38-900f-4250-85d6-0674e72bb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-00ea3775-433a-40df-9859-7d20eceb7fc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86908904-172.17.0.21-1595366984548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-d4df3b47-42dd-433e-9e88-9bf4d03423c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-519efd8b-38af-43f3-8e28-d58b3b63cc44,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-f89434c8-59d1-40c7-8e06-332522fccea4,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-9a9c9e67-2a84-4f6b-bdb2-ac96e415f6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-f61aacb2-1e06-4126-9357-26423919ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-abdbcb5a-0948-4278-b92e-fcd36ef9df32,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-d86d6a92-27c9-40d4-a5fb-30d0c02a6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-496f408f-b250-4f21-9ff3-54ff19b9fb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86908904-172.17.0.21-1595366984548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-d4df3b47-42dd-433e-9e88-9bf4d03423c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-519efd8b-38af-43f3-8e28-d58b3b63cc44,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-f89434c8-59d1-40c7-8e06-332522fccea4,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-9a9c9e67-2a84-4f6b-bdb2-ac96e415f6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-f61aacb2-1e06-4126-9357-26423919ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-abdbcb5a-0948-4278-b92e-fcd36ef9df32,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-d86d6a92-27c9-40d4-a5fb-30d0c02a6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-496f408f-b250-4f21-9ff3-54ff19b9fb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752869387-172.17.0.21-1595367429369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-bd8ec466-8b8f-47c0-a4bb-cb42ccdc5967,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-229c5f5e-f195-44bb-84da-721cff81fb94,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-ac1710ad-5119-489b-99de-28fd83821883,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-27d82fd4-45a5-4c0f-886a-c9785062c7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-c84a967c-420a-4016-9bc8-a6c3bf9248b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-1fac7b36-e2c8-4aa7-951d-cc070b1f9159,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-c6e29c3e-6644-4261-8e59-af05daa4cc23,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-20df7034-9e95-4382-b588-0fbcb00179fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752869387-172.17.0.21-1595367429369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-bd8ec466-8b8f-47c0-a4bb-cb42ccdc5967,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-229c5f5e-f195-44bb-84da-721cff81fb94,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-ac1710ad-5119-489b-99de-28fd83821883,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-27d82fd4-45a5-4c0f-886a-c9785062c7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-c84a967c-420a-4016-9bc8-a6c3bf9248b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-1fac7b36-e2c8-4aa7-951d-cc070b1f9159,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-c6e29c3e-6644-4261-8e59-af05daa4cc23,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-20df7034-9e95-4382-b588-0fbcb00179fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182813037-172.17.0.21-1595367501743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-61af40ac-5264-4875-b63e-b43945a07f57,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-efbadc2e-6440-446e-9dac-3c7e9e816baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-f096740d-877d-4622-8d89-469a9d1eb67a,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-b517b44d-2a18-45b2-8de7-e42fa59ed52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-fcc21268-8c79-4464-894a-10ded1a91f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-1380277f-e57f-4747-a9ae-544b2a6f44cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-b659fb5e-b0ed-4599-945f-f86f731156ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-d7962fc5-615f-4a71-9d37-e68ffe78990e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182813037-172.17.0.21-1595367501743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-61af40ac-5264-4875-b63e-b43945a07f57,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-efbadc2e-6440-446e-9dac-3c7e9e816baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-f096740d-877d-4622-8d89-469a9d1eb67a,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-b517b44d-2a18-45b2-8de7-e42fa59ed52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-fcc21268-8c79-4464-894a-10ded1a91f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-1380277f-e57f-4747-a9ae-544b2a6f44cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-b659fb5e-b0ed-4599-945f-f86f731156ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-d7962fc5-615f-4a71-9d37-e68ffe78990e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198685610-172.17.0.21-1595367882316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41663,DS-a747c1cb-a770-43b5-9d89-7903597257ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-7d4fc325-af47-4390-8195-ff15402bed17,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-0f574a83-8720-44d4-a8ca-c641dc14c799,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-4a3f5269-bab7-4d8b-ad7e-713aac3e821f,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-a26f7019-d45f-4603-9b41-284198653726,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-a045cca4-d25c-4bb0-af42-f6a2b22a5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-cf9390ea-f9c2-4f54-91b8-545e13e4c010,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-6418526f-7317-440b-a4a1-fe6a61351784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198685610-172.17.0.21-1595367882316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41663,DS-a747c1cb-a770-43b5-9d89-7903597257ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-7d4fc325-af47-4390-8195-ff15402bed17,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-0f574a83-8720-44d4-a8ca-c641dc14c799,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-4a3f5269-bab7-4d8b-ad7e-713aac3e821f,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-a26f7019-d45f-4603-9b41-284198653726,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-a045cca4-d25c-4bb0-af42-f6a2b22a5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-cf9390ea-f9c2-4f54-91b8-545e13e4c010,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-6418526f-7317-440b-a4a1-fe6a61351784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5265
