reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844349219-172.17.0.11-1595320949606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33164,DS-f5e4c297-1feb-4e24-b8db-a71bc7a6689c,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-eb61f1af-387b-4ba9-9577-dcb59dd1f173,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-5e7da924-d742-4933-b7d6-48f0d47db361,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-363731a9-c107-416e-9ef0-f479e7435594,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-478d1d0b-42ed-4545-bd89-672dd19da134,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-20b0bfcb-98d3-4769-a9ad-0d0630a9db18,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-6115b78f-6f42-4ef5-887b-e8ad7ab2a977,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-a099d181-611b-4c8b-9373-0bc6be0ca764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844349219-172.17.0.11-1595320949606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33164,DS-f5e4c297-1feb-4e24-b8db-a71bc7a6689c,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-eb61f1af-387b-4ba9-9577-dcb59dd1f173,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-5e7da924-d742-4933-b7d6-48f0d47db361,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-363731a9-c107-416e-9ef0-f479e7435594,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-478d1d0b-42ed-4545-bd89-672dd19da134,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-20b0bfcb-98d3-4769-a9ad-0d0630a9db18,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-6115b78f-6f42-4ef5-887b-e8ad7ab2a977,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-a099d181-611b-4c8b-9373-0bc6be0ca764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487640170-172.17.0.11-1595321320267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35256,DS-67e0eb17-6ef9-4706-a46a-6b8aa1f105c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-0f76e5f8-d5f5-408d-aa8d-4ad1a27a5497,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-8edf3ea9-5278-4241-825c-fbccba722ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-1447069d-97ba-4c01-be70-df5f27bc944e,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-33cb06ae-4dbc-41a7-a14f-9ca5704674c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-2f0f8f16-1101-40e3-9621-ee68b927dd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-f9b53778-2c16-4d26-b640-c5aef1011c52,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-24cb5b13-bc2a-453f-bca4-0b8e3a48f0d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487640170-172.17.0.11-1595321320267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35256,DS-67e0eb17-6ef9-4706-a46a-6b8aa1f105c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-0f76e5f8-d5f5-408d-aa8d-4ad1a27a5497,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-8edf3ea9-5278-4241-825c-fbccba722ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-1447069d-97ba-4c01-be70-df5f27bc944e,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-33cb06ae-4dbc-41a7-a14f-9ca5704674c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-2f0f8f16-1101-40e3-9621-ee68b927dd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-f9b53778-2c16-4d26-b640-c5aef1011c52,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-24cb5b13-bc2a-453f-bca4-0b8e3a48f0d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512211195-172.17.0.11-1595321647053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40412,DS-808e3335-758a-430d-88da-2b12e28792ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-4f90e19b-df6b-431e-a414-2792ea556ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-5d7b57a1-43ff-41b8-8997-6229274b722c,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-5496c483-1b9c-4601-8a00-ac89888f2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-c7984c77-4270-440f-88e7-68fbebde191d,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-2991c414-b94f-4f1b-b8e7-5940c0a8e1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-18445680-42da-466f-9eaf-bd2e266bee8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-e54026b6-d0f5-4e32-bc32-19310f6085de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512211195-172.17.0.11-1595321647053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40412,DS-808e3335-758a-430d-88da-2b12e28792ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-4f90e19b-df6b-431e-a414-2792ea556ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-5d7b57a1-43ff-41b8-8997-6229274b722c,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-5496c483-1b9c-4601-8a00-ac89888f2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-c7984c77-4270-440f-88e7-68fbebde191d,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-2991c414-b94f-4f1b-b8e7-5940c0a8e1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-18445680-42da-466f-9eaf-bd2e266bee8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-e54026b6-d0f5-4e32-bc32-19310f6085de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156411961-172.17.0.11-1595321990233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-67a13e64-c6bb-46f8-b510-9cc57d383f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-a629301c-bd6e-4827-92eb-3edd0dd8c5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-2768bced-057e-4b6e-aba9-5c3b4fa2b450,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-c79463fd-1531-405f-8372-98a13eef8105,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-2a9c816a-66ec-4c37-8752-30ea46bb89fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-b561ffe3-2506-4993-9bd2-e0270fe2c044,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-fd14ac85-f742-453a-9b9d-2c5e55f41155,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-8ad97b82-ff55-403f-ad12-a06fec1e1b94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156411961-172.17.0.11-1595321990233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-67a13e64-c6bb-46f8-b510-9cc57d383f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-a629301c-bd6e-4827-92eb-3edd0dd8c5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-2768bced-057e-4b6e-aba9-5c3b4fa2b450,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-c79463fd-1531-405f-8372-98a13eef8105,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-2a9c816a-66ec-4c37-8752-30ea46bb89fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-b561ffe3-2506-4993-9bd2-e0270fe2c044,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-fd14ac85-f742-453a-9b9d-2c5e55f41155,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-8ad97b82-ff55-403f-ad12-a06fec1e1b94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752704625-172.17.0.11-1595322173946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-13fd5c6a-be34-404e-8871-a57309cc77d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-0b9ec3ef-a00c-4518-bd43-7aab44af62b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-43b7a64b-2069-45e5-9835-0ea80e6d68b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-4b7ec829-2113-47a8-bd54-67b87d9cab41,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-4142b4cf-3e0d-49c7-a26e-58ce596209b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-57cca639-ca40-4f16-a3c0-af24121f5fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-6b0549a8-cc53-4ec5-bec2-43f0dd404505,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-95a84d75-50b4-4379-af03-d7dcfe6a232a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752704625-172.17.0.11-1595322173946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-13fd5c6a-be34-404e-8871-a57309cc77d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-0b9ec3ef-a00c-4518-bd43-7aab44af62b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-43b7a64b-2069-45e5-9835-0ea80e6d68b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-4b7ec829-2113-47a8-bd54-67b87d9cab41,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-4142b4cf-3e0d-49c7-a26e-58ce596209b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-57cca639-ca40-4f16-a3c0-af24121f5fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-6b0549a8-cc53-4ec5-bec2-43f0dd404505,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-95a84d75-50b4-4379-af03-d7dcfe6a232a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216367718-172.17.0.11-1595322936523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34133,DS-a0bfb52d-dd0d-471b-b570-b8e4a1c34546,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-3cdf135f-bd81-46ef-ab4e-daec54d280c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-a965bf02-9466-4733-ba21-6c54bb1fdad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-cd96176c-e7be-43ef-a8e8-18e766f4b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-ec4268d2-8216-4e2b-ba57-5443806d6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-69b8de4a-2f5d-421c-9794-9aab98282e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-60be4117-30fb-487c-9aa0-b6cd890d383c,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-7b1d9859-d367-45d6-ad5a-cc4d2ed3ae11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216367718-172.17.0.11-1595322936523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34133,DS-a0bfb52d-dd0d-471b-b570-b8e4a1c34546,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-3cdf135f-bd81-46ef-ab4e-daec54d280c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-a965bf02-9466-4733-ba21-6c54bb1fdad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-cd96176c-e7be-43ef-a8e8-18e766f4b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-ec4268d2-8216-4e2b-ba57-5443806d6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-69b8de4a-2f5d-421c-9794-9aab98282e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-60be4117-30fb-487c-9aa0-b6cd890d383c,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-7b1d9859-d367-45d6-ad5a-cc4d2ed3ae11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208663219-172.17.0.11-1595322977012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-6584e796-dccb-4b67-9b5e-0d5335da6f46,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-bb3f751c-a892-40e0-ba38-51c4fd85021f,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-43a7d6ef-a47e-4b07-b4a4-0a69605aa949,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-d5bbdaf3-c27f-4f85-b619-be14221025a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-224f5a03-b522-4d80-9d09-acb9a9c85320,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-c7f27d3d-faad-406f-88bd-b8a2c0915cea,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-3e0302d9-f014-4521-ae59-301f7edae060,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-e66e1eda-eada-47d6-84f6-f6677412e062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208663219-172.17.0.11-1595322977012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-6584e796-dccb-4b67-9b5e-0d5335da6f46,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-bb3f751c-a892-40e0-ba38-51c4fd85021f,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-43a7d6ef-a47e-4b07-b4a4-0a69605aa949,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-d5bbdaf3-c27f-4f85-b619-be14221025a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-224f5a03-b522-4d80-9d09-acb9a9c85320,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-c7f27d3d-faad-406f-88bd-b8a2c0915cea,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-3e0302d9-f014-4521-ae59-301f7edae060,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-e66e1eda-eada-47d6-84f6-f6677412e062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458965176-172.17.0.11-1595323122861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-80c58f93-66ca-4c7f-983b-e6087b50f000,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-6d3996b9-367a-48fd-aade-3a5f12480ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-c3182ab3-b6cd-4d1e-a2db-4e8b0c3c4e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-919296ec-f0a9-45b5-b902-1756210497b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-4e588a1c-4f72-4f70-b434-5ccaab9cb404,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-2810807a-3532-480f-a3ec-30b2bee1b71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-22c0b3ed-8c40-484c-809b-5e4f4019b411,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-5ad5f872-0a37-4ede-ac1d-8cf85623ca9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458965176-172.17.0.11-1595323122861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-80c58f93-66ca-4c7f-983b-e6087b50f000,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-6d3996b9-367a-48fd-aade-3a5f12480ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-c3182ab3-b6cd-4d1e-a2db-4e8b0c3c4e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-919296ec-f0a9-45b5-b902-1756210497b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-4e588a1c-4f72-4f70-b434-5ccaab9cb404,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-2810807a-3532-480f-a3ec-30b2bee1b71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-22c0b3ed-8c40-484c-809b-5e4f4019b411,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-5ad5f872-0a37-4ede-ac1d-8cf85623ca9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236392804-172.17.0.11-1595323158984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45889,DS-799cbdfe-02ff-4744-baac-6b6e4ce4580a,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-57e84abf-6ad0-402e-84de-be58f9a9e300,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-5ef7f972-abd3-40f4-8a74-2fa5dbe7b681,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-e482f682-c4c9-4d79-8d65-ddf7629e9ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-36dab3a5-f39b-47e3-800b-7d61eafc3073,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-b4044339-50f4-4ea0-8fdc-7c6a5fde873c,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-91aa5851-d369-4c98-b392-ec13c3ffc5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-292c0034-49a4-4020-8733-efef39af9459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236392804-172.17.0.11-1595323158984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45889,DS-799cbdfe-02ff-4744-baac-6b6e4ce4580a,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-57e84abf-6ad0-402e-84de-be58f9a9e300,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-5ef7f972-abd3-40f4-8a74-2fa5dbe7b681,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-e482f682-c4c9-4d79-8d65-ddf7629e9ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-36dab3a5-f39b-47e3-800b-7d61eafc3073,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-b4044339-50f4-4ea0-8fdc-7c6a5fde873c,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-91aa5851-d369-4c98-b392-ec13c3ffc5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-292c0034-49a4-4020-8733-efef39af9459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608484760-172.17.0.11-1595323995540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-89f953c6-2414-4b9a-89d8-ea07ca49761e,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-2cbbb8b5-0933-4a91-8616-f7af6e7b4b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-10cc4385-47a2-48d6-a169-d4001b792608,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-d4ca1242-45b3-4eb8-b7ab-530692cb5231,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-8649bce7-060a-41f6-bbd6-544bafb997b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-0b65ba94-136e-4e50-ba62-e829742e370c,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-50eb60b1-63d5-4406-9fd9-76fba28093fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-f417bdb9-c557-4655-a4d6-37bf40d8e421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608484760-172.17.0.11-1595323995540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-89f953c6-2414-4b9a-89d8-ea07ca49761e,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-2cbbb8b5-0933-4a91-8616-f7af6e7b4b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-10cc4385-47a2-48d6-a169-d4001b792608,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-d4ca1242-45b3-4eb8-b7ab-530692cb5231,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-8649bce7-060a-41f6-bbd6-544bafb997b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-0b65ba94-136e-4e50-ba62-e829742e370c,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-50eb60b1-63d5-4406-9fd9-76fba28093fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-f417bdb9-c557-4655-a4d6-37bf40d8e421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734499314-172.17.0.11-1595324337103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-436262a4-0e1d-4405-8f6c-8f29c9ec33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-af740639-ea3c-4257-864e-44c30348266c,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-f3113e95-ca91-4359-8865-feaa199b5f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-cfde4c1c-b723-4262-948b-cca8f7d3979b,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-caf3bb0d-9418-4d81-a03d-6b5d1eac7b26,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-8ae3ceda-8ea0-4a8c-8709-c76256a80b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-1f6121c3-d896-4601-a1f9-3ced4d127f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-fc3101fb-9628-4759-b9d1-0873ae0d6a5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734499314-172.17.0.11-1595324337103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-436262a4-0e1d-4405-8f6c-8f29c9ec33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-af740639-ea3c-4257-864e-44c30348266c,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-f3113e95-ca91-4359-8865-feaa199b5f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-cfde4c1c-b723-4262-948b-cca8f7d3979b,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-caf3bb0d-9418-4d81-a03d-6b5d1eac7b26,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-8ae3ceda-8ea0-4a8c-8709-c76256a80b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-1f6121c3-d896-4601-a1f9-3ced4d127f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-fc3101fb-9628-4759-b9d1-0873ae0d6a5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519715436-172.17.0.11-1595324451743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-3debcecb-905d-4c31-895c-bb7a349647ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-3b836946-38da-48c0-8d12-0337c6cb3319,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-f26babec-9e64-4453-8c9a-d8ca92a22818,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-dbee4e96-3d90-4e34-84e2-decfb4b2a67a,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-818b7c9b-b334-4a0d-b667-defa681655e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-120f5800-f3bf-416d-98e7-f8bd9848c9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-b1457daa-cbad-4ecc-86b6-78d4d2ea3cea,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-b66671f0-5afa-4566-95e7-ecfcf6a1262f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519715436-172.17.0.11-1595324451743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-3debcecb-905d-4c31-895c-bb7a349647ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-3b836946-38da-48c0-8d12-0337c6cb3319,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-f26babec-9e64-4453-8c9a-d8ca92a22818,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-dbee4e96-3d90-4e34-84e2-decfb4b2a67a,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-818b7c9b-b334-4a0d-b667-defa681655e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-120f5800-f3bf-416d-98e7-f8bd9848c9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-b1457daa-cbad-4ecc-86b6-78d4d2ea3cea,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-b66671f0-5afa-4566-95e7-ecfcf6a1262f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322713188-172.17.0.11-1595325056601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-6d22da1c-f6de-4a45-9f45-23688b73fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-8c08b5b7-ea6a-4583-9527-7172dfaa8b51,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-3df497a7-cf48-432d-a0d7-0c10bed88cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-b10f3e7c-fc4a-4ef4-be40-224c30623fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-378bb825-ba6c-4c11-9056-f99f0979705f,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-4adfd135-9183-40c6-ad7b-66d33169549e,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-e6233ecd-96b1-4458-ac7f-d58c5c6c551b,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-10bc4e32-9885-4894-b16d-24c4b4bd6972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322713188-172.17.0.11-1595325056601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-6d22da1c-f6de-4a45-9f45-23688b73fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-8c08b5b7-ea6a-4583-9527-7172dfaa8b51,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-3df497a7-cf48-432d-a0d7-0c10bed88cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-b10f3e7c-fc4a-4ef4-be40-224c30623fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-378bb825-ba6c-4c11-9056-f99f0979705f,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-4adfd135-9183-40c6-ad7b-66d33169549e,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-e6233ecd-96b1-4458-ac7f-d58c5c6c551b,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-10bc4e32-9885-4894-b16d-24c4b4bd6972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012256556-172.17.0.11-1595325165740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-f07b706c-9206-42e7-b0a6-ae4f0a550d97,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-caa8da7e-4c96-4ec9-a8d2-e2b9c4f62529,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-3dfc9b75-fab3-43f6-8d04-8526d6be07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-7b6bc2a1-589f-4d30-8810-b950bcc7524c,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-bffa2b5e-a6b8-4f90-b338-187ffc3b04b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-d3b7244a-c6bb-4d6c-aaf1-14e84ca678b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-4576b4bd-fb49-450d-93f3-e7f0cd0ba6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-ab6a2bd1-913e-4fe4-bee1-04fd85232e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012256556-172.17.0.11-1595325165740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-f07b706c-9206-42e7-b0a6-ae4f0a550d97,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-caa8da7e-4c96-4ec9-a8d2-e2b9c4f62529,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-3dfc9b75-fab3-43f6-8d04-8526d6be07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-7b6bc2a1-589f-4d30-8810-b950bcc7524c,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-bffa2b5e-a6b8-4f90-b338-187ffc3b04b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-d3b7244a-c6bb-4d6c-aaf1-14e84ca678b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-4576b4bd-fb49-450d-93f3-e7f0cd0ba6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-ab6a2bd1-913e-4fe4-bee1-04fd85232e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597642507-172.17.0.11-1595325243803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-e4ae2e3e-2d16-4879-995e-dfbd0e506a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-dd371838-9039-4905-8e9b-286a3899b301,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-be636c35-3504-4476-8909-eaabfb406020,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-dde89367-443c-42dc-b51c-c006f73a8cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-c8a1a4aa-480a-4cde-bb99-81f45b1409bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-ef6c37a5-1a16-41e8-a548-998ad1b22e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-2b92c1da-e350-4ea8-ac19-4e232c07fb97,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-d0854b80-b0c7-4922-ba71-2af10b992e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597642507-172.17.0.11-1595325243803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-e4ae2e3e-2d16-4879-995e-dfbd0e506a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-dd371838-9039-4905-8e9b-286a3899b301,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-be636c35-3504-4476-8909-eaabfb406020,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-dde89367-443c-42dc-b51c-c006f73a8cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-c8a1a4aa-480a-4cde-bb99-81f45b1409bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-ef6c37a5-1a16-41e8-a548-998ad1b22e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-2b92c1da-e350-4ea8-ac19-4e232c07fb97,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-d0854b80-b0c7-4922-ba71-2af10b992e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5532
