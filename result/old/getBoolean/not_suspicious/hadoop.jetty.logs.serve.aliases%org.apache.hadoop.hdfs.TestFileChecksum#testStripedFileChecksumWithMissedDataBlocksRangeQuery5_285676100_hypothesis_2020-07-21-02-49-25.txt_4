reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369819541-172.17.0.8-1595300171676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-3677f4b5-680c-416c-8289-e664c931dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-6f5846b4-eb77-4f47-a36b-afb0e8739303,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-52e129c4-1fe8-40e0-af79-edb6045cf891,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-91619860-e2b3-40c2-89aa-31f23a6a18e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-419accc5-394c-4832-b4f3-b6e153602e21,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-fe51e0f5-3466-4cb9-b2a8-cbf0ef98b89c,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-338946cd-1c67-45a4-a5f2-9a5fb681683d,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-ab145e9b-8111-49f4-b74c-9d6f52675da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369819541-172.17.0.8-1595300171676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-3677f4b5-680c-416c-8289-e664c931dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-6f5846b4-eb77-4f47-a36b-afb0e8739303,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-52e129c4-1fe8-40e0-af79-edb6045cf891,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-91619860-e2b3-40c2-89aa-31f23a6a18e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-419accc5-394c-4832-b4f3-b6e153602e21,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-fe51e0f5-3466-4cb9-b2a8-cbf0ef98b89c,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-338946cd-1c67-45a4-a5f2-9a5fb681683d,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-ab145e9b-8111-49f4-b74c-9d6f52675da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356938976-172.17.0.8-1595300358178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-7498e1aa-822c-43a3-85b4-0d834a5fafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-5d3e03ad-dbbd-4569-a942-e4de1e13db40,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-55882e15-707f-42df-88e8-d2747e0450e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-58cf6495-e44b-4920-bd0c-b522a520cffa,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-fe2e0b94-987f-4b52-baf8-057e74a808e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-ec9d1a5b-88bd-4166-8bc0-645944fad902,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-a54ee7d0-ca8b-4639-9f26-29eddda5c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-25aeb5e3-1801-44c8-b061-72d83f7cd978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356938976-172.17.0.8-1595300358178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-7498e1aa-822c-43a3-85b4-0d834a5fafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-5d3e03ad-dbbd-4569-a942-e4de1e13db40,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-55882e15-707f-42df-88e8-d2747e0450e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-58cf6495-e44b-4920-bd0c-b522a520cffa,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-fe2e0b94-987f-4b52-baf8-057e74a808e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-ec9d1a5b-88bd-4166-8bc0-645944fad902,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-a54ee7d0-ca8b-4639-9f26-29eddda5c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-25aeb5e3-1801-44c8-b061-72d83f7cd978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44447835-172.17.0.8-1595300622855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-4ae7d798-fd60-4b28-aa27-a79756565ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-d10a2fe9-c0be-4e60-80fe-b2b634b0c541,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-44b489c8-7429-49ee-b1d9-45253b091012,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-07fa7c8e-2d42-4974-9f61-f33a88c88ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-1658dc6f-fca4-48a2-83e3-f9e9e745a999,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-e06ce501-91c2-4cef-8c2c-c4a30bf7fe62,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-fc458108-cc4f-4ee2-833c-8d5c2c08de3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-f99c5604-7620-4154-9b2d-da5b1863ca98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44447835-172.17.0.8-1595300622855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-4ae7d798-fd60-4b28-aa27-a79756565ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-d10a2fe9-c0be-4e60-80fe-b2b634b0c541,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-44b489c8-7429-49ee-b1d9-45253b091012,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-07fa7c8e-2d42-4974-9f61-f33a88c88ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-1658dc6f-fca4-48a2-83e3-f9e9e745a999,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-e06ce501-91c2-4cef-8c2c-c4a30bf7fe62,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-fc458108-cc4f-4ee2-833c-8d5c2c08de3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-f99c5604-7620-4154-9b2d-da5b1863ca98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269554036-172.17.0.8-1595300978277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-a6dc6914-a87c-4e34-8588-c87b25cd14bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-2880972c-bffb-42fc-bc22-627039060416,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-218f55ff-0c3d-47f4-80d6-8f418fbda3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-41c89b25-aa9c-4188-b701-6af84f1634f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-7ca6b90f-26c5-427e-95d2-ccf3637c5cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-42150940-84b0-4031-8c51-21f442a395f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-8d4fc2ec-df5f-46b6-b4ed-fbe9649542c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-ca6fee0a-2ede-4c76-b8b0-3b76aa6c49c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269554036-172.17.0.8-1595300978277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-a6dc6914-a87c-4e34-8588-c87b25cd14bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-2880972c-bffb-42fc-bc22-627039060416,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-218f55ff-0c3d-47f4-80d6-8f418fbda3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-41c89b25-aa9c-4188-b701-6af84f1634f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-7ca6b90f-26c5-427e-95d2-ccf3637c5cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-42150940-84b0-4031-8c51-21f442a395f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-8d4fc2ec-df5f-46b6-b4ed-fbe9649542c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-ca6fee0a-2ede-4c76-b8b0-3b76aa6c49c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408697134-172.17.0.8-1595301015739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36772,DS-8c5995f9-56a8-4bf5-823b-abea2fc9295e,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-44ebe652-abc8-4117-8c5e-50d5c2bf9558,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-edcee5d1-5ca2-463d-b38b-e7616f70b041,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-ccc83464-05ac-44ae-a78e-0df3c9a7eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-e7fd7505-fc92-4dc8-91b9-652da7376c38,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-557b9306-3866-453e-bafc-524094523f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-dd4d62a8-88e7-4faf-a9a1-afc00026503b,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-5b81e4e5-4856-4b59-b082-da088faeda11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408697134-172.17.0.8-1595301015739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36772,DS-8c5995f9-56a8-4bf5-823b-abea2fc9295e,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-44ebe652-abc8-4117-8c5e-50d5c2bf9558,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-edcee5d1-5ca2-463d-b38b-e7616f70b041,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-ccc83464-05ac-44ae-a78e-0df3c9a7eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-e7fd7505-fc92-4dc8-91b9-652da7376c38,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-557b9306-3866-453e-bafc-524094523f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-dd4d62a8-88e7-4faf-a9a1-afc00026503b,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-5b81e4e5-4856-4b59-b082-da088faeda11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330113491-172.17.0.8-1595301088767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33846,DS-39542d22-ba13-4bdb-b047-460d81880813,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-9ba5ad5f-bec3-4477-b501-32f8223022f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-aa02bead-4630-4d6f-b753-d238fbdc30d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-84353347-62fb-4808-8f27-d0dea776b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-db503e86-d54e-4bc2-a779-695466abcb21,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-d7bf8514-82c5-426f-935e-449c36080cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-9a76b2a3-7ade-49bd-9bf7-cddf4bf3bfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-680d7d09-0a1f-414f-a722-36693c6493f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330113491-172.17.0.8-1595301088767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33846,DS-39542d22-ba13-4bdb-b047-460d81880813,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-9ba5ad5f-bec3-4477-b501-32f8223022f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-aa02bead-4630-4d6f-b753-d238fbdc30d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-84353347-62fb-4808-8f27-d0dea776b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-db503e86-d54e-4bc2-a779-695466abcb21,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-d7bf8514-82c5-426f-935e-449c36080cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-9a76b2a3-7ade-49bd-9bf7-cddf4bf3bfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-680d7d09-0a1f-414f-a722-36693c6493f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298635098-172.17.0.8-1595301158821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-6a6ade09-c2a4-499c-bf0f-337c4b77974e,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-7fe3532f-3ff7-45c6-858c-6e45c4ada104,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-0840ba30-cc0c-4df5-87c3-bece9e3ec6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-422fe3f2-b7b4-4aa8-b82b-b39f306421ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-d6dedce2-043a-4358-850b-99e5c20a0644,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-f12a04e7-3a49-43ff-af16-cd54124d2bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-c8142216-3740-4a83-9ed3-a1e8317a79d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-b7ee7085-ee6e-4851-97e6-797d6cb85bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298635098-172.17.0.8-1595301158821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-6a6ade09-c2a4-499c-bf0f-337c4b77974e,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-7fe3532f-3ff7-45c6-858c-6e45c4ada104,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-0840ba30-cc0c-4df5-87c3-bece9e3ec6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-422fe3f2-b7b4-4aa8-b82b-b39f306421ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-d6dedce2-043a-4358-850b-99e5c20a0644,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-f12a04e7-3a49-43ff-af16-cd54124d2bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-c8142216-3740-4a83-9ed3-a1e8317a79d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-b7ee7085-ee6e-4851-97e6-797d6cb85bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441716779-172.17.0.8-1595301195158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35722,DS-b0cedc3a-26f3-4a9b-9337-9decaa386c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-31880a31-07ae-4d6a-8997-a561d59d0031,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-39dfc05f-8b72-4969-9f5f-b35cc864e234,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-2ae0b7f2-ac96-4a91-8efa-5462972b0ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-88191fa5-9010-4839-8ccd-afe5d1fee27a,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-7ce1a25e-707e-4a88-bc96-97b788fddbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-af6eb205-b334-4e2f-9336-db51ee1a94d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-e3a537ee-d623-41b5-b54e-2d5c569e28dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441716779-172.17.0.8-1595301195158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35722,DS-b0cedc3a-26f3-4a9b-9337-9decaa386c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-31880a31-07ae-4d6a-8997-a561d59d0031,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-39dfc05f-8b72-4969-9f5f-b35cc864e234,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-2ae0b7f2-ac96-4a91-8efa-5462972b0ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-88191fa5-9010-4839-8ccd-afe5d1fee27a,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-7ce1a25e-707e-4a88-bc96-97b788fddbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-af6eb205-b334-4e2f-9336-db51ee1a94d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-e3a537ee-d623-41b5-b54e-2d5c569e28dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548594379-172.17.0.8-1595301589750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42828,DS-22041719-dc67-4237-b7b1-689ffeb1b30f,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-2bf0a282-d79e-411f-89f0-7adf797c092e,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-012004ec-3731-4704-8a55-b9f0bb1d144c,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-504fac2b-1349-4115-84a1-8161eb956732,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-b222dade-8b4f-4cdd-b50d-63c51dabf145,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-c38ceb0d-5d8c-4416-8522-7acdd1bb364d,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-ef39663d-c71d-4323-bb75-e241644775ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-ed66d5f9-e02b-4e95-8a8f-1533e55df633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548594379-172.17.0.8-1595301589750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42828,DS-22041719-dc67-4237-b7b1-689ffeb1b30f,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-2bf0a282-d79e-411f-89f0-7adf797c092e,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-012004ec-3731-4704-8a55-b9f0bb1d144c,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-504fac2b-1349-4115-84a1-8161eb956732,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-b222dade-8b4f-4cdd-b50d-63c51dabf145,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-c38ceb0d-5d8c-4416-8522-7acdd1bb364d,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-ef39663d-c71d-4323-bb75-e241644775ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-ed66d5f9-e02b-4e95-8a8f-1533e55df633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429510591-172.17.0.8-1595302132999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37859,DS-a9bcbe53-9d28-42db-8b33-5696af60574b,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-dc2f7417-92b7-43f8-a53a-75241a516d93,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-6e70ea28-9ff1-48b7-b015-50c792e7609e,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-845f4ab1-61ed-4fcf-ab5e-d8d76b0a5990,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-c180fa05-9fdc-418d-b654-b0a611d893f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-b0e676e3-58e2-4a52-9102-3104b4ccb3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-2a21e953-485f-45be-aa3b-5a7fd2deb5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-a42d8064-8ccc-400e-bd38-b169041cb506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429510591-172.17.0.8-1595302132999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37859,DS-a9bcbe53-9d28-42db-8b33-5696af60574b,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-dc2f7417-92b7-43f8-a53a-75241a516d93,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-6e70ea28-9ff1-48b7-b015-50c792e7609e,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-845f4ab1-61ed-4fcf-ab5e-d8d76b0a5990,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-c180fa05-9fdc-418d-b654-b0a611d893f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-b0e676e3-58e2-4a52-9102-3104b4ccb3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-2a21e953-485f-45be-aa3b-5a7fd2deb5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-a42d8064-8ccc-400e-bd38-b169041cb506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397965113-172.17.0.8-1595302382408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-ffc92de5-e082-4305-b84b-256600a5769f,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-d0e91a67-f96c-40c5-b2ac-cd931831f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-d860aa42-7a19-4e53-b919-e4e89ff59c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-c0fd2ef8-941d-4f2f-8007-bf345739bbab,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-9f074347-b12c-47fd-b04f-1dd908c24ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-5e0457e4-4e4d-4c57-9668-8ad88c32b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-f3bab31a-0823-43ec-9323-00770a420510,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-0686d334-4cd7-4de2-acbc-6fa24840e79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397965113-172.17.0.8-1595302382408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-ffc92de5-e082-4305-b84b-256600a5769f,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-d0e91a67-f96c-40c5-b2ac-cd931831f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-d860aa42-7a19-4e53-b919-e4e89ff59c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-c0fd2ef8-941d-4f2f-8007-bf345739bbab,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-9f074347-b12c-47fd-b04f-1dd908c24ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-5e0457e4-4e4d-4c57-9668-8ad88c32b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-f3bab31a-0823-43ec-9323-00770a420510,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-0686d334-4cd7-4de2-acbc-6fa24840e79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301184452-172.17.0.8-1595302531273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-bfee5667-fbf7-4d8a-a952-fab696900b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-bed9321d-9183-4875-8705-6d5f0d48cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-0e202d2d-0d8e-4fe6-8ee6-3661dc1821b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-ffb9772d-1997-444c-be94-35837f791da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-4fa6028b-ad22-46bc-923f-d68bd0656cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-128e2272-b414-4c66-a161-83d2e3c5a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-0c548b13-6673-449b-ab95-1655ca2944d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-9f14baf7-6b10-4361-8f28-cc060b309a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301184452-172.17.0.8-1595302531273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-bfee5667-fbf7-4d8a-a952-fab696900b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-bed9321d-9183-4875-8705-6d5f0d48cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-0e202d2d-0d8e-4fe6-8ee6-3661dc1821b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-ffb9772d-1997-444c-be94-35837f791da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-4fa6028b-ad22-46bc-923f-d68bd0656cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-128e2272-b414-4c66-a161-83d2e3c5a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-0c548b13-6673-449b-ab95-1655ca2944d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-9f14baf7-6b10-4361-8f28-cc060b309a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122202117-172.17.0.8-1595302570409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33092,DS-938d5646-f018-4935-b404-b01ff739e0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-10dc1ba7-b0d4-42d4-aa18-4f7b78e67c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-dfc0f96f-6c3e-4806-bfba-332e92c5f565,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-dbf5fc2e-6e2b-47a8-9d29-f24bb7271bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-2af40c60-d587-4706-888d-7bfd7e4c6422,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-98e009d8-0072-48f6-803c-e538afe9d394,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-e83d1bf2-604e-4991-8ef2-fac2de2ab5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-1aaa3831-782f-4db9-9025-97e9c8e217b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122202117-172.17.0.8-1595302570409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33092,DS-938d5646-f018-4935-b404-b01ff739e0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-10dc1ba7-b0d4-42d4-aa18-4f7b78e67c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-dfc0f96f-6c3e-4806-bfba-332e92c5f565,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-dbf5fc2e-6e2b-47a8-9d29-f24bb7271bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-2af40c60-d587-4706-888d-7bfd7e4c6422,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-98e009d8-0072-48f6-803c-e538afe9d394,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-e83d1bf2-604e-4991-8ef2-fac2de2ab5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-1aaa3831-782f-4db9-9025-97e9c8e217b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618086659-172.17.0.8-1595302930816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-abd81d9b-86d5-47a2-9907-18150b4144fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-e2c89a28-594e-4331-9aba-69f32f1a4066,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-22af9910-cb75-4f0f-aa45-2f762a98507f,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-8908278a-9958-4152-9763-9040053e9c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-7a5c7829-be4c-42bd-9fa6-3005f11c08e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-22737338-44f1-4bc2-91ac-e99fb9a5f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-723e81cd-de80-4aa8-9753-5f150cd9b518,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-d39ecdb1-81b6-4e8d-84cf-d5f6c3db3d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618086659-172.17.0.8-1595302930816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-abd81d9b-86d5-47a2-9907-18150b4144fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-e2c89a28-594e-4331-9aba-69f32f1a4066,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-22af9910-cb75-4f0f-aa45-2f762a98507f,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-8908278a-9958-4152-9763-9040053e9c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-7a5c7829-be4c-42bd-9fa6-3005f11c08e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-22737338-44f1-4bc2-91ac-e99fb9a5f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-723e81cd-de80-4aa8-9753-5f150cd9b518,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-d39ecdb1-81b6-4e8d-84cf-d5f6c3db3d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141793346-172.17.0.8-1595304106159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33595,DS-f4e5664d-d97a-4763-a9e7-21b365da0d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-472a42d2-aee1-4f52-84e0-0f2d7c7d3120,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-f6a0cdc5-cc2a-47bd-927a-75bab45fa1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-3b67c150-2985-467d-ad87-a74247b73210,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-6e19f958-9b8f-4f95-8c6d-608366463fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-4c0ca150-3a06-4b33-aae1-31f064f135c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-96f7617c-b463-4cd9-8f94-ed056801d161,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-7c47d12b-bf7a-4580-b4e3-6e8f5b6c8fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141793346-172.17.0.8-1595304106159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33595,DS-f4e5664d-d97a-4763-a9e7-21b365da0d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-472a42d2-aee1-4f52-84e0-0f2d7c7d3120,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-f6a0cdc5-cc2a-47bd-927a-75bab45fa1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-3b67c150-2985-467d-ad87-a74247b73210,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-6e19f958-9b8f-4f95-8c6d-608366463fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-4c0ca150-3a06-4b33-aae1-31f064f135c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-96f7617c-b463-4cd9-8f94-ed056801d161,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-7c47d12b-bf7a-4580-b4e3-6e8f5b6c8fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307466118-172.17.0.8-1595304264164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42163,DS-3f863b8d-66a1-437c-b6dd-9e58529cf676,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-c173c2e0-a481-4e6f-a537-76f6717560e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-de43e5aa-57fe-44d5-bd28-2b0ba2f03340,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-8e2148f7-5a95-4e02-a535-3048bff260fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-98b04309-9758-462c-8bfb-0dc5b6372ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-c7c31378-42a5-4ba2-ab72-163a71f4af01,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-8987dceb-4596-44d7-9b72-b382adfdf6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-3773e1c2-3351-4a68-af80-ccfaff1eb701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307466118-172.17.0.8-1595304264164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42163,DS-3f863b8d-66a1-437c-b6dd-9e58529cf676,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-c173c2e0-a481-4e6f-a537-76f6717560e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-de43e5aa-57fe-44d5-bd28-2b0ba2f03340,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-8e2148f7-5a95-4e02-a535-3048bff260fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-98b04309-9758-462c-8bfb-0dc5b6372ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-c7c31378-42a5-4ba2-ab72-163a71f4af01,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-8987dceb-4596-44d7-9b72-b382adfdf6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-3773e1c2-3351-4a68-af80-ccfaff1eb701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252841049-172.17.0.8-1595304407511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37526,DS-15be5ee7-8cd0-4f22-bcbf-2b6200819df9,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-add785aa-1ace-464f-993d-74d6af8d8c46,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-2c2d5ea1-0240-41df-ac75-cf93bf7ebbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-95b0bf02-b244-484d-a315-454949a89289,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-dc908d56-859d-44ae-a7ef-4899f45a9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-b6e473f8-b96a-4377-91e6-2ff804d0f700,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-c7829963-2176-42f5-a31b-517b9c438bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-5f63edfc-1cc1-4b03-8702-34b35c17693f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252841049-172.17.0.8-1595304407511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37526,DS-15be5ee7-8cd0-4f22-bcbf-2b6200819df9,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-add785aa-1ace-464f-993d-74d6af8d8c46,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-2c2d5ea1-0240-41df-ac75-cf93bf7ebbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-95b0bf02-b244-484d-a315-454949a89289,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-dc908d56-859d-44ae-a7ef-4899f45a9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-b6e473f8-b96a-4377-91e6-2ff804d0f700,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-c7829963-2176-42f5-a31b-517b9c438bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-5f63edfc-1cc1-4b03-8702-34b35c17693f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334210754-172.17.0.8-1595304849355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33222,DS-9483eeb0-8fb7-4f3a-b7c6-537ecd951576,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-edcd84be-749c-4c48-a3f8-dbc68e30de57,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-b35c0e5c-2214-4fc0-b003-933375bc6802,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-383a9bb5-84f7-43e1-8d1c-8fd0a404fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-fd942cb7-904c-484b-a18b-55a796177096,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-7a146f61-e936-453d-895a-3df584431cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-1631b2e2-f765-40f9-a7e4-15d07a54b035,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-e2dd3dfb-8b14-466d-9853-5f39d8d05386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334210754-172.17.0.8-1595304849355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33222,DS-9483eeb0-8fb7-4f3a-b7c6-537ecd951576,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-edcd84be-749c-4c48-a3f8-dbc68e30de57,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-b35c0e5c-2214-4fc0-b003-933375bc6802,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-383a9bb5-84f7-43e1-8d1c-8fd0a404fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-fd942cb7-904c-484b-a18b-55a796177096,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-7a146f61-e936-453d-895a-3df584431cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-1631b2e2-f765-40f9-a7e4-15d07a54b035,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-e2dd3dfb-8b14-466d-9853-5f39d8d05386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438438235-172.17.0.8-1595305097692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-22325d16-5a13-472b-b189-001f3f8df7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-16453057-6030-449d-b9af-bbf548f14fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-04af2022-78a3-43ae-8941-2d96657900ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-c40896c9-44ec-49c8-aeb0-646a3edb6a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a9708553-dbb0-44a7-827c-a8adcd58138b,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-fadc7c6e-ca2c-4e4b-9001-d2d1f0fa65e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-3246e474-1f46-43db-9c6b-da1357a5cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-4336468a-d647-4fac-ba2c-3e6b813100b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438438235-172.17.0.8-1595305097692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-22325d16-5a13-472b-b189-001f3f8df7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-16453057-6030-449d-b9af-bbf548f14fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-04af2022-78a3-43ae-8941-2d96657900ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-c40896c9-44ec-49c8-aeb0-646a3edb6a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a9708553-dbb0-44a7-827c-a8adcd58138b,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-fadc7c6e-ca2c-4e4b-9001-d2d1f0fa65e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-3246e474-1f46-43db-9c6b-da1357a5cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-4336468a-d647-4fac-ba2c-3e6b813100b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5453
