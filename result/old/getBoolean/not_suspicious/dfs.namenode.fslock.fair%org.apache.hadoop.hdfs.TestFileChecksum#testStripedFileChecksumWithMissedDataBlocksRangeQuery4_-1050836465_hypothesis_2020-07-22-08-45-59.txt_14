reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409202678-172.17.0.13-1595407577062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34828,DS-9363a4b2-5eee-4d5b-86c9-18ecc433261b,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-e1c9d96a-c2e0-4309-856a-43c4a5757bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-dc971885-1522-4d68-b858-a5af55f396bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-aa1270ea-300a-4a37-90c5-cfe51ad47b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-c4a33a74-f894-42ad-a4e4-075ba2381315,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-1206a3c9-5d7e-4ee2-928a-c3d280b681b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-a7e5ba9b-7128-4355-a87a-2c9f2f0c0062,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-df798e22-db4f-420c-8045-551a5d03451e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409202678-172.17.0.13-1595407577062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34828,DS-9363a4b2-5eee-4d5b-86c9-18ecc433261b,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-e1c9d96a-c2e0-4309-856a-43c4a5757bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-dc971885-1522-4d68-b858-a5af55f396bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-aa1270ea-300a-4a37-90c5-cfe51ad47b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-c4a33a74-f894-42ad-a4e4-075ba2381315,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-1206a3c9-5d7e-4ee2-928a-c3d280b681b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-a7e5ba9b-7128-4355-a87a-2c9f2f0c0062,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-df798e22-db4f-420c-8045-551a5d03451e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943733025-172.17.0.13-1595407731660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-a42279e2-9d83-4400-a10c-e84e9158fcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-46c53b06-1a1e-4d88-b0c9-c400f64fb400,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-157ffcad-1631-411a-a701-3957521cabb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-89e51b59-c073-4a6f-8d1d-89c7ec0934f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-9ced68f0-38b9-46c2-9407-0942736b6854,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-81cfc19d-c21c-4e93-87d9-b0b8d5bbeb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-fdbf4c45-f013-4704-85ea-55164e06b013,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-52a6c96a-dc7c-4b7c-9b5a-a43c6f1571e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943733025-172.17.0.13-1595407731660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-a42279e2-9d83-4400-a10c-e84e9158fcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-46c53b06-1a1e-4d88-b0c9-c400f64fb400,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-157ffcad-1631-411a-a701-3957521cabb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-89e51b59-c073-4a6f-8d1d-89c7ec0934f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-9ced68f0-38b9-46c2-9407-0942736b6854,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-81cfc19d-c21c-4e93-87d9-b0b8d5bbeb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-fdbf4c45-f013-4704-85ea-55164e06b013,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-52a6c96a-dc7c-4b7c-9b5a-a43c6f1571e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115108755-172.17.0.13-1595407807738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-df450955-3956-431d-b8ae-1537bdbefc70,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-362931f0-8278-4d28-99bf-b91fa3c5d24b,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-2591a3a7-8dbf-495b-aafd-ba04dd1e8f30,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-6e789246-4b97-42a9-8bf4-b4322886364b,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-8984a2a9-a2be-4aad-ab19-8e9b34e979dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-2ec40476-7c5a-48c6-9f5d-91502e31f880,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-19f9b2fa-3215-440d-a466-a1466e40f5de,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-60753c0f-8b92-47bf-ac04-4f721da99b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115108755-172.17.0.13-1595407807738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-df450955-3956-431d-b8ae-1537bdbefc70,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-362931f0-8278-4d28-99bf-b91fa3c5d24b,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-2591a3a7-8dbf-495b-aafd-ba04dd1e8f30,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-6e789246-4b97-42a9-8bf4-b4322886364b,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-8984a2a9-a2be-4aad-ab19-8e9b34e979dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-2ec40476-7c5a-48c6-9f5d-91502e31f880,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-19f9b2fa-3215-440d-a466-a1466e40f5de,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-60753c0f-8b92-47bf-ac04-4f721da99b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177427450-172.17.0.13-1595407844513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-b5e82733-edb0-45a5-9960-a9769dbc1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-9207fa3a-4919-4811-90ad-2f2bd53daf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-2887e595-f366-4523-afe5-a0e130baf273,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-2d768da9-6b7f-4fee-a8c9-d3de6907a9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-1a0187ed-7a98-4439-81b9-2182cf141ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-53e63b22-d3e2-4a92-ad62-d6d79e9876c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-b8e5c742-0617-436e-8abf-274b644a421a,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-129d7df4-4ab5-44fb-bf71-bf52d321697a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177427450-172.17.0.13-1595407844513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-b5e82733-edb0-45a5-9960-a9769dbc1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-9207fa3a-4919-4811-90ad-2f2bd53daf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-2887e595-f366-4523-afe5-a0e130baf273,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-2d768da9-6b7f-4fee-a8c9-d3de6907a9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-1a0187ed-7a98-4439-81b9-2182cf141ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-53e63b22-d3e2-4a92-ad62-d6d79e9876c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-b8e5c742-0617-436e-8abf-274b644a421a,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-129d7df4-4ab5-44fb-bf71-bf52d321697a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692005169-172.17.0.13-1595408281125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-8db20dc0-1993-4ad5-a70a-4ef01414f52d,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-138638d8-2188-4bf1-9339-07a41a541d36,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-a20e7c75-4bc5-4192-ae50-5c0d78c316e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-be13ea8b-e311-4510-8374-d484014e1ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-440ff70d-f5f7-4ee6-891d-8c6c86098af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-82a9cdf5-2849-4b22-b269-0ea80c5fdad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-81b8bb5e-305b-45e0-a7eb-b736003e9e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-e9385167-95ae-4ee1-9c25-8431c5cc70de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692005169-172.17.0.13-1595408281125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-8db20dc0-1993-4ad5-a70a-4ef01414f52d,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-138638d8-2188-4bf1-9339-07a41a541d36,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-a20e7c75-4bc5-4192-ae50-5c0d78c316e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-be13ea8b-e311-4510-8374-d484014e1ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-440ff70d-f5f7-4ee6-891d-8c6c86098af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-82a9cdf5-2849-4b22-b269-0ea80c5fdad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-81b8bb5e-305b-45e0-a7eb-b736003e9e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-e9385167-95ae-4ee1-9c25-8431c5cc70de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801461521-172.17.0.13-1595408591630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-7df234d2-9e76-475e-ac36-3c799f75703f,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-3a284b54-8468-4a20-8f6b-351e83776522,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-7637fc00-37d4-4be7-8b07-b3e7745e8868,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-2e415340-e03f-48da-8529-7a2e3a0bec36,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-2445d026-ae46-4ff7-9e74-e656f0cdd660,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-ab511c13-fefd-4c21-be2c-104e3d4a5e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-67024b04-92e8-4c43-a40a-bf22caffc7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-65372c94-c4e0-4423-bb12-ca52c965f75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801461521-172.17.0.13-1595408591630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-7df234d2-9e76-475e-ac36-3c799f75703f,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-3a284b54-8468-4a20-8f6b-351e83776522,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-7637fc00-37d4-4be7-8b07-b3e7745e8868,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-2e415340-e03f-48da-8529-7a2e3a0bec36,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-2445d026-ae46-4ff7-9e74-e656f0cdd660,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-ab511c13-fefd-4c21-be2c-104e3d4a5e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-67024b04-92e8-4c43-a40a-bf22caffc7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-65372c94-c4e0-4423-bb12-ca52c965f75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903455527-172.17.0.13-1595408624631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-6743bd9d-aaa6-4a26-9804-28128e2a6c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-e590e14a-96dc-4086-a66a-8df32ad3a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-b9e9fd34-78bc-48d9-b14b-3152e730f75d,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-b38a872c-6b00-45a7-b982-4d6c61b33780,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-cea36463-6fb0-4388-8aa4-1c10a40e6a91,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-0a8730d6-2b0c-4c9f-8389-be3d1f98c81f,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-4014c2d6-7ac6-4596-b1fd-d0df6cadd6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-73aacd98-b5ff-457e-8f2e-327bd5aad067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903455527-172.17.0.13-1595408624631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-6743bd9d-aaa6-4a26-9804-28128e2a6c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-e590e14a-96dc-4086-a66a-8df32ad3a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-b9e9fd34-78bc-48d9-b14b-3152e730f75d,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-b38a872c-6b00-45a7-b982-4d6c61b33780,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-cea36463-6fb0-4388-8aa4-1c10a40e6a91,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-0a8730d6-2b0c-4c9f-8389-be3d1f98c81f,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-4014c2d6-7ac6-4596-b1fd-d0df6cadd6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-73aacd98-b5ff-457e-8f2e-327bd5aad067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114924383-172.17.0.13-1595408651913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-ae4d3c5b-2a2e-4bda-8a66-557725987dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-a98f5fbf-1cd3-4e70-96ca-86a2be7d4afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-1d5a1a7c-9878-4dbe-9808-a56e70222a07,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-34b961c7-1140-4f90-9571-0aa4f4b9bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-93e4e7c6-b49c-42d0-aa55-06a548a0d836,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-49a711ba-b1b4-4672-8427-aebd48500286,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-1ceac0d6-aaad-47f9-9c9b-9493f1e65f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-91f05e68-d9e8-4460-8ed5-9b83b0752ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114924383-172.17.0.13-1595408651913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-ae4d3c5b-2a2e-4bda-8a66-557725987dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-a98f5fbf-1cd3-4e70-96ca-86a2be7d4afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-1d5a1a7c-9878-4dbe-9808-a56e70222a07,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-34b961c7-1140-4f90-9571-0aa4f4b9bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-93e4e7c6-b49c-42d0-aa55-06a548a0d836,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-49a711ba-b1b4-4672-8427-aebd48500286,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-1ceac0d6-aaad-47f9-9c9b-9493f1e65f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-91f05e68-d9e8-4460-8ed5-9b83b0752ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786218377-172.17.0.13-1595408898902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-527a4a76-0fe4-485c-896d-c88c6b48db24,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-d92fb321-a193-4abc-a852-9afcb7f759e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-2485a19e-a66e-48e8-a61c-a995d75152db,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-19b63163-2f16-4f2a-b6d3-cd9085b09a84,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-e679794a-d50b-4df8-9ac7-59b666a9dd71,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-95fa03c5-0463-4807-8bcf-62002566a67d,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-b326de6f-7ba9-4709-8214-66a17e6b541e,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-e35e2222-8f6c-4e9f-bc8f-7c533b51ad52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786218377-172.17.0.13-1595408898902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-527a4a76-0fe4-485c-896d-c88c6b48db24,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-d92fb321-a193-4abc-a852-9afcb7f759e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-2485a19e-a66e-48e8-a61c-a995d75152db,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-19b63163-2f16-4f2a-b6d3-cd9085b09a84,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-e679794a-d50b-4df8-9ac7-59b666a9dd71,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-95fa03c5-0463-4807-8bcf-62002566a67d,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-b326de6f-7ba9-4709-8214-66a17e6b541e,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-e35e2222-8f6c-4e9f-bc8f-7c533b51ad52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50809831-172.17.0.13-1595409031414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-c03b7a88-f191-4ca3-b665-baa2adc0bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-7f43850b-a763-490b-a4f2-200dacc6c092,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-ef45b05c-7423-4c5a-a152-1268157ea004,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-c5c15ae6-84bb-4940-9e22-08f2a09fec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4cc44f43-52a7-421b-9b58-aa930884774c,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-ccedff9d-a512-4dff-9bed-b790ab2fb62d,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-028c6181-0c1e-4856-bbb4-70f4e3965db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-49a9c8c0-25ca-41ba-92f3-0d4b79291541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50809831-172.17.0.13-1595409031414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-c03b7a88-f191-4ca3-b665-baa2adc0bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-7f43850b-a763-490b-a4f2-200dacc6c092,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-ef45b05c-7423-4c5a-a152-1268157ea004,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-c5c15ae6-84bb-4940-9e22-08f2a09fec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4cc44f43-52a7-421b-9b58-aa930884774c,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-ccedff9d-a512-4dff-9bed-b790ab2fb62d,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-028c6181-0c1e-4856-bbb4-70f4e3965db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-49a9c8c0-25ca-41ba-92f3-0d4b79291541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398369278-172.17.0.13-1595409408336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-342ce3d9-dba4-483b-bd8e-a6868b3b45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-3a548444-6614-4b5b-8257-dbb89e008d52,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-9806f951-de33-4344-8d42-ca69c9ec8684,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-2a56057c-dce5-4d7a-b660-22a2f01f7f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-9c01f8dc-f4df-435b-ab89-7311152bbb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-19b17cfb-4df5-4138-86bc-1bc75f0da9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-ad2d3d2c-f9cc-4ac7-9929-5bb931f9d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-7122b74c-8980-441f-a08c-6390efc6539e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398369278-172.17.0.13-1595409408336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-342ce3d9-dba4-483b-bd8e-a6868b3b45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-3a548444-6614-4b5b-8257-dbb89e008d52,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-9806f951-de33-4344-8d42-ca69c9ec8684,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-2a56057c-dce5-4d7a-b660-22a2f01f7f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-9c01f8dc-f4df-435b-ab89-7311152bbb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-19b17cfb-4df5-4138-86bc-1bc75f0da9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-ad2d3d2c-f9cc-4ac7-9929-5bb931f9d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-7122b74c-8980-441f-a08c-6390efc6539e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607277185-172.17.0.13-1595409682775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-ba02a872-82d0-418e-86e4-bf67af557bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-2f4cc95b-b987-40bf-a7d7-1e5ad3891df1,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-897178bd-023a-44b1-b61c-1a7c84badab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-653b4489-7350-413b-aa23-94321be5e748,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-97592819-c615-43cd-8b41-4e976f1019a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-64dc908b-359c-4080-bdae-ce64dddafa74,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-74b7e134-0b04-4754-a149-01624a02c099,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-5b9c33d8-abbd-495d-b10e-d079b3e35166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607277185-172.17.0.13-1595409682775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-ba02a872-82d0-418e-86e4-bf67af557bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-2f4cc95b-b987-40bf-a7d7-1e5ad3891df1,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-897178bd-023a-44b1-b61c-1a7c84badab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-653b4489-7350-413b-aa23-94321be5e748,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-97592819-c615-43cd-8b41-4e976f1019a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-64dc908b-359c-4080-bdae-ce64dddafa74,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-74b7e134-0b04-4754-a149-01624a02c099,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-5b9c33d8-abbd-495d-b10e-d079b3e35166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540321063-172.17.0.13-1595409982638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38480,DS-83e443b0-7123-4868-abb1-aad4a81912a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-d4840ba6-50c7-410d-862d-26c556cfe761,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-d2c733bf-4387-47be-8415-a0b3c284e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-af0cee03-e187-495e-9d62-de5b4914e54e,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-e47bfbf5-c275-4f3a-912d-25faee77920f,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-e4e528fe-4224-45f7-bbc5-d2e7692cc80f,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-f156fd36-8aec-4de7-b2ce-7b3a1506aadd,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-30112bc3-0b64-4ad0-bd86-b7b1f16d8321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540321063-172.17.0.13-1595409982638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38480,DS-83e443b0-7123-4868-abb1-aad4a81912a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-d4840ba6-50c7-410d-862d-26c556cfe761,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-d2c733bf-4387-47be-8415-a0b3c284e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-af0cee03-e187-495e-9d62-de5b4914e54e,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-e47bfbf5-c275-4f3a-912d-25faee77920f,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-e4e528fe-4224-45f7-bbc5-d2e7692cc80f,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-f156fd36-8aec-4de7-b2ce-7b3a1506aadd,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-30112bc3-0b64-4ad0-bd86-b7b1f16d8321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156754941-172.17.0.13-1595410859801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-dfd8d1c5-33b6-4680-a47a-00293c8013dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-39ffb74d-9cbf-44e8-b74e-75ad9285336e,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-6809f955-67a6-40c3-81ca-d5766485f615,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-10abbf49-8d53-4907-8eb4-136f47f97fce,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-9c855aaa-c2fc-48b0-b881-671bb0f743e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-de22b9a1-1536-4c71-bb33-8e86f04ebc59,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-6dc42139-6a49-43f1-8ed0-40e282091403,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-f7810b1b-2833-4a43-ab3f-f52dda91ce66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156754941-172.17.0.13-1595410859801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-dfd8d1c5-33b6-4680-a47a-00293c8013dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-39ffb74d-9cbf-44e8-b74e-75ad9285336e,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-6809f955-67a6-40c3-81ca-d5766485f615,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-10abbf49-8d53-4907-8eb4-136f47f97fce,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-9c855aaa-c2fc-48b0-b881-671bb0f743e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-de22b9a1-1536-4c71-bb33-8e86f04ebc59,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-6dc42139-6a49-43f1-8ed0-40e282091403,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-f7810b1b-2833-4a43-ab3f-f52dda91ce66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758389787-172.17.0.13-1595411071457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39969,DS-aa910115-8c61-4fa3-aeca-97507c5d21b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-d08a88e9-ffba-4c8a-ab32-3c33669fb078,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-67c09e98-52ea-4897-9172-0688fd3668f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-d5966570-464d-481d-9e76-129e1729e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-18e6600b-99a2-4209-a8f9-2851d2aa15fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-57917e06-c69b-433a-b221-2585abac3cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-f77af4a5-b15e-4f61-bfa8-102be2ccd2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-3348ef27-2e7b-419c-866c-50b7a2df5785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758389787-172.17.0.13-1595411071457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39969,DS-aa910115-8c61-4fa3-aeca-97507c5d21b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-d08a88e9-ffba-4c8a-ab32-3c33669fb078,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-67c09e98-52ea-4897-9172-0688fd3668f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-d5966570-464d-481d-9e76-129e1729e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-18e6600b-99a2-4209-a8f9-2851d2aa15fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-57917e06-c69b-433a-b221-2585abac3cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-f77af4a5-b15e-4f61-bfa8-102be2ccd2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-3348ef27-2e7b-419c-866c-50b7a2df5785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941440290-172.17.0.13-1595411622251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45859,DS-793cd070-4b2b-42c0-8cc2-90cec5e7ac69,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-c0f3758a-71ad-4561-b7bb-3fc3320da37a,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-70a77b47-bd1a-4304-8d59-a4671266ef86,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-e6e997c0-6568-4be0-ab51-0c5fbf300177,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-565f8aec-2923-43f0-9e54-05cb2dfcbbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-46361f10-86a1-4883-9be2-18b2a45176ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-713af3f7-62b6-422e-b46c-15bffc56ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-bfe34fd9-cc4f-404e-9403-7fe54bc15028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941440290-172.17.0.13-1595411622251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45859,DS-793cd070-4b2b-42c0-8cc2-90cec5e7ac69,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-c0f3758a-71ad-4561-b7bb-3fc3320da37a,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-70a77b47-bd1a-4304-8d59-a4671266ef86,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-e6e997c0-6568-4be0-ab51-0c5fbf300177,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-565f8aec-2923-43f0-9e54-05cb2dfcbbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-46361f10-86a1-4883-9be2-18b2a45176ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-713af3f7-62b6-422e-b46c-15bffc56ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-bfe34fd9-cc4f-404e-9403-7fe54bc15028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859030664-172.17.0.13-1595411789829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35725,DS-0ebf86cd-b6da-4ed2-9e64-eb9b2a580f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-7d6a9978-6dbf-49b7-ba42-7b994b282b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-5d574cae-d8ad-4fc0-a77d-f8cd31604e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-0af07487-3b6d-43d1-adae-d8c840144ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-f614ddb1-a98c-430c-afbd-3ccde79c9ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-72645b39-e57e-4c4c-9021-42ef1ef6a713,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-5a132109-f203-4b99-b221-fb24bd284589,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-2bdaecf1-68d4-4c0e-9d74-9cf306efadc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859030664-172.17.0.13-1595411789829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35725,DS-0ebf86cd-b6da-4ed2-9e64-eb9b2a580f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-7d6a9978-6dbf-49b7-ba42-7b994b282b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-5d574cae-d8ad-4fc0-a77d-f8cd31604e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-0af07487-3b6d-43d1-adae-d8c840144ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-f614ddb1-a98c-430c-afbd-3ccde79c9ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-72645b39-e57e-4c4c-9021-42ef1ef6a713,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-5a132109-f203-4b99-b221-fb24bd284589,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-2bdaecf1-68d4-4c0e-9d74-9cf306efadc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648440689-172.17.0.13-1595412211625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39412,DS-2a26b90f-16eb-4df5-b508-aebebbdfd217,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-d615fdfb-ced3-478b-ad47-a3179f757006,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-4b2335e3-a966-4990-818e-e8335a638b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-0f1e6175-5bab-4ad7-9e10-5b53fe18c0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-b5115c6b-f679-4399-b02b-4578bb7811f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-cbe703e9-812c-4134-aac6-18fa2c0ba302,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-cc92dda5-fbcb-4b3e-bcf2-ecf2259f6b14,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-24203ac8-a8b2-4769-ba24-4bbea7812db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648440689-172.17.0.13-1595412211625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39412,DS-2a26b90f-16eb-4df5-b508-aebebbdfd217,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-d615fdfb-ced3-478b-ad47-a3179f757006,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-4b2335e3-a966-4990-818e-e8335a638b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-0f1e6175-5bab-4ad7-9e10-5b53fe18c0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-b5115c6b-f679-4399-b02b-4578bb7811f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-cbe703e9-812c-4134-aac6-18fa2c0ba302,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-cc92dda5-fbcb-4b3e-bcf2-ecf2259f6b14,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-24203ac8-a8b2-4769-ba24-4bbea7812db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5198
