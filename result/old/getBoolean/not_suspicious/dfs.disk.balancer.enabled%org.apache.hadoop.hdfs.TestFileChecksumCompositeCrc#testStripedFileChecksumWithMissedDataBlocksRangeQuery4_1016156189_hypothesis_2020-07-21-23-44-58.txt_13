reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281313186-172.17.0.8-1595375160403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35578,DS-e2faecb4-54c9-43ac-a070-33920dba3d58,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-c243405d-b758-4ab5-82e1-bd96789f3b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-d3e75128-6ab4-4734-b723-4b0e9f7bae27,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-c7a866e8-cb2b-4207-8da4-71b1bb57c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-dbdbc300-975a-43a0-a44e-acd3d1b3fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-e1723124-8ee2-4c5d-af36-6fef08ea29f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-795bafde-7248-4fd0-8f49-ef480187b31c,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-38d1b4d4-8564-4dd1-9f90-c1d21ac43f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281313186-172.17.0.8-1595375160403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35578,DS-e2faecb4-54c9-43ac-a070-33920dba3d58,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-c243405d-b758-4ab5-82e1-bd96789f3b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-d3e75128-6ab4-4734-b723-4b0e9f7bae27,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-c7a866e8-cb2b-4207-8da4-71b1bb57c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-dbdbc300-975a-43a0-a44e-acd3d1b3fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-e1723124-8ee2-4c5d-af36-6fef08ea29f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-795bafde-7248-4fd0-8f49-ef480187b31c,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-38d1b4d4-8564-4dd1-9f90-c1d21ac43f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269214124-172.17.0.8-1595375231019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-0e8b388d-5220-4546-9aab-4b328c678cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-c9029dd2-e48b-4ad1-8756-321ec603cc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-0f5a49a4-5a61-4bdf-9036-95dfc0fc4aac,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-d55c64f1-12ec-4076-ba84-6b43493deab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-21342f74-d705-46ab-b9f0-11e12030d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-d9ce8d8e-76d7-46c0-b5d9-bc6a0912abbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-c9b38caf-008b-4cfb-a70c-3ad5c18a67e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-b0b95ebe-5e32-4185-825f-e5f910da7809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269214124-172.17.0.8-1595375231019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-0e8b388d-5220-4546-9aab-4b328c678cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-c9029dd2-e48b-4ad1-8756-321ec603cc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-0f5a49a4-5a61-4bdf-9036-95dfc0fc4aac,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-d55c64f1-12ec-4076-ba84-6b43493deab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-21342f74-d705-46ab-b9f0-11e12030d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-d9ce8d8e-76d7-46c0-b5d9-bc6a0912abbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-c9b38caf-008b-4cfb-a70c-3ad5c18a67e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-b0b95ebe-5e32-4185-825f-e5f910da7809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709372169-172.17.0.8-1595376491973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-31dc4c3e-3519-4ac5-8606-98ad850f8e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-e36d560e-903b-4a3d-9577-90e785d67145,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-20cccfcf-f75c-4c54-9151-d3e9c6d58fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-2bac2660-f10a-447d-8207-1dabaa4c02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-f59b03b1-d45a-4e62-aa04-20cf427303c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-284fafcc-30c3-43a3-9968-ea151158b654,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-56177efe-b7c0-4f6c-9407-e8f6ab82d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-d7375671-26b8-4738-9a30-91bb69c76fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709372169-172.17.0.8-1595376491973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-31dc4c3e-3519-4ac5-8606-98ad850f8e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-e36d560e-903b-4a3d-9577-90e785d67145,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-20cccfcf-f75c-4c54-9151-d3e9c6d58fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-2bac2660-f10a-447d-8207-1dabaa4c02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-f59b03b1-d45a-4e62-aa04-20cf427303c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-284fafcc-30c3-43a3-9968-ea151158b654,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-56177efe-b7c0-4f6c-9407-e8f6ab82d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-d7375671-26b8-4738-9a30-91bb69c76fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824930239-172.17.0.8-1595376587695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43267,DS-e12e05c9-b0f5-4ca9-bc75-2801293bdff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-63a99bbd-608e-4aca-8caa-870627ef2253,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-0f9f1215-da94-46f2-9f63-0bd1289daf90,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-5c9a7453-3ab4-47b3-9267-5a099f55aea0,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-1473a4b0-c495-493c-9b05-32fb7ad29fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-2ffe7245-5111-486f-8b82-3bfa9cc1ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-62c88804-f243-4f03-afa1-5755a7795212,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-5742465e-41ba-4a05-8f27-928d84aff372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824930239-172.17.0.8-1595376587695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43267,DS-e12e05c9-b0f5-4ca9-bc75-2801293bdff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-63a99bbd-608e-4aca-8caa-870627ef2253,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-0f9f1215-da94-46f2-9f63-0bd1289daf90,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-5c9a7453-3ab4-47b3-9267-5a099f55aea0,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-1473a4b0-c495-493c-9b05-32fb7ad29fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-2ffe7245-5111-486f-8b82-3bfa9cc1ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-62c88804-f243-4f03-afa1-5755a7795212,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-5742465e-41ba-4a05-8f27-928d84aff372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235253826-172.17.0.8-1595376696293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34918,DS-7c84d67c-c2f5-4014-bbb1-58414647baee,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-787e8174-a939-4634-90c1-c7555eaf1b95,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-2e3520fd-add1-4496-b68e-13a59a338168,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-19993093-f9aa-40eb-b6ef-d99bda992d71,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-652bc6a0-b992-47ce-a7cf-d3c40bc4d76b,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-529b532d-e493-416c-a540-0f1ffbfaac48,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-15514212-772c-4ecc-98dc-29f908cfa349,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-9d97810d-8eaf-42f5-a850-b3b19003722b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235253826-172.17.0.8-1595376696293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34918,DS-7c84d67c-c2f5-4014-bbb1-58414647baee,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-787e8174-a939-4634-90c1-c7555eaf1b95,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-2e3520fd-add1-4496-b68e-13a59a338168,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-19993093-f9aa-40eb-b6ef-d99bda992d71,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-652bc6a0-b992-47ce-a7cf-d3c40bc4d76b,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-529b532d-e493-416c-a540-0f1ffbfaac48,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-15514212-772c-4ecc-98dc-29f908cfa349,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-9d97810d-8eaf-42f5-a850-b3b19003722b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025490315-172.17.0.8-1595377225914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34661,DS-0de577a9-5c81-48ea-adf8-630bc31f82a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-0c4bd157-744c-487e-be3d-c65858a39d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-66f4e50e-5c82-4609-97d8-f8c62fa24335,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-137eebdd-cac6-480f-b48b-09714fc19e53,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-2cf37ae9-bb3f-4616-bce6-068fbfb1b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-8837c34e-43dc-47ea-80e8-7c5db206d857,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-cf801f1d-28d1-44be-a0a9-f1a94e8b93b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-b3e8ebad-a9d9-4e7f-90c6-e2f5ac31d227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025490315-172.17.0.8-1595377225914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34661,DS-0de577a9-5c81-48ea-adf8-630bc31f82a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-0c4bd157-744c-487e-be3d-c65858a39d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-66f4e50e-5c82-4609-97d8-f8c62fa24335,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-137eebdd-cac6-480f-b48b-09714fc19e53,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-2cf37ae9-bb3f-4616-bce6-068fbfb1b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-8837c34e-43dc-47ea-80e8-7c5db206d857,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-cf801f1d-28d1-44be-a0a9-f1a94e8b93b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-b3e8ebad-a9d9-4e7f-90c6-e2f5ac31d227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238154187-172.17.0.8-1595377532317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43277,DS-e418c92f-8cb9-4dbf-abe8-cff71caa83d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-118e1b56-e15a-4a75-86f7-bd7356a4861d,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-236de96b-f8f8-4f5f-9917-f1246e2f6065,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-b50d0cf8-d14a-43c5-9046-2eca3c43ae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-61ed5129-8dcb-4f17-8569-be16838ffb74,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-1a9df74b-fca5-4dad-ae43-d6e1de06ed4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-eed3a072-08af-4b1f-bdee-05c0cc2e29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-bfd465f5-5c20-4cee-b90f-c66d003b8895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238154187-172.17.0.8-1595377532317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43277,DS-e418c92f-8cb9-4dbf-abe8-cff71caa83d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-118e1b56-e15a-4a75-86f7-bd7356a4861d,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-236de96b-f8f8-4f5f-9917-f1246e2f6065,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-b50d0cf8-d14a-43c5-9046-2eca3c43ae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-61ed5129-8dcb-4f17-8569-be16838ffb74,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-1a9df74b-fca5-4dad-ae43-d6e1de06ed4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-eed3a072-08af-4b1f-bdee-05c0cc2e29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-bfd465f5-5c20-4cee-b90f-c66d003b8895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927945832-172.17.0.8-1595377974517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40233,DS-6b7c74bf-0276-405a-a051-39067f864195,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-36f26e12-87b2-4d8d-b6a2-42dd17931589,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-74cf2c1d-020a-4fdb-96da-1c45d2de4e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-fc02c19e-1941-47c3-b841-825a1241137b,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-fec806c7-70ef-4a30-a66e-13e0e4a4862b,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-53ec3a3e-83eb-42bd-8571-d4ead5d4e15e,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-0ff08ec0-12ee-4b59-8920-ee1fa406be00,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-ef51a53e-06fa-40a5-9234-8380aa861b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927945832-172.17.0.8-1595377974517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40233,DS-6b7c74bf-0276-405a-a051-39067f864195,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-36f26e12-87b2-4d8d-b6a2-42dd17931589,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-74cf2c1d-020a-4fdb-96da-1c45d2de4e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-fc02c19e-1941-47c3-b841-825a1241137b,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-fec806c7-70ef-4a30-a66e-13e0e4a4862b,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-53ec3a3e-83eb-42bd-8571-d4ead5d4e15e,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-0ff08ec0-12ee-4b59-8920-ee1fa406be00,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-ef51a53e-06fa-40a5-9234-8380aa861b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825693739-172.17.0.8-1595378108861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-fc77aefb-ffbf-4d9f-b970-e61be51194b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-4cd3c530-8378-4d18-9975-0fab47a048ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-998fa5dd-aec1-4262-a39b-8d46fc9b8e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-edf727b0-894b-4342-a0a2-e6f33828c235,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-62dfdf1f-01f1-4eff-9efe-f0637ce5d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-8f0b43d1-0f0d-4a62-b052-9cc82afab4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-10e2bb76-6e10-4bbe-b90a-a276f4875cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-f85a1622-4444-4d57-aefe-ba217909de59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825693739-172.17.0.8-1595378108861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-fc77aefb-ffbf-4d9f-b970-e61be51194b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-4cd3c530-8378-4d18-9975-0fab47a048ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-998fa5dd-aec1-4262-a39b-8d46fc9b8e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-edf727b0-894b-4342-a0a2-e6f33828c235,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-62dfdf1f-01f1-4eff-9efe-f0637ce5d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-8f0b43d1-0f0d-4a62-b052-9cc82afab4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-10e2bb76-6e10-4bbe-b90a-a276f4875cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-f85a1622-4444-4d57-aefe-ba217909de59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347090765-172.17.0.8-1595378811752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-3c22b67c-f03e-4c32-8348-f3f3ac78d48c,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-7538c1a6-569a-4a45-96e2-011c38788ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-0f6e1dfd-f84b-4967-93fb-7747dfe45e45,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-22760f5c-14c7-487f-bdfa-4b584177f4db,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-e31dbcff-286b-4a7d-bada-20ffd9daf2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-920f95a0-2065-4b0e-9b35-cf0cebd27920,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-eab03de3-c158-4530-af36-cdc2dd9e930a,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d24002bc-27cc-4a07-ab69-48f4a7146b56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347090765-172.17.0.8-1595378811752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-3c22b67c-f03e-4c32-8348-f3f3ac78d48c,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-7538c1a6-569a-4a45-96e2-011c38788ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-0f6e1dfd-f84b-4967-93fb-7747dfe45e45,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-22760f5c-14c7-487f-bdfa-4b584177f4db,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-e31dbcff-286b-4a7d-bada-20ffd9daf2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-920f95a0-2065-4b0e-9b35-cf0cebd27920,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-eab03de3-c158-4530-af36-cdc2dd9e930a,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d24002bc-27cc-4a07-ab69-48f4a7146b56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030513297-172.17.0.8-1595379239766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34712,DS-696c8a9c-992f-4ca9-8761-791578eff746,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-f746f2e4-1bb5-42fe-80f2-053ced3e9de8,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-acc430d2-0e9d-4910-8be5-c65e1cb121e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-f13f329b-65f8-4288-8e49-873e43a82613,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-28bfece2-b1d0-44e0-9f1e-b5429f631182,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-f099f6f4-8391-449d-a62a-dd6c10a968b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-7086b828-788b-4960-bb34-0bb1cbe427f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-d8435e9a-7b2c-4c01-9e10-34aa68c43d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030513297-172.17.0.8-1595379239766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34712,DS-696c8a9c-992f-4ca9-8761-791578eff746,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-f746f2e4-1bb5-42fe-80f2-053ced3e9de8,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-acc430d2-0e9d-4910-8be5-c65e1cb121e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-f13f329b-65f8-4288-8e49-873e43a82613,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-28bfece2-b1d0-44e0-9f1e-b5429f631182,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-f099f6f4-8391-449d-a62a-dd6c10a968b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-7086b828-788b-4960-bb34-0bb1cbe427f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-d8435e9a-7b2c-4c01-9e10-34aa68c43d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162945751-172.17.0.8-1595379368231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43292,DS-3aff2a11-f7fe-4e6f-9cbd-8f067ab2b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-22413ce7-77bc-4b9c-a5ba-5c904647093b,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-d200b4ef-7197-4090-b55d-b531d5e44304,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-70da4524-de57-4cd2-a58b-8d0e199d0051,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-5a87d0d9-399e-4389-a33c-347765e9db09,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-aee691d0-1e82-4d06-950f-aa08ecc27768,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-43083f05-5355-409b-9971-c00532c38fea,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-175d7bb3-9001-4d42-9c9e-f34e081cb3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162945751-172.17.0.8-1595379368231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43292,DS-3aff2a11-f7fe-4e6f-9cbd-8f067ab2b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-22413ce7-77bc-4b9c-a5ba-5c904647093b,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-d200b4ef-7197-4090-b55d-b531d5e44304,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-70da4524-de57-4cd2-a58b-8d0e199d0051,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-5a87d0d9-399e-4389-a33c-347765e9db09,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-aee691d0-1e82-4d06-950f-aa08ecc27768,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-43083f05-5355-409b-9971-c00532c38fea,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-175d7bb3-9001-4d42-9c9e-f34e081cb3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293049614-172.17.0.8-1595379755395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34202,DS-796931ef-16cc-4ed7-86b4-a5cc96af7ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-dbf1d48f-dd33-48ac-a4c2-05e24864439b,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-ec2eb552-1512-4a86-926e-dfaeb1e5a8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-3a8c26a2-82b4-4bee-92cd-5903a2aff927,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-95528495-9dbb-4f79-8bd4-e84c8bfbd66f,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-5ed75c5c-17c7-4934-a219-9ae9a510de23,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-a7a637de-b798-4103-a8ce-5dc352d562b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-ada835e3-7eec-4c2a-97ac-9952d175744f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293049614-172.17.0.8-1595379755395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34202,DS-796931ef-16cc-4ed7-86b4-a5cc96af7ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-dbf1d48f-dd33-48ac-a4c2-05e24864439b,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-ec2eb552-1512-4a86-926e-dfaeb1e5a8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-3a8c26a2-82b4-4bee-92cd-5903a2aff927,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-95528495-9dbb-4f79-8bd4-e84c8bfbd66f,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-5ed75c5c-17c7-4934-a219-9ae9a510de23,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-a7a637de-b798-4103-a8ce-5dc352d562b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-ada835e3-7eec-4c2a-97ac-9952d175744f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5243
