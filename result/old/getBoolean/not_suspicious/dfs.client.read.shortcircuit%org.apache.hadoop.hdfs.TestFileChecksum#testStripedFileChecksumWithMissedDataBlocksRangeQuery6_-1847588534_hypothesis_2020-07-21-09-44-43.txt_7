reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745825985-172.17.0.6-1595324701106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33819,DS-90895b0a-7847-45e8-a493-e8cb6f57567a,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-0bc56144-849e-4a86-ae7a-750279a5ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-0124c703-18d8-4738-9944-e6fc0ade0bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-94538f5c-58c2-41da-bbac-51db3f057d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-7b6750fd-9c66-4549-b126-7bc223e1300d,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-a556c1fc-4b83-4ef2-bc9c-4753ef5065d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-bab4de13-1484-4dec-b94f-4c98fdd7267e,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-16b6ea26-2df2-4fc5-aff7-046259b1cd5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745825985-172.17.0.6-1595324701106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33819,DS-90895b0a-7847-45e8-a493-e8cb6f57567a,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-0bc56144-849e-4a86-ae7a-750279a5ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-0124c703-18d8-4738-9944-e6fc0ade0bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-94538f5c-58c2-41da-bbac-51db3f057d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-7b6750fd-9c66-4549-b126-7bc223e1300d,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-a556c1fc-4b83-4ef2-bc9c-4753ef5065d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-bab4de13-1484-4dec-b94f-4c98fdd7267e,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-16b6ea26-2df2-4fc5-aff7-046259b1cd5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809799988-172.17.0.6-1595325236887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-85fea2e7-f291-4210-a9c4-3ce97fe4b262,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-46a7f378-8c1d-4d15-bc6f-b498cdda4f13,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-4e54cc75-9381-4a2f-9683-e6c03e176a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-4ee4fdff-f02f-45d3-bf60-b9214d4af9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-e434b139-02e7-427f-a448-18834de23259,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-91fcf525-f98a-461f-98c2-64ab6c73773e,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-3ef4fea4-d2d3-473d-8608-1cb8b44f9d36,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-d2c64457-54f3-4448-86a5-9f8f1e36a582,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809799988-172.17.0.6-1595325236887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-85fea2e7-f291-4210-a9c4-3ce97fe4b262,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-46a7f378-8c1d-4d15-bc6f-b498cdda4f13,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-4e54cc75-9381-4a2f-9683-e6c03e176a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-4ee4fdff-f02f-45d3-bf60-b9214d4af9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-e434b139-02e7-427f-a448-18834de23259,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-91fcf525-f98a-461f-98c2-64ab6c73773e,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-3ef4fea4-d2d3-473d-8608-1cb8b44f9d36,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-d2c64457-54f3-4448-86a5-9f8f1e36a582,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179948900-172.17.0.6-1595325369878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-ad031541-9c4c-41f6-89f0-62759f145984,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-1dbea87b-d04d-41a0-b2eb-8ce3f6073eda,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-79db0eb4-08b8-4ce2-839a-a20425bf0c68,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-7d30ad2a-b82f-451d-9a28-95738edb1660,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-ace1275f-a980-48a3-9856-f9f26ca282b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-97c668eb-0fa4-47eb-8595-a4daa18bc75e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-b5b255b0-53bf-4eaf-9dc0-46db1c45ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-f2efcdff-f506-4802-a158-a3eac771c394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179948900-172.17.0.6-1595325369878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-ad031541-9c4c-41f6-89f0-62759f145984,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-1dbea87b-d04d-41a0-b2eb-8ce3f6073eda,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-79db0eb4-08b8-4ce2-839a-a20425bf0c68,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-7d30ad2a-b82f-451d-9a28-95738edb1660,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-ace1275f-a980-48a3-9856-f9f26ca282b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-97c668eb-0fa4-47eb-8595-a4daa18bc75e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-b5b255b0-53bf-4eaf-9dc0-46db1c45ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-f2efcdff-f506-4802-a158-a3eac771c394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362274465-172.17.0.6-1595325674804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33032,DS-6e62e4bd-59c7-43a4-9cf9-da05c85b129d,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-863252cf-2f33-4aac-8cca-9e5373409cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-7f6dfffb-115d-4fd4-8a05-0bf7e9264c65,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-96b0dc24-5b51-4c1b-8065-c229718f751e,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-c6057d09-2e96-4639-be4e-91b247b44b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-cdf19e91-3e81-43e4-906f-89fde2433ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-10693298-49d4-4636-a9ac-f12c3fdec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-c341f89b-45fc-4eb0-91e5-7f162ddbc631,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362274465-172.17.0.6-1595325674804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33032,DS-6e62e4bd-59c7-43a4-9cf9-da05c85b129d,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-863252cf-2f33-4aac-8cca-9e5373409cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-7f6dfffb-115d-4fd4-8a05-0bf7e9264c65,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-96b0dc24-5b51-4c1b-8065-c229718f751e,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-c6057d09-2e96-4639-be4e-91b247b44b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-cdf19e91-3e81-43e4-906f-89fde2433ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-10693298-49d4-4636-a9ac-f12c3fdec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-c341f89b-45fc-4eb0-91e5-7f162ddbc631,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996308013-172.17.0.6-1595325771670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-0a1d4c33-94c8-4637-ac59-2333d53ac590,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-52719c66-e2ec-4d23-8241-542e383af8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-f06f88b6-a0df-4b1e-9ae1-ecd8bef9e1da,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-0e45bc86-99e2-4d1c-aab2-4d20cdd2ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-d3e415fb-1a11-4a05-beef-ed2e1b49507c,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-00f92325-26a5-45f9-be73-f7637a625965,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-cd3bca3d-e473-430c-8da9-0ba569786195,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b90c57b8-f685-49c6-bb90-72880046437e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996308013-172.17.0.6-1595325771670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-0a1d4c33-94c8-4637-ac59-2333d53ac590,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-52719c66-e2ec-4d23-8241-542e383af8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-f06f88b6-a0df-4b1e-9ae1-ecd8bef9e1da,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-0e45bc86-99e2-4d1c-aab2-4d20cdd2ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-d3e415fb-1a11-4a05-beef-ed2e1b49507c,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-00f92325-26a5-45f9-be73-f7637a625965,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-cd3bca3d-e473-430c-8da9-0ba569786195,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b90c57b8-f685-49c6-bb90-72880046437e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061164549-172.17.0.6-1595326077785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41467,DS-e2819294-78ef-485f-9cc9-b2a74abcd822,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-26671c94-4f87-4de1-ae6f-8aa12ee2a0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-dca58262-00f1-4f93-b00b-c0786fc677d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-b6ca0833-de60-4be0-983b-df3731fb6e27,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-e21321d0-e6ad-4649-8bb0-452a2707547d,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-11512c70-d814-4154-8b68-c09cfb1c36b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-59367eb7-6eb9-4350-80c3-9e00b20dc291,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-5b5e1b54-fb9d-4377-bb17-0f6d2d7953a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061164549-172.17.0.6-1595326077785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41467,DS-e2819294-78ef-485f-9cc9-b2a74abcd822,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-26671c94-4f87-4de1-ae6f-8aa12ee2a0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-dca58262-00f1-4f93-b00b-c0786fc677d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-b6ca0833-de60-4be0-983b-df3731fb6e27,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-e21321d0-e6ad-4649-8bb0-452a2707547d,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-11512c70-d814-4154-8b68-c09cfb1c36b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-59367eb7-6eb9-4350-80c3-9e00b20dc291,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-5b5e1b54-fb9d-4377-bb17-0f6d2d7953a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516871287-172.17.0.6-1595326570430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-60f4d9e3-9894-4a21-943d-d1466206541b,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-9a4816ad-b004-481c-8cf1-cc12c575d4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-c62598f0-f1eb-4f67-8467-1662e9bd0855,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-c8a675c1-a0c1-4f7f-be18-694d1673b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-6829aa8a-eb9f-4ebf-8f84-e18c52dde182,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-e82c828f-9c1f-4439-b85d-bccb00c899b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-4eb1a550-660b-4d57-87aa-f9041fac0c47,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-98e358a3-84a0-45b3-9c41-e3f3fd95d63a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516871287-172.17.0.6-1595326570430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-60f4d9e3-9894-4a21-943d-d1466206541b,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-9a4816ad-b004-481c-8cf1-cc12c575d4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-c62598f0-f1eb-4f67-8467-1662e9bd0855,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-c8a675c1-a0c1-4f7f-be18-694d1673b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-6829aa8a-eb9f-4ebf-8f84-e18c52dde182,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-e82c828f-9c1f-4439-b85d-bccb00c899b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-4eb1a550-660b-4d57-87aa-f9041fac0c47,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-98e358a3-84a0-45b3-9c41-e3f3fd95d63a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457507790-172.17.0.6-1595326629098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-2a3bfb60-2fc4-425b-9f83-d37dd1cd32c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-6340f6a9-6aae-4d48-a2aa-284623235e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-5738e6d6-9fd1-4e14-8ac1-238f18ca5921,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-de4f74f6-e138-4574-a06f-9560e07ec5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-2df0fb6b-18f5-44bd-9f2d-fa21795f5082,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-528aa110-e0db-43ce-b556-2397d6201701,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-d50f1fe3-596c-4899-9740-15bd2166092b,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-4675c36a-0c26-4c27-b646-d99de2f0b01c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457507790-172.17.0.6-1595326629098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-2a3bfb60-2fc4-425b-9f83-d37dd1cd32c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-6340f6a9-6aae-4d48-a2aa-284623235e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-5738e6d6-9fd1-4e14-8ac1-238f18ca5921,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-de4f74f6-e138-4574-a06f-9560e07ec5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-2df0fb6b-18f5-44bd-9f2d-fa21795f5082,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-528aa110-e0db-43ce-b556-2397d6201701,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-d50f1fe3-596c-4899-9740-15bd2166092b,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-4675c36a-0c26-4c27-b646-d99de2f0b01c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397558848-172.17.0.6-1595326705009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-597453ec-6bd1-429e-8194-daf55ae1c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-547dddbc-972d-4c62-a73d-5f549e9d2895,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-abdf763a-156d-462c-9149-9cb8fd47443c,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-60a13331-94f1-4ea5-9614-d8e2dbaad411,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-0292c10d-7a44-4500-9654-d56c10086e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-7a7bbe16-7811-4750-8b61-ee8bb448db16,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-cd5bdaeb-6db2-4af1-a60a-df6d41fa6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-770bd6c1-0110-4a11-a512-fdb96300da61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397558848-172.17.0.6-1595326705009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-597453ec-6bd1-429e-8194-daf55ae1c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-547dddbc-972d-4c62-a73d-5f549e9d2895,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-abdf763a-156d-462c-9149-9cb8fd47443c,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-60a13331-94f1-4ea5-9614-d8e2dbaad411,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-0292c10d-7a44-4500-9654-d56c10086e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-7a7bbe16-7811-4750-8b61-ee8bb448db16,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-cd5bdaeb-6db2-4af1-a60a-df6d41fa6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-770bd6c1-0110-4a11-a512-fdb96300da61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156098659-172.17.0.6-1595326771306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-907daaf6-db5c-4948-913c-ba99ef7af20f,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-6950390b-55a7-4223-ab64-c9b0d8a785c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-2d9e61ba-2c95-4fb0-9f9c-007e35c1cf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-a8f35765-7a6c-48a1-bcc3-1a0187f4bdda,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-cca4be32-9a25-4d57-9061-ca38b1096b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-3f460c4e-2505-4d06-b7ed-8d2073fe0592,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-763cef51-f983-4294-af52-37198bebc70e,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-601dee14-bbbc-4840-9554-a1ad6956f5e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156098659-172.17.0.6-1595326771306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-907daaf6-db5c-4948-913c-ba99ef7af20f,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-6950390b-55a7-4223-ab64-c9b0d8a785c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-2d9e61ba-2c95-4fb0-9f9c-007e35c1cf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-a8f35765-7a6c-48a1-bcc3-1a0187f4bdda,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-cca4be32-9a25-4d57-9061-ca38b1096b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-3f460c4e-2505-4d06-b7ed-8d2073fe0592,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-763cef51-f983-4294-af52-37198bebc70e,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-601dee14-bbbc-4840-9554-a1ad6956f5e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776490679-172.17.0.6-1595326890198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42171,DS-ce1bfe8e-4c39-43ea-8d30-32cf9f2591b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-b3b41ae3-a3b2-4213-8097-d4d92320e6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-4165b803-de19-4180-a978-55f826f7008b,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-b3b80b8c-d9bc-4ec7-a81d-5bc876538490,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-2fc6649f-e83d-4284-a0c5-bb0c3fe555e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-3f8e716a-5d39-40fd-85aa-06bce393855b,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-d5099b66-4190-4815-89a2-f8d01f9b23b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-6ea9a6db-74ea-4400-9e8d-90e4d1a2dcd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776490679-172.17.0.6-1595326890198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42171,DS-ce1bfe8e-4c39-43ea-8d30-32cf9f2591b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-b3b41ae3-a3b2-4213-8097-d4d92320e6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-4165b803-de19-4180-a978-55f826f7008b,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-b3b80b8c-d9bc-4ec7-a81d-5bc876538490,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-2fc6649f-e83d-4284-a0c5-bb0c3fe555e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-3f8e716a-5d39-40fd-85aa-06bce393855b,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-d5099b66-4190-4815-89a2-f8d01f9b23b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-6ea9a6db-74ea-4400-9e8d-90e4d1a2dcd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534915888-172.17.0.6-1595326923576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37397,DS-ff2a747b-6f63-45fb-bfd5-9bc79de88602,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-1ef7db59-d8b6-40b3-9317-ecce281429a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-f98becae-2cc5-4149-a9af-06577c52b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-8cb038a9-6492-444a-8263-5aef162d1281,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-4dd74510-ee45-42e4-8094-cea09e998260,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-d2eef5d0-fb9c-47d6-8875-3fc1c4902da6,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-79a174f7-7750-4f12-8659-e343b52410ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-b24b9f4c-04f4-4cf0-84ae-459712562972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534915888-172.17.0.6-1595326923576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37397,DS-ff2a747b-6f63-45fb-bfd5-9bc79de88602,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-1ef7db59-d8b6-40b3-9317-ecce281429a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-f98becae-2cc5-4149-a9af-06577c52b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-8cb038a9-6492-444a-8263-5aef162d1281,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-4dd74510-ee45-42e4-8094-cea09e998260,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-d2eef5d0-fb9c-47d6-8875-3fc1c4902da6,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-79a174f7-7750-4f12-8659-e343b52410ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-b24b9f4c-04f4-4cf0-84ae-459712562972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140720802-172.17.0.6-1595327078786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-1ad615b1-c17f-479c-b8af-6fe251e1dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-e2dc138f-a594-4074-9672-5d06177b9ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-301bbe06-8cf5-4e11-bf9a-bda2c33aaa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-4f0778b3-be07-4e2f-ab2a-35679f2c2016,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-509dc328-f086-4e9e-99e5-821fef95e8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-8935d5e0-ccfb-48a5-8b3d-382fd9c2107d,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-4d3362f3-47f4-4cab-a5bf-de1093d28049,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-94b6d786-4274-4000-9be3-154de279aa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140720802-172.17.0.6-1595327078786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-1ad615b1-c17f-479c-b8af-6fe251e1dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-e2dc138f-a594-4074-9672-5d06177b9ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-301bbe06-8cf5-4e11-bf9a-bda2c33aaa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-4f0778b3-be07-4e2f-ab2a-35679f2c2016,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-509dc328-f086-4e9e-99e5-821fef95e8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-8935d5e0-ccfb-48a5-8b3d-382fd9c2107d,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-4d3362f3-47f4-4cab-a5bf-de1093d28049,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-94b6d786-4274-4000-9be3-154de279aa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469296121-172.17.0.6-1595327260749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39360,DS-4cd8015f-5234-4e48-8220-71786cb9ec5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-a876a4ea-f243-4633-8004-d748812fdcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-a5fc0e40-9caa-49ac-a699-bc4233c52e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-a32cc3b6-98f6-4ff0-b346-524f17f1b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-52807a56-628d-4f47-9ad4-ecb9f89ecd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-f195f0cd-8006-4c18-b286-e006c0313b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-778d99c2-d111-4f49-96bd-7e0413ad8329,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-467e60cb-67b7-443a-96c9-cd229c659401,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469296121-172.17.0.6-1595327260749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39360,DS-4cd8015f-5234-4e48-8220-71786cb9ec5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-a876a4ea-f243-4633-8004-d748812fdcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-a5fc0e40-9caa-49ac-a699-bc4233c52e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-a32cc3b6-98f6-4ff0-b346-524f17f1b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-52807a56-628d-4f47-9ad4-ecb9f89ecd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-f195f0cd-8006-4c18-b286-e006c0313b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-778d99c2-d111-4f49-96bd-7e0413ad8329,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-467e60cb-67b7-443a-96c9-cd229c659401,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573236340-172.17.0.6-1595327444033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-460379ae-1c00-4d90-8b7c-4e3f11608aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-35c62c9a-a230-407b-85fa-f8cec65c5a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-86004609-5df7-4436-bb62-f4b8920dd089,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-825d64cb-6eab-4aa1-9ab8-b5b4f60f6ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-6cc3c2b5-1388-43d3-973e-e7cae1f84b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-d88c713a-709c-47bd-92f4-bfb60f87c124,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-79886f31-67b8-4f93-9b40-34a07647283d,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-3eeb9b6c-1a0f-41b2-bb65-3baaeca8696d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573236340-172.17.0.6-1595327444033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-460379ae-1c00-4d90-8b7c-4e3f11608aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-35c62c9a-a230-407b-85fa-f8cec65c5a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-86004609-5df7-4436-bb62-f4b8920dd089,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-825d64cb-6eab-4aa1-9ab8-b5b4f60f6ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-6cc3c2b5-1388-43d3-973e-e7cae1f84b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-d88c713a-709c-47bd-92f4-bfb60f87c124,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-79886f31-67b8-4f93-9b40-34a07647283d,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-3eeb9b6c-1a0f-41b2-bb65-3baaeca8696d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773087512-172.17.0.6-1595327475859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-ef5bcb53-5d03-45c3-b036-3f9c5fe94921,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-fdc410b2-aba8-4d5d-befb-0911dad2518e,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-69c56fcc-a063-4fa5-aa6d-4ec154f230de,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-4bce3bf5-32d4-4fcd-ae88-a4a2614f8040,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-2b3a464f-b349-41f8-9e97-3424e4daeddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-652556a6-29c2-480b-87a5-83083bd2a571,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-e7e06bf6-8649-4968-8f16-899241042115,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-bfb88363-31fb-422e-91d9-35aab8972561,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773087512-172.17.0.6-1595327475859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-ef5bcb53-5d03-45c3-b036-3f9c5fe94921,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-fdc410b2-aba8-4d5d-befb-0911dad2518e,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-69c56fcc-a063-4fa5-aa6d-4ec154f230de,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-4bce3bf5-32d4-4fcd-ae88-a4a2614f8040,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-2b3a464f-b349-41f8-9e97-3424e4daeddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-652556a6-29c2-480b-87a5-83083bd2a571,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-e7e06bf6-8649-4968-8f16-899241042115,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-bfb88363-31fb-422e-91d9-35aab8972561,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792198796-172.17.0.6-1595327552536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-4f9ebf2b-341b-41f3-8fd9-600c6151b178,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-66d8464f-70f8-472f-bea4-72914279ba45,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-a1fabf76-a2cb-4a0e-b851-45bf48b78040,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-fe8551cd-d385-441e-a074-b2b3fa8de560,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-d8de2cd4-c8a0-4650-a04d-c4d984436e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-d08de891-69a9-4a0a-8409-d61ea4108885,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-022e203f-beda-44ca-b482-c9a6c55aea58,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-8f6bd1ac-f093-4b6e-96e7-c7840d506e5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792198796-172.17.0.6-1595327552536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-4f9ebf2b-341b-41f3-8fd9-600c6151b178,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-66d8464f-70f8-472f-bea4-72914279ba45,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-a1fabf76-a2cb-4a0e-b851-45bf48b78040,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-fe8551cd-d385-441e-a074-b2b3fa8de560,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-d8de2cd4-c8a0-4650-a04d-c4d984436e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-d08de891-69a9-4a0a-8409-d61ea4108885,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-022e203f-beda-44ca-b482-c9a6c55aea58,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-8f6bd1ac-f093-4b6e-96e7-c7840d506e5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092145363-172.17.0.6-1595327622292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-8cf51fa7-8750-4913-9cf8-74f9fd60bbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-01b2064a-72a9-4ca5-b024-c8026e36ad1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-52eccdd5-2109-4b59-8f6b-c86de3db11d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-3250b18f-f1b3-4a4d-936e-7abfd5d7ab5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-e9e663ae-0683-4a19-a657-11699e2dbde8,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-bfb0ef22-ce34-42ba-b9bd-f44dbc5d14dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-9730712a-85e6-497b-8cdd-eade1f71f23a,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-19eda787-374f-41fb-883b-06e2bd217be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092145363-172.17.0.6-1595327622292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-8cf51fa7-8750-4913-9cf8-74f9fd60bbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-01b2064a-72a9-4ca5-b024-c8026e36ad1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-52eccdd5-2109-4b59-8f6b-c86de3db11d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-3250b18f-f1b3-4a4d-936e-7abfd5d7ab5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-e9e663ae-0683-4a19-a657-11699e2dbde8,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-bfb0ef22-ce34-42ba-b9bd-f44dbc5d14dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-9730712a-85e6-497b-8cdd-eade1f71f23a,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-19eda787-374f-41fb-883b-06e2bd217be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618302253-172.17.0.6-1595327769209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-1b9ab26a-99fb-4401-928f-9707285cf194,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-c925edfc-10dc-42b6-87c8-9be8fb6c5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-62c3c536-9da1-48c1-b7f5-f962e3f0f15b,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-39be1d60-6950-4448-959b-da82b14e66b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-bdf2343d-1e04-43ae-9ff1-e499f4bbab1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-b07d3b35-1c34-46c8-9624-9d90915f6c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-935ef1bc-54ec-4c65-875c-edce2e7dca38,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-e2805ae6-7fc9-4c1c-a385-6cc04731d54a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618302253-172.17.0.6-1595327769209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-1b9ab26a-99fb-4401-928f-9707285cf194,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-c925edfc-10dc-42b6-87c8-9be8fb6c5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-62c3c536-9da1-48c1-b7f5-f962e3f0f15b,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-39be1d60-6950-4448-959b-da82b14e66b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-bdf2343d-1e04-43ae-9ff1-e499f4bbab1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-b07d3b35-1c34-46c8-9624-9d90915f6c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-935ef1bc-54ec-4c65-875c-edce2e7dca38,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-e2805ae6-7fc9-4c1c-a385-6cc04731d54a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444281948-172.17.0.6-1595327838919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46432,DS-de02c1c8-af8b-447c-9477-39054b4e35a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-533abeae-5792-4afa-9573-858e849461ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-5e523df4-d291-4939-9025-c01c09a80ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-43d93918-a4cd-4a4b-a3b3-4b90da1ebf68,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-f81773b7-4757-42cd-9e42-c7a884a869e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-24c18a86-4bd4-4a71-933d-91e2b0f9f186,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-3708d877-67e5-43bc-a201-82c43ee2742a,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-8c3e5a1e-7ba4-425b-aff2-7c703bb2717f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444281948-172.17.0.6-1595327838919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46432,DS-de02c1c8-af8b-447c-9477-39054b4e35a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-533abeae-5792-4afa-9573-858e849461ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-5e523df4-d291-4939-9025-c01c09a80ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-43d93918-a4cd-4a4b-a3b3-4b90da1ebf68,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-f81773b7-4757-42cd-9e42-c7a884a869e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-24c18a86-4bd4-4a71-933d-91e2b0f9f186,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-3708d877-67e5-43bc-a201-82c43ee2742a,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-8c3e5a1e-7ba4-425b-aff2-7c703bb2717f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106603045-172.17.0.6-1595328048484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-01e29fe4-239a-4fe6-be72-4810baaf24a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-88511d7e-a3ad-4732-afb4-f40210d80253,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-3736281a-b78d-43e1-a4a4-9e547b1eed18,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-4f495105-a43f-4c18-9f08-93f86588f8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-2e87f28a-7c72-4623-aa2c-b2bb55631a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-f0aea124-17b9-4981-8f77-defd2919fc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e23392b7-6d70-4f38-a1fb-6a5a37efb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-6172a3e8-0c60-466d-9aa4-d7d249e80b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106603045-172.17.0.6-1595328048484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-01e29fe4-239a-4fe6-be72-4810baaf24a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-88511d7e-a3ad-4732-afb4-f40210d80253,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-3736281a-b78d-43e1-a4a4-9e547b1eed18,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-4f495105-a43f-4c18-9f08-93f86588f8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-2e87f28a-7c72-4623-aa2c-b2bb55631a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-f0aea124-17b9-4981-8f77-defd2919fc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e23392b7-6d70-4f38-a1fb-6a5a37efb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-6172a3e8-0c60-466d-9aa4-d7d249e80b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609481079-172.17.0.6-1595328209593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-ea2bdfcc-b89e-4741-b566-46e589e23f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-e851d2ae-d349-4e33-be1b-074c52875ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-474c110f-eda6-4184-a03c-002aa252d875,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-dea3b66e-af11-4dd4-9512-415b340349a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-2f6713fe-4d49-4fce-ad6c-e0743fe0d243,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-87f6b49c-91ba-4acc-af3a-5193ba14c929,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-e0a878cb-14a1-428a-8995-fd2282e57a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-c76db019-d1f0-44b3-a130-8bee8ef34a3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609481079-172.17.0.6-1595328209593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-ea2bdfcc-b89e-4741-b566-46e589e23f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-e851d2ae-d349-4e33-be1b-074c52875ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-474c110f-eda6-4184-a03c-002aa252d875,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-dea3b66e-af11-4dd4-9512-415b340349a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-2f6713fe-4d49-4fce-ad6c-e0743fe0d243,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-87f6b49c-91ba-4acc-af3a-5193ba14c929,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-e0a878cb-14a1-428a-8995-fd2282e57a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-c76db019-d1f0-44b3-a130-8bee8ef34a3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429409201-172.17.0.6-1595328280587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39498,DS-bbda541b-47eb-41fe-a471-1bcd13ffdd81,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-e18522aa-0981-4c2b-8860-eab788d6d230,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-9cae0fbe-dbce-4f53-97ce-1297aa5f1ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-6f401849-d782-4340-abef-0dd21931f27a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-74ea1c89-0f3a-4ef0-8539-2a13eed4e556,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-52ffd042-c14f-4f80-8e60-749171e3914b,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-23c5e61c-ea1d-4887-84bd-e44ac5bfa314,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-a512ea22-8f85-4e11-b885-aafd37b262e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429409201-172.17.0.6-1595328280587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39498,DS-bbda541b-47eb-41fe-a471-1bcd13ffdd81,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-e18522aa-0981-4c2b-8860-eab788d6d230,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-9cae0fbe-dbce-4f53-97ce-1297aa5f1ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-6f401849-d782-4340-abef-0dd21931f27a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-74ea1c89-0f3a-4ef0-8539-2a13eed4e556,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-52ffd042-c14f-4f80-8e60-749171e3914b,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-23c5e61c-ea1d-4887-84bd-e44ac5bfa314,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-a512ea22-8f85-4e11-b885-aafd37b262e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892400466-172.17.0.6-1595328310906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-cad0b55b-f743-4d19-8853-b6578574d152,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-29477db3-87ad-4cef-b1ff-d0666f78d41d,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-65f7c6e2-c8f0-4cf2-8298-46425bc38f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-5ddd383a-b3d2-4019-95b1-8dafb0e1b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-bc813bcf-2f1c-4a8f-a05a-4636c7f0618e,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-534f1462-5bf5-433d-9925-4ebb87b4c0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-d8996dae-1992-416b-ba78-e8efad5fbcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-27fbc44a-2cc9-4e73-b518-2839c6dad077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892400466-172.17.0.6-1595328310906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-cad0b55b-f743-4d19-8853-b6578574d152,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-29477db3-87ad-4cef-b1ff-d0666f78d41d,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-65f7c6e2-c8f0-4cf2-8298-46425bc38f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-5ddd383a-b3d2-4019-95b1-8dafb0e1b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-bc813bcf-2f1c-4a8f-a05a-4636c7f0618e,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-534f1462-5bf5-433d-9925-4ebb87b4c0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-d8996dae-1992-416b-ba78-e8efad5fbcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-27fbc44a-2cc9-4e73-b518-2839c6dad077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611705822-172.17.0.6-1595328391066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38335,DS-79c2492b-9d09-41d8-8a1b-a9b4489d108c,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-0314e20f-e0c4-482b-971d-8c30c2fcf732,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-747f25c7-abfa-41d8-888c-464b0a3dfcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-2d20c44c-7b4e-4c68-b5a3-07c863931d75,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-0d717dc2-9727-4c2f-8227-f6db7dfd9d90,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-380a9ff0-5a2a-4c6a-87f3-412159793091,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-df1ab6e6-5f56-44d4-8f14-50038a440650,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-e85da954-c02f-4797-9343-5f822129e17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611705822-172.17.0.6-1595328391066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38335,DS-79c2492b-9d09-41d8-8a1b-a9b4489d108c,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-0314e20f-e0c4-482b-971d-8c30c2fcf732,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-747f25c7-abfa-41d8-888c-464b0a3dfcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-2d20c44c-7b4e-4c68-b5a3-07c863931d75,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-0d717dc2-9727-4c2f-8227-f6db7dfd9d90,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-380a9ff0-5a2a-4c6a-87f3-412159793091,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-df1ab6e6-5f56-44d4-8f14-50038a440650,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-e85da954-c02f-4797-9343-5f822129e17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147122158-172.17.0.6-1595328562091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-f4c27765-2b45-4234-958a-bccf9698fb85,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-a07a75ba-a028-44d6-b8e1-b01907924e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-00064411-7087-4789-9027-777db9fa8e72,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-1a87d15a-b7e3-45cf-adde-f7c142578548,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-92950512-3aa4-431d-902c-8358d6200824,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-0bc630d1-9768-4a10-b056-23a9435317bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-2a3d54df-e221-4400-a0cf-85b5740fb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-8536546a-9cf2-4253-bd6f-7215d03f1a6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147122158-172.17.0.6-1595328562091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-f4c27765-2b45-4234-958a-bccf9698fb85,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-a07a75ba-a028-44d6-b8e1-b01907924e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-00064411-7087-4789-9027-777db9fa8e72,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-1a87d15a-b7e3-45cf-adde-f7c142578548,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-92950512-3aa4-431d-902c-8358d6200824,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-0bc630d1-9768-4a10-b056-23a9435317bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-2a3d54df-e221-4400-a0cf-85b5740fb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-8536546a-9cf2-4253-bd6f-7215d03f1a6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968831458-172.17.0.6-1595329041673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-845fe774-dff8-4bb4-8914-909231e5569a,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-24d51122-9307-4297-adab-30a1bc42fbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-9ce17dac-f059-479f-ad09-705e6151e006,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-b8a5f31b-0f09-482e-8dd8-e2341720460a,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-9662f115-78aa-4b5c-8bc4-0c57888b08bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-4a43434e-9a63-492e-a26b-a900a72a1cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-c7e6799d-bb93-4714-8d3b-513080dde01e,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-034632e3-4c60-439b-9fe0-04897501d418,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968831458-172.17.0.6-1595329041673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-845fe774-dff8-4bb4-8914-909231e5569a,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-24d51122-9307-4297-adab-30a1bc42fbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-9ce17dac-f059-479f-ad09-705e6151e006,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-b8a5f31b-0f09-482e-8dd8-e2341720460a,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-9662f115-78aa-4b5c-8bc4-0c57888b08bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-4a43434e-9a63-492e-a26b-a900a72a1cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-c7e6799d-bb93-4714-8d3b-513080dde01e,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-034632e3-4c60-439b-9fe0-04897501d418,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690130507-172.17.0.6-1595329330986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-2bc96da3-44d7-4440-8989-19700b4be5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-673f1fab-2286-4382-9cad-7a6d67b8b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-dae57acf-619f-4d6a-8a33-c0cd7cf8012c,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-3d47f746-adb7-43d7-8ad6-fa56d19f7568,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-88108e3d-e766-4c07-b949-d2306caeb5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-6af3dd81-f58a-4b74-a14d-70d8f6b53225,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-0b3b1d93-6bde-483a-b6ab-d920334a654c,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-4dfbbc91-e2a2-4aa1-96e6-f5af93e678d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690130507-172.17.0.6-1595329330986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-2bc96da3-44d7-4440-8989-19700b4be5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-673f1fab-2286-4382-9cad-7a6d67b8b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-dae57acf-619f-4d6a-8a33-c0cd7cf8012c,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-3d47f746-adb7-43d7-8ad6-fa56d19f7568,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-88108e3d-e766-4c07-b949-d2306caeb5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-6af3dd81-f58a-4b74-a14d-70d8f6b53225,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-0b3b1d93-6bde-483a-b6ab-d920334a654c,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-4dfbbc91-e2a2-4aa1-96e6-f5af93e678d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827219665-172.17.0.6-1595329477290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-7d57d68e-7a6e-41a9-8265-9a61c20ad578,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-f39abd65-e48a-424b-a3b8-35041cf66b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-77d471ad-b4a2-45a3-9ec5-43fc2a3f1514,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-8b910136-413e-46c0-a148-e8af36caa24a,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-438a0ded-156d-4886-9e81-05c818230d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-7a04c6ea-5b58-43c3-b34e-34e4b3be6464,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-928afc01-d1db-40d6-baad-d2fee4d29e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-1e08d525-cad4-41f6-aabe-30f1e08556a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827219665-172.17.0.6-1595329477290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-7d57d68e-7a6e-41a9-8265-9a61c20ad578,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-f39abd65-e48a-424b-a3b8-35041cf66b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-77d471ad-b4a2-45a3-9ec5-43fc2a3f1514,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-8b910136-413e-46c0-a148-e8af36caa24a,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-438a0ded-156d-4886-9e81-05c818230d60,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-7a04c6ea-5b58-43c3-b34e-34e4b3be6464,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-928afc01-d1db-40d6-baad-d2fee4d29e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-1e08d525-cad4-41f6-aabe-30f1e08556a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127732248-172.17.0.6-1595329585410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-5ce231d5-8ed4-4b90-aae6-17002591dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-8d8feeb6-34be-4de1-be4a-172d7069feff,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-a869ac52-e997-41be-91a6-7d5863930e81,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-d5e65b2c-d910-4b32-8954-8c3ec1036463,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-0bb12a53-3d8f-4c2d-86a3-3f1f058407b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-3a07f301-fc0b-4f17-aa38-212b7c4e5a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-ed3a8694-8071-4752-a06a-c9327b651cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-023868d2-662e-42ca-9865-3bb50944aca7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127732248-172.17.0.6-1595329585410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-5ce231d5-8ed4-4b90-aae6-17002591dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-8d8feeb6-34be-4de1-be4a-172d7069feff,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-a869ac52-e997-41be-91a6-7d5863930e81,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-d5e65b2c-d910-4b32-8954-8c3ec1036463,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-0bb12a53-3d8f-4c2d-86a3-3f1f058407b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-3a07f301-fc0b-4f17-aa38-212b7c4e5a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-ed3a8694-8071-4752-a06a-c9327b651cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-023868d2-662e-42ca-9865-3bb50944aca7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060967834-172.17.0.6-1595329731237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-6a27064d-5c1d-481c-8bbd-913a556e735f,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-fb6b5360-147e-4c81-92e2-9c189535492d,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-736f4057-0457-46db-b10c-568e3272480f,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-35df2650-c945-4959-a918-e84015af192e,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-3723d907-0693-4055-a33b-0a0f6edff17f,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-e44a9bdd-9b8c-4b27-9de0-af65b584979e,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-668d7d74-e55c-4e90-9fe9-11eccfb053d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-59d6f887-b574-4e54-9324-2e521b1f140c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060967834-172.17.0.6-1595329731237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-6a27064d-5c1d-481c-8bbd-913a556e735f,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-fb6b5360-147e-4c81-92e2-9c189535492d,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-736f4057-0457-46db-b10c-568e3272480f,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-35df2650-c945-4959-a918-e84015af192e,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-3723d907-0693-4055-a33b-0a0f6edff17f,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-e44a9bdd-9b8c-4b27-9de0-af65b584979e,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-668d7d74-e55c-4e90-9fe9-11eccfb053d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-59d6f887-b574-4e54-9324-2e521b1f140c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5232
