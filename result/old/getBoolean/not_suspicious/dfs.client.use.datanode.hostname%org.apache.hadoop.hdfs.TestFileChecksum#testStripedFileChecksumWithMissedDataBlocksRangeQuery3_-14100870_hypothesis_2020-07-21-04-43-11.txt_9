reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342881253-172.17.0.15-1595307280730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44363,DS-c2189d4c-5ddb-4346-85a8-35aee67ec5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-4121dcc4-b221-40ee-a7c9-ecaf973bb39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-f9ffddb7-260f-439f-aa48-d68cb2bfb857,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-d13440a2-ad1f-4049-bb9b-323335ecea55,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-731d9c40-99e1-4230-9573-cd9fe9c253d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-24fc2314-6c1f-4636-80f1-aa3a740543d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-c1e8d572-5142-4e17-8c00-41753a60ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-4c84f49f-788e-4e3b-8411-7f72085e643c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342881253-172.17.0.15-1595307280730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44363,DS-c2189d4c-5ddb-4346-85a8-35aee67ec5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-4121dcc4-b221-40ee-a7c9-ecaf973bb39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-f9ffddb7-260f-439f-aa48-d68cb2bfb857,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-d13440a2-ad1f-4049-bb9b-323335ecea55,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-731d9c40-99e1-4230-9573-cd9fe9c253d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-24fc2314-6c1f-4636-80f1-aa3a740543d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-c1e8d572-5142-4e17-8c00-41753a60ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-4c84f49f-788e-4e3b-8411-7f72085e643c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637047625-172.17.0.15-1595307393678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-caa10052-37c7-4548-9fa3-3acad933bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-9b667457-61c8-4f14-96fe-11a62af1c167,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-1b724fc6-437a-45f1-b488-3fad4b33d2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-f731941e-5770-4b21-a4e3-5e9e4e1191d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-53a858ac-b933-4917-8fa6-de82ef52fa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-1f7eaf65-8517-4a99-bdad-6db59657e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-b3168755-2581-49b6-a272-a5e727b7ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-dd3c2824-809c-496b-9e72-266386b09386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637047625-172.17.0.15-1595307393678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-caa10052-37c7-4548-9fa3-3acad933bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-9b667457-61c8-4f14-96fe-11a62af1c167,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-1b724fc6-437a-45f1-b488-3fad4b33d2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-f731941e-5770-4b21-a4e3-5e9e4e1191d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-53a858ac-b933-4917-8fa6-de82ef52fa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-1f7eaf65-8517-4a99-bdad-6db59657e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-b3168755-2581-49b6-a272-a5e727b7ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-dd3c2824-809c-496b-9e72-266386b09386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037589252-172.17.0.15-1595308037924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46447,DS-838369d1-a40d-43b2-a6be-a7c891e89196,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-1f6f7583-0999-4d0e-b9be-557b4bb55b38,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-c84b3491-4e0b-44dc-91e6-06a63e84cf47,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-effcb7b6-8563-4203-aa6b-0d224b78b900,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-80c33dad-265f-45b6-9816-b3e88f79e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-7f33d28c-d9c3-4a3f-a26a-48f434efc710,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-037ab846-f891-4bba-a9e5-505b186b8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-5120cf87-6344-4d63-b061-fd4467092235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037589252-172.17.0.15-1595308037924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46447,DS-838369d1-a40d-43b2-a6be-a7c891e89196,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-1f6f7583-0999-4d0e-b9be-557b4bb55b38,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-c84b3491-4e0b-44dc-91e6-06a63e84cf47,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-effcb7b6-8563-4203-aa6b-0d224b78b900,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-80c33dad-265f-45b6-9816-b3e88f79e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-7f33d28c-d9c3-4a3f-a26a-48f434efc710,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-037ab846-f891-4bba-a9e5-505b186b8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-5120cf87-6344-4d63-b061-fd4467092235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122249917-172.17.0.15-1595308353335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46463,DS-d612390b-b64b-4633-b324-4ac5f31bf4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-2a11b22f-90dd-48cd-ab29-b4eb19c0c575,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-c3456ae1-d409-4863-8bcc-635a69e3b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-4ca3432e-8fae-436f-a77c-8ef29d7cd118,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-7284ed60-69f7-4900-956b-7a07de317f40,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-5a090d0c-d1a1-447d-a6ed-e70c7643ba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-77a7ede7-4b63-4d67-9e08-90805acdf6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-7c0396ff-0440-4a42-bee7-49e9136fa243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122249917-172.17.0.15-1595308353335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46463,DS-d612390b-b64b-4633-b324-4ac5f31bf4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-2a11b22f-90dd-48cd-ab29-b4eb19c0c575,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-c3456ae1-d409-4863-8bcc-635a69e3b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-4ca3432e-8fae-436f-a77c-8ef29d7cd118,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-7284ed60-69f7-4900-956b-7a07de317f40,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-5a090d0c-d1a1-447d-a6ed-e70c7643ba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-77a7ede7-4b63-4d67-9e08-90805acdf6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-7c0396ff-0440-4a42-bee7-49e9136fa243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146344993-172.17.0.15-1595308837481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37449,DS-18d5a584-f057-43c4-8a80-c1704b204830,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-73f7c12b-b1e4-46ed-8b7c-68c5b4cba683,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-e3c59c47-4923-4703-a0f6-98ea0f934893,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-7b7844d4-d8dc-43d6-a4d9-8e35945737b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-0fef5211-b811-4dea-8a96-af040ea4ed65,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-6ea2b7ca-287b-4ad8-a815-c99635fb6128,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-79f5d959-e321-4612-858a-8c0b97a3cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-94b6b0c0-ae25-4744-802a-2751850ff840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146344993-172.17.0.15-1595308837481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37449,DS-18d5a584-f057-43c4-8a80-c1704b204830,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-73f7c12b-b1e4-46ed-8b7c-68c5b4cba683,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-e3c59c47-4923-4703-a0f6-98ea0f934893,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-7b7844d4-d8dc-43d6-a4d9-8e35945737b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-0fef5211-b811-4dea-8a96-af040ea4ed65,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-6ea2b7ca-287b-4ad8-a815-c99635fb6128,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-79f5d959-e321-4612-858a-8c0b97a3cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-94b6b0c0-ae25-4744-802a-2751850ff840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804785991-172.17.0.15-1595308938285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44126,DS-9e3ae8b8-e8bb-4438-b53b-dcdc9248bf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-700ec84f-8e56-4fc2-84b8-dfba6957d7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-e2affb48-22d8-44d9-9898-368b332104d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-d049aa06-9bf5-4065-96d2-08c091782136,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-9c3fd94f-4755-4b5c-9521-ed89c84a210c,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-657fe22d-5c29-4cf4-a337-19c585bbb41d,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-e20d3dbc-126f-4bc6-940c-f44e43885532,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-42edefdf-4858-4756-b4fb-bfbfa89847cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804785991-172.17.0.15-1595308938285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44126,DS-9e3ae8b8-e8bb-4438-b53b-dcdc9248bf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-700ec84f-8e56-4fc2-84b8-dfba6957d7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-e2affb48-22d8-44d9-9898-368b332104d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-d049aa06-9bf5-4065-96d2-08c091782136,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-9c3fd94f-4755-4b5c-9521-ed89c84a210c,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-657fe22d-5c29-4cf4-a337-19c585bbb41d,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-e20d3dbc-126f-4bc6-940c-f44e43885532,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-42edefdf-4858-4756-b4fb-bfbfa89847cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461313754-172.17.0.15-1595309500819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46081,DS-9440d12b-9f5c-4a13-ab3b-85dd0a60b061,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-2c1b7448-5f74-411e-88f7-0f39e68554a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-03e945e8-be43-4a33-ae5e-8f5187ab3f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-109c4af5-3486-4e05-a736-98167c46137b,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-13941750-0655-40b4-b983-e3b7d437bbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-e94ee5a6-c58a-4575-85cf-df5a17b23b18,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-a1557605-9bec-4354-ae3a-127324654877,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-f4e3d26b-2222-46f8-9447-0bfd281bf4a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461313754-172.17.0.15-1595309500819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46081,DS-9440d12b-9f5c-4a13-ab3b-85dd0a60b061,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-2c1b7448-5f74-411e-88f7-0f39e68554a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-03e945e8-be43-4a33-ae5e-8f5187ab3f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-109c4af5-3486-4e05-a736-98167c46137b,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-13941750-0655-40b4-b983-e3b7d437bbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-e94ee5a6-c58a-4575-85cf-df5a17b23b18,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-a1557605-9bec-4354-ae3a-127324654877,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-f4e3d26b-2222-46f8-9447-0bfd281bf4a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628678573-172.17.0.15-1595309897126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42691,DS-d7d87ebf-7113-40a1-934e-d3b354c8bf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-c9bad7a2-5125-4a6c-9852-1963648cba05,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-68366cef-d8ba-45f3-8f7d-941197cc1b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-f4cbb0e3-1e11-40b1-bf6a-4b5f1963eab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-846eb978-cf08-4c8b-89cc-3b8b83d0f545,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-cf924a63-d92f-40a7-b67a-cc1f6332e746,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-031324f9-b054-4b62-bf6d-7fedd2a206ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-c4b76070-91f2-44f8-88fc-f137df4e9762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628678573-172.17.0.15-1595309897126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42691,DS-d7d87ebf-7113-40a1-934e-d3b354c8bf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-c9bad7a2-5125-4a6c-9852-1963648cba05,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-68366cef-d8ba-45f3-8f7d-941197cc1b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-f4cbb0e3-1e11-40b1-bf6a-4b5f1963eab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-846eb978-cf08-4c8b-89cc-3b8b83d0f545,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-cf924a63-d92f-40a7-b67a-cc1f6332e746,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-031324f9-b054-4b62-bf6d-7fedd2a206ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-c4b76070-91f2-44f8-88fc-f137df4e9762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87608332-172.17.0.15-1595310129419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39226,DS-8bb007a9-b9cc-447b-9b83-c5f2ef22f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-97730874-381f-4e80-8c7e-6f27c4ec3a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-ea0d6c50-86e1-48a0-83b4-7f89a6a4978c,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-dcc4f1ef-5b88-4256-a361-a42b9ffd77c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-7e22d6c6-109b-4eba-b6ce-79f186381a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-e047f557-a00c-4a22-8011-81b7e703f525,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-ccb04905-765d-40eb-b153-4a89e291f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-5ca8585b-abbc-4b32-8f66-9224170089c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87608332-172.17.0.15-1595310129419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39226,DS-8bb007a9-b9cc-447b-9b83-c5f2ef22f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-97730874-381f-4e80-8c7e-6f27c4ec3a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-ea0d6c50-86e1-48a0-83b4-7f89a6a4978c,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-dcc4f1ef-5b88-4256-a361-a42b9ffd77c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-7e22d6c6-109b-4eba-b6ce-79f186381a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-e047f557-a00c-4a22-8011-81b7e703f525,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-ccb04905-765d-40eb-b153-4a89e291f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-5ca8585b-abbc-4b32-8f66-9224170089c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974429201-172.17.0.15-1595311451135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-499c2654-3432-426a-99ee-1e0305754792,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f4b6b29e-23e8-4e42-9113-9a9a5db5123a,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-75a913c5-9274-405c-b7d5-388c676c0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-3ed30c1e-00bb-4b5d-882f-94add9ab078f,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-ca541224-beb1-4128-977e-a764e222be18,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-5be22a51-7107-470c-bbbf-5950a5c64b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-2554c589-c9e8-4951-a3d9-840e1caaa998,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-055fa963-51fd-4bf5-a677-b25e084ebb8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974429201-172.17.0.15-1595311451135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-499c2654-3432-426a-99ee-1e0305754792,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f4b6b29e-23e8-4e42-9113-9a9a5db5123a,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-75a913c5-9274-405c-b7d5-388c676c0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-3ed30c1e-00bb-4b5d-882f-94add9ab078f,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-ca541224-beb1-4128-977e-a764e222be18,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-5be22a51-7107-470c-bbbf-5950a5c64b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-2554c589-c9e8-4951-a3d9-840e1caaa998,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-055fa963-51fd-4bf5-a677-b25e084ebb8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125607913-172.17.0.15-1595311913312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38167,DS-fb0c29cf-5a3b-4970-ab7a-ab383e1ea8af,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-131540d6-5809-4cde-89d9-aba9465f3b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-3fdffc58-318c-4946-bce8-bbd790f1ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-6ad7950b-6682-403d-88cf-e08abd7aeb93,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-7e2392ea-acd0-4c59-927b-d077d407331a,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-1648e23f-67bc-4947-a94c-9e7762ece407,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-a267d8df-4d89-416a-80dd-6cfec5d09f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-26cd2e86-43d7-4439-bf83-025719416eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125607913-172.17.0.15-1595311913312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38167,DS-fb0c29cf-5a3b-4970-ab7a-ab383e1ea8af,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-131540d6-5809-4cde-89d9-aba9465f3b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-3fdffc58-318c-4946-bce8-bbd790f1ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-6ad7950b-6682-403d-88cf-e08abd7aeb93,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-7e2392ea-acd0-4c59-927b-d077d407331a,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-1648e23f-67bc-4947-a94c-9e7762ece407,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-a267d8df-4d89-416a-80dd-6cfec5d09f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-26cd2e86-43d7-4439-bf83-025719416eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5574
