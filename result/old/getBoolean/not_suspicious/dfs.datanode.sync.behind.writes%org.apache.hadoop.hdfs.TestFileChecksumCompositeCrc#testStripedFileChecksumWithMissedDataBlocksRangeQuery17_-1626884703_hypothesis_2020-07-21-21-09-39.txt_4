reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693430514-172.17.0.9-1595365893455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36503,DS-cdf5be13-952b-4c75-960e-22167b5b8896,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-b01cfb62-4871-4b9b-b12f-e7ad34d952b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-1736b70a-e473-4cc9-916d-72c0e3561a55,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-9060be16-e838-43c9-b951-f6d3dadb334c,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-4a1698a0-31bb-4905-9cee-a27d69e10689,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-cc0eb440-70b1-4c2f-bcb6-4f9da53a5706,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-7580e738-8ee7-4d8d-bdcb-3bd1bd4f4715,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-9b3edab4-4353-4430-998d-1d52340a747b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693430514-172.17.0.9-1595365893455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36503,DS-cdf5be13-952b-4c75-960e-22167b5b8896,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-b01cfb62-4871-4b9b-b12f-e7ad34d952b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-1736b70a-e473-4cc9-916d-72c0e3561a55,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-9060be16-e838-43c9-b951-f6d3dadb334c,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-4a1698a0-31bb-4905-9cee-a27d69e10689,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-cc0eb440-70b1-4c2f-bcb6-4f9da53a5706,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-7580e738-8ee7-4d8d-bdcb-3bd1bd4f4715,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-9b3edab4-4353-4430-998d-1d52340a747b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636158143-172.17.0.9-1595366524604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41644,DS-bfc73ec7-d668-42c0-b8f2-c5e8f44d0dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-53713290-23fe-48ea-b3e7-b884027947ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-906b5298-4409-4926-b86e-774915608d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-74b43cff-340c-4dd2-8384-dedd8cd7252d,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-f0784751-9bc3-4311-be48-d47289119350,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-f89786de-1d22-4e4b-a574-88fcd8ee637f,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-be1a04f5-da09-45d1-becd-6387de1cfdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-22033f1b-3583-4cb4-9612-cfb48dc1cdcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636158143-172.17.0.9-1595366524604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41644,DS-bfc73ec7-d668-42c0-b8f2-c5e8f44d0dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-53713290-23fe-48ea-b3e7-b884027947ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-906b5298-4409-4926-b86e-774915608d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-74b43cff-340c-4dd2-8384-dedd8cd7252d,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-f0784751-9bc3-4311-be48-d47289119350,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-f89786de-1d22-4e4b-a574-88fcd8ee637f,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-be1a04f5-da09-45d1-becd-6387de1cfdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-22033f1b-3583-4cb4-9612-cfb48dc1cdcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110105003-172.17.0.9-1595366552293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37705,DS-ecfc0a82-63ab-4929-8845-47197187b132,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-20087036-94ca-493f-948b-ee56b36685ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-bc7c6700-97fd-45fd-a749-c2856c3ab452,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-940242ee-a743-4dfc-9264-3c6bdb15945f,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-fe3c7db3-8ce8-4436-8121-1eec58d4ae53,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-ed4890a2-a005-499c-8b4b-dd5b03b46aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-2bc6089d-d019-471d-a696-2823e049eab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-8b18444f-ccf0-48ea-9796-5d2b50b239ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110105003-172.17.0.9-1595366552293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37705,DS-ecfc0a82-63ab-4929-8845-47197187b132,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-20087036-94ca-493f-948b-ee56b36685ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-bc7c6700-97fd-45fd-a749-c2856c3ab452,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-940242ee-a743-4dfc-9264-3c6bdb15945f,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-fe3c7db3-8ce8-4436-8121-1eec58d4ae53,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-ed4890a2-a005-499c-8b4b-dd5b03b46aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-2bc6089d-d019-471d-a696-2823e049eab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-8b18444f-ccf0-48ea-9796-5d2b50b239ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199508027-172.17.0.9-1595366581393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34841,DS-a347af49-193b-470a-8d3a-ff0b5f22865d,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-0d401bae-bd06-40a6-8a08-f5f423f716fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-bc3a2148-b656-447c-8fda-629dce5b5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-74c96127-8cd7-45ce-9982-c00f6358c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-36597313-c5fc-499b-93d9-2f371843d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-b7cdbdea-0c93-4be2-9eea-cd5152e6fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-a0ab1a0e-c0a4-4519-83ca-4151ef387fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-26533a0c-5175-4825-bc49-5a27f49861b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199508027-172.17.0.9-1595366581393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34841,DS-a347af49-193b-470a-8d3a-ff0b5f22865d,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-0d401bae-bd06-40a6-8a08-f5f423f716fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-bc3a2148-b656-447c-8fda-629dce5b5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-74c96127-8cd7-45ce-9982-c00f6358c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-36597313-c5fc-499b-93d9-2f371843d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-b7cdbdea-0c93-4be2-9eea-cd5152e6fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-a0ab1a0e-c0a4-4519-83ca-4151ef387fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-26533a0c-5175-4825-bc49-5a27f49861b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768565666-172.17.0.9-1595366617410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-d1b57b48-0015-4ebf-b716-648555732fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-46373e74-3199-41cd-a172-c4595e14d696,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-b0c8eedc-ac68-4bef-8403-bc73e6d1bbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-6101df8b-ff24-4997-a63d-d464179cb5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-666bd8a9-b6eb-41bb-928b-4f55d83dbd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-8c363ff5-0fba-4e66-9f80-8b5ede5f55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-9bf04207-01a9-496c-a476-31976da33a78,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-a41e8b8d-3529-4e31-b395-22e51b4d99fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768565666-172.17.0.9-1595366617410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-d1b57b48-0015-4ebf-b716-648555732fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-46373e74-3199-41cd-a172-c4595e14d696,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-b0c8eedc-ac68-4bef-8403-bc73e6d1bbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-6101df8b-ff24-4997-a63d-d464179cb5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-666bd8a9-b6eb-41bb-928b-4f55d83dbd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-8c363ff5-0fba-4e66-9f80-8b5ede5f55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-9bf04207-01a9-496c-a476-31976da33a78,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-a41e8b8d-3529-4e31-b395-22e51b4d99fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566951232-172.17.0.9-1595366687426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-0732038c-359d-4b7d-b161-ca7450da9220,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-1f66e999-0680-4954-877e-b09b790a0584,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-7e1d38da-af4e-4147-ac28-ab1abbcabbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-420c8ab7-8c51-43e1-a7d5-3f40e93eb038,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-dc2418ed-2f92-4ebd-ade0-3610c5f79b66,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-148649c5-2df1-45c5-9c1a-0cf36c31a6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-2c104c36-65c1-4b1d-913c-2cad9714aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-aacbdd81-a7e9-493d-acf4-f4d87c586ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566951232-172.17.0.9-1595366687426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-0732038c-359d-4b7d-b161-ca7450da9220,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-1f66e999-0680-4954-877e-b09b790a0584,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-7e1d38da-af4e-4147-ac28-ab1abbcabbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-420c8ab7-8c51-43e1-a7d5-3f40e93eb038,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-dc2418ed-2f92-4ebd-ade0-3610c5f79b66,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-148649c5-2df1-45c5-9c1a-0cf36c31a6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-2c104c36-65c1-4b1d-913c-2cad9714aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-aacbdd81-a7e9-493d-acf4-f4d87c586ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174022974-172.17.0.9-1595366911173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44115,DS-6ad86c4c-f02a-4598-87dd-ebf0dbcc2311,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-260a87d8-df6d-4dd6-ba78-2b2e80281949,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-895751cf-be25-4bcd-82d4-97055d577097,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-b4a66854-0a9e-4f30-8ddb-156786c90548,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-e02253ba-ef1b-4686-9c8d-814929ba6a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-6e10b016-a82a-49de-ad47-71b69f17f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-b7e9a5ba-7b81-404b-9ea5-9fefa9549900,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-4b67df2d-d060-49ff-9334-0b4ebda956ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174022974-172.17.0.9-1595366911173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44115,DS-6ad86c4c-f02a-4598-87dd-ebf0dbcc2311,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-260a87d8-df6d-4dd6-ba78-2b2e80281949,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-895751cf-be25-4bcd-82d4-97055d577097,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-b4a66854-0a9e-4f30-8ddb-156786c90548,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-e02253ba-ef1b-4686-9c8d-814929ba6a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-6e10b016-a82a-49de-ad47-71b69f17f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-b7e9a5ba-7b81-404b-9ea5-9fefa9549900,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-4b67df2d-d060-49ff-9334-0b4ebda956ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148308625-172.17.0.9-1595367023769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-a78fa66e-23a3-4a3a-8669-aa726e386d10,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-1dddbe78-f3bc-457b-80b0-6ee5e8b96764,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-a3f7fcb5-43a9-44d9-8ad1-932b1d1ad2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-c9481fb3-5add-49b0-adcd-8c9fb11bf476,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-e4524ed6-fe60-4d2d-93fc-bfe3bd1e28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-59a8f1bb-698e-4f22-93fb-29e134554fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-4811786b-d0d5-4353-b6bd-bfa7ebe5fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-2f25516d-79dd-46f9-ad5d-7a15c32307de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148308625-172.17.0.9-1595367023769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-a78fa66e-23a3-4a3a-8669-aa726e386d10,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-1dddbe78-f3bc-457b-80b0-6ee5e8b96764,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-a3f7fcb5-43a9-44d9-8ad1-932b1d1ad2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-c9481fb3-5add-49b0-adcd-8c9fb11bf476,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-e4524ed6-fe60-4d2d-93fc-bfe3bd1e28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-59a8f1bb-698e-4f22-93fb-29e134554fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-4811786b-d0d5-4353-b6bd-bfa7ebe5fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-2f25516d-79dd-46f9-ad5d-7a15c32307de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229880227-172.17.0.9-1595367272324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34285,DS-397a7d23-7b7b-4147-a978-349778d6ce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-ea73c1ee-c057-487d-9909-19209469c945,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-42b38d70-ff94-47fc-997a-7f808184c25d,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-904c0096-6bfe-4d30-8ba9-33490f261c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-9ad61a5c-5e21-43d6-a6b0-a8484bf3b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-53b06cd0-a032-4d14-8848-db71aff6d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-18abf8af-02c5-4e97-9d18-09a1163a6a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-42f68670-7327-45d1-ba72-7e97f305469a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229880227-172.17.0.9-1595367272324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34285,DS-397a7d23-7b7b-4147-a978-349778d6ce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-ea73c1ee-c057-487d-9909-19209469c945,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-42b38d70-ff94-47fc-997a-7f808184c25d,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-904c0096-6bfe-4d30-8ba9-33490f261c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-9ad61a5c-5e21-43d6-a6b0-a8484bf3b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-53b06cd0-a032-4d14-8848-db71aff6d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-18abf8af-02c5-4e97-9d18-09a1163a6a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-42f68670-7327-45d1-ba72-7e97f305469a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174886376-172.17.0.9-1595367877529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45876,DS-74b03d6f-da17-4c78-92b0-8ae93bfef066,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-b7590764-46bd-4599-a61b-26c63f9bc448,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-278d3092-ba91-48dd-9966-4c396d491e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-2e190754-e01e-4ef7-976a-8e80d2660bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-48bf6ef4-b8f8-4cfa-b478-f3985a899e74,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6d693bad-db58-4832-8425-cc829174c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-0a261e50-b885-4a29-8fa7-ef09cb2a3cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-ae125cdd-0380-4dbe-bb20-11be29b93dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174886376-172.17.0.9-1595367877529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45876,DS-74b03d6f-da17-4c78-92b0-8ae93bfef066,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-b7590764-46bd-4599-a61b-26c63f9bc448,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-278d3092-ba91-48dd-9966-4c396d491e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-2e190754-e01e-4ef7-976a-8e80d2660bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-48bf6ef4-b8f8-4cfa-b478-f3985a899e74,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6d693bad-db58-4832-8425-cc829174c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-0a261e50-b885-4a29-8fa7-ef09cb2a3cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-ae125cdd-0380-4dbe-bb20-11be29b93dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704424722-172.17.0.9-1595368188457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-d579b04b-936d-49ab-bd0f-85e556514b81,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-bc75f491-26db-47c1-9ce3-e71171b9ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-6d28853a-d72e-41a5-a2f5-14de80057df3,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-6bb75556-311b-45b5-88c1-95002517cae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-69a05efc-7e16-4558-9a83-3982ef940802,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-1152f87f-867c-457a-b549-64e65ad6d250,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-8bcc990b-c288-4d40-bf3c-55ff0799d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-7565902f-e4d2-4e39-a69f-3f1e952c5da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704424722-172.17.0.9-1595368188457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-d579b04b-936d-49ab-bd0f-85e556514b81,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-bc75f491-26db-47c1-9ce3-e71171b9ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-6d28853a-d72e-41a5-a2f5-14de80057df3,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-6bb75556-311b-45b5-88c1-95002517cae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-69a05efc-7e16-4558-9a83-3982ef940802,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-1152f87f-867c-457a-b549-64e65ad6d250,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-8bcc990b-c288-4d40-bf3c-55ff0799d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-7565902f-e4d2-4e39-a69f-3f1e952c5da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845231779-172.17.0.9-1595368879984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43954,DS-75c49fe2-4e28-491c-ac26-42e0c141d44a,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-eb0dcfda-8680-4dc1-a6a9-4f36d0a60a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-8c2c6999-3b1f-4a9d-8d4d-b9f114453702,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-074c6743-fb96-4bb2-ace7-c08ef9d96d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-507945a7-6ca5-414d-8715-203214a9f722,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-bb82b311-2789-4679-8491-9adfed518962,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-5b50ded2-7c10-4b8a-95a3-90801c5cbd03,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-f5fd9e9f-4800-4b9b-90ff-cb44098d8f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845231779-172.17.0.9-1595368879984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43954,DS-75c49fe2-4e28-491c-ac26-42e0c141d44a,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-eb0dcfda-8680-4dc1-a6a9-4f36d0a60a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-8c2c6999-3b1f-4a9d-8d4d-b9f114453702,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-074c6743-fb96-4bb2-ace7-c08ef9d96d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-507945a7-6ca5-414d-8715-203214a9f722,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-bb82b311-2789-4679-8491-9adfed518962,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-5b50ded2-7c10-4b8a-95a3-90801c5cbd03,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-f5fd9e9f-4800-4b9b-90ff-cb44098d8f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962792537-172.17.0.9-1595369088784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46349,DS-2049f536-7f95-4c70-8024-797b3cce9460,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-fc5fa133-c346-4946-a0e4-cd38d39da9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-9f33084c-4b4f-48a3-872e-4a4a0e5dd787,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-863bd627-95a0-4d1f-a61d-beeb988c9aef,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-e9a101a7-5f73-4439-8dd0-96f5116846ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-0aaace23-76db-49dc-8689-f9e66c5a8e52,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-0abe3bd4-789a-4dc1-ae4d-cbab69281ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-b2662e16-1849-4622-92a2-08a5afe98d01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962792537-172.17.0.9-1595369088784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46349,DS-2049f536-7f95-4c70-8024-797b3cce9460,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-fc5fa133-c346-4946-a0e4-cd38d39da9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-9f33084c-4b4f-48a3-872e-4a4a0e5dd787,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-863bd627-95a0-4d1f-a61d-beeb988c9aef,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-e9a101a7-5f73-4439-8dd0-96f5116846ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-0aaace23-76db-49dc-8689-f9e66c5a8e52,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-0abe3bd4-789a-4dc1-ae4d-cbab69281ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-b2662e16-1849-4622-92a2-08a5afe98d01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331596003-172.17.0.9-1595369248470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-17e27eb8-473c-4185-9d61-43a184d4c345,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-f681b457-f089-4873-b031-7c4b5d276fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-c3a4dec5-9a1f-489e-9e69-892dd6c4685b,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-5aea4536-7a30-435c-9a1c-02b6709ebddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-74edf571-af6f-4b45-a9b5-9ad9a7876f72,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-74c81dc6-143d-4fcd-8581-99ff5c67a07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-666ff502-ef3f-4396-b82c-c9db51be4417,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-cea7437a-448b-4d58-b334-e85e3aa64b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331596003-172.17.0.9-1595369248470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-17e27eb8-473c-4185-9d61-43a184d4c345,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-f681b457-f089-4873-b031-7c4b5d276fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-c3a4dec5-9a1f-489e-9e69-892dd6c4685b,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-5aea4536-7a30-435c-9a1c-02b6709ebddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-74edf571-af6f-4b45-a9b5-9ad9a7876f72,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-74c81dc6-143d-4fcd-8581-99ff5c67a07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-666ff502-ef3f-4396-b82c-c9db51be4417,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-cea7437a-448b-4d58-b334-e85e3aa64b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859698610-172.17.0.9-1595369690133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-2c9f816b-416b-4941-b5a1-87398999b971,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-2888baca-1c82-4600-a89e-0fc7569d6132,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-193ea7d5-3f5e-472d-be30-63bafa7da7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-c8e66e6b-6f07-487e-9add-a8302bcfe8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-2fed3d7b-0e3a-4e2a-ba76-6046e66d66f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-0fd95c27-5389-4f8d-85b4-8070544b590c,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-a0819975-0ccb-40d5-8f68-be08018455d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-3f2683d4-fa91-415e-8bb9-fbb04acebe69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859698610-172.17.0.9-1595369690133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-2c9f816b-416b-4941-b5a1-87398999b971,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-2888baca-1c82-4600-a89e-0fc7569d6132,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-193ea7d5-3f5e-472d-be30-63bafa7da7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-c8e66e6b-6f07-487e-9add-a8302bcfe8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-2fed3d7b-0e3a-4e2a-ba76-6046e66d66f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-0fd95c27-5389-4f8d-85b4-8070544b590c,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-a0819975-0ccb-40d5-8f68-be08018455d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-3f2683d4-fa91-415e-8bb9-fbb04acebe69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917926144-172.17.0.9-1595369720569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38776,DS-41ebba1b-4fd9-48f4-ae9f-d278847670d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-1d6a069c-8530-496a-a8ad-e6aa59ab54e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-066d3736-725d-4ec1-aaad-6a10d411244f,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-740bbdbe-6137-4f8d-a308-3e4d8530b124,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-0448408d-5f69-45de-961d-6ec975c331f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-597551c9-372f-4581-bf5e-8edb5cd74f64,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-3d543ee4-a816-4aff-a899-905f3810c3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-af63db9c-8684-49cc-84f2-50190bbaa52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917926144-172.17.0.9-1595369720569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38776,DS-41ebba1b-4fd9-48f4-ae9f-d278847670d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-1d6a069c-8530-496a-a8ad-e6aa59ab54e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-066d3736-725d-4ec1-aaad-6a10d411244f,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-740bbdbe-6137-4f8d-a308-3e4d8530b124,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-0448408d-5f69-45de-961d-6ec975c331f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-597551c9-372f-4581-bf5e-8edb5cd74f64,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-3d543ee4-a816-4aff-a899-905f3810c3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-af63db9c-8684-49cc-84f2-50190bbaa52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409533398-172.17.0.9-1595370085731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34953,DS-a5e0a69f-1e0b-4681-90f2-17130aa62563,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-17b8f7b6-6436-4e12-8180-9df5b3fb65e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-41c2464f-d965-411a-be32-855eecf20f66,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-2eb3a153-bdc5-4cf7-9615-6a85d1c0d5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-41bd86a5-7058-42a6-ae0b-7fed17758dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-a4090d76-c195-49cf-895f-963aadb4de26,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-99d126a7-63d8-4954-af9a-184c88f114cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-af294af3-d75e-4ec7-a56b-e1a24bf7870b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409533398-172.17.0.9-1595370085731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34953,DS-a5e0a69f-1e0b-4681-90f2-17130aa62563,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-17b8f7b6-6436-4e12-8180-9df5b3fb65e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-41c2464f-d965-411a-be32-855eecf20f66,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-2eb3a153-bdc5-4cf7-9615-6a85d1c0d5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-41bd86a5-7058-42a6-ae0b-7fed17758dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-a4090d76-c195-49cf-895f-963aadb4de26,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-99d126a7-63d8-4954-af9a-184c88f114cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-af294af3-d75e-4ec7-a56b-e1a24bf7870b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199738851-172.17.0.9-1595370335752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33156,DS-509b9170-168b-4858-936d-6e8c8b95b690,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-ff22d007-8cfe-4b6d-bd27-34a7340985f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-57d4e7f9-add1-485b-88e9-8ac8acd06c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-88ae98c2-206f-463e-bb71-78ef1d2c0dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-b802d3b0-fbcf-4261-968f-f154d7a75608,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-fb1c25f3-515d-42dc-917b-005a8b2b3051,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-5542a290-81be-44c7-8fae-4150bb6ef0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-b07abc93-2ed1-4ce2-b27f-7b561480f39f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199738851-172.17.0.9-1595370335752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33156,DS-509b9170-168b-4858-936d-6e8c8b95b690,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-ff22d007-8cfe-4b6d-bd27-34a7340985f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-57d4e7f9-add1-485b-88e9-8ac8acd06c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-88ae98c2-206f-463e-bb71-78ef1d2c0dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-b802d3b0-fbcf-4261-968f-f154d7a75608,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-fb1c25f3-515d-42dc-917b-005a8b2b3051,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-5542a290-81be-44c7-8fae-4150bb6ef0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-b07abc93-2ed1-4ce2-b27f-7b561480f39f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24921763-172.17.0.9-1595370682296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36490,DS-1ad040c1-5c8b-4231-9b33-c7ae49d9cc02,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-c2bd8acf-f7b5-4c29-ac5c-376fa2a65170,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-7e17b319-1de8-4d07-9333-cee971d33acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-4d51236a-33ea-4506-af51-4615a9991a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-879bf7bd-9e99-458f-ab1b-d3969922b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-5c80cc37-13bc-4666-9ee0-55e3bba4a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-c30b8ab3-b64a-455a-bc07-6b9b40e953f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-d0fcdb3a-9a86-40af-ba04-db93941e7e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24921763-172.17.0.9-1595370682296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36490,DS-1ad040c1-5c8b-4231-9b33-c7ae49d9cc02,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-c2bd8acf-f7b5-4c29-ac5c-376fa2a65170,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-7e17b319-1de8-4d07-9333-cee971d33acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-4d51236a-33ea-4506-af51-4615a9991a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-879bf7bd-9e99-458f-ab1b-d3969922b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-5c80cc37-13bc-4666-9ee0-55e3bba4a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-c30b8ab3-b64a-455a-bc07-6b9b40e953f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-d0fcdb3a-9a86-40af-ba04-db93941e7e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881614718-172.17.0.9-1595370761561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37127,DS-78be7fe1-c07c-432c-a472-a77970c8a48f,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-88fef8ea-7479-4a4d-854e-c6db82d36555,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-43c666bc-5718-4ae0-975a-f5552ddbb02c,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-717096dd-8a19-4a42-96ba-75d5b9e10522,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-f40b34fd-0ac1-47e4-b3de-d237d037b925,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-d14e9ae3-37b0-4826-8128-fa4163c9e890,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-f4d56d3a-fbd1-465b-8959-14465b948df1,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-9479e229-03ce-4def-a6f5-e07ecaf94198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881614718-172.17.0.9-1595370761561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37127,DS-78be7fe1-c07c-432c-a472-a77970c8a48f,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-88fef8ea-7479-4a4d-854e-c6db82d36555,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-43c666bc-5718-4ae0-975a-f5552ddbb02c,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-717096dd-8a19-4a42-96ba-75d5b9e10522,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-f40b34fd-0ac1-47e4-b3de-d237d037b925,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-d14e9ae3-37b0-4826-8128-fa4163c9e890,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-f4d56d3a-fbd1-465b-8959-14465b948df1,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-9479e229-03ce-4def-a6f5-e07ecaf94198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5179
