reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491120818-172.17.0.2-1595364628877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-c3764a08-21c0-4ccd-9871-f136d9d75ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-74de2cac-e083-4bf6-842b-18c8fe8e6598,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-cb777ea2-8401-48b1-973a-69452d80e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-0405f54c-27cd-4b9f-a991-40d7463e2c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-b5b8d5bc-2971-4077-990a-0957bd7874b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-4122e18a-bb95-4b1c-8558-31958938251b,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-70af3277-67fc-4e13-a8f3-7a04bbcb662b,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-842fdaff-e409-42b6-942c-237696da9a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491120818-172.17.0.2-1595364628877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-c3764a08-21c0-4ccd-9871-f136d9d75ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-74de2cac-e083-4bf6-842b-18c8fe8e6598,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-cb777ea2-8401-48b1-973a-69452d80e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-0405f54c-27cd-4b9f-a991-40d7463e2c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-b5b8d5bc-2971-4077-990a-0957bd7874b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-4122e18a-bb95-4b1c-8558-31958938251b,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-70af3277-67fc-4e13-a8f3-7a04bbcb662b,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-842fdaff-e409-42b6-942c-237696da9a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552692494-172.17.0.2-1595364999163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34899,DS-ae5f0a2a-cf8e-4fb6-8b8b-8076d56bd991,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-4d865732-6c8a-49c5-adaa-2089b955ee94,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-c6db47e2-bf6d-42cd-90a2-7f60af7d5487,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-dbf82051-5518-4ac0-84b8-ff2669ad691a,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-e08f44e4-b914-4fea-8cc9-f04f3af88ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-a49bb474-d86d-46e0-a224-584f5abb5b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-3a2dd8f1-2a1f-4391-992f-aa64298dc120,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-34b6185f-3003-4ede-94b2-983fa48d5fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552692494-172.17.0.2-1595364999163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34899,DS-ae5f0a2a-cf8e-4fb6-8b8b-8076d56bd991,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-4d865732-6c8a-49c5-adaa-2089b955ee94,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-c6db47e2-bf6d-42cd-90a2-7f60af7d5487,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-dbf82051-5518-4ac0-84b8-ff2669ad691a,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-e08f44e4-b914-4fea-8cc9-f04f3af88ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-a49bb474-d86d-46e0-a224-584f5abb5b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-3a2dd8f1-2a1f-4391-992f-aa64298dc120,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-34b6185f-3003-4ede-94b2-983fa48d5fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638255706-172.17.0.2-1595365267159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36229,DS-94fe8809-0f0a-4e02-addf-22de311faa11,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-e962ec20-26fd-4ba5-993a-a1e54e6d1f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-b0160902-8171-49dd-8e9c-4f41b132f70a,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-54dc8845-227f-4e67-ad58-e89280d63252,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-8ed0acae-c0b5-4374-975a-d26b138dae67,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-6664761c-75e6-466c-a993-1e5d13aa86f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-d77c23df-a0dc-4142-aa03-acfde1529549,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-37c7c101-b6be-4e21-93bb-bc503a5c0823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638255706-172.17.0.2-1595365267159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36229,DS-94fe8809-0f0a-4e02-addf-22de311faa11,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-e962ec20-26fd-4ba5-993a-a1e54e6d1f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-b0160902-8171-49dd-8e9c-4f41b132f70a,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-54dc8845-227f-4e67-ad58-e89280d63252,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-8ed0acae-c0b5-4374-975a-d26b138dae67,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-6664761c-75e6-466c-a993-1e5d13aa86f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-d77c23df-a0dc-4142-aa03-acfde1529549,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-37c7c101-b6be-4e21-93bb-bc503a5c0823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320916669-172.17.0.2-1595365376103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-10d14222-e165-4d38-bae7-fedea0928117,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-63cdd2c7-91ba-4db3-9634-87eb76ad5171,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-4466168d-ab83-4afd-b1b8-6e0b88c91d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-dfa6658c-48dc-467a-93a2-1070ddbbe28f,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-15d709e3-5156-484f-934d-d9a286bb25de,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-d41249bc-e499-4dc5-898a-05438a95f572,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-424f4101-cf38-47e9-9083-34260faa6bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-cf86726d-d765-426f-ab48-9d7193cf0b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320916669-172.17.0.2-1595365376103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-10d14222-e165-4d38-bae7-fedea0928117,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-63cdd2c7-91ba-4db3-9634-87eb76ad5171,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-4466168d-ab83-4afd-b1b8-6e0b88c91d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-dfa6658c-48dc-467a-93a2-1070ddbbe28f,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-15d709e3-5156-484f-934d-d9a286bb25de,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-d41249bc-e499-4dc5-898a-05438a95f572,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-424f4101-cf38-47e9-9083-34260faa6bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-cf86726d-d765-426f-ab48-9d7193cf0b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544514378-172.17.0.2-1595365982787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-2c2484f0-baa2-40ce-92ec-ee61d9a12cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-0856cfde-7f4f-448b-a9f7-79dbb89226b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-1f03aba3-db1d-48de-908d-ae226610168e,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-c6b32bc6-580e-428f-963e-220199c87ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-f2e5d659-88ec-4d60-a8da-d647b21ebd49,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-7588f3c1-fc4b-46bc-a190-7ccdd3126e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-c2e5c84b-5adc-4429-9644-59405414cae8,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-d75f200c-3d65-40f1-aa52-9899772b8b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544514378-172.17.0.2-1595365982787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-2c2484f0-baa2-40ce-92ec-ee61d9a12cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-0856cfde-7f4f-448b-a9f7-79dbb89226b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-1f03aba3-db1d-48de-908d-ae226610168e,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-c6b32bc6-580e-428f-963e-220199c87ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-f2e5d659-88ec-4d60-a8da-d647b21ebd49,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-7588f3c1-fc4b-46bc-a190-7ccdd3126e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-c2e5c84b-5adc-4429-9644-59405414cae8,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-d75f200c-3d65-40f1-aa52-9899772b8b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771098434-172.17.0.2-1595366195963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-c2b9dc2b-0f1f-47fd-b4be-adefab77bc14,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-30e68cad-678f-424a-bbc5-52515d61d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-ba401f64-df4b-48db-ba0f-43b43e393e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-5cbc78f3-19a2-4f77-a969-13768491b598,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-c3eb51ca-de00-43ad-aa37-0d917e8fcd62,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-760d0b96-7799-4d24-9ee0-22a663b79e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-8c5202f2-9f6f-4641-8e60-a4d569faabe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-ca32f5ea-4bea-4bcf-aac4-e4495babded8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771098434-172.17.0.2-1595366195963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-c2b9dc2b-0f1f-47fd-b4be-adefab77bc14,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-30e68cad-678f-424a-bbc5-52515d61d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-ba401f64-df4b-48db-ba0f-43b43e393e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-5cbc78f3-19a2-4f77-a969-13768491b598,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-c3eb51ca-de00-43ad-aa37-0d917e8fcd62,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-760d0b96-7799-4d24-9ee0-22a663b79e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-8c5202f2-9f6f-4641-8e60-a4d569faabe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-ca32f5ea-4bea-4bcf-aac4-e4495babded8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224818598-172.17.0.2-1595366225723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43276,DS-8d8ed702-dc94-4961-9d7f-13887773b0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f0ce83ed-3d6a-4c0a-9512-665f8d64e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-74023b62-cce5-47a8-b748-dc836cfa1dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-42f9737a-7653-44b1-bc94-c17ac26befb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-eba5ddbc-25cb-49c3-bcdd-830adae1a468,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-11e4eff8-3432-4022-b63b-e0e96f3f93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-0a84517e-8f65-4ef8-bef3-6d864ee065a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-9ac1e9c9-52c1-4839-acbb-0bb08604e11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224818598-172.17.0.2-1595366225723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43276,DS-8d8ed702-dc94-4961-9d7f-13887773b0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f0ce83ed-3d6a-4c0a-9512-665f8d64e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-74023b62-cce5-47a8-b748-dc836cfa1dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-42f9737a-7653-44b1-bc94-c17ac26befb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-eba5ddbc-25cb-49c3-bcdd-830adae1a468,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-11e4eff8-3432-4022-b63b-e0e96f3f93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-0a84517e-8f65-4ef8-bef3-6d864ee065a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-9ac1e9c9-52c1-4839-acbb-0bb08604e11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177184850-172.17.0.2-1595366326319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-8f6d163c-b6a3-4f3e-a6f7-d06df984ddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-0975ba6a-3496-4153-9dcf-fcdb380da272,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-1124786f-159d-4bbd-8182-024397a95dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-bcf16a72-9410-4621-ab3a-6111d169bfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-c5c5fb5f-7a44-4df4-bb35-081001166c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-0814c5b7-98b6-4469-9f77-d5c9fd6c1698,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-bb96e619-1204-4381-a8b7-9f5bdafadb72,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-eeebe6ea-ae1e-44f6-9848-2e1776b2f312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177184850-172.17.0.2-1595366326319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-8f6d163c-b6a3-4f3e-a6f7-d06df984ddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-0975ba6a-3496-4153-9dcf-fcdb380da272,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-1124786f-159d-4bbd-8182-024397a95dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-bcf16a72-9410-4621-ab3a-6111d169bfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-c5c5fb5f-7a44-4df4-bb35-081001166c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-0814c5b7-98b6-4469-9f77-d5c9fd6c1698,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-bb96e619-1204-4381-a8b7-9f5bdafadb72,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-eeebe6ea-ae1e-44f6-9848-2e1776b2f312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179369605-172.17.0.2-1595366539362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-4d9e02c6-4bb0-483c-977a-c18acb2dd74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-87c57826-d677-43a3-adb8-fa2d443f57f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-cc995480-f288-4324-a2f9-84c5ccf7aeed,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-05bd2683-f9a9-44b3-81af-5bc520a3e56a,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-201370e8-4029-4c52-a660-9f487886c537,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-b04a1b29-c96a-4651-9326-ed5d7c5aeb64,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-e4562816-a6e5-4152-8909-dd82249693b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-2f7195bc-afe1-4830-b602-9e76a4f29d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179369605-172.17.0.2-1595366539362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-4d9e02c6-4bb0-483c-977a-c18acb2dd74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-87c57826-d677-43a3-adb8-fa2d443f57f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-cc995480-f288-4324-a2f9-84c5ccf7aeed,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-05bd2683-f9a9-44b3-81af-5bc520a3e56a,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-201370e8-4029-4c52-a660-9f487886c537,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-b04a1b29-c96a-4651-9326-ed5d7c5aeb64,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-e4562816-a6e5-4152-8909-dd82249693b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-2f7195bc-afe1-4830-b602-9e76a4f29d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105069520-172.17.0.2-1595367467958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38054,DS-616e78e7-e1be-4962-aa0b-474218d46d51,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-5cceef8d-9fb1-49ba-9e59-f006373834f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-b1b5bb10-6b1f-4222-a6a2-cfeaeec0adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-79dd24c0-b035-4791-aa6b-9f4b62077614,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-4837170b-ba63-45fd-9839-0adc2e6c3301,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-06e1135e-53cf-4ce0-9f12-1191e9771586,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-2365e01d-6da7-4331-b274-8693d396ef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-c06c5a18-2a53-44fe-b2cd-0087f4f72735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105069520-172.17.0.2-1595367467958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38054,DS-616e78e7-e1be-4962-aa0b-474218d46d51,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-5cceef8d-9fb1-49ba-9e59-f006373834f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-b1b5bb10-6b1f-4222-a6a2-cfeaeec0adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-79dd24c0-b035-4791-aa6b-9f4b62077614,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-4837170b-ba63-45fd-9839-0adc2e6c3301,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-06e1135e-53cf-4ce0-9f12-1191e9771586,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-2365e01d-6da7-4331-b274-8693d396ef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-c06c5a18-2a53-44fe-b2cd-0087f4f72735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700397604-172.17.0.2-1595367525860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38752,DS-d8104e25-541f-47d4-9635-0ebab5ee67b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-81d1b052-ef04-4186-a634-26d15e34af57,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-25f65c61-f131-4f32-bee8-8cb972f31f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-cbe77581-f899-4aa1-8864-9779b1657c84,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-a06bed32-6bf9-4233-9b82-a975a9c3f4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-e25d0221-8502-408e-a359-cfb57eff2e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-720460de-0651-44f3-b5af-2e742c3a6b71,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-904c8374-6e89-4421-852a-d0f6e3fc513c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700397604-172.17.0.2-1595367525860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38752,DS-d8104e25-541f-47d4-9635-0ebab5ee67b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-81d1b052-ef04-4186-a634-26d15e34af57,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-25f65c61-f131-4f32-bee8-8cb972f31f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-cbe77581-f899-4aa1-8864-9779b1657c84,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-a06bed32-6bf9-4233-9b82-a975a9c3f4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-e25d0221-8502-408e-a359-cfb57eff2e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-720460de-0651-44f3-b5af-2e742c3a6b71,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-904c8374-6e89-4421-852a-d0f6e3fc513c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009133207-172.17.0.2-1595367782227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35477,DS-574b5929-ed53-4f1c-8309-574e3799742c,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-37d081b9-a7a5-4a2e-9f6e-3cec861fb963,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-8f6844bf-e2bf-4927-99de-08fab7934129,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-10b39b4d-3a8a-4eda-b2b0-f2063fbafa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-17bf6c22-c56e-4b76-b0a1-ecd25a2bf02d,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-0973e05e-2477-4dd8-b3a0-ea839bf3efc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-4beb3ecf-67c9-423f-b3cd-b8803fc60297,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-72ddc948-07df-4b83-ac58-686f56d85e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009133207-172.17.0.2-1595367782227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35477,DS-574b5929-ed53-4f1c-8309-574e3799742c,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-37d081b9-a7a5-4a2e-9f6e-3cec861fb963,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-8f6844bf-e2bf-4927-99de-08fab7934129,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-10b39b4d-3a8a-4eda-b2b0-f2063fbafa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-17bf6c22-c56e-4b76-b0a1-ecd25a2bf02d,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-0973e05e-2477-4dd8-b3a0-ea839bf3efc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-4beb3ecf-67c9-423f-b3cd-b8803fc60297,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-72ddc948-07df-4b83-ac58-686f56d85e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576618821-172.17.0.2-1595367916310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34865,DS-3d051804-52c6-49e4-a37f-0107a45710e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-86c59d0e-90a5-4240-8388-bc9b15935991,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-d7c1b866-111f-437b-b41d-68468dae2bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-2f26a56f-df7f-4d24-a69a-f210cb2de3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-e5efc72a-8570-4a69-b912-9f5ab0a5bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-bf623f76-388d-48b6-b955-f94ed70acfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-f6f472d6-a719-4e8c-9cab-82dc6d842eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-81c9d672-71c7-4792-a7aa-eb35dfd84d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576618821-172.17.0.2-1595367916310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34865,DS-3d051804-52c6-49e4-a37f-0107a45710e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-86c59d0e-90a5-4240-8388-bc9b15935991,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-d7c1b866-111f-437b-b41d-68468dae2bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-2f26a56f-df7f-4d24-a69a-f210cb2de3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-e5efc72a-8570-4a69-b912-9f5ab0a5bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-bf623f76-388d-48b6-b955-f94ed70acfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-f6f472d6-a719-4e8c-9cab-82dc6d842eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-81c9d672-71c7-4792-a7aa-eb35dfd84d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956519524-172.17.0.2-1595368238722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36186,DS-1b264528-10d0-425a-a341-eac749b50f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-762d10f5-9e45-4f26-b75b-8808ca12e67b,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-dc2c6a77-a056-49ad-bae9-cd0c35a9703c,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-5d3f7076-7593-4fb1-94ca-bf085544db54,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-4d87d79e-b786-4b11-ade0-731cea47edaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-5496ee92-41db-45d1-a47a-88f2ebc474e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-6a387bfe-4b6f-416b-a831-4ed144acab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-236b598c-0c6e-430c-95dc-49c83ed465b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956519524-172.17.0.2-1595368238722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36186,DS-1b264528-10d0-425a-a341-eac749b50f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-762d10f5-9e45-4f26-b75b-8808ca12e67b,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-dc2c6a77-a056-49ad-bae9-cd0c35a9703c,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-5d3f7076-7593-4fb1-94ca-bf085544db54,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-4d87d79e-b786-4b11-ade0-731cea47edaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-5496ee92-41db-45d1-a47a-88f2ebc474e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-6a387bfe-4b6f-416b-a831-4ed144acab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-236b598c-0c6e-430c-95dc-49c83ed465b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124334103-172.17.0.2-1595368434330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44347,DS-89dd4610-8b12-484c-8f0c-959f63d4c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-46a5a275-0250-48e8-88af-841f034aadb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-5197ad41-6f04-4df0-942e-b7a1665b71f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-3a02dc33-913a-4b30-96a5-c974acee9ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-c80c54aa-81a6-4281-a9ad-de72edf75572,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-2669befd-6dee-4509-9742-cc57a0fbc80e,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-fef2d146-82a7-4f2e-b842-be2919dd988c,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-9e26fc58-9b47-4c59-883b-028d7ab13acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124334103-172.17.0.2-1595368434330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44347,DS-89dd4610-8b12-484c-8f0c-959f63d4c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-46a5a275-0250-48e8-88af-841f034aadb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-5197ad41-6f04-4df0-942e-b7a1665b71f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-3a02dc33-913a-4b30-96a5-c974acee9ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-c80c54aa-81a6-4281-a9ad-de72edf75572,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-2669befd-6dee-4509-9742-cc57a0fbc80e,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-fef2d146-82a7-4f2e-b842-be2919dd988c,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-9e26fc58-9b47-4c59-883b-028d7ab13acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095092175-172.17.0.2-1595368955564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-cd99f7df-ce19-437e-829f-d25aae6bbb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-282b7bf8-6add-4827-84b1-b95cdc6b146f,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-cb8e1fb5-137f-48c2-8645-8210e9c9c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-71251687-63b1-457b-bd9a-1c1294f4599f,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-5ff859f7-0f94-4597-8e8f-e0acc30047c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-83d7bc2c-6bcd-404b-8358-72c3af61b661,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-1a87162d-f88d-4274-aac5-f76109353901,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-1ac7ab57-c7fe-4334-8649-2ddd40257164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095092175-172.17.0.2-1595368955564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-cd99f7df-ce19-437e-829f-d25aae6bbb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-282b7bf8-6add-4827-84b1-b95cdc6b146f,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-cb8e1fb5-137f-48c2-8645-8210e9c9c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-71251687-63b1-457b-bd9a-1c1294f4599f,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-5ff859f7-0f94-4597-8e8f-e0acc30047c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-83d7bc2c-6bcd-404b-8358-72c3af61b661,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-1a87162d-f88d-4274-aac5-f76109353901,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-1ac7ab57-c7fe-4334-8649-2ddd40257164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4888
