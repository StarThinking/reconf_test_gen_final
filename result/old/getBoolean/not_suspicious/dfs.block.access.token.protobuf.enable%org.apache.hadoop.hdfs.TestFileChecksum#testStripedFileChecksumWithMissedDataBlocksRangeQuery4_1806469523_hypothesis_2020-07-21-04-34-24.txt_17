reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596359466-172.17.0.18-1595306330151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-fba2d0b4-931f-4742-8ea7-06791f6db5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-8fb4391c-6551-4cef-8b46-865c1c449cad,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-1d8d78c6-a172-4d61-9fcf-ee8a8d1b1201,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-a05a8710-3e79-45a3-b1f1-0df728fed594,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-9b37c706-ea06-4b7c-a0f5-a708bfe66c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-870264e9-683f-4184-84a9-405b69a1b347,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-5f983a36-1e44-4bea-bd99-296664a2a992,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-9b79b662-6ed0-48ce-9a0b-1a86a04571dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596359466-172.17.0.18-1595306330151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-fba2d0b4-931f-4742-8ea7-06791f6db5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-8fb4391c-6551-4cef-8b46-865c1c449cad,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-1d8d78c6-a172-4d61-9fcf-ee8a8d1b1201,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-a05a8710-3e79-45a3-b1f1-0df728fed594,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-9b37c706-ea06-4b7c-a0f5-a708bfe66c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-870264e9-683f-4184-84a9-405b69a1b347,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-5f983a36-1e44-4bea-bd99-296664a2a992,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-9b79b662-6ed0-48ce-9a0b-1a86a04571dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113181691-172.17.0.18-1595306929746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42516,DS-bde1a434-6dda-46a2-a974-d97b455627f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-b18c1920-d99c-4ecc-8f8e-fa40a9debd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-e5fb832e-7544-4dd2-a5fa-1c026378a652,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-0d14a0eb-4a77-4603-abfa-24953025c87e,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-b3e3dfd1-a379-484c-b182-4e0a9c39b304,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-b52eb341-17f4-4182-9c7f-c3148e380ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-2fe3a8be-6536-4d6d-9727-458eb3bfad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-2f3738c0-9b1f-4eda-9e89-807fc0903c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113181691-172.17.0.18-1595306929746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42516,DS-bde1a434-6dda-46a2-a974-d97b455627f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-b18c1920-d99c-4ecc-8f8e-fa40a9debd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-e5fb832e-7544-4dd2-a5fa-1c026378a652,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-0d14a0eb-4a77-4603-abfa-24953025c87e,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-b3e3dfd1-a379-484c-b182-4e0a9c39b304,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-b52eb341-17f4-4182-9c7f-c3148e380ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-2fe3a8be-6536-4d6d-9727-458eb3bfad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-2f3738c0-9b1f-4eda-9e89-807fc0903c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506297124-172.17.0.18-1595307290334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44873,DS-4667312f-0629-4bc5-9e14-0217cd738195,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-948ed51d-68f5-422d-94a5-5bd2e05334e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-f8e6e821-dce6-4b58-a770-92b90b411522,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-bf248090-e85e-4df8-9b7a-c757108d4e88,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-182f1aae-6027-4852-a2a4-9da2aa8c75f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-109419fa-6645-42d9-8357-92a3bcb1f696,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-036e1a33-22be-4c77-9ba9-6f2259c89a90,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-1b7adcff-e360-415d-a739-a775d590b1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506297124-172.17.0.18-1595307290334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44873,DS-4667312f-0629-4bc5-9e14-0217cd738195,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-948ed51d-68f5-422d-94a5-5bd2e05334e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-f8e6e821-dce6-4b58-a770-92b90b411522,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-bf248090-e85e-4df8-9b7a-c757108d4e88,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-182f1aae-6027-4852-a2a4-9da2aa8c75f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-109419fa-6645-42d9-8357-92a3bcb1f696,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-036e1a33-22be-4c77-9ba9-6f2259c89a90,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-1b7adcff-e360-415d-a739-a775d590b1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29487941-172.17.0.18-1595307700789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-ba439b1f-ddb4-48a4-8c54-0837c9a3d022,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-5ffd91d3-5150-4264-8362-a78b28f4e32e,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-2df80b15-662f-4712-90c5-4c2936388ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-a109b18d-b32c-4832-834e-583f35b83962,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-36155cb2-07ad-4845-b2ca-fdc055bb6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-f5d50621-04c0-4d2b-93c2-fdfb55eb5235,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-0a55dcbe-337c-4025-bad9-a452606d313e,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-f8d849ad-ba4c-4eb6-976a-de84b8980674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29487941-172.17.0.18-1595307700789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-ba439b1f-ddb4-48a4-8c54-0837c9a3d022,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-5ffd91d3-5150-4264-8362-a78b28f4e32e,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-2df80b15-662f-4712-90c5-4c2936388ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-a109b18d-b32c-4832-834e-583f35b83962,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-36155cb2-07ad-4845-b2ca-fdc055bb6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-f5d50621-04c0-4d2b-93c2-fdfb55eb5235,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-0a55dcbe-337c-4025-bad9-a452606d313e,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-f8d849ad-ba4c-4eb6-976a-de84b8980674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451697950-172.17.0.18-1595308857595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-e3973ed4-6d0b-4376-8fff-f90fb558d73f,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-fef8f531-1f69-447e-8427-e4521d017c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-b93f0934-eaa1-48eb-907d-c09715c80462,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-a0cb3905-c36b-4efc-ada5-e4743a2cb0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-1126ea9f-0e40-4457-b6cb-ad99c604c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-efa48fea-6184-4e98-9508-e3ebd9a51e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-3ef2a15d-183e-43fc-9667-97140109e353,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-f5ab7667-43ea-40f7-b4c3-fcdd67183865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451697950-172.17.0.18-1595308857595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-e3973ed4-6d0b-4376-8fff-f90fb558d73f,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-fef8f531-1f69-447e-8427-e4521d017c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-b93f0934-eaa1-48eb-907d-c09715c80462,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-a0cb3905-c36b-4efc-ada5-e4743a2cb0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-1126ea9f-0e40-4457-b6cb-ad99c604c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-efa48fea-6184-4e98-9508-e3ebd9a51e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-3ef2a15d-183e-43fc-9667-97140109e353,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-f5ab7667-43ea-40f7-b4c3-fcdd67183865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736691021-172.17.0.18-1595309270351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40798,DS-06894168-4423-4ec7-be40-c7261bbd49c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-1f71d428-24aa-4805-a35c-e4ffedff45ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-850a34f4-4c01-4261-b8f4-dcda3904604f,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-c90c075d-98c3-4115-bac1-bfcf02656b28,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-9112ff39-fcc5-45e0-8cdf-82771260cba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-377859e6-a39b-4b47-bcfe-79a80801c85c,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-b1abe8b0-5019-4ae1-9ef0-c53ff9088cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-2932c1c4-329d-408d-9cb9-687474e35062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736691021-172.17.0.18-1595309270351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40798,DS-06894168-4423-4ec7-be40-c7261bbd49c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-1f71d428-24aa-4805-a35c-e4ffedff45ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-850a34f4-4c01-4261-b8f4-dcda3904604f,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-c90c075d-98c3-4115-bac1-bfcf02656b28,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-9112ff39-fcc5-45e0-8cdf-82771260cba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-377859e6-a39b-4b47-bcfe-79a80801c85c,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-b1abe8b0-5019-4ae1-9ef0-c53ff9088cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-2932c1c4-329d-408d-9cb9-687474e35062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443543273-172.17.0.18-1595310496928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45153,DS-748bdc88-1ed8-45b0-b92f-34e385551451,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-9cb71018-85f3-40fa-b520-2eeddb45f906,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-914b4dc8-6d77-4767-bbc0-94a285850080,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-2bd688fb-aff0-437d-9af1-c0b9e6518535,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-f12fbc16-8291-4c3c-9fcb-3ff2d7969360,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-e2712331-e815-4b3e-b8f0-59726302b7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-ede56b9f-19cc-415f-b64c-55a00584fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-258eb547-7aae-4f22-a152-ba6ba00b91d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443543273-172.17.0.18-1595310496928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45153,DS-748bdc88-1ed8-45b0-b92f-34e385551451,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-9cb71018-85f3-40fa-b520-2eeddb45f906,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-914b4dc8-6d77-4767-bbc0-94a285850080,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-2bd688fb-aff0-437d-9af1-c0b9e6518535,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-f12fbc16-8291-4c3c-9fcb-3ff2d7969360,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-e2712331-e815-4b3e-b8f0-59726302b7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-ede56b9f-19cc-415f-b64c-55a00584fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-258eb547-7aae-4f22-a152-ba6ba00b91d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050909744-172.17.0.18-1595310949384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-48c22ef0-7171-4553-a044-eac6294076da,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-a1e76039-7241-48b3-ae81-858ac8a045e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-a1fa60b2-7134-4b28-862d-0a3be8731b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-7dd2b0c0-bf4e-471e-9826-1c09af155bad,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-501af639-f85d-4d65-b3b9-aff3fe82155d,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-306a5a30-e58c-4dc0-b57f-db38f74235fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-18d7ecda-6fba-4bde-98c6-03a0ac744bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-11f9a4f5-1de4-4c97-b0ae-6c7b6194f520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050909744-172.17.0.18-1595310949384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-48c22ef0-7171-4553-a044-eac6294076da,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-a1e76039-7241-48b3-ae81-858ac8a045e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-a1fa60b2-7134-4b28-862d-0a3be8731b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-7dd2b0c0-bf4e-471e-9826-1c09af155bad,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-501af639-f85d-4d65-b3b9-aff3fe82155d,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-306a5a30-e58c-4dc0-b57f-db38f74235fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-18d7ecda-6fba-4bde-98c6-03a0ac744bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-11f9a4f5-1de4-4c97-b0ae-6c7b6194f520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928081303-172.17.0.18-1595310989241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-2c753cd3-32a5-462e-84da-369734db1dff,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-5641e451-3c46-465d-9e6c-34c2f047acd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-b7425e30-3102-41f8-9523-9a94988bc176,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-e0eb4b40-c6d1-4126-8abb-4018b36ff133,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-5306f5c9-8200-4c4f-b58f-a06eb6098f27,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-2e5d8317-d31c-4a84-816d-5ea1584bc26c,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-38942c73-4741-4168-868b-0f3234512e42,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-5b67d491-e8fe-44ba-97a3-e3c448a52813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928081303-172.17.0.18-1595310989241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-2c753cd3-32a5-462e-84da-369734db1dff,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-5641e451-3c46-465d-9e6c-34c2f047acd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-b7425e30-3102-41f8-9523-9a94988bc176,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-e0eb4b40-c6d1-4126-8abb-4018b36ff133,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-5306f5c9-8200-4c4f-b58f-a06eb6098f27,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-2e5d8317-d31c-4a84-816d-5ea1584bc26c,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-38942c73-4741-4168-868b-0f3234512e42,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-5b67d491-e8fe-44ba-97a3-e3c448a52813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51971203-172.17.0.18-1595312125285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41101,DS-9e63c5ae-93c8-4827-b30e-154a845fa5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-4c2dc6b1-34ee-4a0a-ad50-b69e5c06844a,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-98c32c0f-2d8f-44c4-86b6-e0f15b29c278,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-5a7d0e1c-c010-4976-99fc-6426cb5e3f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-806edf88-20e0-4e57-939f-028712171e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-88e5cd8a-4f71-44c4-8887-89d6ba4e90fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-94db46dc-84bb-41d8-bfb6-ed440ef4db71,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-aecee036-2182-406b-bd75-e0fc5e7d82f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51971203-172.17.0.18-1595312125285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41101,DS-9e63c5ae-93c8-4827-b30e-154a845fa5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-4c2dc6b1-34ee-4a0a-ad50-b69e5c06844a,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-98c32c0f-2d8f-44c4-86b6-e0f15b29c278,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-5a7d0e1c-c010-4976-99fc-6426cb5e3f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-806edf88-20e0-4e57-939f-028712171e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-88e5cd8a-4f71-44c4-8887-89d6ba4e90fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-94db46dc-84bb-41d8-bfb6-ed440ef4db71,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-aecee036-2182-406b-bd75-e0fc5e7d82f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432430066-172.17.0.18-1595312482706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-cf0362f6-01a4-41a3-b271-182ae71a0245,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-a58cf06a-951c-4632-9684-d72af7a87b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-65046d50-830b-4053-a252-c0eb7534226c,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-57d7fb76-cd9a-411f-b68e-00dde500292a,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-c3646f86-5a50-47a5-81f6-234920188843,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-2d8ffecd-e432-40db-beeb-cfca71e200f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-ead8f1ec-8ebe-4011-b657-7166f09e69f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-2831177f-fdef-49bf-8d0d-ec9bc31c5306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432430066-172.17.0.18-1595312482706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-cf0362f6-01a4-41a3-b271-182ae71a0245,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-a58cf06a-951c-4632-9684-d72af7a87b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-65046d50-830b-4053-a252-c0eb7534226c,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-57d7fb76-cd9a-411f-b68e-00dde500292a,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-c3646f86-5a50-47a5-81f6-234920188843,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-2d8ffecd-e432-40db-beeb-cfca71e200f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-ead8f1ec-8ebe-4011-b657-7166f09e69f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-2831177f-fdef-49bf-8d0d-ec9bc31c5306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6441
