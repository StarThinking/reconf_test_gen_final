reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122190466-172.17.0.11-1595358686196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-2770bf89-7216-416e-aeb1-3a161b634c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-da4e56de-9215-42fc-8783-2f4276ed3137,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-83ffecd5-9c2b-446f-bc31-87c184fea24f,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-9315f6dd-1db4-4760-9e02-d5d42a22022b,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-dfaf6671-f114-443a-af7e-95fb15a961bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-7fe4e037-95d8-406e-9ac1-bc782a55c414,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-c6ca551b-b749-408c-94c8-a24ffb147e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-86a828fb-acb1-45c5-b3c8-a5e5b5f2ddcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122190466-172.17.0.11-1595358686196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-2770bf89-7216-416e-aeb1-3a161b634c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-da4e56de-9215-42fc-8783-2f4276ed3137,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-83ffecd5-9c2b-446f-bc31-87c184fea24f,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-9315f6dd-1db4-4760-9e02-d5d42a22022b,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-dfaf6671-f114-443a-af7e-95fb15a961bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-7fe4e037-95d8-406e-9ac1-bc782a55c414,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-c6ca551b-b749-408c-94c8-a24ffb147e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-86a828fb-acb1-45c5-b3c8-a5e5b5f2ddcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-843241138-172.17.0.11-1595358969532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-4d14d52c-be0b-4a24-bdba-456701695ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-f44095c2-94f2-427b-9d44-d07081307b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-70c37a17-94dd-4bed-b260-3ecf59446e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-57863686-0446-4bc7-96c5-629a929a303c,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-3279c264-0a18-4355-9cb4-3697d540f4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-af6a9fc0-edce-472a-a76b-04a585f4946b,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-77e769a4-741a-4e47-8025-b7c59176d73c,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-758fc056-e119-4057-8c91-b92565014cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-843241138-172.17.0.11-1595358969532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-4d14d52c-be0b-4a24-bdba-456701695ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-f44095c2-94f2-427b-9d44-d07081307b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-70c37a17-94dd-4bed-b260-3ecf59446e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-57863686-0446-4bc7-96c5-629a929a303c,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-3279c264-0a18-4355-9cb4-3697d540f4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-af6a9fc0-edce-472a-a76b-04a585f4946b,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-77e769a4-741a-4e47-8025-b7c59176d73c,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-758fc056-e119-4057-8c91-b92565014cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231775001-172.17.0.11-1595359030234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34581,DS-50d3c875-4a44-44e4-a513-bfad04779b41,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-f5cf9ab1-7805-47e6-9696-b8885183611c,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-20a1f7fc-6a07-4784-b95a-fa3d8970818b,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-2f5a3611-a789-4f5a-8f48-57ae601ca52b,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-29ece8a2-971c-4bfd-9b30-016fbe7e861e,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-3824ce21-f84b-42a1-b84b-8860420b7d50,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-c3a46359-2ec3-4f1c-9aa8-6737660eef59,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-b8939c2a-66a8-4e93-8e44-914e557281c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231775001-172.17.0.11-1595359030234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34581,DS-50d3c875-4a44-44e4-a513-bfad04779b41,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-f5cf9ab1-7805-47e6-9696-b8885183611c,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-20a1f7fc-6a07-4784-b95a-fa3d8970818b,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-2f5a3611-a789-4f5a-8f48-57ae601ca52b,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-29ece8a2-971c-4bfd-9b30-016fbe7e861e,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-3824ce21-f84b-42a1-b84b-8860420b7d50,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-c3a46359-2ec3-4f1c-9aa8-6737660eef59,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-b8939c2a-66a8-4e93-8e44-914e557281c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762779178-172.17.0.11-1595359452250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-c8fa5d64-c6ff-4587-a43a-63c1bc65fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-4420f312-22cd-4e58-babb-421d66489a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-2d433de1-9244-4d3b-9361-5e098307406d,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-cce15b17-235f-45e2-83bf-3c8dc6983a88,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-9e448a71-3700-45ab-91c0-1be9e23ece35,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-cb10f9b7-1c5e-4208-b848-a64541d87725,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-ce8d4f6f-43ae-478a-8732-640ba6d75af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-396724ab-5146-466b-b74f-053a4c3b7664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762779178-172.17.0.11-1595359452250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-c8fa5d64-c6ff-4587-a43a-63c1bc65fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-4420f312-22cd-4e58-babb-421d66489a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-2d433de1-9244-4d3b-9361-5e098307406d,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-cce15b17-235f-45e2-83bf-3c8dc6983a88,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-9e448a71-3700-45ab-91c0-1be9e23ece35,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-cb10f9b7-1c5e-4208-b848-a64541d87725,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-ce8d4f6f-43ae-478a-8732-640ba6d75af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-396724ab-5146-466b-b74f-053a4c3b7664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780811884-172.17.0.11-1595359557664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40950,DS-3e4b0d1c-1dfd-4f4e-b5ca-815458708da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-8f311af0-d15b-47ef-a11e-5706b389782c,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-6d54d091-74d2-4223-b6de-8cb249ad2fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-84a3a25c-62bf-4b63-b7d3-6c7805cbc57a,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-a3c1d5f9-0229-480f-b886-181a793e9f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-489083a0-708b-40ec-ad6b-2572884f13d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-c5b5fff0-ef82-4cc8-bc02-e9537672ff00,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-adf066a0-a4f3-4e9d-a63d-f6757a241fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780811884-172.17.0.11-1595359557664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40950,DS-3e4b0d1c-1dfd-4f4e-b5ca-815458708da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-8f311af0-d15b-47ef-a11e-5706b389782c,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-6d54d091-74d2-4223-b6de-8cb249ad2fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-84a3a25c-62bf-4b63-b7d3-6c7805cbc57a,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-a3c1d5f9-0229-480f-b886-181a793e9f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-489083a0-708b-40ec-ad6b-2572884f13d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-c5b5fff0-ef82-4cc8-bc02-e9537672ff00,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-adf066a0-a4f3-4e9d-a63d-f6757a241fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936435608-172.17.0.11-1595359629357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35413,DS-b54d0d6e-b492-48e1-b98c-68734b7ba9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-5cd5d189-ba56-40a8-bf55-39ce6a2962e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-b5542ffa-f2c8-42a1-9e30-91370b7595fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-b23d9726-be64-420c-8509-45caf9becf70,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-923714bc-57a5-4a5c-bf00-14538d493cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-d530fb93-3518-49ba-a797-7177f9035ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-3208728e-1761-45c0-87e9-8394ea98099c,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-2c748c12-1000-424b-97f8-3472f3911171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936435608-172.17.0.11-1595359629357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35413,DS-b54d0d6e-b492-48e1-b98c-68734b7ba9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-5cd5d189-ba56-40a8-bf55-39ce6a2962e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-b5542ffa-f2c8-42a1-9e30-91370b7595fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-b23d9726-be64-420c-8509-45caf9becf70,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-923714bc-57a5-4a5c-bf00-14538d493cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-d530fb93-3518-49ba-a797-7177f9035ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-3208728e-1761-45c0-87e9-8394ea98099c,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-2c748c12-1000-424b-97f8-3472f3911171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789043508-172.17.0.11-1595359790770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45399,DS-ef3dac4a-cef3-4baf-a482-b322fcf40feb,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-dccdd794-a02e-434e-b3f6-6fb30953876e,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-57e7f20d-3532-416a-8aad-b8517192491f,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-528f1c09-75de-4bf4-9bd2-c5290f4b1611,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-4e5b3545-df93-47d0-8bca-84ea74a98743,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-e2b78417-af2e-4dc0-b986-ab7d82298dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-194bb0b1-ac98-4f25-b06a-27983bb7dc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-b79115f7-d922-43a2-8e21-0cb33cf14e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789043508-172.17.0.11-1595359790770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45399,DS-ef3dac4a-cef3-4baf-a482-b322fcf40feb,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-dccdd794-a02e-434e-b3f6-6fb30953876e,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-57e7f20d-3532-416a-8aad-b8517192491f,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-528f1c09-75de-4bf4-9bd2-c5290f4b1611,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-4e5b3545-df93-47d0-8bca-84ea74a98743,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-e2b78417-af2e-4dc0-b986-ab7d82298dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-194bb0b1-ac98-4f25-b06a-27983bb7dc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-b79115f7-d922-43a2-8e21-0cb33cf14e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607171183-172.17.0.11-1595360044134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-a7523179-9654-44b2-af4a-b12dc566c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-d07182ff-698c-4970-95d2-c680b352f3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-55a33680-2fdc-4f8d-9a16-9d1692c8459c,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-03f4c019-4820-43b1-ad2d-0a01c6521677,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-7deb7230-0318-4bac-8192-2249e5183af5,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-a1fefc23-1d7e-4b67-bd16-3be3a47bc30e,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-8f9cdfc3-b92c-49f5-bc83-1718998b4bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-40106a6a-8b57-4c78-8d8f-aa6d55fe6a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607171183-172.17.0.11-1595360044134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-a7523179-9654-44b2-af4a-b12dc566c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-d07182ff-698c-4970-95d2-c680b352f3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-55a33680-2fdc-4f8d-9a16-9d1692c8459c,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-03f4c019-4820-43b1-ad2d-0a01c6521677,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-7deb7230-0318-4bac-8192-2249e5183af5,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-a1fefc23-1d7e-4b67-bd16-3be3a47bc30e,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-8f9cdfc3-b92c-49f5-bc83-1718998b4bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-40106a6a-8b57-4c78-8d8f-aa6d55fe6a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567675915-172.17.0.11-1595360408552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41573,DS-22e166e2-e5af-4669-8126-ac0d0a78a016,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-8284c5c7-7e3d-4d06-aadf-469d6fea4a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-d19c752f-6412-4084-bb34-b839c2e6c0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-c497b84a-e4e4-4b84-847e-a01dba3d33ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-1f13dba3-8f02-4cbe-be01-6a9abdbbd91a,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-8c140b2a-615b-4315-ae40-8298c57333bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-08236d44-2869-474e-9fbc-fbeac878908b,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-6cbeabb5-3555-4611-b40b-67665e92e372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567675915-172.17.0.11-1595360408552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41573,DS-22e166e2-e5af-4669-8126-ac0d0a78a016,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-8284c5c7-7e3d-4d06-aadf-469d6fea4a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-d19c752f-6412-4084-bb34-b839c2e6c0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-c497b84a-e4e4-4b84-847e-a01dba3d33ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-1f13dba3-8f02-4cbe-be01-6a9abdbbd91a,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-8c140b2a-615b-4315-ae40-8298c57333bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-08236d44-2869-474e-9fbc-fbeac878908b,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-6cbeabb5-3555-4611-b40b-67665e92e372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627083665-172.17.0.11-1595360444824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-0936621d-d05b-4780-9f6e-070c1887f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-51afb1e5-9ece-45f3-a1f7-ab4a8524ebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-5320d830-0627-4e62-8d8e-eb8c44b034b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-a049e198-e8a1-4542-8177-c1c3da639c03,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-88312ac1-876f-46cf-90f7-c53db911b72c,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-4d3de69b-edaf-4e70-b7f9-381832f44efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-a15b582d-cde5-42f4-8cdb-3e5232bd69e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-0df73fbf-c7dc-4475-9589-594280a51074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627083665-172.17.0.11-1595360444824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-0936621d-d05b-4780-9f6e-070c1887f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-51afb1e5-9ece-45f3-a1f7-ab4a8524ebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-5320d830-0627-4e62-8d8e-eb8c44b034b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-a049e198-e8a1-4542-8177-c1c3da639c03,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-88312ac1-876f-46cf-90f7-c53db911b72c,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-4d3de69b-edaf-4e70-b7f9-381832f44efd,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-a15b582d-cde5-42f4-8cdb-3e5232bd69e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-0df73fbf-c7dc-4475-9589-594280a51074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719556157-172.17.0.11-1595360509770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41082,DS-c8d5751f-2b2d-4ec5-8f83-8c0dffe3a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-bd899e24-78af-4435-b386-4917dc102bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-11493ad2-725c-4e3e-9e31-ec7a0b41b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c096dacb-a2b7-459b-8769-318ab0fe3961,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-64d1e743-0b03-49b4-a66d-59c56b69516c,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-1ffd5cb4-338d-42c4-915e-f9cb38ebd8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-68ff68b3-4d14-40e0-a32d-4b037c9bf1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-736babf0-bede-45b9-be9b-384ed63d4603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719556157-172.17.0.11-1595360509770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41082,DS-c8d5751f-2b2d-4ec5-8f83-8c0dffe3a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-bd899e24-78af-4435-b386-4917dc102bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-11493ad2-725c-4e3e-9e31-ec7a0b41b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c096dacb-a2b7-459b-8769-318ab0fe3961,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-64d1e743-0b03-49b4-a66d-59c56b69516c,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-1ffd5cb4-338d-42c4-915e-f9cb38ebd8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-68ff68b3-4d14-40e0-a32d-4b037c9bf1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-736babf0-bede-45b9-be9b-384ed63d4603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-394286472-172.17.0.11-1595360654666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-aa47f136-315a-4dc3-ba4c-a430919916ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-07318d5e-1282-43fd-acd1-3360e679dea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-104bbfa6-e471-44fd-8827-608999ed4eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-8bdc4289-daa4-4b6d-bf8f-1485059b2543,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-06d4d2d6-2ad8-4464-91c1-e3e0901ba92f,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-f3dc9a62-fe35-43c9-92ce-e8e5d298ce40,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-e9d31dc0-caec-41a1-a40b-337a438a5291,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-75cd7806-c956-4a35-852b-428f1e8a810e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-394286472-172.17.0.11-1595360654666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-aa47f136-315a-4dc3-ba4c-a430919916ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-07318d5e-1282-43fd-acd1-3360e679dea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-104bbfa6-e471-44fd-8827-608999ed4eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-8bdc4289-daa4-4b6d-bf8f-1485059b2543,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-06d4d2d6-2ad8-4464-91c1-e3e0901ba92f,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-f3dc9a62-fe35-43c9-92ce-e8e5d298ce40,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-e9d31dc0-caec-41a1-a40b-337a438a5291,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-75cd7806-c956-4a35-852b-428f1e8a810e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425392660-172.17.0.11-1595360693295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-cb66d59a-4297-4a66-bacb-bf2ecd100a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-ed41dc6c-fe90-465b-a017-6924c5768079,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-b30cf93b-5557-4c93-b4cc-e874c1a5cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-31139560-cb47-475e-a5f6-388b428f2208,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-8b74ea8f-9601-49ac-9cc7-821d247f553d,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-9e3f4a8d-712c-4a59-a118-21de56521c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-e6dcc9ea-1439-4930-9b35-bfe55ebc1bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-848e07e4-0c8e-4567-b608-cec308e1e47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425392660-172.17.0.11-1595360693295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-cb66d59a-4297-4a66-bacb-bf2ecd100a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-ed41dc6c-fe90-465b-a017-6924c5768079,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-b30cf93b-5557-4c93-b4cc-e874c1a5cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-31139560-cb47-475e-a5f6-388b428f2208,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-8b74ea8f-9601-49ac-9cc7-821d247f553d,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-9e3f4a8d-712c-4a59-a118-21de56521c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-e6dcc9ea-1439-4930-9b35-bfe55ebc1bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-848e07e4-0c8e-4567-b608-cec308e1e47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563884822-172.17.0.11-1595360765715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35381,DS-6bccb57f-0c8e-4ba3-a880-4e83de3b14ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-69a07144-f1cd-4d25-81ec-6c6775b9fb25,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-1d420dd9-be27-4286-9973-9a6f52bb07cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-bac4fbef-c53b-443c-bc22-290bd4d638f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-b5cc1337-92d9-4c5d-b6d7-c225a122d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-2284e008-b525-48cc-95a9-6731aadf8e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e23d487b-30f5-4de2-8b8f-3f36dee5a872,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-97c25faf-663e-4ac9-a8d1-19f42600203f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563884822-172.17.0.11-1595360765715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35381,DS-6bccb57f-0c8e-4ba3-a880-4e83de3b14ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-69a07144-f1cd-4d25-81ec-6c6775b9fb25,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-1d420dd9-be27-4286-9973-9a6f52bb07cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-bac4fbef-c53b-443c-bc22-290bd4d638f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-b5cc1337-92d9-4c5d-b6d7-c225a122d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-2284e008-b525-48cc-95a9-6731aadf8e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e23d487b-30f5-4de2-8b8f-3f36dee5a872,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-97c25faf-663e-4ac9-a8d1-19f42600203f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850249502-172.17.0.11-1595361168672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37810,DS-6166812a-ff30-4315-9038-6232a4d2ca08,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-97f68205-6014-432f-8126-b42a97a93f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-0c01fbc8-ad4b-4a9c-803e-8ae14a2c91df,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-5053c295-f1bb-450d-9bf5-5e5bff973aab,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-7ac261bc-77c1-49e2-9404-e2eca75929c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-85f130d5-3a6b-4b0b-ba27-b21e07f48412,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-f34ac860-71bb-4bc6-8671-09f2c1a8bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-74bf2058-7d71-4dc7-9db8-5942b2113587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850249502-172.17.0.11-1595361168672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37810,DS-6166812a-ff30-4315-9038-6232a4d2ca08,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-97f68205-6014-432f-8126-b42a97a93f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-0c01fbc8-ad4b-4a9c-803e-8ae14a2c91df,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-5053c295-f1bb-450d-9bf5-5e5bff973aab,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-7ac261bc-77c1-49e2-9404-e2eca75929c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-85f130d5-3a6b-4b0b-ba27-b21e07f48412,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-f34ac860-71bb-4bc6-8671-09f2c1a8bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-74bf2058-7d71-4dc7-9db8-5942b2113587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710114676-172.17.0.11-1595361632772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-54032125-39da-4cc3-9371-75009012bc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-b51bd23a-33e2-4d18-aa49-1c7776797729,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-df19ac8a-66a9-4034-ae75-87fec678b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-e714037b-0679-40d2-a4fb-cdcdade8a465,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-3a41b4c1-b46e-4cc5-a895-701cfe87e2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-35fcbb8d-b7ec-4eca-8a9e-9ef7bfa2b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-6f8af72f-b2fa-453e-a50f-72875c8dab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-f97c6013-7e48-4f37-a8bf-5f8378f503f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710114676-172.17.0.11-1595361632772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-54032125-39da-4cc3-9371-75009012bc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-b51bd23a-33e2-4d18-aa49-1c7776797729,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-df19ac8a-66a9-4034-ae75-87fec678b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-e714037b-0679-40d2-a4fb-cdcdade8a465,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-3a41b4c1-b46e-4cc5-a895-701cfe87e2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-35fcbb8d-b7ec-4eca-8a9e-9ef7bfa2b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-6f8af72f-b2fa-453e-a50f-72875c8dab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-f97c6013-7e48-4f37-a8bf-5f8378f503f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138726318-172.17.0.11-1595361807450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38819,DS-cba8fe8a-0db8-488f-b746-cf05e4c719bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-9c878605-358e-4b16-a7fc-9a630f4f2a48,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-695c699f-9e93-4f2f-89c9-1c2ba78cfa44,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-f1fac41f-a026-4087-ad27-65ca6c3caee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-ac06f5f8-ed7f-40b9-b964-ad6f333e044f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-225f5c0b-a728-4b87-b60f-cffb3c3d1577,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-5fb23294-ef46-4d15-be33-1bc690ca4308,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-fad52c24-4f2b-4f00-a118-5b021b43ad52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138726318-172.17.0.11-1595361807450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38819,DS-cba8fe8a-0db8-488f-b746-cf05e4c719bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-9c878605-358e-4b16-a7fc-9a630f4f2a48,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-695c699f-9e93-4f2f-89c9-1c2ba78cfa44,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-f1fac41f-a026-4087-ad27-65ca6c3caee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-ac06f5f8-ed7f-40b9-b964-ad6f333e044f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-225f5c0b-a728-4b87-b60f-cffb3c3d1577,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-5fb23294-ef46-4d15-be33-1bc690ca4308,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-fad52c24-4f2b-4f00-a118-5b021b43ad52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617087870-172.17.0.11-1595363037042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39775,DS-6e413a26-1bea-4a16-a1cc-5662dfd84717,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-0a098c48-15b3-49f4-9e3b-98934908bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-15c0107b-07a0-4f11-9535-5beb2e7a0153,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-6deeb60d-8903-4dbe-9081-e7b85ffde07a,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-d49f3ea6-fdcf-4bac-a795-5e6a9f554d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-258c5102-ca46-4db2-87dc-54ca0fc7921c,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-9cd9d1e8-7fce-445b-98e4-35a17d4aca34,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-58cb937d-2124-46f5-9933-23b030541d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617087870-172.17.0.11-1595363037042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39775,DS-6e413a26-1bea-4a16-a1cc-5662dfd84717,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-0a098c48-15b3-49f4-9e3b-98934908bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-15c0107b-07a0-4f11-9535-5beb2e7a0153,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-6deeb60d-8903-4dbe-9081-e7b85ffde07a,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-d49f3ea6-fdcf-4bac-a795-5e6a9f554d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-258c5102-ca46-4db2-87dc-54ca0fc7921c,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-9cd9d1e8-7fce-445b-98e4-35a17d4aca34,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-58cb937d-2124-46f5-9933-23b030541d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733564741-172.17.0.11-1595363140554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46677,DS-013651d9-b2cf-413b-8884-529ae172b0af,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-3a9ab55b-5de6-4039-9ebb-c7d7c840bc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-48ca5142-ce5e-4075-a3b4-68f9f54bfc29,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-c034d310-6430-492d-8136-4c4ee52cdb37,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-ba0c1275-501f-49d2-887b-7e5522747888,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-fc180648-655e-4375-8757-185524c688a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-9b787ad7-11d3-4a8c-8e94-fe28d666c465,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-90a256cc-bbea-41bc-be63-d6ce56b12acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733564741-172.17.0.11-1595363140554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46677,DS-013651d9-b2cf-413b-8884-529ae172b0af,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-3a9ab55b-5de6-4039-9ebb-c7d7c840bc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-48ca5142-ce5e-4075-a3b4-68f9f54bfc29,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-c034d310-6430-492d-8136-4c4ee52cdb37,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-ba0c1275-501f-49d2-887b-7e5522747888,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-fc180648-655e-4375-8757-185524c688a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-9b787ad7-11d3-4a8c-8e94-fe28d666c465,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-90a256cc-bbea-41bc-be63-d6ce56b12acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450402140-172.17.0.11-1595363281915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-72231a48-388a-4d51-9796-adec21707f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-d8ac87ed-6b91-4fd0-8d96-112fd741d458,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-545d5278-0c4a-4e87-9df1-9759bb038075,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-b6c1c6bb-70ed-4af8-9813-51b8f2c22ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-8e829b07-5465-4511-8d5a-6a6e0983055e,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-17d545f3-5145-48eb-a271-63fd223c9c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-6866eac8-5ddb-49f9-a142-ed4c368a6ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-8b9b8676-b43f-403e-89b8-ca9f0c9760d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450402140-172.17.0.11-1595363281915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-72231a48-388a-4d51-9796-adec21707f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-d8ac87ed-6b91-4fd0-8d96-112fd741d458,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-545d5278-0c4a-4e87-9df1-9759bb038075,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-b6c1c6bb-70ed-4af8-9813-51b8f2c22ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-8e829b07-5465-4511-8d5a-6a6e0983055e,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-17d545f3-5145-48eb-a271-63fd223c9c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-6866eac8-5ddb-49f9-a142-ed4c368a6ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-8b9b8676-b43f-403e-89b8-ca9f0c9760d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372779310-172.17.0.11-1595363459194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38025,DS-b48cb125-e223-408b-b886-1d8c41fb208b,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-366b79b2-a06a-46dd-ab45-be1caeb6df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-b0689b03-83ba-43d6-b9dd-b6b8754228a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-751c122e-3735-496d-b684-d27adfe7e8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-2e0e2243-7818-46c3-b107-d4285074f5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-cdab70b3-893a-45a1-a3c2-90ef2bc5c761,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-87db997b-4b15-4196-91aa-41db68d37df3,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-c4b691bc-feb3-4009-9ab8-53a8025164c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372779310-172.17.0.11-1595363459194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38025,DS-b48cb125-e223-408b-b886-1d8c41fb208b,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-366b79b2-a06a-46dd-ab45-be1caeb6df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-b0689b03-83ba-43d6-b9dd-b6b8754228a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-751c122e-3735-496d-b684-d27adfe7e8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-2e0e2243-7818-46c3-b107-d4285074f5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-cdab70b3-893a-45a1-a3c2-90ef2bc5c761,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-87db997b-4b15-4196-91aa-41db68d37df3,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-c4b691bc-feb3-4009-9ab8-53a8025164c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769102604-172.17.0.11-1595363644993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-f0a11585-fc56-4653-8219-13094cd12b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-02348d4d-65ad-4caf-9e87-0a2c81dbe01f,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-e773deab-e8cb-4983-b579-4337b57e6477,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-badaccf5-361f-4647-87ee-327267509cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-bede0e84-6fc8-48c9-8052-2375619201c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-7087e340-0c04-453a-a920-1870051e966a,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-e4993500-fdad-445b-9244-b6438f4641e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-b8ecbc48-bea2-41a1-ae76-792809a61706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769102604-172.17.0.11-1595363644993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-f0a11585-fc56-4653-8219-13094cd12b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-02348d4d-65ad-4caf-9e87-0a2c81dbe01f,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-e773deab-e8cb-4983-b579-4337b57e6477,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-badaccf5-361f-4647-87ee-327267509cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-bede0e84-6fc8-48c9-8052-2375619201c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-7087e340-0c04-453a-a920-1870051e966a,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-e4993500-fdad-445b-9244-b6438f4641e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-b8ecbc48-bea2-41a1-ae76-792809a61706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5214
