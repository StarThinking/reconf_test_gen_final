reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375702839-172.17.0.20-1595353711403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44068,DS-a05db09a-a1a1-4d43-9448-6758003da577,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-24767b9a-1f18-4e3a-af07-fadff9deef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-6bf3e1af-fa71-439b-94b8-c0abb296814f,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-5c0f4cac-6e4e-4e2d-9efc-2f0a6807ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-c3eaaee3-82e3-410d-8643-dcab5f4aa907,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-093b1341-feb8-4dc5-a549-aa34a4b7b75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-9c3d9a7e-57ac-4e82-8147-cb0f3580d1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-4a85971e-b300-4763-ab2d-488c8e7b8c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375702839-172.17.0.20-1595353711403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44068,DS-a05db09a-a1a1-4d43-9448-6758003da577,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-24767b9a-1f18-4e3a-af07-fadff9deef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-6bf3e1af-fa71-439b-94b8-c0abb296814f,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-5c0f4cac-6e4e-4e2d-9efc-2f0a6807ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-c3eaaee3-82e3-410d-8643-dcab5f4aa907,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-093b1341-feb8-4dc5-a549-aa34a4b7b75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-9c3d9a7e-57ac-4e82-8147-cb0f3580d1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-4a85971e-b300-4763-ab2d-488c8e7b8c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612789342-172.17.0.20-1595354054857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-70db5d4a-ae56-4842-a68a-bde46e2178e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-7657da12-b31c-43e8-a7a5-40765c781554,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-20e3b0d7-27ff-421f-97ab-d0348535827e,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-4eae0505-7e22-4fc4-b785-1f2e0eb43ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-750e2275-9486-4339-a844-609618924b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-f01995ed-1441-4bb7-93d8-bc7aa8235b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-2700b1d8-7808-4b32-92f4-1ff3fb4b3106,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-0650471f-e8c2-482b-a1cc-fc159f628956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612789342-172.17.0.20-1595354054857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-70db5d4a-ae56-4842-a68a-bde46e2178e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-7657da12-b31c-43e8-a7a5-40765c781554,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-20e3b0d7-27ff-421f-97ab-d0348535827e,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-4eae0505-7e22-4fc4-b785-1f2e0eb43ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-750e2275-9486-4339-a844-609618924b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-f01995ed-1441-4bb7-93d8-bc7aa8235b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-2700b1d8-7808-4b32-92f4-1ff3fb4b3106,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-0650471f-e8c2-482b-a1cc-fc159f628956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506981554-172.17.0.20-1595354514683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-cb3704fe-affb-41c9-a37f-dc3668aa52e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-e973b63e-c86e-4e91-a897-262547fcb0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-7a91882b-fcf0-45d8-bc60-0f428708acf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-54db7e93-4467-4961-9422-9b09be616301,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-ba1dd1f7-2130-48cc-9f67-12767d479c05,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-869c37ec-4855-43ec-8ad6-f0da5c77deba,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-1802191d-56db-47f2-983e-8a0d48c2fdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f5b8aafa-f83d-49a3-813c-80c993a2042f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506981554-172.17.0.20-1595354514683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-cb3704fe-affb-41c9-a37f-dc3668aa52e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-e973b63e-c86e-4e91-a897-262547fcb0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-7a91882b-fcf0-45d8-bc60-0f428708acf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-54db7e93-4467-4961-9422-9b09be616301,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-ba1dd1f7-2130-48cc-9f67-12767d479c05,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-869c37ec-4855-43ec-8ad6-f0da5c77deba,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-1802191d-56db-47f2-983e-8a0d48c2fdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f5b8aafa-f83d-49a3-813c-80c993a2042f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354583189-172.17.0.20-1595354601944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43384,DS-2641b0d9-c681-4286-84a2-57d23d0d02f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-dee56c18-c415-4d8a-b6b6-81e7b02afc96,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-79023472-bf10-42f1-949a-29be00a8463f,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-ff00e47f-3dea-4898-8b1d-c68990005074,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-5fd8c0d0-a620-40f7-9edd-c686d61d17c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-712c1d0d-630b-43a5-b53d-44d4c418b6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-0eeaa25a-95bd-4393-8183-978abf9ffee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-817b26d3-ca08-4ac3-bc33-43a7346deb38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354583189-172.17.0.20-1595354601944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43384,DS-2641b0d9-c681-4286-84a2-57d23d0d02f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-dee56c18-c415-4d8a-b6b6-81e7b02afc96,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-79023472-bf10-42f1-949a-29be00a8463f,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-ff00e47f-3dea-4898-8b1d-c68990005074,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-5fd8c0d0-a620-40f7-9edd-c686d61d17c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-712c1d0d-630b-43a5-b53d-44d4c418b6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-0eeaa25a-95bd-4393-8183-978abf9ffee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-817b26d3-ca08-4ac3-bc33-43a7346deb38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664961336-172.17.0.20-1595354945191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-e27efb45-ae71-4c50-a840-27880a8fc4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-baf33c26-9287-47ee-b894-bcdbda18645b,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-9d8507b0-805a-4e68-af78-51961bf2127d,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-0841ec84-2b7b-45f2-9dfb-2325a5677626,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-8b572571-bcbb-4d7c-911f-ba89fd80f0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-ba409d35-b8fd-4006-8f21-6212579ae092,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-5a9e6a7f-65d1-4352-bcdb-74f586f8ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-279a0a6f-1714-4cb1-a434-ae0e47c9d44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664961336-172.17.0.20-1595354945191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-e27efb45-ae71-4c50-a840-27880a8fc4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-baf33c26-9287-47ee-b894-bcdbda18645b,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-9d8507b0-805a-4e68-af78-51961bf2127d,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-0841ec84-2b7b-45f2-9dfb-2325a5677626,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-8b572571-bcbb-4d7c-911f-ba89fd80f0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-ba409d35-b8fd-4006-8f21-6212579ae092,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-5a9e6a7f-65d1-4352-bcdb-74f586f8ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-279a0a6f-1714-4cb1-a434-ae0e47c9d44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476807142-172.17.0.20-1595357510747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-326c05b5-e683-4ce3-a267-66b162169e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-5184e32f-9316-4aee-9f6f-916c0dc9160a,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-e41a2780-40cf-4013-99a9-3b898654099c,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-f290cc15-3ccf-4a43-b871-59f49c1b6c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-a8e879ca-c118-4b00-87a8-8018d21a52d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-031daf31-5ca1-4541-94f2-fbe0dccb9b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-e95ab0d5-43b5-4db6-ad83-2e46a38988fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-5aaad06b-8068-413e-877f-1672bc4b604c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476807142-172.17.0.20-1595357510747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-326c05b5-e683-4ce3-a267-66b162169e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-5184e32f-9316-4aee-9f6f-916c0dc9160a,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-e41a2780-40cf-4013-99a9-3b898654099c,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-f290cc15-3ccf-4a43-b871-59f49c1b6c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-a8e879ca-c118-4b00-87a8-8018d21a52d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-031daf31-5ca1-4541-94f2-fbe0dccb9b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-e95ab0d5-43b5-4db6-ad83-2e46a38988fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-5aaad06b-8068-413e-877f-1672bc4b604c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610652744-172.17.0.20-1595357744201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-5f3e5f32-f448-4a65-a7ee-c6d6678bd917,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-4e5e2cec-0a0f-419f-ab0f-aeeba8835fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-9a8e0b8f-2543-4835-a613-11a8c8c95238,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-f392f335-6ed2-44d6-9d4f-ad8f57c4f9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-4489eec8-da14-4032-acf9-fdf90bdf4e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-307907b6-a280-43c9-a6c0-97d7fcd8c189,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-667570e5-9d07-4b4c-b999-4f58fc01790c,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-b2b6f377-c813-472b-8e75-13bd4526e43f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610652744-172.17.0.20-1595357744201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-5f3e5f32-f448-4a65-a7ee-c6d6678bd917,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-4e5e2cec-0a0f-419f-ab0f-aeeba8835fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-9a8e0b8f-2543-4835-a613-11a8c8c95238,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-f392f335-6ed2-44d6-9d4f-ad8f57c4f9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-4489eec8-da14-4032-acf9-fdf90bdf4e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-307907b6-a280-43c9-a6c0-97d7fcd8c189,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-667570e5-9d07-4b4c-b999-4f58fc01790c,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-b2b6f377-c813-472b-8e75-13bd4526e43f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475446007-172.17.0.20-1595357780595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39176,DS-f2374785-954a-4de7-a980-3592129c2f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-580960aa-e090-4639-b9c4-92e59f003a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-d10fa324-76a5-4ce6-8df2-ec0cff57c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-ffa29e5b-3bb2-4d9a-b921-e85f71de4b15,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-6fde5fa7-a06f-445b-a9a5-ca6526114a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-0412af9c-4f1b-4fd9-8183-66e3952276b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-349cb933-cbbe-4006-bfca-cb7bff2caaad,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-f05733e2-4e05-4653-8707-9717ce56dc8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475446007-172.17.0.20-1595357780595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39176,DS-f2374785-954a-4de7-a980-3592129c2f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-580960aa-e090-4639-b9c4-92e59f003a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-d10fa324-76a5-4ce6-8df2-ec0cff57c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-ffa29e5b-3bb2-4d9a-b921-e85f71de4b15,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-6fde5fa7-a06f-445b-a9a5-ca6526114a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-0412af9c-4f1b-4fd9-8183-66e3952276b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-349cb933-cbbe-4006-bfca-cb7bff2caaad,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-f05733e2-4e05-4653-8707-9717ce56dc8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086440825-172.17.0.20-1595358088042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-11ffa6a4-3104-42a3-8ab5-4e9cd2632e80,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-31ad2c96-7695-4adc-beb5-5e3c4790c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-63543a1b-dba6-4969-a151-94812e626bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-9be7827d-371b-47bb-b7f0-4e8e224b0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-3c5880dd-284e-405a-831d-07f8c31aee73,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-6166bb87-58f9-4116-9c8c-005674d93286,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-57bf1bad-4b9f-4dfd-b204-2f43f04d0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-43276d13-fcc3-4bfa-90e6-a8c63f37dd9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086440825-172.17.0.20-1595358088042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-11ffa6a4-3104-42a3-8ab5-4e9cd2632e80,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-31ad2c96-7695-4adc-beb5-5e3c4790c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-63543a1b-dba6-4969-a151-94812e626bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-9be7827d-371b-47bb-b7f0-4e8e224b0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-3c5880dd-284e-405a-831d-07f8c31aee73,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-6166bb87-58f9-4116-9c8c-005674d93286,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-57bf1bad-4b9f-4dfd-b204-2f43f04d0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-43276d13-fcc3-4bfa-90e6-a8c63f37dd9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229035841-172.17.0.20-1595358232283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38403,DS-675a595f-d2a9-4bdf-943d-25c1c54d3ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-f594f6bf-3b5f-4b4e-8910-6e3f4f7acf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-5930df00-b74a-4f59-ac87-366dc7ce8348,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-f31711b3-6300-4a41-9ea6-84fccfde826c,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-c62f5d2b-43c6-45bb-85bf-0f714873eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-617da1d0-ec05-41d5-b301-9965b93053ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-f4f40709-db16-49d9-841f-02f79bdfe414,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-274bea43-1986-42b9-b5d7-6a063f3729c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229035841-172.17.0.20-1595358232283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38403,DS-675a595f-d2a9-4bdf-943d-25c1c54d3ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-f594f6bf-3b5f-4b4e-8910-6e3f4f7acf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-5930df00-b74a-4f59-ac87-366dc7ce8348,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-f31711b3-6300-4a41-9ea6-84fccfde826c,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-c62f5d2b-43c6-45bb-85bf-0f714873eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-617da1d0-ec05-41d5-b301-9965b93053ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-f4f40709-db16-49d9-841f-02f79bdfe414,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-274bea43-1986-42b9-b5d7-6a063f3729c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911800201-172.17.0.20-1595358335952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-af2d40c3-f2f8-486b-9fdf-af3fab76b9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-29de51af-7129-4aa5-bc99-8399a3ef3488,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-745b4680-7ccf-4e8c-8778-eb0f14a08961,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-e22c81fc-d65a-484c-ba7d-e5f5cd139e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-fda5a939-8b6e-465e-ab9d-375e90979cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-2f5964d5-bc55-4477-8bef-ec7d5f7bbb71,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-c8e431ec-2a66-485b-9750-bcaed311d000,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-50785cc5-313f-4cab-a831-82f2e855e78c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911800201-172.17.0.20-1595358335952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-af2d40c3-f2f8-486b-9fdf-af3fab76b9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-29de51af-7129-4aa5-bc99-8399a3ef3488,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-745b4680-7ccf-4e8c-8778-eb0f14a08961,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-e22c81fc-d65a-484c-ba7d-e5f5cd139e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-fda5a939-8b6e-465e-ab9d-375e90979cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-2f5964d5-bc55-4477-8bef-ec7d5f7bbb71,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-c8e431ec-2a66-485b-9750-bcaed311d000,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-50785cc5-313f-4cab-a831-82f2e855e78c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613018656-172.17.0.20-1595358443100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-aeece551-315f-4ef8-9755-3ba940843fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-9bbf5f7d-06b4-4467-aeeb-0aba486739c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-3b996ed4-a93f-477c-8bb2-fb3fd420a74c,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-7b9084ae-3678-4640-a01c-5b3a3e48a23d,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-1f2f54d9-4866-4ab0-8738-41c17d6c8310,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-111fe62e-8d34-4653-b974-85ccd51eae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-277dc47d-e25e-4940-aee2-23c8f9a923e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-1db2622f-a7e5-4318-9102-8708447238ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613018656-172.17.0.20-1595358443100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-aeece551-315f-4ef8-9755-3ba940843fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-9bbf5f7d-06b4-4467-aeeb-0aba486739c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-3b996ed4-a93f-477c-8bb2-fb3fd420a74c,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-7b9084ae-3678-4640-a01c-5b3a3e48a23d,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-1f2f54d9-4866-4ab0-8738-41c17d6c8310,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-111fe62e-8d34-4653-b974-85ccd51eae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-277dc47d-e25e-4940-aee2-23c8f9a923e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-1db2622f-a7e5-4318-9102-8708447238ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352686918-172.17.0.20-1595358474586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-ddf7cd2d-1214-4e8b-bb28-9004b15058a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-beedd41c-5b7e-4bda-af7c-343e7ea883e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-2adc8f07-6147-4148-8476-63a516f903dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-142d835e-d315-4320-ae37-5a8ea5ab910f,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-6068d5a0-b7aa-43a6-bac6-249153ce86ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-92239393-42e3-437f-b2b2-281e96549dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-d5712c06-a7e1-4057-b6e9-d3c22ce59f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-7f42ff45-80f6-476d-b713-84f7724d25f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352686918-172.17.0.20-1595358474586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-ddf7cd2d-1214-4e8b-bb28-9004b15058a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-beedd41c-5b7e-4bda-af7c-343e7ea883e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-2adc8f07-6147-4148-8476-63a516f903dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-142d835e-d315-4320-ae37-5a8ea5ab910f,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-6068d5a0-b7aa-43a6-bac6-249153ce86ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-92239393-42e3-437f-b2b2-281e96549dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-d5712c06-a7e1-4057-b6e9-d3c22ce59f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-7f42ff45-80f6-476d-b713-84f7724d25f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5007
