reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255984160-172.17.0.20-1595363190476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-1b21ddc2-a298-485c-9752-3fa2e36299cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-dd2ad131-f6be-4c11-b5c1-a86b8bca8474,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-e7ad1c75-d645-497e-b4c5-59bfb41304e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-5e9df3bb-6a8b-43fa-977e-ba4417ac43cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-382ecbea-cc6c-485b-8306-44eac84b5801,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-67d9519f-6ddb-4678-bb80-779d396d0329,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-10986807-65c5-4f15-a6be-0e06538135a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-9e7d186d-1797-4691-8d2a-173367e9cc53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255984160-172.17.0.20-1595363190476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-1b21ddc2-a298-485c-9752-3fa2e36299cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-dd2ad131-f6be-4c11-b5c1-a86b8bca8474,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-e7ad1c75-d645-497e-b4c5-59bfb41304e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-5e9df3bb-6a8b-43fa-977e-ba4417ac43cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-382ecbea-cc6c-485b-8306-44eac84b5801,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-67d9519f-6ddb-4678-bb80-779d396d0329,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-10986807-65c5-4f15-a6be-0e06538135a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-9e7d186d-1797-4691-8d2a-173367e9cc53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318686234-172.17.0.20-1595363324084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39710,DS-31ec83ce-ef0f-4a5a-abe8-6d60cb18663c,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-e4206842-f726-4ff6-af6b-5b44abfec86d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-1ffe9d1b-d4a3-4980-9cb7-7b93c0a6c395,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-fb5dc0a0-7e1c-4375-88da-a68c01c04eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-e0b2626c-74a4-4eff-a0a5-261420be5566,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-0e554514-d082-4e70-8ab0-21030b0465e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-c2a99a56-298f-45c0-9d82-a52d1e785007,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-9b8ec660-b42e-4cdb-9631-46d1c472922d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318686234-172.17.0.20-1595363324084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39710,DS-31ec83ce-ef0f-4a5a-abe8-6d60cb18663c,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-e4206842-f726-4ff6-af6b-5b44abfec86d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-1ffe9d1b-d4a3-4980-9cb7-7b93c0a6c395,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-fb5dc0a0-7e1c-4375-88da-a68c01c04eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-e0b2626c-74a4-4eff-a0a5-261420be5566,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-0e554514-d082-4e70-8ab0-21030b0465e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-c2a99a56-298f-45c0-9d82-a52d1e785007,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-9b8ec660-b42e-4cdb-9631-46d1c472922d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223154508-172.17.0.20-1595363392707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42898,DS-d059c625-f920-43e3-8d20-37e136083724,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-96fa72ad-79e8-4d89-815a-fbce03a3e8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-a48b37b7-a539-4dc2-89a6-349bb12b632a,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-651cd175-d2d4-4218-a7a8-20edf491eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-7374fef5-8602-4e66-8b82-7b5bd1a2a576,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-2c0c62df-720a-4690-afe8-9dca3694976e,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-5a22ac4f-f027-45ad-b18e-0b22dd16c8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-6f1fa289-bd25-4a8d-8e62-f7111ab30b79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223154508-172.17.0.20-1595363392707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42898,DS-d059c625-f920-43e3-8d20-37e136083724,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-96fa72ad-79e8-4d89-815a-fbce03a3e8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-a48b37b7-a539-4dc2-89a6-349bb12b632a,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-651cd175-d2d4-4218-a7a8-20edf491eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-7374fef5-8602-4e66-8b82-7b5bd1a2a576,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-2c0c62df-720a-4690-afe8-9dca3694976e,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-5a22ac4f-f027-45ad-b18e-0b22dd16c8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-6f1fa289-bd25-4a8d-8e62-f7111ab30b79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110878494-172.17.0.20-1595363431525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38390,DS-f184218a-ba9f-4c4f-94b5-355d57f14cec,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-a730748a-1933-4b68-b135-8f96eec29051,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-cc7575f6-1d50-4d4f-b60d-e0960735d1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-3a03740e-1e6d-4cdc-9465-4a41d5382aea,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-56f5ebc5-9d52-4a1f-93b0-ba23c36f9071,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-9ad953fa-68ed-4585-a9ce-2222f2b2a512,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-2cd0a7c8-4ab0-476a-97c7-dc9e4d73fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-2bf8f150-4465-4929-a89c-3016e5936337,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110878494-172.17.0.20-1595363431525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38390,DS-f184218a-ba9f-4c4f-94b5-355d57f14cec,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-a730748a-1933-4b68-b135-8f96eec29051,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-cc7575f6-1d50-4d4f-b60d-e0960735d1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-3a03740e-1e6d-4cdc-9465-4a41d5382aea,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-56f5ebc5-9d52-4a1f-93b0-ba23c36f9071,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-9ad953fa-68ed-4585-a9ce-2222f2b2a512,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-2cd0a7c8-4ab0-476a-97c7-dc9e4d73fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-2bf8f150-4465-4929-a89c-3016e5936337,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385395402-172.17.0.20-1595363684960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41225,DS-69ebfa51-4369-435b-a196-55560649b934,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-82f6dfea-cb5d-4583-ad3f-fe86782dc9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-1df42fa5-8dac-4834-b6ba-828d44d121d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-716280ef-ed52-4e00-a7a4-9649857d2efe,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-cb425b21-3d66-42a3-824e-bf90c6df967b,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-4c32407e-a11c-456e-98f7-0e60ef00e334,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-1a39754b-2348-406d-8c9d-9f422c1da769,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-5357aef7-01f6-4f17-9525-8759011e6f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385395402-172.17.0.20-1595363684960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41225,DS-69ebfa51-4369-435b-a196-55560649b934,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-82f6dfea-cb5d-4583-ad3f-fe86782dc9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-1df42fa5-8dac-4834-b6ba-828d44d121d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-716280ef-ed52-4e00-a7a4-9649857d2efe,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-cb425b21-3d66-42a3-824e-bf90c6df967b,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-4c32407e-a11c-456e-98f7-0e60ef00e334,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-1a39754b-2348-406d-8c9d-9f422c1da769,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-5357aef7-01f6-4f17-9525-8759011e6f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489089479-172.17.0.20-1595363798729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42821,DS-380bf40c-d9cf-4900-8ddc-8822d34a8e00,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-07d5f4c0-f399-4583-9068-7e9dc4283b17,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-28ed3861-89b0-4e0f-8d19-dcc114049a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-30437e03-229b-4df6-af62-1a946b857159,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-aef14b4c-d9ab-4f85-87aa-fa17512d6939,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-1ca25b1b-cea7-46f9-8209-c0dbcf9e507d,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-ae25c930-ce0b-4ff8-869b-3f331afe1f41,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-fc9cd6a8-8d4d-4d22-8c20-aa82f1e82e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489089479-172.17.0.20-1595363798729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42821,DS-380bf40c-d9cf-4900-8ddc-8822d34a8e00,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-07d5f4c0-f399-4583-9068-7e9dc4283b17,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-28ed3861-89b0-4e0f-8d19-dcc114049a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-30437e03-229b-4df6-af62-1a946b857159,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-aef14b4c-d9ab-4f85-87aa-fa17512d6939,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-1ca25b1b-cea7-46f9-8209-c0dbcf9e507d,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-ae25c930-ce0b-4ff8-869b-3f331afe1f41,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-fc9cd6a8-8d4d-4d22-8c20-aa82f1e82e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390683163-172.17.0.20-1595363874019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41823,DS-34aa055f-26f5-45d7-ba7a-b995fb37e5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-ff5aa3af-8b32-4b0c-9e4b-e8d14dca5420,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-5cce2c54-e828-440c-be23-f2ca5011c76d,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-fd10bedc-6fae-4d17-919f-a27483d8ff27,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-c3ab077f-82c1-4b9f-a00d-05d1ea25ec79,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-88875bfc-fa86-40e3-96fe-a02dc57023f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-43b5c4ac-74ed-4850-b942-ca28da2ca3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-286a37f1-843e-4a5c-9d31-c7835d77cee8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390683163-172.17.0.20-1595363874019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41823,DS-34aa055f-26f5-45d7-ba7a-b995fb37e5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-ff5aa3af-8b32-4b0c-9e4b-e8d14dca5420,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-5cce2c54-e828-440c-be23-f2ca5011c76d,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-fd10bedc-6fae-4d17-919f-a27483d8ff27,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-c3ab077f-82c1-4b9f-a00d-05d1ea25ec79,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-88875bfc-fa86-40e3-96fe-a02dc57023f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-43b5c4ac-74ed-4850-b942-ca28da2ca3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-286a37f1-843e-4a5c-9d31-c7835d77cee8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428443220-172.17.0.20-1595363910105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40473,DS-93aee866-1dd5-429a-b910-2b5a0670c1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-a048da33-d69a-4c78-b427-400ddb3675d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-6db73d85-7f40-4046-a85a-e5ab6af52e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-179f0f95-0a07-4431-9c4f-36cd022f4a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-e6b5e10c-7dfd-4e3a-9d28-12eac36157f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-76969e4e-4ee9-4d29-a625-e6b0bc674810,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-b82e82b4-a933-488d-8081-cb36a3e7d0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-99377723-36c7-4ce0-af27-9f730b770785,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428443220-172.17.0.20-1595363910105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40473,DS-93aee866-1dd5-429a-b910-2b5a0670c1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-a048da33-d69a-4c78-b427-400ddb3675d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-6db73d85-7f40-4046-a85a-e5ab6af52e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-179f0f95-0a07-4431-9c4f-36cd022f4a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-e6b5e10c-7dfd-4e3a-9d28-12eac36157f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-76969e4e-4ee9-4d29-a625-e6b0bc674810,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-b82e82b4-a933-488d-8081-cb36a3e7d0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-99377723-36c7-4ce0-af27-9f730b770785,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474270232-172.17.0.20-1595364286450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44397,DS-5b15724b-a44e-434a-8e02-af7c516ed4df,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-10398613-b5a5-4ee1-8e93-cf0ba974b535,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-d9b2727d-272e-4b83-b266-a54d40c71ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-ff6d5ece-f751-426b-93bb-41bdbc7cf366,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-25d6ae6c-976d-4d71-bcd3-71f9b943e5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-ae776019-0f14-4108-a6a3-45bcd128c6de,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-73f90f37-e706-4bb9-9033-a64ee67c58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-e88c7e74-085e-426c-977e-3f78fa117744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474270232-172.17.0.20-1595364286450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44397,DS-5b15724b-a44e-434a-8e02-af7c516ed4df,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-10398613-b5a5-4ee1-8e93-cf0ba974b535,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-d9b2727d-272e-4b83-b266-a54d40c71ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-ff6d5ece-f751-426b-93bb-41bdbc7cf366,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-25d6ae6c-976d-4d71-bcd3-71f9b943e5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-ae776019-0f14-4108-a6a3-45bcd128c6de,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-73f90f37-e706-4bb9-9033-a64ee67c58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-e88c7e74-085e-426c-977e-3f78fa117744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082526148-172.17.0.20-1595364318015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37401,DS-5ee12054-f8be-4b68-9723-683cd9ca35a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-a5f35adf-1a35-45ab-a51c-45fcac5d8eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-0cb62031-0225-46ba-9cb2-6ef19a96273b,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-1f2595a9-29f3-417d-b9dc-83e4ada15fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-5b0aed5e-3436-4f84-b57e-aefd27dde1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-d05b0919-cb9b-4f0d-892d-0bdad1b9eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-9223c20b-a3b9-4184-a7cf-229eae1ad267,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-75f51458-6290-4c9e-9f66-b0ca795652cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082526148-172.17.0.20-1595364318015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37401,DS-5ee12054-f8be-4b68-9723-683cd9ca35a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-a5f35adf-1a35-45ab-a51c-45fcac5d8eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-0cb62031-0225-46ba-9cb2-6ef19a96273b,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-1f2595a9-29f3-417d-b9dc-83e4ada15fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-5b0aed5e-3436-4f84-b57e-aefd27dde1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-d05b0919-cb9b-4f0d-892d-0bdad1b9eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-9223c20b-a3b9-4184-a7cf-229eae1ad267,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-75f51458-6290-4c9e-9f66-b0ca795652cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887341313-172.17.0.20-1595364472231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38397,DS-0ae7c460-f706-49d3-a9f0-4c6a1ce76d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-c40dd2ae-5922-4e3b-9aea-60934d4ae21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-6257e660-4628-4988-a1fb-0fcd8179d540,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-06cff118-0ab4-4286-9485-f3970fb5a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-8b7a998c-f930-4124-8914-896ca3531b99,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-f5b0d4ea-f49e-4e54-bb6a-a4aaaaaebd56,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-db256a91-461c-4dbc-88c7-d3e53aeca379,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-321f6edb-1d80-4fb5-8969-ff09e72e3767,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887341313-172.17.0.20-1595364472231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38397,DS-0ae7c460-f706-49d3-a9f0-4c6a1ce76d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-c40dd2ae-5922-4e3b-9aea-60934d4ae21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-6257e660-4628-4988-a1fb-0fcd8179d540,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-06cff118-0ab4-4286-9485-f3970fb5a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-8b7a998c-f930-4124-8914-896ca3531b99,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-f5b0d4ea-f49e-4e54-bb6a-a4aaaaaebd56,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-db256a91-461c-4dbc-88c7-d3e53aeca379,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-321f6edb-1d80-4fb5-8969-ff09e72e3767,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828213855-172.17.0.20-1595364569575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-e5f7fbca-c660-40c0-a634-ba7ee812cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-8a47a9b7-d535-42ee-936b-5e64a77305e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-d1bff9aa-9345-4027-99c5-f06d6d9359ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-0809aada-76ad-44e0-871e-872586183fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-513422f7-07cb-4d0e-acfc-14eee1a2cbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-df4f005e-9583-4848-a4f8-9aacb4157bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-d2895c3d-9951-43ea-a405-5e144c821eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-e6101e82-6fb9-4097-b18c-5a79b24a2d22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828213855-172.17.0.20-1595364569575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-e5f7fbca-c660-40c0-a634-ba7ee812cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-8a47a9b7-d535-42ee-936b-5e64a77305e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-d1bff9aa-9345-4027-99c5-f06d6d9359ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-0809aada-76ad-44e0-871e-872586183fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-513422f7-07cb-4d0e-acfc-14eee1a2cbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-df4f005e-9583-4848-a4f8-9aacb4157bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-d2895c3d-9951-43ea-a405-5e144c821eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-e6101e82-6fb9-4097-b18c-5a79b24a2d22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035465392-172.17.0.20-1595364601253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-b592efac-d71c-48ad-9fd9-e8d08ad56907,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-c9a1d38d-6655-42c8-be85-58b02ff78eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-4cbcd206-d757-4b66-971d-0fd0b6154161,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-cf214c63-24a5-4b88-92e2-97d0875efab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-947bd175-8e5e-4c15-99bc-f492acac6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-642cb042-533c-4a9e-a70e-0a1707110381,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-e74973bd-4cde-4325-a43b-0219fb144519,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-d1b72a40-d3d3-4be4-820b-45143d222fa6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035465392-172.17.0.20-1595364601253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-b592efac-d71c-48ad-9fd9-e8d08ad56907,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-c9a1d38d-6655-42c8-be85-58b02ff78eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-4cbcd206-d757-4b66-971d-0fd0b6154161,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-cf214c63-24a5-4b88-92e2-97d0875efab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-947bd175-8e5e-4c15-99bc-f492acac6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-642cb042-533c-4a9e-a70e-0a1707110381,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-e74973bd-4cde-4325-a43b-0219fb144519,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-d1b72a40-d3d3-4be4-820b-45143d222fa6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367061146-172.17.0.20-1595365357489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36880,DS-4023a65c-a3dd-44df-b0bc-046920525242,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-33d2960b-50b2-4881-ab19-3465e2fd3cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-10a8d491-480b-4e00-9f82-84dcb5c00975,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-8c55ee24-3e2d-49a7-b777-b4284ab19e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-97cf9e53-81a6-4e3b-a817-e523f84e76c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-b47f5bee-e1db-4a2a-b58d-7c416a34f128,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-ce37c879-a455-4883-b80a-ff9f57b2ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-2188ae1f-e221-4905-b08e-9818c815d8a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367061146-172.17.0.20-1595365357489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36880,DS-4023a65c-a3dd-44df-b0bc-046920525242,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-33d2960b-50b2-4881-ab19-3465e2fd3cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-10a8d491-480b-4e00-9f82-84dcb5c00975,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-8c55ee24-3e2d-49a7-b777-b4284ab19e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-97cf9e53-81a6-4e3b-a817-e523f84e76c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-b47f5bee-e1db-4a2a-b58d-7c416a34f128,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-ce37c879-a455-4883-b80a-ff9f57b2ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-2188ae1f-e221-4905-b08e-9818c815d8a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770574212-172.17.0.20-1595365397655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40027,DS-363d19e8-c979-4e52-b873-a8267132dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-0161cfd6-dbd8-43a0-bfc9-b549cb7dc55e,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-d5750570-2912-4665-8910-48421948c829,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-665f8142-f76f-472b-af9b-b4c8856a6269,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-4af6894a-e4b0-41c9-8f4e-170ccd606cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-efe93035-286d-4f8d-b75a-ab3847f1f273,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-082e33b3-0d64-40c7-afe3-6add8a43c585,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-80fab77e-364e-4873-9744-7ca4e34ebbe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770574212-172.17.0.20-1595365397655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40027,DS-363d19e8-c979-4e52-b873-a8267132dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-0161cfd6-dbd8-43a0-bfc9-b549cb7dc55e,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-d5750570-2912-4665-8910-48421948c829,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-665f8142-f76f-472b-af9b-b4c8856a6269,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-4af6894a-e4b0-41c9-8f4e-170ccd606cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-efe93035-286d-4f8d-b75a-ab3847f1f273,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-082e33b3-0d64-40c7-afe3-6add8a43c585,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-80fab77e-364e-4873-9744-7ca4e34ebbe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062520470-172.17.0.20-1595365564090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-0edf7f5e-5c37-40c3-8107-90719911bb80,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-f50bfedf-f20b-41d6-8ee7-508e509fdc98,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-5a2cceaa-d2c1-4ee8-9133-63d1a2d0d6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-eaf3aa95-82ec-4724-98f5-3c03e62260aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-5fb05a89-d1c2-4bb0-a321-7fe4c6f64e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-4e1783a1-c32d-451f-abbe-20cf105375ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-dab0eed0-3c56-4d35-ae4d-1fb38b42f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-b60ce751-5c79-409f-90fa-b33d991f6cf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062520470-172.17.0.20-1595365564090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-0edf7f5e-5c37-40c3-8107-90719911bb80,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-f50bfedf-f20b-41d6-8ee7-508e509fdc98,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-5a2cceaa-d2c1-4ee8-9133-63d1a2d0d6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-eaf3aa95-82ec-4724-98f5-3c03e62260aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-5fb05a89-d1c2-4bb0-a321-7fe4c6f64e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-4e1783a1-c32d-451f-abbe-20cf105375ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-dab0eed0-3c56-4d35-ae4d-1fb38b42f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-b60ce751-5c79-409f-90fa-b33d991f6cf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017423740-172.17.0.20-1595365640691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-397ee220-c0a6-45bb-8e6b-b36adf293445,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-99d8dc9a-da03-4589-8c72-fbb030d64df5,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-85402a20-c3bf-4593-aaae-2c6907fcdf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-38f6999b-9bb8-458f-89ba-9b97b6c921e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-77f12754-55d5-4b9d-bd8a-9f7a961fc39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-e5706431-618e-4638-b0c4-11d0e33dee18,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-925513e9-160b-4d9b-bf8e-8f0d5feaf8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-01c35053-8d9b-4a6f-8a4e-68c3962985c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017423740-172.17.0.20-1595365640691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-397ee220-c0a6-45bb-8e6b-b36adf293445,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-99d8dc9a-da03-4589-8c72-fbb030d64df5,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-85402a20-c3bf-4593-aaae-2c6907fcdf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-38f6999b-9bb8-458f-89ba-9b97b6c921e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-77f12754-55d5-4b9d-bd8a-9f7a961fc39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-e5706431-618e-4638-b0c4-11d0e33dee18,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-925513e9-160b-4d9b-bf8e-8f0d5feaf8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-01c35053-8d9b-4a6f-8a4e-68c3962985c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465155454-172.17.0.20-1595365714841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36581,DS-06805ebe-5a72-43cb-91a4-286f7eb597c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-ef567d5d-b3a1-43fa-8e15-47274929c13e,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-e1899a41-0ada-4d50-bb05-5606ba1f3ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-a82b5049-c411-4775-ba41-06b063f4ae4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-405b2186-bec0-4b64-9506-7d650bef03a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-74f63487-a81d-4fc4-a6d9-58425f9e4de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-7002db4d-eb25-4d59-94e9-bd209dcc1229,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-918c6e57-7736-4e86-8f4a-c98fab863c8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465155454-172.17.0.20-1595365714841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36581,DS-06805ebe-5a72-43cb-91a4-286f7eb597c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-ef567d5d-b3a1-43fa-8e15-47274929c13e,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-e1899a41-0ada-4d50-bb05-5606ba1f3ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-a82b5049-c411-4775-ba41-06b063f4ae4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-405b2186-bec0-4b64-9506-7d650bef03a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-74f63487-a81d-4fc4-a6d9-58425f9e4de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-7002db4d-eb25-4d59-94e9-bd209dcc1229,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-918c6e57-7736-4e86-8f4a-c98fab863c8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453932805-172.17.0.20-1595365775241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-5a260865-c942-4bd7-9083-1b5e7c74cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-29fa3d3e-579b-4865-b4ec-189669a3678d,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-fbefff49-7807-40a8-a28e-d575952e01f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-a1c59e77-e9e7-49c2-bd8d-74d73a6f2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-cb98564f-f14f-48e6-9a76-2b9c102ceca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-347ae41e-a1af-4acb-8dac-e12cde0cc020,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-5ba4950b-c821-400e-afb7-3ce28555f18b,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-e9228b6a-66c4-44c3-a80b-94597a058df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453932805-172.17.0.20-1595365775241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-5a260865-c942-4bd7-9083-1b5e7c74cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-29fa3d3e-579b-4865-b4ec-189669a3678d,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-fbefff49-7807-40a8-a28e-d575952e01f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-a1c59e77-e9e7-49c2-bd8d-74d73a6f2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-cb98564f-f14f-48e6-9a76-2b9c102ceca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-347ae41e-a1af-4acb-8dac-e12cde0cc020,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-5ba4950b-c821-400e-afb7-3ce28555f18b,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-e9228b6a-66c4-44c3-a80b-94597a058df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123104235-172.17.0.20-1595365948830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37758,DS-1585402d-e43b-4daf-9aa4-22af7c8414b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-805d17f1-e2e9-4235-bc82-8197a420a7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-f4c09a81-6b2b-462c-a9dc-e624dd3e2e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-8f1f9dc8-ad61-40cf-b5ec-87f3dabaceca,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-70d6e7ce-270c-451b-a320-b0879b29cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-65bee88f-32fc-495e-ab78-7a5a62300380,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-9e331d0a-12b8-4d33-89e2-1f7dcf49b6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-628d8ed7-06ca-4baa-a443-e58a82cebc5f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123104235-172.17.0.20-1595365948830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37758,DS-1585402d-e43b-4daf-9aa4-22af7c8414b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-805d17f1-e2e9-4235-bc82-8197a420a7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-f4c09a81-6b2b-462c-a9dc-e624dd3e2e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-8f1f9dc8-ad61-40cf-b5ec-87f3dabaceca,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-70d6e7ce-270c-451b-a320-b0879b29cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-65bee88f-32fc-495e-ab78-7a5a62300380,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-9e331d0a-12b8-4d33-89e2-1f7dcf49b6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-628d8ed7-06ca-4baa-a443-e58a82cebc5f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220008469-172.17.0.20-1595366024543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41536,DS-ac280468-351c-4492-8a83-21bc8b03b359,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-8a85b796-01a5-4318-8088-a258962abfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-1cf9b886-79fd-43f0-b1d6-3969439f6a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-177d6e96-beb9-4f97-ae80-e8f7137f8b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-7208e449-db90-4ef0-8fb2-c71920399c14,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-a74d62eb-82e8-4234-afd4-dbedfd4c01f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-f32d4628-5d4e-47d7-8a85-d24160adea29,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-34fd0ef2-0a15-4984-85a7-cdb3a562dbde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220008469-172.17.0.20-1595366024543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41536,DS-ac280468-351c-4492-8a83-21bc8b03b359,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-8a85b796-01a5-4318-8088-a258962abfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-1cf9b886-79fd-43f0-b1d6-3969439f6a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-177d6e96-beb9-4f97-ae80-e8f7137f8b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-7208e449-db90-4ef0-8fb2-c71920399c14,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-a74d62eb-82e8-4234-afd4-dbedfd4c01f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-f32d4628-5d4e-47d7-8a85-d24160adea29,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-34fd0ef2-0a15-4984-85a7-cdb3a562dbde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937364439-172.17.0.20-1595366098694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-8a6a76bb-4ee3-4146-8014-a116e41159a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-06ff2494-98d9-48e2-a453-482087f67667,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-e7f3aab2-dfcb-4dcb-9e97-98536ad53a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-bad233b8-f5ef-422e-9df6-96b7e47a0892,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-ae95bcaa-cd87-43b7-acc3-54b8d3e0a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-beab43b1-0ea3-48e8-96b8-69b0317085e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-c076043a-af9f-469f-b893-84c9796053c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-205a250f-ff6b-464e-bf97-03ab64c64c66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937364439-172.17.0.20-1595366098694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-8a6a76bb-4ee3-4146-8014-a116e41159a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-06ff2494-98d9-48e2-a453-482087f67667,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-e7f3aab2-dfcb-4dcb-9e97-98536ad53a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-bad233b8-f5ef-422e-9df6-96b7e47a0892,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-ae95bcaa-cd87-43b7-acc3-54b8d3e0a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-beab43b1-0ea3-48e8-96b8-69b0317085e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-c076043a-af9f-469f-b893-84c9796053c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-205a250f-ff6b-464e-bf97-03ab64c64c66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15649642-172.17.0.20-1595366137308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-2d910723-e7e4-4fc6-8aac-f7e9944f2ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-8827aa05-4d39-4ecc-bcb6-a601f95f5467,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-c9531f1b-7eb0-4655-a5d7-26c61011372b,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-c2d0229b-e5b2-4176-a3f1-2d85f44b1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-4e35afe5-81da-4209-969d-ddd5b09d574d,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-e5f0d424-4e28-44e0-bf1b-d74eb7d4ec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-7f4d1bbd-52fe-4af3-87a5-aaaa886099b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-b615b6f0-e7d9-4b72-96b8-285ed229d60d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15649642-172.17.0.20-1595366137308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-2d910723-e7e4-4fc6-8aac-f7e9944f2ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-8827aa05-4d39-4ecc-bcb6-a601f95f5467,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-c9531f1b-7eb0-4655-a5d7-26c61011372b,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-c2d0229b-e5b2-4176-a3f1-2d85f44b1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-4e35afe5-81da-4209-969d-ddd5b09d574d,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-e5f0d424-4e28-44e0-bf1b-d74eb7d4ec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-7f4d1bbd-52fe-4af3-87a5-aaaa886099b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-b615b6f0-e7d9-4b72-96b8-285ed229d60d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353507132-172.17.0.20-1595366202034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44017,DS-9333c359-aef7-4fa2-afe8-bd40a371ae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-cc39ea0d-ec88-4d66-a45b-d51ebe325679,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-9ca47f1b-e9b3-4e2d-9cc9-bd18fb4780b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-cfe57c44-3bb1-4980-a1c6-7be393b89dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-3a80bed5-ef7f-41f2-a75c-b66f02a89c02,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-9ed0823c-e41c-4de1-9a9b-357acdd213d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-a48603d9-ac3f-4957-95e6-b7f113ef0522,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-a9ac14b2-0e1d-40bf-88f6-9313fd22d729,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353507132-172.17.0.20-1595366202034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44017,DS-9333c359-aef7-4fa2-afe8-bd40a371ae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-cc39ea0d-ec88-4d66-a45b-d51ebe325679,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-9ca47f1b-e9b3-4e2d-9cc9-bd18fb4780b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-cfe57c44-3bb1-4980-a1c6-7be393b89dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-3a80bed5-ef7f-41f2-a75c-b66f02a89c02,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-9ed0823c-e41c-4de1-9a9b-357acdd213d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-a48603d9-ac3f-4957-95e6-b7f113ef0522,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-a9ac14b2-0e1d-40bf-88f6-9313fd22d729,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529206553-172.17.0.20-1595366478302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-6c5830b8-5e54-42ef-a776-b6e0fabf65a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-18a86f55-f3a6-4e8f-a6e0-e6ff8a28e336,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-96525bba-53b6-483e-a308-5aa1b5098426,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-74cec492-0db7-4763-a36c-b97500712835,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-5582d658-242b-47db-bb71-7d1187c29838,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-3c259495-20d3-4cc7-a85c-0dacb1aec32d,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-6a8d03c2-1d43-4b95-95f5-34ea45c47818,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-5a9ebebf-bceb-4c05-a1a9-ec55c9d477bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529206553-172.17.0.20-1595366478302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-6c5830b8-5e54-42ef-a776-b6e0fabf65a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-18a86f55-f3a6-4e8f-a6e0-e6ff8a28e336,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-96525bba-53b6-483e-a308-5aa1b5098426,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-74cec492-0db7-4763-a36c-b97500712835,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-5582d658-242b-47db-bb71-7d1187c29838,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-3c259495-20d3-4cc7-a85c-0dacb1aec32d,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-6a8d03c2-1d43-4b95-95f5-34ea45c47818,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-5a9ebebf-bceb-4c05-a1a9-ec55c9d477bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543866683-172.17.0.20-1595366613695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44531,DS-735eb36b-df9a-4984-9379-5d2dc8ca167c,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-646d9b01-b310-4cb2-ae7b-98a77f270378,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-8d005eb8-f3f3-43fa-bd65-754bcb0abb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-ebf43561-e23d-4705-a6a8-d34e39868b79,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-51e19c56-a99f-4baa-a06b-5f563f6e140a,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-3c11cdc1-b6c2-43f1-be44-2c1e51da92f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-51fed02b-dcb4-4ebb-94ba-99b9a5c79372,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-3e3c2d96-c543-4344-8d0e-522ee15eeece,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543866683-172.17.0.20-1595366613695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44531,DS-735eb36b-df9a-4984-9379-5d2dc8ca167c,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-646d9b01-b310-4cb2-ae7b-98a77f270378,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-8d005eb8-f3f3-43fa-bd65-754bcb0abb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-ebf43561-e23d-4705-a6a8-d34e39868b79,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-51e19c56-a99f-4baa-a06b-5f563f6e140a,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-3c11cdc1-b6c2-43f1-be44-2c1e51da92f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-51fed02b-dcb4-4ebb-94ba-99b9a5c79372,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-3e3c2d96-c543-4344-8d0e-522ee15eeece,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846183363-172.17.0.20-1595366838299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39412,DS-164e7912-2de7-476a-988f-59cf940c3462,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-9881191e-1f30-4e49-95af-0bc1ae9ac2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-e3dd7dad-c64b-4768-9254-1e25e9dcdbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-7a54f10b-656f-47e5-99be-289bf7d4fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-6534da15-8d8b-4190-8bfb-0af149459baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-2280f5d5-e202-4b12-aaf1-c0f1dc64fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-6da8b437-5b40-4517-9f51-5bfb3fe67fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-d58b2b73-19cb-4723-a437-4db57012ef4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846183363-172.17.0.20-1595366838299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39412,DS-164e7912-2de7-476a-988f-59cf940c3462,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-9881191e-1f30-4e49-95af-0bc1ae9ac2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-e3dd7dad-c64b-4768-9254-1e25e9dcdbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-7a54f10b-656f-47e5-99be-289bf7d4fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-6534da15-8d8b-4190-8bfb-0af149459baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-2280f5d5-e202-4b12-aaf1-c0f1dc64fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-6da8b437-5b40-4517-9f51-5bfb3fe67fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-d58b2b73-19cb-4723-a437-4db57012ef4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865288474-172.17.0.20-1595366938440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34645,DS-5056b950-6f38-447f-86b8-18262d2495f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-b8ce6c90-bcb6-464b-8aa4-2ac6391603ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-3093dd66-ee83-46a4-bb00-c53624c71b54,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-43cb48eb-2713-4281-949c-9fc6d48fadba,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-81e348a8-6242-4eda-be77-c3f422420ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-0bcf9e82-9de9-44fe-9898-39628f79fa51,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-a6eca843-cb07-4da7-a410-f41ff7f50d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-4443bf45-6bc2-401b-812f-94ac6efa7db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865288474-172.17.0.20-1595366938440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34645,DS-5056b950-6f38-447f-86b8-18262d2495f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-b8ce6c90-bcb6-464b-8aa4-2ac6391603ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-3093dd66-ee83-46a4-bb00-c53624c71b54,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-43cb48eb-2713-4281-949c-9fc6d48fadba,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-81e348a8-6242-4eda-be77-c3f422420ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-0bcf9e82-9de9-44fe-9898-39628f79fa51,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-a6eca843-cb07-4da7-a410-f41ff7f50d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-4443bf45-6bc2-401b-812f-94ac6efa7db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662959436-172.17.0.20-1595367012505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-db5036bb-a1af-4d3a-a80e-2bf6e8d84adc,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-bd04a113-aa65-4aa5-95ef-98643e52119c,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-a36be05e-e111-4abc-9c55-3b4b29851f34,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-ca9bf8f3-10e3-4e40-b682-06dd309eb7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-72f0107d-7b3a-48ad-8f03-8b5da475682f,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-56e41c92-53aa-47ab-b4c4-7dfe1c212dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-d79eb238-63f2-47dc-9e0b-64cb3c065302,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-231b6b49-e375-47dc-99ac-a79db230ac9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662959436-172.17.0.20-1595367012505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-db5036bb-a1af-4d3a-a80e-2bf6e8d84adc,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-bd04a113-aa65-4aa5-95ef-98643e52119c,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-a36be05e-e111-4abc-9c55-3b4b29851f34,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-ca9bf8f3-10e3-4e40-b682-06dd309eb7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-72f0107d-7b3a-48ad-8f03-8b5da475682f,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-56e41c92-53aa-47ab-b4c4-7dfe1c212dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-d79eb238-63f2-47dc-9e0b-64cb3c065302,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-231b6b49-e375-47dc-99ac-a79db230ac9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221281495-172.17.0.20-1595367044865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-8b36fae9-a5f1-40e4-85f3-42f064daae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-39b6818a-9371-4792-9f7e-a3c889a67789,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-bc0cd706-4481-46f3-accc-d3629380124f,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-fef24766-0e82-4679-9380-1efcd652bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-78b0bff2-aad1-4f73-9435-599e639249ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-5dfead8a-f31a-4afd-a35b-d736d405905a,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-d24e7a54-0dc1-4292-a8e9-8ce410d80ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-6c17283b-2bd7-444a-a8ad-e3f62a8b12dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221281495-172.17.0.20-1595367044865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-8b36fae9-a5f1-40e4-85f3-42f064daae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-39b6818a-9371-4792-9f7e-a3c889a67789,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-bc0cd706-4481-46f3-accc-d3629380124f,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-fef24766-0e82-4679-9380-1efcd652bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-78b0bff2-aad1-4f73-9435-599e639249ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-5dfead8a-f31a-4afd-a35b-d736d405905a,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-d24e7a54-0dc1-4292-a8e9-8ce410d80ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-6c17283b-2bd7-444a-a8ad-e3f62a8b12dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638401471-172.17.0.20-1595367259923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34609,DS-de05b3e5-9ad5-4889-acd8-09de2bbec321,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-5d48d708-4bfd-4c11-89ff-d613582f710b,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-c76b6b22-b862-4500-9025-4c6b6ab6cf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-df660986-7e0e-4924-8e8f-1944b0e521ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-7e1d0eb0-2154-4f9d-ba7e-c3a4b09b07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-59fa7e73-de37-4e4f-b3db-794a46eb3c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-c4b5f1ab-d893-4bf0-8dda-9558187402f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-9b1888ce-0391-4c4b-af25-2ec25a3c5e8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638401471-172.17.0.20-1595367259923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34609,DS-de05b3e5-9ad5-4889-acd8-09de2bbec321,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-5d48d708-4bfd-4c11-89ff-d613582f710b,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-c76b6b22-b862-4500-9025-4c6b6ab6cf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-df660986-7e0e-4924-8e8f-1944b0e521ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-7e1d0eb0-2154-4f9d-ba7e-c3a4b09b07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-59fa7e73-de37-4e4f-b3db-794a46eb3c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-c4b5f1ab-d893-4bf0-8dda-9558187402f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-9b1888ce-0391-4c4b-af25-2ec25a3c5e8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774339832-172.17.0.20-1595367326766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-6460a643-1e3e-4ec4-84a6-d0f4820a9ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-e2ac8874-4271-4c04-aee5-f2065b909ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-0f6b07b8-6854-43fe-a886-e402157b1e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-a4f4d635-1932-4971-9630-800cd5603319,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-445517c0-d779-440a-9da8-38ab1fe4441f,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-dafbd7ba-328e-4292-9d1e-2c9b2324db8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-b564c6bc-c4fe-4f75-b87a-150ce15f9ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-3e25c5b8-8932-4594-8088-582e859a6533,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774339832-172.17.0.20-1595367326766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-6460a643-1e3e-4ec4-84a6-d0f4820a9ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-e2ac8874-4271-4c04-aee5-f2065b909ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-0f6b07b8-6854-43fe-a886-e402157b1e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-a4f4d635-1932-4971-9630-800cd5603319,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-445517c0-d779-440a-9da8-38ab1fe4441f,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-dafbd7ba-328e-4292-9d1e-2c9b2324db8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-b564c6bc-c4fe-4f75-b87a-150ce15f9ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-3e25c5b8-8932-4594-8088-582e859a6533,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006092608-172.17.0.20-1595367434169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41168,DS-3c6af45c-bb92-4601-8958-281e6de2e243,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-9fc006b1-4708-42ea-9d16-b0652dcab45f,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-c6cc8502-19e9-4f78-8375-38c418325020,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-734ef4f6-2f13-4af4-9c9b-466e316cd047,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-87fb6a8c-cd06-4242-af98-b9129e18ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-f25dd543-f5f9-4b60-8346-23ef2bf3b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-7c9273a5-22c7-4e45-af4f-a7c7725e9bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-c2bb57be-dcfa-4642-ac10-e2a3478342cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006092608-172.17.0.20-1595367434169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41168,DS-3c6af45c-bb92-4601-8958-281e6de2e243,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-9fc006b1-4708-42ea-9d16-b0652dcab45f,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-c6cc8502-19e9-4f78-8375-38c418325020,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-734ef4f6-2f13-4af4-9c9b-466e316cd047,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-87fb6a8c-cd06-4242-af98-b9129e18ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-f25dd543-f5f9-4b60-8346-23ef2bf3b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-7c9273a5-22c7-4e45-af4f-a7c7725e9bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-c2bb57be-dcfa-4642-ac10-e2a3478342cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988292774-172.17.0.20-1595367856284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46726,DS-3c8b3f49-4817-4858-83c0-f7291e7d3c42,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-4f1bb1d0-b2e2-4dcf-a0df-ba3d75d38fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-28863505-fcf7-401e-81fc-85dc7c706f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-61386e24-d479-4248-b849-9d860de9d4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-0e9f25ed-21bf-47af-a281-f44844054d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-1cf2be00-46c4-48f1-b5fb-214e86d91736,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-1a520cfc-cc64-4608-ab21-be7a68f7a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-71fcc160-aa29-4507-9116-00de2fcd0880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988292774-172.17.0.20-1595367856284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46726,DS-3c8b3f49-4817-4858-83c0-f7291e7d3c42,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-4f1bb1d0-b2e2-4dcf-a0df-ba3d75d38fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-28863505-fcf7-401e-81fc-85dc7c706f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-61386e24-d479-4248-b849-9d860de9d4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-0e9f25ed-21bf-47af-a281-f44844054d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-1cf2be00-46c4-48f1-b5fb-214e86d91736,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-1a520cfc-cc64-4608-ab21-be7a68f7a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-71fcc160-aa29-4507-9116-00de2fcd0880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836450079-172.17.0.20-1595367933552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-82442bf4-0b01-4f89-bcb6-faa67a02f2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-64fd8239-055d-46a2-8bb2-30824d0278da,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-98fdf14a-b447-475c-9525-66c17a3ea9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-408ee6e5-d520-44ff-b04e-b07679e4d2db,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-6b7288f2-b53a-4709-982b-1a7a8dc3bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-98c39ffd-b09f-4bd9-9482-c2679d950a01,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-15d9ecf8-ae74-4236-8c59-2ed427fccf76,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-2a8016e4-6da2-4ab4-8bc7-85f000f4800b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836450079-172.17.0.20-1595367933552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43291,DS-82442bf4-0b01-4f89-bcb6-faa67a02f2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-64fd8239-055d-46a2-8bb2-30824d0278da,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-98fdf14a-b447-475c-9525-66c17a3ea9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-408ee6e5-d520-44ff-b04e-b07679e4d2db,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-6b7288f2-b53a-4709-982b-1a7a8dc3bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-98c39ffd-b09f-4bd9-9482-c2679d950a01,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-15d9ecf8-ae74-4236-8c59-2ed427fccf76,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-2a8016e4-6da2-4ab4-8bc7-85f000f4800b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125170595-172.17.0.20-1595368051907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35201,DS-bae2ec43-6468-456f-a377-20aeec8fd661,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-e7a7539b-0cca-471e-878f-21e17fa09e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-36cce612-c288-4c5c-a420-31e3a9a13226,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-3214974c-4abc-4938-9049-df78203412a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-b31d6d10-20c3-4c1f-9bda-1b357ee6b2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-2125c05a-c3c8-4ddd-9565-6082ac73ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-21caf378-00cb-46f1-b1b4-c94e59d535f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-081a9045-f1dc-4658-97ab-3f3253ea603b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125170595-172.17.0.20-1595368051907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35201,DS-bae2ec43-6468-456f-a377-20aeec8fd661,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-e7a7539b-0cca-471e-878f-21e17fa09e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-36cce612-c288-4c5c-a420-31e3a9a13226,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-3214974c-4abc-4938-9049-df78203412a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-b31d6d10-20c3-4c1f-9bda-1b357ee6b2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-2125c05a-c3c8-4ddd-9565-6082ac73ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-21caf378-00cb-46f1-b1b4-c94e59d535f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-081a9045-f1dc-4658-97ab-3f3253ea603b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306302583-172.17.0.20-1595368224423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39273,DS-8ec1eaae-d145-4d62-b3e1-3b7918da8f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-89b52aab-3206-4b30-b1c2-93d5439056a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-d5e89312-d520-42a6-805b-a3ca07bfad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-220ea711-6ae4-4a92-9530-4d89b3d1fdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-14357af3-0077-40f3-b88e-9905b3872c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-8e28d2e9-f235-45a5-a85b-44be2bacfa01,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-73635188-e9f4-4d47-b4aa-7e6bd9b1d7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-1e2e3c62-d9ac-44a8-a7d1-6b1013e676fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306302583-172.17.0.20-1595368224423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39273,DS-8ec1eaae-d145-4d62-b3e1-3b7918da8f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-89b52aab-3206-4b30-b1c2-93d5439056a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-d5e89312-d520-42a6-805b-a3ca07bfad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-220ea711-6ae4-4a92-9530-4d89b3d1fdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-14357af3-0077-40f3-b88e-9905b3872c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-8e28d2e9-f235-45a5-a85b-44be2bacfa01,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-73635188-e9f4-4d47-b4aa-7e6bd9b1d7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-1e2e3c62-d9ac-44a8-a7d1-6b1013e676fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750882782-172.17.0.20-1595368274447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39808,DS-415e80c7-de53-403f-a27c-93ea2082abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-622d7922-9cb7-4034-a489-3cf5ff0e4d14,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-11731f41-d8c8-4f89-8022-803d49435e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-e8ef5b43-979d-485d-b73f-874b0291d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-200758f8-0a78-4adf-874d-ee177b0fc728,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-055ab85f-05ac-4517-a8d5-fce770145e79,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-d0061984-4552-4e13-90e2-025bfcf74289,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-23b46b06-1231-4e10-8f72-d0754a57f63d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750882782-172.17.0.20-1595368274447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39808,DS-415e80c7-de53-403f-a27c-93ea2082abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-622d7922-9cb7-4034-a489-3cf5ff0e4d14,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-11731f41-d8c8-4f89-8022-803d49435e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-e8ef5b43-979d-485d-b73f-874b0291d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-200758f8-0a78-4adf-874d-ee177b0fc728,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-055ab85f-05ac-4517-a8d5-fce770145e79,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-d0061984-4552-4e13-90e2-025bfcf74289,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-23b46b06-1231-4e10-8f72-d0754a57f63d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523433954-172.17.0.20-1595368310663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-9e871fb5-3495-4de8-b97f-fcb6539699bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-6c27f996-3a93-4f46-a71f-09f8e1a2bf47,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-0d8be63e-b417-4324-8e07-51e7655595e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-86c49376-6ece-4132-8ab3-b04318393476,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-9408840f-7703-4f28-a19f-05d4b1b2a638,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-5cc5ec75-7624-4b3a-808e-251e98f92e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-e0f46f79-3632-4932-8490-69bcbb2c6349,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-d111f368-a671-4077-95df-11ca917fd4d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523433954-172.17.0.20-1595368310663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-9e871fb5-3495-4de8-b97f-fcb6539699bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-6c27f996-3a93-4f46-a71f-09f8e1a2bf47,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-0d8be63e-b417-4324-8e07-51e7655595e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-86c49376-6ece-4132-8ab3-b04318393476,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-9408840f-7703-4f28-a19f-05d4b1b2a638,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-5cc5ec75-7624-4b3a-808e-251e98f92e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-e0f46f79-3632-4932-8490-69bcbb2c6349,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-d111f368-a671-4077-95df-11ca917fd4d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 5395
