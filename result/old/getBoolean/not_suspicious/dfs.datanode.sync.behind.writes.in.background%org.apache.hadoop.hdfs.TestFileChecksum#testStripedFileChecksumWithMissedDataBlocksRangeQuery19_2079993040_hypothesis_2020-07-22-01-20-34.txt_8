reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870920523-172.17.0.13-1595381486223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-28fda93b-7133-4b9c-94ec-9aed92b11fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-ff8bb44b-6954-4cb5-a6a9-ee764b947559,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-f1a7a87a-0f54-47df-afdb-c518184cdd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-1370e2ec-4aca-4df2-be98-4359efc2b471,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-cc91739e-7c0a-433b-ad8d-3cb54073bbea,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-a72bb3b5-50f3-437d-b165-a1ec684e1365,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-b7b04276-5b81-4128-929c-f7ed69ff7ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-1df2ca57-e02f-44fe-a167-9fa1ccdfd61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870920523-172.17.0.13-1595381486223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-28fda93b-7133-4b9c-94ec-9aed92b11fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-ff8bb44b-6954-4cb5-a6a9-ee764b947559,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-f1a7a87a-0f54-47df-afdb-c518184cdd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-1370e2ec-4aca-4df2-be98-4359efc2b471,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-cc91739e-7c0a-433b-ad8d-3cb54073bbea,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-a72bb3b5-50f3-437d-b165-a1ec684e1365,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-b7b04276-5b81-4128-929c-f7ed69ff7ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-1df2ca57-e02f-44fe-a167-9fa1ccdfd61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026542362-172.17.0.13-1595381828878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-0aa51585-28a6-4fea-b276-23b6b2ce3274,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-585b2d67-5a42-4811-a0b7-511ace225b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-d8681e81-5806-455c-ae79-3744b2ca5781,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-8b0646e0-1ccb-412d-8715-ac25cdb7066f,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-4e0ab588-931b-4a71-8375-d68934b0761c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-07c78ac0-8af9-4ef8-af30-930a6fa0c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-eab0a0e9-19ab-4233-8ed4-194b842d62d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-74a75cf9-e6c0-4b92-a6c6-82a1695429ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026542362-172.17.0.13-1595381828878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-0aa51585-28a6-4fea-b276-23b6b2ce3274,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-585b2d67-5a42-4811-a0b7-511ace225b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-d8681e81-5806-455c-ae79-3744b2ca5781,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-8b0646e0-1ccb-412d-8715-ac25cdb7066f,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-4e0ab588-931b-4a71-8375-d68934b0761c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-07c78ac0-8af9-4ef8-af30-930a6fa0c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-eab0a0e9-19ab-4233-8ed4-194b842d62d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-74a75cf9-e6c0-4b92-a6c6-82a1695429ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764838180-172.17.0.13-1595382054009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34401,DS-1a5294fe-c826-455f-8c0b-595ad88efbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-42e6d2fc-ac80-43c4-be02-c13d6994b704,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-0544fc9f-8770-478b-8aac-36756958af29,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-e3e8e988-065c-47ae-bdd0-178afa434ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-a1cb3356-8e6c-4e33-b90e-b9195f3ed494,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-3cefe8b6-7024-4e52-9de5-468b2dbd8a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-a73eb5d8-0bf8-415c-bafe-ec2089d8901d,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-6ed1c082-5513-4ab2-a507-4b41f505cfee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764838180-172.17.0.13-1595382054009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34401,DS-1a5294fe-c826-455f-8c0b-595ad88efbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-42e6d2fc-ac80-43c4-be02-c13d6994b704,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-0544fc9f-8770-478b-8aac-36756958af29,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-e3e8e988-065c-47ae-bdd0-178afa434ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-a1cb3356-8e6c-4e33-b90e-b9195f3ed494,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-3cefe8b6-7024-4e52-9de5-468b2dbd8a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-a73eb5d8-0bf8-415c-bafe-ec2089d8901d,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-6ed1c082-5513-4ab2-a507-4b41f505cfee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018832170-172.17.0.13-1595382849614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41735,DS-ef889174-5fdd-4ea1-b3b7-7a9ee8e7dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-29e00614-047f-4199-83d6-8fdeb56d1f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-d58f9a16-c719-45d0-a5f4-db9412a835a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-bcefe5a1-53b9-48ed-b895-75403e3d14ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-c5e2a913-c77a-48b5-bdc0-30da38633c28,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-fa9afec0-2e0d-4556-bcb1-4b0651a59dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-dea7aea5-eccc-4399-806b-60c3ed740371,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ff17e77f-1c82-40ae-8f5d-d7e5b68a378c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018832170-172.17.0.13-1595382849614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41735,DS-ef889174-5fdd-4ea1-b3b7-7a9ee8e7dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-29e00614-047f-4199-83d6-8fdeb56d1f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-d58f9a16-c719-45d0-a5f4-db9412a835a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-bcefe5a1-53b9-48ed-b895-75403e3d14ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-c5e2a913-c77a-48b5-bdc0-30da38633c28,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-fa9afec0-2e0d-4556-bcb1-4b0651a59dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-dea7aea5-eccc-4399-806b-60c3ed740371,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ff17e77f-1c82-40ae-8f5d-d7e5b68a378c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542373374-172.17.0.13-1595382881988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-521b870b-1fdb-4187-838e-3ea571dc5e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-45aaa1fd-8c86-40f8-ae2b-641dba5f0f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-3a778c4a-4c83-4e86-903b-10d2ceb4f80d,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-01b3f0af-34eb-4592-b90d-83fad851ef8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-f80320de-9d0c-4578-b85d-bd3bc6cfccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-87cc42f0-e5ff-43db-b441-16391ffb3341,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-b149c03a-847a-45fa-bb9a-b21c0c484344,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-8367dc72-f9a1-42a5-a225-7936f75339ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542373374-172.17.0.13-1595382881988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-521b870b-1fdb-4187-838e-3ea571dc5e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-45aaa1fd-8c86-40f8-ae2b-641dba5f0f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-3a778c4a-4c83-4e86-903b-10d2ceb4f80d,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-01b3f0af-34eb-4592-b90d-83fad851ef8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-f80320de-9d0c-4578-b85d-bd3bc6cfccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-87cc42f0-e5ff-43db-b441-16391ffb3341,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-b149c03a-847a-45fa-bb9a-b21c0c484344,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-8367dc72-f9a1-42a5-a225-7936f75339ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709453392-172.17.0.13-1595383223242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-b29dae80-e04b-4ea1-8dbf-c7ee311ee926,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-c0a4e21c-a190-4c14-be09-747fad5132bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-62976d23-f1c7-4cdd-8f29-6a961d27c185,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-43de57ac-af33-4fbf-9f3a-803cba0b323b,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-62fb5ff2-9db6-4d35-9b42-d4800f6caff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-3499514a-8a9f-439d-b4a4-0447b9f76121,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-35e1a349-9d06-4c04-95fc-001285de8c59,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-78664042-f325-4f3c-9b12-8fde4fb59905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709453392-172.17.0.13-1595383223242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-b29dae80-e04b-4ea1-8dbf-c7ee311ee926,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-c0a4e21c-a190-4c14-be09-747fad5132bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-62976d23-f1c7-4cdd-8f29-6a961d27c185,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-43de57ac-af33-4fbf-9f3a-803cba0b323b,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-62fb5ff2-9db6-4d35-9b42-d4800f6caff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-3499514a-8a9f-439d-b4a4-0447b9f76121,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-35e1a349-9d06-4c04-95fc-001285de8c59,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-78664042-f325-4f3c-9b12-8fde4fb59905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264211641-172.17.0.13-1595383295128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-c6e90392-f73c-4da2-8389-a36ba87be18d,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-fb91e5de-4002-4628-83d1-d840ef5e68df,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-0643b683-ca60-4e4a-bd12-1e4ac45c7c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-c4a81fea-cfad-4ab3-9180-acd5fdf3c413,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-71500e50-48c2-47ed-b3d0-ef339c6b367f,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-18ecf9d5-ccb6-4cbb-8094-4cb7a85aaf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-2f747eaf-39bf-4eb8-a7a3-12a8f1e0ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-5775d22e-ac43-4034-bc34-12998f294214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264211641-172.17.0.13-1595383295128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-c6e90392-f73c-4da2-8389-a36ba87be18d,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-fb91e5de-4002-4628-83d1-d840ef5e68df,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-0643b683-ca60-4e4a-bd12-1e4ac45c7c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-c4a81fea-cfad-4ab3-9180-acd5fdf3c413,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-71500e50-48c2-47ed-b3d0-ef339c6b367f,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-18ecf9d5-ccb6-4cbb-8094-4cb7a85aaf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-2f747eaf-39bf-4eb8-a7a3-12a8f1e0ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-5775d22e-ac43-4034-bc34-12998f294214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-863725258-172.17.0.13-1595383541764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43732,DS-4e6cb3e5-8cb8-4afd-b51c-bf1a17e17b69,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-dd878b83-0313-4d03-8fc7-84d93166303d,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-c0d0f354-1050-4516-a986-21d0ecb8030c,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-0abe83e3-d091-4f83-8be1-c5d106d00e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-1874c848-b040-4c32-81f8-66ef8c9b5e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-a4e11080-240f-4e62-91b1-03218b17d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-52e8f846-f2fc-422c-b8d2-00a646d2a848,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-06eb7936-7be9-44b4-99e2-d1734b17efcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-863725258-172.17.0.13-1595383541764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43732,DS-4e6cb3e5-8cb8-4afd-b51c-bf1a17e17b69,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-dd878b83-0313-4d03-8fc7-84d93166303d,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-c0d0f354-1050-4516-a986-21d0ecb8030c,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-0abe83e3-d091-4f83-8be1-c5d106d00e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-1874c848-b040-4c32-81f8-66ef8c9b5e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-a4e11080-240f-4e62-91b1-03218b17d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-52e8f846-f2fc-422c-b8d2-00a646d2a848,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-06eb7936-7be9-44b4-99e2-d1734b17efcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328301743-172.17.0.13-1595383711495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44004,DS-e597b37c-60fd-466f-8ee3-edc3359d6699,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-168d6ae9-84aa-47fc-8e5e-2c1b726274e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-30c2f8ce-2e91-4657-896e-bb420cf2d795,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-e442a546-5029-47b8-af33-7eed162bca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-80c71043-3803-4cc0-bbd0-1091e1c6e3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-6772f123-6238-46c4-a906-e0a2e0d9272f,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-23bf09d9-c1b3-4def-bb74-32ceab4fe0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-bc8b7612-6f75-4461-9a4f-c934071d394c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328301743-172.17.0.13-1595383711495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44004,DS-e597b37c-60fd-466f-8ee3-edc3359d6699,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-168d6ae9-84aa-47fc-8e5e-2c1b726274e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-30c2f8ce-2e91-4657-896e-bb420cf2d795,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-e442a546-5029-47b8-af33-7eed162bca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-80c71043-3803-4cc0-bbd0-1091e1c6e3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-6772f123-6238-46c4-a906-e0a2e0d9272f,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-23bf09d9-c1b3-4def-bb74-32ceab4fe0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-bc8b7612-6f75-4461-9a4f-c934071d394c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238748689-172.17.0.13-1595383809632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-fb62c073-4799-4b96-994c-4c284bf4445e,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-9f8ba687-5813-4c2c-b454-63d70fb3c9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-0585bbc6-2bf1-4782-8ff4-96ad5dd317c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-72149cb4-8df6-4093-9f8a-56cc1bd01f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-60017165-8bdd-4480-a22e-d6a93561299d,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-e1461779-fecf-4840-b927-c9c3645f6070,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-091e549a-f36f-47e8-9005-7fe3be47794d,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-45eba127-956e-461a-b9c1-0fd7e3f65604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238748689-172.17.0.13-1595383809632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-fb62c073-4799-4b96-994c-4c284bf4445e,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-9f8ba687-5813-4c2c-b454-63d70fb3c9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-0585bbc6-2bf1-4782-8ff4-96ad5dd317c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-72149cb4-8df6-4093-9f8a-56cc1bd01f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-60017165-8bdd-4480-a22e-d6a93561299d,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-e1461779-fecf-4840-b927-c9c3645f6070,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-091e549a-f36f-47e8-9005-7fe3be47794d,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-45eba127-956e-461a-b9c1-0fd7e3f65604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116045733-172.17.0.13-1595383844231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37818,DS-41dc4d2d-a2d1-4144-bb04-3840f5f085c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-c047ca52-a941-4040-96e0-e3d514a674b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-5ad9cb77-98b0-4854-b06d-fd35d8ad8d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-fb240ec1-2dd2-4778-817e-26802a9d3c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-7f729a46-dd05-40e8-9a10-3bc9d23591aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-87f02544-5b51-4af3-9ae0-6056df810834,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d2b7fa14-2aac-4b2d-ac1c-4110433e87da,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-1213c85d-73e6-41de-bf1a-6a482d1c6659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116045733-172.17.0.13-1595383844231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37818,DS-41dc4d2d-a2d1-4144-bb04-3840f5f085c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-c047ca52-a941-4040-96e0-e3d514a674b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-5ad9cb77-98b0-4854-b06d-fd35d8ad8d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-fb240ec1-2dd2-4778-817e-26802a9d3c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-7f729a46-dd05-40e8-9a10-3bc9d23591aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-87f02544-5b51-4af3-9ae0-6056df810834,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d2b7fa14-2aac-4b2d-ac1c-4110433e87da,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-1213c85d-73e6-41de-bf1a-6a482d1c6659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019560927-172.17.0.13-1595383882799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35283,DS-4f39a8e0-b581-40c5-b9dc-b6a56a97cf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-dddb5f86-4766-4715-9f0a-8d37eed1fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-934ca51a-cdb6-41cc-8c4d-79a3e02bd210,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-853091ae-0783-4cc6-890c-6e4aaffd53c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-0c50f334-344a-41f5-8e79-4a19710f0766,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-386db311-fd33-4d31-8b0a-efc1202f37cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-89fb01c9-283e-4181-a9c3-54b04aba299a,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-b177422f-e9e8-4f46-b3fd-ee1fb5d82292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019560927-172.17.0.13-1595383882799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35283,DS-4f39a8e0-b581-40c5-b9dc-b6a56a97cf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-dddb5f86-4766-4715-9f0a-8d37eed1fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-934ca51a-cdb6-41cc-8c4d-79a3e02bd210,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-853091ae-0783-4cc6-890c-6e4aaffd53c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-0c50f334-344a-41f5-8e79-4a19710f0766,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-386db311-fd33-4d31-8b0a-efc1202f37cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-89fb01c9-283e-4181-a9c3-54b04aba299a,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-b177422f-e9e8-4f46-b3fd-ee1fb5d82292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048794696-172.17.0.13-1595384084550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34006,DS-d8e506f0-efdf-48ea-8ecf-154e4db07723,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-9d7006b1-fcc9-4dc4-87de-cdad6c5f1fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-b98f0a2c-6285-4533-8726-aea3acd2d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-b9674da3-1f56-487a-9530-8d671cffef91,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-45256de1-eb99-4f0e-96c3-9d69d163bcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-9e073265-aef2-47dd-9896-a4cc2c0d3129,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-ec0390a4-d4f3-442a-a965-0a633568f870,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-2271a224-ebcc-41b8-bca4-97853484302b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048794696-172.17.0.13-1595384084550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34006,DS-d8e506f0-efdf-48ea-8ecf-154e4db07723,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-9d7006b1-fcc9-4dc4-87de-cdad6c5f1fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-b98f0a2c-6285-4533-8726-aea3acd2d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-b9674da3-1f56-487a-9530-8d671cffef91,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-45256de1-eb99-4f0e-96c3-9d69d163bcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-9e073265-aef2-47dd-9896-a4cc2c0d3129,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-ec0390a4-d4f3-442a-a965-0a633568f870,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-2271a224-ebcc-41b8-bca4-97853484302b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587959401-172.17.0.13-1595384160242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36793,DS-24b64e94-00ee-404e-a442-e6fec49ea6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-04727fc7-8bef-4ee3-9b6b-054e9eb83260,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-c9c06ccc-0d7c-4714-a695-e3ef73940ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-b3cd9c23-39cc-46b8-83b1-e1cdd16c9488,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-f33172d1-3d17-4c66-8430-cca4f3fa0a51,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-b3db98af-70b2-4cc3-b538-240d8fa98fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-06b8d2a7-6c51-43f6-b1d0-19e4d54fbe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-4a9a11c3-6050-4558-bbbc-d84fef26b21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587959401-172.17.0.13-1595384160242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36793,DS-24b64e94-00ee-404e-a442-e6fec49ea6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-04727fc7-8bef-4ee3-9b6b-054e9eb83260,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-c9c06ccc-0d7c-4714-a695-e3ef73940ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-b3cd9c23-39cc-46b8-83b1-e1cdd16c9488,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-f33172d1-3d17-4c66-8430-cca4f3fa0a51,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-b3db98af-70b2-4cc3-b538-240d8fa98fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-06b8d2a7-6c51-43f6-b1d0-19e4d54fbe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-4a9a11c3-6050-4558-bbbc-d84fef26b21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608344884-172.17.0.13-1595384365243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37933,DS-b5c27123-abc3-4db2-9b5f-bba662d5a295,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-227904fc-813d-4dc5-8e07-4f2e83f339ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-8a63a986-c6fb-4cbe-9b3f-5f212107cab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-23af27c4-c048-4c71-adfb-63ecc5ff7533,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-a2c9a497-4b5f-47b2-9c83-2b7c46356a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-fafa8c02-2a7f-4437-8b53-c5ae810145ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-57a0bd31-0701-4d87-8ae5-a65be51d88a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-fe419975-4fae-451c-b795-91063dcf8e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608344884-172.17.0.13-1595384365243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37933,DS-b5c27123-abc3-4db2-9b5f-bba662d5a295,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-227904fc-813d-4dc5-8e07-4f2e83f339ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-8a63a986-c6fb-4cbe-9b3f-5f212107cab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-23af27c4-c048-4c71-adfb-63ecc5ff7533,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-a2c9a497-4b5f-47b2-9c83-2b7c46356a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-fafa8c02-2a7f-4437-8b53-c5ae810145ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-57a0bd31-0701-4d87-8ae5-a65be51d88a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-fe419975-4fae-451c-b795-91063dcf8e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161967308-172.17.0.13-1595384548791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-8429072c-231f-4b43-8c0e-f1cbdfa52642,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-2d89d736-be48-4ba9-8b6e-3e901488505a,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-81dcf520-bc12-438a-866a-d547fb835ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-8ef48fe7-53dd-436c-9b32-d0de34b9c9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-7264e380-65aa-4b04-8154-20b6842aaa09,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-14fdb7df-3667-45d0-aceb-715863149443,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-699de66d-1278-48e3-b684-6719d8863983,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-718bde15-4577-4f82-a74e-6ad666c413ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161967308-172.17.0.13-1595384548791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-8429072c-231f-4b43-8c0e-f1cbdfa52642,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-2d89d736-be48-4ba9-8b6e-3e901488505a,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-81dcf520-bc12-438a-866a-d547fb835ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-8ef48fe7-53dd-436c-9b32-d0de34b9c9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-7264e380-65aa-4b04-8154-20b6842aaa09,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-14fdb7df-3667-45d0-aceb-715863149443,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-699de66d-1278-48e3-b684-6719d8863983,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-718bde15-4577-4f82-a74e-6ad666c413ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401419298-172.17.0.13-1595385517579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-4884c6c5-b125-4169-8cac-d4e5d5caf2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-8ac718e4-f59b-461e-8975-88b9394ebd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-379f65e8-1cf4-4c06-bc03-1f339548d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-5d90418a-8c3c-4dbd-9aa7-d0428b5658e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-016da6cb-94c0-465c-ad49-7da257729f40,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-4ab5a036-98bf-4f8f-a4f7-7737df8bdaee,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-27a36e6e-1a72-4cfd-a6bc-784196d2b775,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-26b5d94e-c760-4f5c-a180-501dcd5efdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401419298-172.17.0.13-1595385517579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-4884c6c5-b125-4169-8cac-d4e5d5caf2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-8ac718e4-f59b-461e-8975-88b9394ebd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-379f65e8-1cf4-4c06-bc03-1f339548d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-5d90418a-8c3c-4dbd-9aa7-d0428b5658e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-016da6cb-94c0-465c-ad49-7da257729f40,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-4ab5a036-98bf-4f8f-a4f7-7737df8bdaee,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-27a36e6e-1a72-4cfd-a6bc-784196d2b775,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-26b5d94e-c760-4f5c-a180-501dcd5efdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1868285842-172.17.0.13-1595385584044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44205,DS-f9f173a8-389c-4743-86c9-d03a9354015a,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-526b6b28-6232-45d1-8e03-6507c6f198a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-6e5fd8c7-e9df-47a8-ac23-13abfa882eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-5cd5887c-70cc-4f7a-832e-f8a41330fe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-057388de-1420-4429-8a4d-e616d668944a,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-172df421-19cf-4fb5-ba20-b0fa7821134f,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-308c05e1-b2ab-416d-a330-c80b589e5f04,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-24427ebf-0652-46dc-bb91-926f2dd75c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1868285842-172.17.0.13-1595385584044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44205,DS-f9f173a8-389c-4743-86c9-d03a9354015a,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-526b6b28-6232-45d1-8e03-6507c6f198a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-6e5fd8c7-e9df-47a8-ac23-13abfa882eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-5cd5887c-70cc-4f7a-832e-f8a41330fe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-057388de-1420-4429-8a4d-e616d668944a,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-172df421-19cf-4fb5-ba20-b0fa7821134f,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-308c05e1-b2ab-416d-a330-c80b589e5f04,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-24427ebf-0652-46dc-bb91-926f2dd75c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5253
