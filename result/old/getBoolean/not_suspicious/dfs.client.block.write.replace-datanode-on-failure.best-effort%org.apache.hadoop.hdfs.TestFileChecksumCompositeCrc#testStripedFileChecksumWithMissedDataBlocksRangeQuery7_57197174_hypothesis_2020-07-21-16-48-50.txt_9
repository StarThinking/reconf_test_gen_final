reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210716152-172.17.0.6-1595350142780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-58ace580-677f-4cd3-95b6-0e17502747d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-6714d140-750b-4882-8feb-df9773476fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-77a45d7c-9d64-4a76-92a9-acf18f4e348a,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-fe6f266f-c45e-420c-a153-bb15734b994d,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-89e7aba4-4f92-460c-87b8-e92885659c64,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-814142de-1ac0-4ea0-8685-3f322bd746ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-e5e4ba1d-3482-4c83-b70d-6c9e431d9710,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-3feef637-10e4-4421-b7ba-334fb1741618,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210716152-172.17.0.6-1595350142780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-58ace580-677f-4cd3-95b6-0e17502747d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-6714d140-750b-4882-8feb-df9773476fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-77a45d7c-9d64-4a76-92a9-acf18f4e348a,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-fe6f266f-c45e-420c-a153-bb15734b994d,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-89e7aba4-4f92-460c-87b8-e92885659c64,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-814142de-1ac0-4ea0-8685-3f322bd746ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-e5e4ba1d-3482-4c83-b70d-6c9e431d9710,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-3feef637-10e4-4421-b7ba-334fb1741618,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740722571-172.17.0.6-1595350218957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-73b7fc5d-533f-4d09-90ae-15ba4cd5f118,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-f3091cdc-76dd-432c-a2b6-5bdd6a800af8,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-f54f0caa-8082-4496-a98e-779084c161bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-4b2676fa-06c4-4805-b1e7-a945f7f19f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-3fc2acef-9241-4816-aca3-432d9be5ec59,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-40687ebd-3e21-42b7-9ce9-4c3f7c8e9233,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-cd4c9c7d-83bd-4fcc-99b6-eaa0c8e52e59,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-df4f7338-03b7-4fa3-9f61-3a6f8ee9ac4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740722571-172.17.0.6-1595350218957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-73b7fc5d-533f-4d09-90ae-15ba4cd5f118,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-f3091cdc-76dd-432c-a2b6-5bdd6a800af8,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-f54f0caa-8082-4496-a98e-779084c161bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-4b2676fa-06c4-4805-b1e7-a945f7f19f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-3fc2acef-9241-4816-aca3-432d9be5ec59,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-40687ebd-3e21-42b7-9ce9-4c3f7c8e9233,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-cd4c9c7d-83bd-4fcc-99b6-eaa0c8e52e59,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-df4f7338-03b7-4fa3-9f61-3a6f8ee9ac4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959617642-172.17.0.6-1595350551631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-f8b90a29-1507-4f68-a8ea-f07cf9b251d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-110fe508-7a29-4a51-8731-8bb45fd01139,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-c25f4da8-5b9a-4b9e-9e7e-5545c933891f,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-4717aab7-41e3-4fbf-a243-83b54f32dece,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-f353fbc8-64c3-4bbf-8150-c9627d6b198e,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-2e907a75-e37f-4997-83ea-5ea8ad6e15ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-5de5d551-3618-407a-b278-1d4a843dd8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-2d98771a-9b0a-481e-befc-4fa64dd24137,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959617642-172.17.0.6-1595350551631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-f8b90a29-1507-4f68-a8ea-f07cf9b251d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-110fe508-7a29-4a51-8731-8bb45fd01139,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-c25f4da8-5b9a-4b9e-9e7e-5545c933891f,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-4717aab7-41e3-4fbf-a243-83b54f32dece,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-f353fbc8-64c3-4bbf-8150-c9627d6b198e,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-2e907a75-e37f-4997-83ea-5ea8ad6e15ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-5de5d551-3618-407a-b278-1d4a843dd8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-2d98771a-9b0a-481e-befc-4fa64dd24137,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619258064-172.17.0.6-1595350609678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-25b429fe-fc71-4dd8-9b70-d10981903065,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-c04ea05e-f183-4e2a-bc5d-ff7c9d755cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-da48bb57-e45b-48bf-9d20-d279d44acdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-4288b7c8-2b93-44e5-8cf3-411087340370,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-980f97a7-662c-44a7-90a1-55a4117949fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-7a70b276-dd5b-4897-9163-3167fb478435,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-00131d65-b8ee-4bb0-8cef-c9e4b7e7c7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-4eb6c36a-ab1b-4813-8f1f-1f2f747a1406,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619258064-172.17.0.6-1595350609678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-25b429fe-fc71-4dd8-9b70-d10981903065,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-c04ea05e-f183-4e2a-bc5d-ff7c9d755cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-da48bb57-e45b-48bf-9d20-d279d44acdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-4288b7c8-2b93-44e5-8cf3-411087340370,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-980f97a7-662c-44a7-90a1-55a4117949fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-7a70b276-dd5b-4897-9163-3167fb478435,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-00131d65-b8ee-4bb0-8cef-c9e4b7e7c7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-4eb6c36a-ab1b-4813-8f1f-1f2f747a1406,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110867511-172.17.0.6-1595350644918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40675,DS-50972c82-fdb2-483d-b2b4-687d971c4f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-e6142a02-39bf-45ec-aab3-f402e13942e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-1aa82088-f414-4508-a7ac-db942c494bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-fdf3c592-3594-451a-bc3b-929c970d37be,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-bda9a292-32df-42bd-86d6-67ad8f910149,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-64b7ef61-185d-4b71-89fb-199c22741624,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-3bf56237-2af7-4714-a60d-7bd2eb4a85ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-26a41637-d1de-4806-af4a-31493b48cede,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110867511-172.17.0.6-1595350644918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40675,DS-50972c82-fdb2-483d-b2b4-687d971c4f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-e6142a02-39bf-45ec-aab3-f402e13942e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-1aa82088-f414-4508-a7ac-db942c494bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-fdf3c592-3594-451a-bc3b-929c970d37be,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-bda9a292-32df-42bd-86d6-67ad8f910149,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-64b7ef61-185d-4b71-89fb-199c22741624,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-3bf56237-2af7-4714-a60d-7bd2eb4a85ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-26a41637-d1de-4806-af4a-31493b48cede,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780907621-172.17.0.6-1595350888126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44884,DS-4220e464-ce2e-4499-9b38-1f2288213b77,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-47a7cfd2-24eb-4ffd-b80f-54d9dbdc47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-13671e3e-0198-437f-b179-4e0cb5846dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-f0c8855f-6c40-4b0c-ba64-c431c02f51e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-5c1b8a34-6f9c-441d-a582-6d0f40888869,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-b2b784c6-5627-4a8d-b141-0920fae25fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-6a651994-bd51-4c01-b96a-0c3072acfb92,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-717b61d9-673f-4451-817f-f74ae49b9a09,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780907621-172.17.0.6-1595350888126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44884,DS-4220e464-ce2e-4499-9b38-1f2288213b77,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-47a7cfd2-24eb-4ffd-b80f-54d9dbdc47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-13671e3e-0198-437f-b179-4e0cb5846dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-f0c8855f-6c40-4b0c-ba64-c431c02f51e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-5c1b8a34-6f9c-441d-a582-6d0f40888869,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-b2b784c6-5627-4a8d-b141-0920fae25fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-6a651994-bd51-4c01-b96a-0c3072acfb92,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-717b61d9-673f-4451-817f-f74ae49b9a09,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734380631-172.17.0.6-1595350955969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-bfa27d18-2b22-4c95-8bbd-da4bacc397ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-c37ad7e5-45bd-4efc-8a8d-b3ee77b01465,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-0efee0a1-dc7f-4710-8369-c2ed7a17a875,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-0df0cd52-a115-4663-a9c8-601e104d10f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-db79dde3-c4eb-4bec-8d62-b05c2e92ce39,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-9236504e-06a5-4506-800c-50c8119087f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-459eb826-fea1-47ae-8dc8-29b35ffe6035,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-0f050bfb-5f10-4bc1-9993-137362e17978,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734380631-172.17.0.6-1595350955969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-bfa27d18-2b22-4c95-8bbd-da4bacc397ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-c37ad7e5-45bd-4efc-8a8d-b3ee77b01465,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-0efee0a1-dc7f-4710-8369-c2ed7a17a875,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-0df0cd52-a115-4663-a9c8-601e104d10f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-db79dde3-c4eb-4bec-8d62-b05c2e92ce39,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-9236504e-06a5-4506-800c-50c8119087f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-459eb826-fea1-47ae-8dc8-29b35ffe6035,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-0f050bfb-5f10-4bc1-9993-137362e17978,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548786336-172.17.0.6-1595351024448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46220,DS-2f99f16b-ee50-45c6-9e74-d80edc4c1491,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-4e76efe6-e693-4691-a440-4692d91c3510,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-a18278ec-d11e-4c8a-949f-7b20d2f3f773,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-2d0529f6-a5a0-42e4-923f-c9a850820685,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-81df52d4-a4ef-4069-a83e-4525b231b9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-51a3c861-9645-4509-843b-5c68de1dff3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-29d109b3-3122-489b-84cc-71e8aeb66e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-af50c159-f142-4838-8f02-172d97982e66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548786336-172.17.0.6-1595351024448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46220,DS-2f99f16b-ee50-45c6-9e74-d80edc4c1491,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-4e76efe6-e693-4691-a440-4692d91c3510,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-a18278ec-d11e-4c8a-949f-7b20d2f3f773,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-2d0529f6-a5a0-42e4-923f-c9a850820685,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-81df52d4-a4ef-4069-a83e-4525b231b9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-51a3c861-9645-4509-843b-5c68de1dff3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-29d109b3-3122-489b-84cc-71e8aeb66e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-af50c159-f142-4838-8f02-172d97982e66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328033016-172.17.0.6-1595351226209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-07c0027c-21dc-4f91-807c-5a663cd341f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-c200058d-36db-4be1-b1d9-507a56d0d587,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-8053a2b5-c180-4930-85a2-62aaabdcf9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-89974bf9-b3fd-4b6e-91f3-dea57dbd59da,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-06ab4f7b-8039-4f1d-aabf-724a568e058b,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-8594bf08-7eba-4dc4-8c40-dc4e2a855546,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-ff29f79c-b969-4641-a37e-d196a8775d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-ce2a003e-4167-4b05-8c03-ce93453a7de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328033016-172.17.0.6-1595351226209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-07c0027c-21dc-4f91-807c-5a663cd341f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-c200058d-36db-4be1-b1d9-507a56d0d587,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-8053a2b5-c180-4930-85a2-62aaabdcf9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-89974bf9-b3fd-4b6e-91f3-dea57dbd59da,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-06ab4f7b-8039-4f1d-aabf-724a568e058b,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-8594bf08-7eba-4dc4-8c40-dc4e2a855546,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-ff29f79c-b969-4641-a37e-d196a8775d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-ce2a003e-4167-4b05-8c03-ce93453a7de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768991598-172.17.0.6-1595351408008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39477,DS-7c485883-e2ad-49e1-a98f-21ef899670f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-ec303df9-fd92-4da1-afc9-125421149e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-32cb9e6d-517e-430d-b799-561872230a58,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-73e43e3a-dd05-41ff-af06-c49d39c2d14e,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-0c601c67-5f12-4c7a-b362-eb7c6ccb3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-97c1a3c7-e76a-460d-ad8e-0aa2fb9ca911,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-ccd941bf-df02-45c2-9eaf-5eecfa2811b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-ca161e9e-4ea7-4be1-8629-c6f92435f478,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768991598-172.17.0.6-1595351408008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39477,DS-7c485883-e2ad-49e1-a98f-21ef899670f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-ec303df9-fd92-4da1-afc9-125421149e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-32cb9e6d-517e-430d-b799-561872230a58,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-73e43e3a-dd05-41ff-af06-c49d39c2d14e,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-0c601c67-5f12-4c7a-b362-eb7c6ccb3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-97c1a3c7-e76a-460d-ad8e-0aa2fb9ca911,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-ccd941bf-df02-45c2-9eaf-5eecfa2811b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-ca161e9e-4ea7-4be1-8629-c6f92435f478,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552106250-172.17.0.6-1595351574832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-2b0ca61c-7162-4ad1-8c18-4e8eee889daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-e9606e86-1c54-4cae-ac6c-893c6e25074f,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-28eb39d4-0f0b-4960-b776-7691b1b6cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-5178737f-0142-4122-b62e-5c6aecc474e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-494190df-cc39-4f88-9383-56983196643b,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-a973c6e9-8297-49dc-b4d2-e477b6aa07e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-cf1e03fa-ce8c-4384-bf82-8f71f300945e,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-cbc0515f-3812-4a07-9e31-690293b7cc1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552106250-172.17.0.6-1595351574832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-2b0ca61c-7162-4ad1-8c18-4e8eee889daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-e9606e86-1c54-4cae-ac6c-893c6e25074f,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-28eb39d4-0f0b-4960-b776-7691b1b6cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-5178737f-0142-4122-b62e-5c6aecc474e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-494190df-cc39-4f88-9383-56983196643b,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-a973c6e9-8297-49dc-b4d2-e477b6aa07e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-cf1e03fa-ce8c-4384-bf82-8f71f300945e,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-cbc0515f-3812-4a07-9e31-690293b7cc1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106356919-172.17.0.6-1595351614159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44376,DS-a5eddcfa-8293-451e-a5aa-b78cd4576f83,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-81ca3fba-126d-44f1-aec0-8ac96f6a46cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-9136ab02-7c69-468f-ad4d-fab8ee1ab041,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-d60a2600-2cae-43c4-8a1b-a2585465f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-74d3f0e1-e496-4848-b682-ad30f599dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-3bff1d51-8f80-4eb8-8438-42643d0efbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-a56ddf84-1a68-4921-aa41-ca6ec793cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-14a278ec-b363-448f-a2d8-32671cd7dc88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106356919-172.17.0.6-1595351614159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44376,DS-a5eddcfa-8293-451e-a5aa-b78cd4576f83,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-81ca3fba-126d-44f1-aec0-8ac96f6a46cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-9136ab02-7c69-468f-ad4d-fab8ee1ab041,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-d60a2600-2cae-43c4-8a1b-a2585465f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-74d3f0e1-e496-4848-b682-ad30f599dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-3bff1d51-8f80-4eb8-8438-42643d0efbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-a56ddf84-1a68-4921-aa41-ca6ec793cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-14a278ec-b363-448f-a2d8-32671cd7dc88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984560768-172.17.0.6-1595351709822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36500,DS-4471fb31-8c9b-450c-a14d-40a51c48e947,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-d0c25c50-9744-41fc-812b-892123d62330,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-94ed5b1f-3e35-40bd-997f-a564565d56d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-dd22a2e2-1469-4b2a-b4be-75be7bba5c23,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-9302e537-4865-4585-ac80-c8b19cde6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-8b4bcc94-8c81-4c42-ac3c-9596d842ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-5f70a147-0731-4a41-98c0-25c4803dd21f,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-76dbfcd7-81e5-442f-abb3-9f64e57fd05f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984560768-172.17.0.6-1595351709822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36500,DS-4471fb31-8c9b-450c-a14d-40a51c48e947,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-d0c25c50-9744-41fc-812b-892123d62330,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-94ed5b1f-3e35-40bd-997f-a564565d56d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-dd22a2e2-1469-4b2a-b4be-75be7bba5c23,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-9302e537-4865-4585-ac80-c8b19cde6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-8b4bcc94-8c81-4c42-ac3c-9596d842ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-5f70a147-0731-4a41-98c0-25c4803dd21f,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-76dbfcd7-81e5-442f-abb3-9f64e57fd05f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422143845-172.17.0.6-1595351963886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33585,DS-9aebcc06-dbbe-4f59-a388-f2f68948b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-1be4220a-1e09-4fa8-a221-09ff8c309b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-ab30c9ee-2122-4272-bd3c-997a30e4e200,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-be94cbcd-1301-4e74-b9c9-0b33c8a0598e,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-24ce970b-e544-45c6-81a3-ebffd5f5f2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-bf74cb83-872d-4616-b28d-a285834c42eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-cfe7ae19-7ae7-4ea7-b57e-5a6efbc6a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-3d6377d3-4367-4c14-bda0-dd4d79181669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422143845-172.17.0.6-1595351963886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33585,DS-9aebcc06-dbbe-4f59-a388-f2f68948b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-1be4220a-1e09-4fa8-a221-09ff8c309b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-ab30c9ee-2122-4272-bd3c-997a30e4e200,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-be94cbcd-1301-4e74-b9c9-0b33c8a0598e,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-24ce970b-e544-45c6-81a3-ebffd5f5f2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-bf74cb83-872d-4616-b28d-a285834c42eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-cfe7ae19-7ae7-4ea7-b57e-5a6efbc6a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-3d6377d3-4367-4c14-bda0-dd4d79181669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723280956-172.17.0.6-1595352168239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36849,DS-1f6d8a7e-1f87-4b43-8779-8e869cefdf65,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-a1fd864f-e24d-42fa-85e9-761fc1a6fc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-0af06e12-8fd8-48ef-a95b-f3e2134b6013,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-b8f154ec-1d79-4a5a-b7ad-c44222bf758f,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-b9b740c8-927d-4cae-a7db-2c93926bd8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-44178810-f879-4452-8459-15f239f53a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-a3681848-623d-4b55-88eb-09dcc620480b,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-15108a53-38c3-4b66-8532-38f6f0607042,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723280956-172.17.0.6-1595352168239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36849,DS-1f6d8a7e-1f87-4b43-8779-8e869cefdf65,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-a1fd864f-e24d-42fa-85e9-761fc1a6fc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-0af06e12-8fd8-48ef-a95b-f3e2134b6013,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-b8f154ec-1d79-4a5a-b7ad-c44222bf758f,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-b9b740c8-927d-4cae-a7db-2c93926bd8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-44178810-f879-4452-8459-15f239f53a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-a3681848-623d-4b55-88eb-09dcc620480b,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-15108a53-38c3-4b66-8532-38f6f0607042,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584125602-172.17.0.6-1595352201130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42247,DS-e0b86792-4037-4a39-9130-7e2e97b62cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-07fea1dc-cef4-4e6b-855f-6f0c9f0fb09e,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-734364c2-7cb5-4873-9bbf-b862fadc6f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e4c3cf0e-1139-4287-94d1-08ba3fc43b85,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-6ff349d2-4fd2-4b66-95b2-7c9a12f8bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-66a6b2a8-4688-4f77-a16c-0a0a6cbbc152,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-5906ba36-04eb-4c18-bfa2-74b52b052104,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f66da1fe-004e-4abb-9eb5-a39424947a8f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584125602-172.17.0.6-1595352201130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42247,DS-e0b86792-4037-4a39-9130-7e2e97b62cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-07fea1dc-cef4-4e6b-855f-6f0c9f0fb09e,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-734364c2-7cb5-4873-9bbf-b862fadc6f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e4c3cf0e-1139-4287-94d1-08ba3fc43b85,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-6ff349d2-4fd2-4b66-95b2-7c9a12f8bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-66a6b2a8-4688-4f77-a16c-0a0a6cbbc152,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-5906ba36-04eb-4c18-bfa2-74b52b052104,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f66da1fe-004e-4abb-9eb5-a39424947a8f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332033269-172.17.0.6-1595352278304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33138,DS-043dfade-3c4f-47a2-baa6-f746fb4ce234,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-686989c3-ef7b-4620-a3a3-ea0622d5f178,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-981c9c40-ae0f-4e6c-b49a-3afe3052cd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-1f012fd2-f3d1-40df-8bf7-a6c2786df362,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-42df4887-d64e-40fe-89a2-db0b3df75f53,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-dc7c45b8-b989-4738-8f71-9ea8a275936c,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-cd2eefb4-ecfd-4bcb-8d99-3f7f7dbc81a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-776bb20b-fcd7-4ffa-8e5c-496cbb378e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332033269-172.17.0.6-1595352278304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33138,DS-043dfade-3c4f-47a2-baa6-f746fb4ce234,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-686989c3-ef7b-4620-a3a3-ea0622d5f178,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-981c9c40-ae0f-4e6c-b49a-3afe3052cd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-1f012fd2-f3d1-40df-8bf7-a6c2786df362,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-42df4887-d64e-40fe-89a2-db0b3df75f53,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-dc7c45b8-b989-4738-8f71-9ea8a275936c,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-cd2eefb4-ecfd-4bcb-8d99-3f7f7dbc81a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-776bb20b-fcd7-4ffa-8e5c-496cbb378e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511110903-172.17.0.6-1595352303764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-bacbdb5d-5f30-4672-85ba-1573cfabcfec,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-9124a637-98fa-41c3-a15b-44c5e00ca8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-796d071b-9b02-4430-a594-c2407a8f37d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-93325a00-6b08-4594-8dca-d8e09167e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-bbbb7fa0-09d1-48ce-8871-25d7dc49f161,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-0b25431c-5e50-4d98-991a-9be48c7465bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-e5a35643-2175-43a8-a342-a4c9df68a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-b925ba2b-6457-4d27-b6d1-a21818a0ab10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511110903-172.17.0.6-1595352303764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-bacbdb5d-5f30-4672-85ba-1573cfabcfec,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-9124a637-98fa-41c3-a15b-44c5e00ca8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-796d071b-9b02-4430-a594-c2407a8f37d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-93325a00-6b08-4594-8dca-d8e09167e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-bbbb7fa0-09d1-48ce-8871-25d7dc49f161,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-0b25431c-5e50-4d98-991a-9be48c7465bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-e5a35643-2175-43a8-a342-a4c9df68a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-b925ba2b-6457-4d27-b6d1-a21818a0ab10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276331342-172.17.0.6-1595352373312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-44df10ea-64c9-412a-ac0c-56b01862b104,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-24c99cec-5aea-49c9-b9e6-4f472444fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-a879aef7-8929-40cc-8fd6-d28762806bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-b5b0ef26-b83b-4c0d-8407-0d8e15f2f23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-e93ed2ed-604a-450a-b3ae-e9f3d337a744,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-33da0ead-8b56-40e2-9853-b5143fe4cf77,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-ec164131-bd71-4680-a9d2-c52512087166,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-f329bb42-a82e-42c1-bb46-0b321b474998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276331342-172.17.0.6-1595352373312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-44df10ea-64c9-412a-ac0c-56b01862b104,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-24c99cec-5aea-49c9-b9e6-4f472444fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-a879aef7-8929-40cc-8fd6-d28762806bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-b5b0ef26-b83b-4c0d-8407-0d8e15f2f23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-e93ed2ed-604a-450a-b3ae-e9f3d337a744,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-33da0ead-8b56-40e2-9853-b5143fe4cf77,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-ec164131-bd71-4680-a9d2-c52512087166,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-f329bb42-a82e-42c1-bb46-0b321b474998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99773098-172.17.0.6-1595352773022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36647,DS-81722d0d-d5e1-4e8d-ae29-67bc5e4c7d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-12a2920f-cd5f-4447-a10f-6081c369d7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-1a6ef631-6eae-4b8c-ac60-aece1092c6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-3a1e3926-d70a-47f1-9e6d-1fc0e8bbf8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-db85598b-6024-4944-b58c-e15a8d5ea121,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-7de13c9a-9dc5-40c9-8a35-cdf5ec23ac77,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-ace937f9-cbb6-4cfc-9287-89a2a0ff2091,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-eb4ee1d7-d0c1-4cb2-8236-b283ca5c78c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99773098-172.17.0.6-1595352773022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36647,DS-81722d0d-d5e1-4e8d-ae29-67bc5e4c7d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-12a2920f-cd5f-4447-a10f-6081c369d7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-1a6ef631-6eae-4b8c-ac60-aece1092c6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-3a1e3926-d70a-47f1-9e6d-1fc0e8bbf8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-db85598b-6024-4944-b58c-e15a8d5ea121,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-7de13c9a-9dc5-40c9-8a35-cdf5ec23ac77,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-ace937f9-cbb6-4cfc-9287-89a2a0ff2091,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-eb4ee1d7-d0c1-4cb2-8236-b283ca5c78c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760898623-172.17.0.6-1595352837908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-23b8acb7-a9d5-471d-8ddf-140c77fee896,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-8831d01c-9779-4017-bb21-d276e18217df,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-bb098639-1c7c-4985-adcd-16ddfda1a91a,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-cf9b6c54-a999-45c2-b27f-1b311f25b182,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-5fdae706-ec03-43af-b008-34a4d3f0cd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-d0331fe6-0653-4916-bd53-7523203b4778,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-1b138c10-547b-4490-982d-6705fd22a6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-36cd02ce-54c9-4782-9859-34305811c68f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760898623-172.17.0.6-1595352837908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-23b8acb7-a9d5-471d-8ddf-140c77fee896,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-8831d01c-9779-4017-bb21-d276e18217df,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-bb098639-1c7c-4985-adcd-16ddfda1a91a,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-cf9b6c54-a999-45c2-b27f-1b311f25b182,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-5fdae706-ec03-43af-b008-34a4d3f0cd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-d0331fe6-0653-4916-bd53-7523203b4778,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-1b138c10-547b-4490-982d-6705fd22a6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-36cd02ce-54c9-4782-9859-34305811c68f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749542571-172.17.0.6-1595353285619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43090,DS-b1f38453-07f1-4e63-a5b6-365043adb7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-074c96ea-22e7-43ee-a3cd-8cb693a96503,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-8ffd3516-6eb4-420e-8424-cf711cebc8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-59375318-0e37-4289-8545-82afaaf71ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-0c55aff0-13dd-4b47-a05d-9c422951b9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-f53826b3-add6-43ee-9043-7015a4766d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-43c7417c-8520-4aed-a70f-9056a192ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-dbb478b5-f76e-4402-9d6d-5e9ba390c028,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749542571-172.17.0.6-1595353285619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43090,DS-b1f38453-07f1-4e63-a5b6-365043adb7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-074c96ea-22e7-43ee-a3cd-8cb693a96503,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-8ffd3516-6eb4-420e-8424-cf711cebc8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-59375318-0e37-4289-8545-82afaaf71ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-0c55aff0-13dd-4b47-a05d-9c422951b9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-f53826b3-add6-43ee-9043-7015a4766d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-43c7417c-8520-4aed-a70f-9056a192ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-dbb478b5-f76e-4402-9d6d-5e9ba390c028,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383658042-172.17.0.6-1595353514971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35055,DS-c39e8024-f248-4904-8ad2-6a54d9911db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-d98b0c67-9468-46b6-9bb1-e53e3915d615,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-923dd70d-97bf-4580-8e1f-7bc3926317d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-12fa303a-39a9-4484-aea9-e5010feecfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-9ecdc97c-d954-455b-adc4-8ddc06ab7ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-6e08a9d9-a5c0-4fe0-9c1d-1fa131095b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-6503aae6-63de-440c-a60b-133e702eb6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-177fc647-2cad-4301-bcb4-b99762e815ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383658042-172.17.0.6-1595353514971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35055,DS-c39e8024-f248-4904-8ad2-6a54d9911db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-d98b0c67-9468-46b6-9bb1-e53e3915d615,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-923dd70d-97bf-4580-8e1f-7bc3926317d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-12fa303a-39a9-4484-aea9-e5010feecfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-9ecdc97c-d954-455b-adc4-8ddc06ab7ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-6e08a9d9-a5c0-4fe0-9c1d-1fa131095b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-6503aae6-63de-440c-a60b-133e702eb6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-177fc647-2cad-4301-bcb4-b99762e815ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073862128-172.17.0.6-1595353851972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42491,DS-7ae91c7d-0611-4d40-92fa-b24fef417d06,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-3e4245da-6a8c-4b4f-a886-18dec6330919,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-5afadea9-07d2-47b7-9cd5-dfcf7799510f,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-dab00fcd-bdc0-43a0-9030-da2f5bef71c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-99e79b26-c9d6-41d0-bfdb-f31e260f9fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-b0c722ca-dd37-4365-b673-fb4633acb875,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-c5f71e1e-ca6a-4332-a968-8f225391a6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-97056c9a-a8b3-4f39-84d8-201031b611c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073862128-172.17.0.6-1595353851972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42491,DS-7ae91c7d-0611-4d40-92fa-b24fef417d06,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-3e4245da-6a8c-4b4f-a886-18dec6330919,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-5afadea9-07d2-47b7-9cd5-dfcf7799510f,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-dab00fcd-bdc0-43a0-9030-da2f5bef71c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-99e79b26-c9d6-41d0-bfdb-f31e260f9fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-b0c722ca-dd37-4365-b673-fb4633acb875,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-c5f71e1e-ca6a-4332-a968-8f225391a6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-97056c9a-a8b3-4f39-84d8-201031b611c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810088086-172.17.0.6-1595354232784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44572,DS-aa3edeb9-c78e-4795-894b-1b2cc3371b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-7072ff55-7660-4de3-b0d3-5e9a92ac2478,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-3c588b05-1f6a-4ddc-acf2-83971c6f649b,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-6c788663-058a-44c4-a4e1-959e6b1d014d,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-7b301f6a-c174-4bf3-a8d6-ac9c752e9375,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-ff0deb66-f97e-41ff-83f7-f433b2375066,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-09296079-fc59-40f9-9011-55818b413c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-11b1d4de-8c2d-4a77-80d1-68f617c8e3bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810088086-172.17.0.6-1595354232784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44572,DS-aa3edeb9-c78e-4795-894b-1b2cc3371b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-7072ff55-7660-4de3-b0d3-5e9a92ac2478,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-3c588b05-1f6a-4ddc-acf2-83971c6f649b,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-6c788663-058a-44c4-a4e1-959e6b1d014d,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-7b301f6a-c174-4bf3-a8d6-ac9c752e9375,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-ff0deb66-f97e-41ff-83f7-f433b2375066,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-09296079-fc59-40f9-9011-55818b413c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-11b1d4de-8c2d-4a77-80d1-68f617c8e3bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213503470-172.17.0.6-1595354373527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41582,DS-21d68223-d512-4f70-8269-39f38820c651,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-203fe8cd-c317-4c96-a01f-9659a8d57769,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-7da72e5c-7ed9-477c-a62a-391daab7a3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-98a3721d-8c9b-41ad-b08d-82a49af39935,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-a6703d0b-3785-4bb2-87dd-b662a0604870,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-5118a09c-364e-4076-a059-42a40cdaaeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-f1b99cfa-4447-43c2-a340-46d62ac90395,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-515b09c8-bd28-46d1-a3f1-cc54614a0e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213503470-172.17.0.6-1595354373527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41582,DS-21d68223-d512-4f70-8269-39f38820c651,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-203fe8cd-c317-4c96-a01f-9659a8d57769,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-7da72e5c-7ed9-477c-a62a-391daab7a3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-98a3721d-8c9b-41ad-b08d-82a49af39935,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-a6703d0b-3785-4bb2-87dd-b662a0604870,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-5118a09c-364e-4076-a059-42a40cdaaeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-f1b99cfa-4447-43c2-a340-46d62ac90395,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-515b09c8-bd28-46d1-a3f1-cc54614a0e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375173500-172.17.0.6-1595354437416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-fd266597-2114-4f93-be4c-c5e35e8f63f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-fdbd98c7-0c28-464c-9269-4cf8fb313794,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-a1db1dd8-7bd6-4c9e-b4b3-2979d4a9c773,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-3b377ccc-bdbf-435f-af08-35847bd16dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-ab241713-eb0a-48aa-9eaa-e1fea63bc2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-ba199ba3-9841-420f-8732-a8778d0760b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-107aca31-8ab6-4409-9f6c-aa2b01e33a99,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-065176a7-14b6-45e2-9619-58474e033e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375173500-172.17.0.6-1595354437416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-fd266597-2114-4f93-be4c-c5e35e8f63f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-fdbd98c7-0c28-464c-9269-4cf8fb313794,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-a1db1dd8-7bd6-4c9e-b4b3-2979d4a9c773,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-3b377ccc-bdbf-435f-af08-35847bd16dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-ab241713-eb0a-48aa-9eaa-e1fea63bc2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-ba199ba3-9841-420f-8732-a8778d0760b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-107aca31-8ab6-4409-9f6c-aa2b01e33a99,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-065176a7-14b6-45e2-9619-58474e033e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943756384-172.17.0.6-1595354471853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32936,DS-08389431-cc59-4a48-b25e-4d0cabc71d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-53de219a-e22e-49d6-8e40-103530d9720f,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-c3610e46-9a55-4e1c-8ee1-e9e34a35530d,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-0085ec27-8e69-492c-8661-7ca11f7e89e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-b75dfc9a-e590-4f21-8337-8bc4f340ae40,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-cca72803-fd10-44de-bff9-60f4e5386758,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-0a569e1e-59d8-438b-8dda-379cc779efdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-002b73af-f761-4adf-9ff8-e368ca20efcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943756384-172.17.0.6-1595354471853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32936,DS-08389431-cc59-4a48-b25e-4d0cabc71d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-53de219a-e22e-49d6-8e40-103530d9720f,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-c3610e46-9a55-4e1c-8ee1-e9e34a35530d,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-0085ec27-8e69-492c-8661-7ca11f7e89e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-b75dfc9a-e590-4f21-8337-8bc4f340ae40,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-cca72803-fd10-44de-bff9-60f4e5386758,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-0a569e1e-59d8-438b-8dda-379cc779efdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-002b73af-f761-4adf-9ff8-e368ca20efcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203555754-172.17.0.6-1595354598605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41458,DS-ff858540-2bd0-46f1-a903-a810f221e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-af580536-d8da-4e84-97b5-d30baf21a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-383cb91a-4479-4f52-bc3c-242a5f46d222,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-d5236249-2750-464a-8ef7-cfabffa7aa13,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-b1280d1e-3155-4f28-bc24-7e9ffce8c3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-976f6ba5-f77f-4a2f-bea6-7cee6d41a1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-20e80f2c-ebde-4ad0-ab5c-dfc3f45c4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-5ed9ac9f-533b-46aa-a02e-6d3fc49eec3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203555754-172.17.0.6-1595354598605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41458,DS-ff858540-2bd0-46f1-a903-a810f221e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-af580536-d8da-4e84-97b5-d30baf21a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-383cb91a-4479-4f52-bc3c-242a5f46d222,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-d5236249-2750-464a-8ef7-cfabffa7aa13,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-b1280d1e-3155-4f28-bc24-7e9ffce8c3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-976f6ba5-f77f-4a2f-bea6-7cee6d41a1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-20e80f2c-ebde-4ad0-ab5c-dfc3f45c4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-5ed9ac9f-533b-46aa-a02e-6d3fc49eec3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948276268-172.17.0.6-1595354716487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36675,DS-8b66692d-9a81-4883-b63c-7c1adf90553f,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-4f4c59e2-9dd3-4447-8847-2fe2a75e411a,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-90a75731-f833-41a9-a16e-53e9fbce2d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-7717a439-410f-484c-b7eb-5f92a7aca517,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-c7467cd7-d8c7-4ed3-a05c-490b6d7a411e,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-027b52f6-55f3-4d36-9edf-9b8c417a4d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-387f1385-0158-4a5a-b699-d6747347e820,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-00e2815e-b125-4e34-8646-31c4a6feb4f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948276268-172.17.0.6-1595354716487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36675,DS-8b66692d-9a81-4883-b63c-7c1adf90553f,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-4f4c59e2-9dd3-4447-8847-2fe2a75e411a,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-90a75731-f833-41a9-a16e-53e9fbce2d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-7717a439-410f-484c-b7eb-5f92a7aca517,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-c7467cd7-d8c7-4ed3-a05c-490b6d7a411e,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-027b52f6-55f3-4d36-9edf-9b8c417a4d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-387f1385-0158-4a5a-b699-d6747347e820,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-00e2815e-b125-4e34-8646-31c4a6feb4f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452795525-172.17.0.6-1595354808329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43547,DS-96daf2ae-4c85-4030-8a09-bf1bc97a7d64,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-3184cc5a-fd84-4d95-aa4c-208de8ce1eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-7bc7c8aa-7683-4617-848f-62a2e6752757,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-fd98a1de-3b6f-4c4a-8e37-2e04a40a665f,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-5bd20d67-cc34-4eec-8a6b-d060ef4e0c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-73a40a87-b718-49ce-97fc-f72a5bcd1ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-df08b276-af86-4bac-b92f-6db43b782048,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-ec8fb8d0-c0a6-4122-adfd-b8e531e32892,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452795525-172.17.0.6-1595354808329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43547,DS-96daf2ae-4c85-4030-8a09-bf1bc97a7d64,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-3184cc5a-fd84-4d95-aa4c-208de8ce1eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-7bc7c8aa-7683-4617-848f-62a2e6752757,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-fd98a1de-3b6f-4c4a-8e37-2e04a40a665f,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-5bd20d67-cc34-4eec-8a6b-d060ef4e0c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-73a40a87-b718-49ce-97fc-f72a5bcd1ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-df08b276-af86-4bac-b92f-6db43b782048,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-ec8fb8d0-c0a6-4122-adfd-b8e531e32892,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536515456-172.17.0.6-1595355013273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-bd12913d-e76a-414e-8d3e-114c1c74944f,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-6bc05625-b7e5-432b-b8f6-d113fbb1cbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-577babdc-0661-49f1-8ca5-9ac05b85fce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-01141d7f-21ab-45e4-bd48-a8b4b79eaebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-b5d3bfc0-8abf-40ff-907a-e58b8f3c8899,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-4ec3dc02-299e-4ffe-88f4-c905bd5f1f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-c9326519-7767-4576-8c8d-efef2c8bdc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-f5d34d03-35fd-4824-aff9-233631ac4b5b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536515456-172.17.0.6-1595355013273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-bd12913d-e76a-414e-8d3e-114c1c74944f,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-6bc05625-b7e5-432b-b8f6-d113fbb1cbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-577babdc-0661-49f1-8ca5-9ac05b85fce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-01141d7f-21ab-45e4-bd48-a8b4b79eaebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-b5d3bfc0-8abf-40ff-907a-e58b8f3c8899,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-4ec3dc02-299e-4ffe-88f4-c905bd5f1f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-c9326519-7767-4576-8c8d-efef2c8bdc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-f5d34d03-35fd-4824-aff9-233631ac4b5b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883822911-172.17.0.6-1595355138507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36684,DS-cf73daee-87f0-486e-97c1-265eaf5dfd51,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-d51ba03b-ea93-4c25-967b-32244012eb09,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-20f042cc-257d-4925-afe4-05e92384dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-0bb7e61a-4a60-477c-a2dc-2e21b94b52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-3b2dff9d-9c81-4153-94fe-ac28700c4cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-271ced9b-8703-4432-870f-d4c01678be20,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-128119f1-a1f5-4a10-abe4-20ecbf5bcf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-7cbd425e-b50d-4f10-afcb-20df03134438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883822911-172.17.0.6-1595355138507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36684,DS-cf73daee-87f0-486e-97c1-265eaf5dfd51,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-d51ba03b-ea93-4c25-967b-32244012eb09,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-20f042cc-257d-4925-afe4-05e92384dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-0bb7e61a-4a60-477c-a2dc-2e21b94b52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-3b2dff9d-9c81-4153-94fe-ac28700c4cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-271ced9b-8703-4432-870f-d4c01678be20,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-128119f1-a1f5-4a10-abe4-20ecbf5bcf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-7cbd425e-b50d-4f10-afcb-20df03134438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5161
