reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636669959-172.17.0.13-1595316376154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37741,DS-bf3440ef-353a-4035-a0ef-d6c683acb41f,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-854f4ffb-6190-4661-9395-73d748a7c91d,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-d250e5b7-487d-4cc8-95b1-e4d8fa88a024,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-016da66f-8316-4c74-be9e-a7de52ca7b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-c7ba852c-f2c7-4bf1-94ba-c65cecde4f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-16c193c8-250c-496d-86f9-73ac561092f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-689ea8c2-f8ec-41a7-b732-5035e2533ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-f978d8cb-d057-4398-8434-1b1d69c7cb5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636669959-172.17.0.13-1595316376154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37741,DS-bf3440ef-353a-4035-a0ef-d6c683acb41f,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-854f4ffb-6190-4661-9395-73d748a7c91d,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-d250e5b7-487d-4cc8-95b1-e4d8fa88a024,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-016da66f-8316-4c74-be9e-a7de52ca7b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-c7ba852c-f2c7-4bf1-94ba-c65cecde4f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-16c193c8-250c-496d-86f9-73ac561092f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-689ea8c2-f8ec-41a7-b732-5035e2533ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-f978d8cb-d057-4398-8434-1b1d69c7cb5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441489674-172.17.0.13-1595317123245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38491,DS-602cc501-f68b-4fa6-925b-eef4c4612e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-e35bce9d-182c-476a-b1d1-6804ff5373d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-5e5dedcf-7ff8-49fe-a45b-6bd99c31c725,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-b1c63dcf-b76c-4949-927d-a8193b80bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-76cd475f-733b-434b-a2fb-65bc296f99b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-ffff7ea7-61d3-40e3-9f76-a1426725d577,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-2edb4100-0231-4157-9543-89fa7265849c,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-21c20646-fb04-4bb1-8326-e76f768e82db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441489674-172.17.0.13-1595317123245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38491,DS-602cc501-f68b-4fa6-925b-eef4c4612e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-e35bce9d-182c-476a-b1d1-6804ff5373d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-5e5dedcf-7ff8-49fe-a45b-6bd99c31c725,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-b1c63dcf-b76c-4949-927d-a8193b80bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-76cd475f-733b-434b-a2fb-65bc296f99b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-ffff7ea7-61d3-40e3-9f76-a1426725d577,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-2edb4100-0231-4157-9543-89fa7265849c,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-21c20646-fb04-4bb1-8326-e76f768e82db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693759462-172.17.0.13-1595317158216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-ac2e1835-a0b6-4c40-b03b-c2bc35de7a46,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-e65ec992-4a12-4356-b1b7-2177e2c18f30,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-d91abd6d-3f46-4533-853a-8cefaea2ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-e60a4c99-a04d-4e08-87f6-f66f5ba29db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-e1b76d7e-78f8-45e6-943a-d5d2ef7af399,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-829aabc2-a68d-4fe4-b80b-66898c1676ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-42927307-fd41-46ab-a01d-a3baafe15f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-d8c26f4d-c107-406e-8155-5b932e1e0891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693759462-172.17.0.13-1595317158216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-ac2e1835-a0b6-4c40-b03b-c2bc35de7a46,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-e65ec992-4a12-4356-b1b7-2177e2c18f30,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-d91abd6d-3f46-4533-853a-8cefaea2ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-e60a4c99-a04d-4e08-87f6-f66f5ba29db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-e1b76d7e-78f8-45e6-943a-d5d2ef7af399,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-829aabc2-a68d-4fe4-b80b-66898c1676ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-42927307-fd41-46ab-a01d-a3baafe15f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-d8c26f4d-c107-406e-8155-5b932e1e0891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625337989-172.17.0.13-1595317788591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44201,DS-969294e1-2f32-43cc-b8f8-9a08e6530314,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-16f852cb-f332-4759-81fb-52cadbb53916,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-ecd23a32-8811-4a60-8f27-67846bdf2d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-159bc4f0-6f3c-4435-a3e9-b39417579147,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-fee5c06e-541f-4b7a-98a1-351add37f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-58854130-96e9-41a0-bc42-ea542be1c27f,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-e163ceb6-b4a9-4b3b-9a40-baba8c26800c,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-289f8f12-2142-4676-bc52-4760c32ecd73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625337989-172.17.0.13-1595317788591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44201,DS-969294e1-2f32-43cc-b8f8-9a08e6530314,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-16f852cb-f332-4759-81fb-52cadbb53916,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-ecd23a32-8811-4a60-8f27-67846bdf2d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-159bc4f0-6f3c-4435-a3e9-b39417579147,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-fee5c06e-541f-4b7a-98a1-351add37f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-58854130-96e9-41a0-bc42-ea542be1c27f,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-e163ceb6-b4a9-4b3b-9a40-baba8c26800c,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-289f8f12-2142-4676-bc52-4760c32ecd73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215983413-172.17.0.13-1595318532814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-c27df976-9cba-4e4c-8061-6e53e492155a,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-2ccbeb4d-4735-4a8c-a530-5dfcc9d928f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-d6d84ec6-95eb-4573-bbb5-29cb2dd4607a,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-71165cff-e79d-46b7-b3f4-0f3ccf94ee34,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-d736d98e-49d9-4414-b08a-0cf7c9482437,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-7d705b28-9f9e-465a-a6b0-06f0257a72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-2b4290a3-f75a-4260-8e80-1ecb2252a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-40c6a5f9-5e8d-4f84-8fe5-1c64e60c77db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215983413-172.17.0.13-1595318532814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-c27df976-9cba-4e4c-8061-6e53e492155a,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-2ccbeb4d-4735-4a8c-a530-5dfcc9d928f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-d6d84ec6-95eb-4573-bbb5-29cb2dd4607a,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-71165cff-e79d-46b7-b3f4-0f3ccf94ee34,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-d736d98e-49d9-4414-b08a-0cf7c9482437,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-7d705b28-9f9e-465a-a6b0-06f0257a72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-2b4290a3-f75a-4260-8e80-1ecb2252a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-40c6a5f9-5e8d-4f84-8fe5-1c64e60c77db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716055796-172.17.0.13-1595318981356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41185,DS-940de523-f835-4e97-8645-8d138fdc38d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-d87f8631-6999-4547-975d-820802de848f,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-95cf9713-d86b-434f-87b8-bb6a9c69d450,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-ac68624c-9226-40d2-9de4-2f66976dd975,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-316af295-264e-4e4e-ae3d-52a63c33f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-ccfa0acf-d506-4d92-bbeb-13c947df0227,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-188904fd-ae37-4349-b041-452eb9482a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-c390dbae-536d-40fb-84cd-6624b0712a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716055796-172.17.0.13-1595318981356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41185,DS-940de523-f835-4e97-8645-8d138fdc38d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-d87f8631-6999-4547-975d-820802de848f,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-95cf9713-d86b-434f-87b8-bb6a9c69d450,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-ac68624c-9226-40d2-9de4-2f66976dd975,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-316af295-264e-4e4e-ae3d-52a63c33f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-ccfa0acf-d506-4d92-bbeb-13c947df0227,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-188904fd-ae37-4349-b041-452eb9482a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-c390dbae-536d-40fb-84cd-6624b0712a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184156161-172.17.0.13-1595319461582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-7ee83d51-dd0f-41a2-b5fe-db3e9d1016eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-dcf03a54-e240-4ecd-a56b-9d8ee1b3333f,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-347503fd-59b6-4b3a-9156-5cf1ce4ac04c,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-9243ae3b-8aaf-411c-8e42-c58dc4d946ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-1693c6dc-3f7c-457b-83a4-d3a52fc5dd41,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-78155d2c-4abd-4d26-9524-227038159878,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-45eb02cd-fce3-49cd-8c3b-937c19f0161f,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-0bdb4556-58c5-4615-ba88-e0e224346b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184156161-172.17.0.13-1595319461582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-7ee83d51-dd0f-41a2-b5fe-db3e9d1016eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-dcf03a54-e240-4ecd-a56b-9d8ee1b3333f,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-347503fd-59b6-4b3a-9156-5cf1ce4ac04c,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-9243ae3b-8aaf-411c-8e42-c58dc4d946ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-1693c6dc-3f7c-457b-83a4-d3a52fc5dd41,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-78155d2c-4abd-4d26-9524-227038159878,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-45eb02cd-fce3-49cd-8c3b-937c19f0161f,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-0bdb4556-58c5-4615-ba88-e0e224346b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211207026-172.17.0.13-1595320073137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-5540fb6d-494f-479e-91cd-da740f0c550d,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-27b1c6c6-a497-4d20-aec0-07ca33f04d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-749d1bb6-12ed-4634-8971-5d68cbc95399,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-b4424a75-93b5-45bc-b5c7-d37ffa39c06c,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-d0823a2a-c1ce-46fb-8009-840a09be3fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-64dbea0d-ecbe-47e9-8306-138452282f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-75a7e1bb-1656-44f6-a96c-f013cceb3887,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-afd4cb78-0fd2-481f-888f-4e67082c650f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211207026-172.17.0.13-1595320073137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-5540fb6d-494f-479e-91cd-da740f0c550d,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-27b1c6c6-a497-4d20-aec0-07ca33f04d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-749d1bb6-12ed-4634-8971-5d68cbc95399,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-b4424a75-93b5-45bc-b5c7-d37ffa39c06c,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-d0823a2a-c1ce-46fb-8009-840a09be3fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-64dbea0d-ecbe-47e9-8306-138452282f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-75a7e1bb-1656-44f6-a96c-f013cceb3887,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-afd4cb78-0fd2-481f-888f-4e67082c650f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062782662-172.17.0.13-1595320523000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43189,DS-d5158609-8747-4e08-a9c8-9406f97d278a,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-c9446cf3-ac2f-4a60-b23b-3b9aa2613e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-323732c5-0ec5-471d-90ee-fb4b4458ae60,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-232be51a-d87f-4b9e-a27d-cc99c3001d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-259ea4f0-56f6-4b53-adc8-53f90e77f122,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-4d3fe004-cced-4881-a32a-1843a3fcac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-6c5577e7-e2c0-4d4c-9225-6cad1432d687,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-b2ccd5a3-3188-40d7-a6a9-89ac40bb8e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062782662-172.17.0.13-1595320523000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43189,DS-d5158609-8747-4e08-a9c8-9406f97d278a,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-c9446cf3-ac2f-4a60-b23b-3b9aa2613e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-323732c5-0ec5-471d-90ee-fb4b4458ae60,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-232be51a-d87f-4b9e-a27d-cc99c3001d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-259ea4f0-56f6-4b53-adc8-53f90e77f122,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-4d3fe004-cced-4881-a32a-1843a3fcac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-6c5577e7-e2c0-4d4c-9225-6cad1432d687,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-b2ccd5a3-3188-40d7-a6a9-89ac40bb8e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968199813-172.17.0.13-1595320832601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-09d34123-9e63-4101-ae63-c1813526f430,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-3c1e6b96-237d-460c-9e28-65903ad7d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-53d914ca-9db8-48b5-a6cd-153305742e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-1a8dd910-ea57-4f6b-8d76-8aaa8094f67e,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-a599321d-eec1-4c02-a543-538388911922,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-e9205c75-dec6-40a6-8a17-4d67673d5671,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-bf8cdbd7-632c-49a7-9758-759c1d52312a,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-35b9579a-846f-440a-a7ed-c5f5112f69d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968199813-172.17.0.13-1595320832601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-09d34123-9e63-4101-ae63-c1813526f430,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-3c1e6b96-237d-460c-9e28-65903ad7d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-53d914ca-9db8-48b5-a6cd-153305742e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-1a8dd910-ea57-4f6b-8d76-8aaa8094f67e,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-a599321d-eec1-4c02-a543-538388911922,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-e9205c75-dec6-40a6-8a17-4d67673d5671,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-bf8cdbd7-632c-49a7-9758-759c1d52312a,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-35b9579a-846f-440a-a7ed-c5f5112f69d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294245863-172.17.0.13-1595321073242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-d6383c8e-4703-4df6-bcd6-30d43a6d8d22,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-f7df30d4-0ece-457f-a3f1-e041c41ae4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-0fd6b795-2e91-4c31-80c2-d2ab43ce31e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-324be7f2-37d9-4df7-847b-c586b1a5d988,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-70a72950-dca8-4aac-90e0-e75a7ca9dacf,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-651ae1c1-c249-4b63-8f74-aa6c31af69a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-77796325-24b2-469f-bcbd-3f64575a8803,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-14d21b93-e151-41b6-8a88-e69746f7efdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294245863-172.17.0.13-1595321073242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-d6383c8e-4703-4df6-bcd6-30d43a6d8d22,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-f7df30d4-0ece-457f-a3f1-e041c41ae4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-0fd6b795-2e91-4c31-80c2-d2ab43ce31e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-324be7f2-37d9-4df7-847b-c586b1a5d988,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-70a72950-dca8-4aac-90e0-e75a7ca9dacf,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-651ae1c1-c249-4b63-8f74-aa6c31af69a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-77796325-24b2-469f-bcbd-3f64575a8803,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-14d21b93-e151-41b6-8a88-e69746f7efdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479830002-172.17.0.13-1595321187983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44493,DS-eeb96405-da7a-4156-93d4-8461b64e73d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-5867d1ec-a2b8-49f0-8975-5f3c64c0cce4,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-353e8c39-8812-4df1-9365-ea3f2c878fed,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-29d177a0-36e3-4ac5-b87a-a8be97c3f378,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-68dfad2f-bc51-471f-aa75-8f5e8f780863,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-4a680c18-da77-48dc-bbf0-0c20471d3c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-632a4885-464e-4428-abbb-7e31a2b7ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-9052ef67-0573-41e7-a59e-e2cc8f14ea06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479830002-172.17.0.13-1595321187983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44493,DS-eeb96405-da7a-4156-93d4-8461b64e73d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-5867d1ec-a2b8-49f0-8975-5f3c64c0cce4,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-353e8c39-8812-4df1-9365-ea3f2c878fed,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-29d177a0-36e3-4ac5-b87a-a8be97c3f378,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-68dfad2f-bc51-471f-aa75-8f5e8f780863,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-4a680c18-da77-48dc-bbf0-0c20471d3c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-632a4885-464e-4428-abbb-7e31a2b7ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-9052ef67-0573-41e7-a59e-e2cc8f14ea06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332396935-172.17.0.13-1595321533751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-4db4050b-511f-423f-a40c-abcdf9eb01a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-cded677d-c2bb-47d5-a804-b1bd15518e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-7cfc0434-d9dc-4202-9b86-5032d01c3721,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-45822aa4-a3e2-484e-a04d-32cfb6886065,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-5db1db72-a9d9-43b2-85ad-05c8ad94d017,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-28571a51-7fd5-4df2-bb60-2bb9d9609ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-386ada27-bdbe-4b27-86ea-5b68adcc0dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-7fdd9316-62f9-45e5-9387-a00312346169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332396935-172.17.0.13-1595321533751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-4db4050b-511f-423f-a40c-abcdf9eb01a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-cded677d-c2bb-47d5-a804-b1bd15518e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-7cfc0434-d9dc-4202-9b86-5032d01c3721,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-45822aa4-a3e2-484e-a04d-32cfb6886065,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-5db1db72-a9d9-43b2-85ad-05c8ad94d017,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-28571a51-7fd5-4df2-bb60-2bb9d9609ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-386ada27-bdbe-4b27-86ea-5b68adcc0dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-7fdd9316-62f9-45e5-9387-a00312346169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5608
