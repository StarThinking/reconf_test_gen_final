reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315559120-172.17.0.12-1595381813252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42430,DS-330a3ce0-53a8-4a7a-bebb-0b514ef0792c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-8406598a-9900-4dbf-bf57-253b6070c156,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-9b10d7e5-6db1-4e50-af86-8c84c0019276,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-70d6615d-7abb-478f-b874-68e252e323d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-6f798844-8ec0-4328-b80e-fb1e50514ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-37476eca-510d-4f1e-a29d-27ec5ff01825,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-a77b5334-7631-44bb-bea3-dd18fb067c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-7b0b8c66-7c84-45e5-b9d6-9c6d6a348ec6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315559120-172.17.0.12-1595381813252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42430,DS-330a3ce0-53a8-4a7a-bebb-0b514ef0792c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-8406598a-9900-4dbf-bf57-253b6070c156,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-9b10d7e5-6db1-4e50-af86-8c84c0019276,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-70d6615d-7abb-478f-b874-68e252e323d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-6f798844-8ec0-4328-b80e-fb1e50514ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-37476eca-510d-4f1e-a29d-27ec5ff01825,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-a77b5334-7631-44bb-bea3-dd18fb067c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-7b0b8c66-7c84-45e5-b9d6-9c6d6a348ec6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422990322-172.17.0.12-1595381846158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36067,DS-e66a6d8b-c87f-49a5-ac21-ee695ec45480,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7ee4fdc5-48cd-465a-a7eb-7568c393b325,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-37a00bdc-7e92-4b53-9645-75dc9d55a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-e54fcdf5-4652-4b2d-9d67-78515575c47d,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-4ed8bd57-6b7c-4329-bfbc-bd827e531ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-857cb90a-5472-4d71-883d-1061b40a04e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-29b5c58d-59d8-4c6e-b08e-4874e63d9854,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-d214062a-ebc8-4076-8620-fc47cfea932e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422990322-172.17.0.12-1595381846158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36067,DS-e66a6d8b-c87f-49a5-ac21-ee695ec45480,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7ee4fdc5-48cd-465a-a7eb-7568c393b325,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-37a00bdc-7e92-4b53-9645-75dc9d55a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-e54fcdf5-4652-4b2d-9d67-78515575c47d,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-4ed8bd57-6b7c-4329-bfbc-bd827e531ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-857cb90a-5472-4d71-883d-1061b40a04e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-29b5c58d-59d8-4c6e-b08e-4874e63d9854,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-d214062a-ebc8-4076-8620-fc47cfea932e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853446590-172.17.0.12-1595382013635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40385,DS-7461b5ff-4b9e-4bfa-ac72-047f45284f99,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-47e2f2da-bde3-4323-9121-e2c2037cfadf,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-9a709bd2-d710-43be-be58-09631ea38e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-10019032-de74-4122-859e-d20c68678265,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-6d2cb237-19ff-4864-9169-1e8be04c702d,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-d3aa781c-3759-4637-a967-32166080a960,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-95f7f836-fdd7-465c-a925-5f5316addaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-7f0db46f-38ec-460d-a02c-7eea8b0e65d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853446590-172.17.0.12-1595382013635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40385,DS-7461b5ff-4b9e-4bfa-ac72-047f45284f99,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-47e2f2da-bde3-4323-9121-e2c2037cfadf,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-9a709bd2-d710-43be-be58-09631ea38e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-10019032-de74-4122-859e-d20c68678265,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-6d2cb237-19ff-4864-9169-1e8be04c702d,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-d3aa781c-3759-4637-a967-32166080a960,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-95f7f836-fdd7-465c-a925-5f5316addaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-7f0db46f-38ec-460d-a02c-7eea8b0e65d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126980217-172.17.0.12-1595382216922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39304,DS-328b984f-9df4-4d63-88a7-169c40de134c,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-62af03d9-e916-4521-b62d-8ad7cb4c963d,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-4e8eb324-d337-4a79-b5ed-9c1f777571f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-8526031f-6bf6-442e-8b50-aad29d415cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-9d15e985-285d-4192-8252-900b8abcdd80,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-ce509065-c5b8-41b1-bba4-70d2be7a0f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-d86c5735-2b78-4d4f-b85b-afa5ab76ba58,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-93f50027-dfd1-4ddf-9368-339b7cc57057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126980217-172.17.0.12-1595382216922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39304,DS-328b984f-9df4-4d63-88a7-169c40de134c,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-62af03d9-e916-4521-b62d-8ad7cb4c963d,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-4e8eb324-d337-4a79-b5ed-9c1f777571f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-8526031f-6bf6-442e-8b50-aad29d415cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-9d15e985-285d-4192-8252-900b8abcdd80,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-ce509065-c5b8-41b1-bba4-70d2be7a0f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-d86c5735-2b78-4d4f-b85b-afa5ab76ba58,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-93f50027-dfd1-4ddf-9368-339b7cc57057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501871531-172.17.0.12-1595382496516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-c01fa7af-6cd1-40ed-aa4e-5e0026254b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-de668156-2cb6-471c-98b8-1ddcc3d93e34,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-23981b37-1b54-49da-b3cf-4b861d6a6939,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-a0599be1-e38c-4173-8322-9029eb87f191,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-648bb3e5-f13f-4cb5-b541-a78776e72a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-fbce1bee-3338-4c6c-9b02-a7b733bacd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-890b249e-5146-4bda-bfa6-46d6754ac5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-e66a9953-8d4a-4763-af2f-f4350576a687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501871531-172.17.0.12-1595382496516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-c01fa7af-6cd1-40ed-aa4e-5e0026254b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-de668156-2cb6-471c-98b8-1ddcc3d93e34,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-23981b37-1b54-49da-b3cf-4b861d6a6939,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-a0599be1-e38c-4173-8322-9029eb87f191,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-648bb3e5-f13f-4cb5-b541-a78776e72a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-fbce1bee-3338-4c6c-9b02-a7b733bacd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-890b249e-5146-4bda-bfa6-46d6754ac5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-e66a9953-8d4a-4763-af2f-f4350576a687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484956274-172.17.0.12-1595382535122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33283,DS-e99beb01-74d6-4414-be33-7b5f36749133,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-06a933f8-2ad5-4872-b5bc-876fadc6a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-49f9051f-f511-494a-a953-3a4e52735e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-b206f3da-462f-48c2-a557-8ff6c74faa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-f117d611-e6a9-45a3-afb4-cc36032d7d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-2a2513f3-a1b5-46a7-a707-94c145e6df93,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-4ff20767-b1f6-46e9-b1a7-d9fa5e2d08d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-75f75967-9b9b-45f8-a289-17ef3e161fb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484956274-172.17.0.12-1595382535122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33283,DS-e99beb01-74d6-4414-be33-7b5f36749133,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-06a933f8-2ad5-4872-b5bc-876fadc6a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-49f9051f-f511-494a-a953-3a4e52735e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-b206f3da-462f-48c2-a557-8ff6c74faa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-f117d611-e6a9-45a3-afb4-cc36032d7d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-2a2513f3-a1b5-46a7-a707-94c145e6df93,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-4ff20767-b1f6-46e9-b1a7-d9fa5e2d08d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-75f75967-9b9b-45f8-a289-17ef3e161fb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604585911-172.17.0.12-1595382604679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43358,DS-f07369a3-0ffa-42d7-91dc-3fbbf75f626a,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-eedbdd2b-9d9b-4167-8d17-c535683dba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-fc74190c-7503-4fa3-94a5-5ba72e93699f,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-2578207a-b832-4db2-8a66-bf907d65d77a,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-58149035-40e9-48af-bf89-a5a44db571ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-712cd3eb-eb43-45bb-b664-0e94d213fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-6a30bf2d-63f3-448d-ac5f-9a2d4d6151d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-cebe9fc0-b1dc-4e4a-b4a4-8a099f495603,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604585911-172.17.0.12-1595382604679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43358,DS-f07369a3-0ffa-42d7-91dc-3fbbf75f626a,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-eedbdd2b-9d9b-4167-8d17-c535683dba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-fc74190c-7503-4fa3-94a5-5ba72e93699f,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-2578207a-b832-4db2-8a66-bf907d65d77a,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-58149035-40e9-48af-bf89-a5a44db571ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-712cd3eb-eb43-45bb-b664-0e94d213fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-6a30bf2d-63f3-448d-ac5f-9a2d4d6151d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-cebe9fc0-b1dc-4e4a-b4a4-8a099f495603,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956255994-172.17.0.12-1595382680254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-29298c34-1c78-4503-8878-5bfe7123a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-ef26f70d-b7c3-4e71-9c8e-172502e19b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-5c91c06e-f81c-41ec-bab5-61da14d3a9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-3a144360-21fd-4c62-b181-93e30fe7dfba,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-6a2b3483-df5c-46ec-b70f-5bd79cbfcd31,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-6ef53a48-3385-4762-afdd-2973bd75854c,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-69966f9e-80d2-4c5f-9f8b-31f49f58e3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-88cdb801-1afa-4072-a94b-e67aafbc7df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956255994-172.17.0.12-1595382680254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-29298c34-1c78-4503-8878-5bfe7123a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-ef26f70d-b7c3-4e71-9c8e-172502e19b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-5c91c06e-f81c-41ec-bab5-61da14d3a9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-3a144360-21fd-4c62-b181-93e30fe7dfba,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-6a2b3483-df5c-46ec-b70f-5bd79cbfcd31,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-6ef53a48-3385-4762-afdd-2973bd75854c,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-69966f9e-80d2-4c5f-9f8b-31f49f58e3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-88cdb801-1afa-4072-a94b-e67aafbc7df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492610196-172.17.0.12-1595382857015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-e1767ec7-2a1e-4793-9627-dab50481b528,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-133ca4c4-832b-4850-a9b2-e75ceb7149b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-ad2d684d-8693-496f-9202-1ed0b88dfa68,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-ad4fb73c-b1d0-413f-9912-3edcaba88e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-ea06f856-70ff-4bd4-9045-c9c1b1c1ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-79dab4bb-ed8b-44c1-84f3-475de701d9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-b1dc1e0a-ee09-4fb0-bd18-15e2dcae603c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-8d6946c7-81e8-4fc4-a24a-eddb8ed2cf1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492610196-172.17.0.12-1595382857015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-e1767ec7-2a1e-4793-9627-dab50481b528,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-133ca4c4-832b-4850-a9b2-e75ceb7149b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-ad2d684d-8693-496f-9202-1ed0b88dfa68,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-ad4fb73c-b1d0-413f-9912-3edcaba88e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-ea06f856-70ff-4bd4-9045-c9c1b1c1ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-79dab4bb-ed8b-44c1-84f3-475de701d9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-b1dc1e0a-ee09-4fb0-bd18-15e2dcae603c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-8d6946c7-81e8-4fc4-a24a-eddb8ed2cf1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371773579-172.17.0.12-1595383027362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33747,DS-b0a9bf8e-c29e-43c3-a65c-3e8d5a8a28b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-bf01d1f1-92ee-4750-8f26-9c8d97fe75e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-259a279d-4fc7-48ac-bc55-371bd200e05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-f50cf56c-531a-4d27-ab3f-93d27f5b8c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-a7ea365e-d21f-48be-bb08-dae2728122ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-8215b90c-06b0-424b-bdb6-0502e47e045a,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-5062c65e-c43a-4a4d-a793-38b1a44af359,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-c65a66ca-0f4e-4516-b324-c6f06777a56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371773579-172.17.0.12-1595383027362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33747,DS-b0a9bf8e-c29e-43c3-a65c-3e8d5a8a28b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-bf01d1f1-92ee-4750-8f26-9c8d97fe75e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-259a279d-4fc7-48ac-bc55-371bd200e05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-f50cf56c-531a-4d27-ab3f-93d27f5b8c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-a7ea365e-d21f-48be-bb08-dae2728122ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-8215b90c-06b0-424b-bdb6-0502e47e045a,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-5062c65e-c43a-4a4d-a793-38b1a44af359,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-c65a66ca-0f4e-4516-b324-c6f06777a56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891548828-172.17.0.12-1595383137056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-da7b27b9-2600-4721-9269-9ee2b71f81f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-d18f6979-ade2-417c-8e18-ffc2aa67d49f,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-e9b31214-6ed3-48e1-8251-dc25589ebe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-1607282f-4645-45f7-bf51-9defc87f5d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-8056ad92-9b52-486a-9f15-a703b335a721,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-d1622ceb-3e59-48c0-b27e-dd0592b8bb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-e2adc9c0-4734-49de-bdae-bdc64812735d,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-62cc201f-26de-4622-a921-0b23bfbb9340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891548828-172.17.0.12-1595383137056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-da7b27b9-2600-4721-9269-9ee2b71f81f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-d18f6979-ade2-417c-8e18-ffc2aa67d49f,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-e9b31214-6ed3-48e1-8251-dc25589ebe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-1607282f-4645-45f7-bf51-9defc87f5d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-8056ad92-9b52-486a-9f15-a703b335a721,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-d1622ceb-3e59-48c0-b27e-dd0592b8bb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-e2adc9c0-4734-49de-bdae-bdc64812735d,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-62cc201f-26de-4622-a921-0b23bfbb9340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942623834-172.17.0.12-1595383339379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46411,DS-6d279aca-53d5-45f1-9aa5-d8d2e695ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-f19348d6-cdc4-4448-b233-9d970f26e827,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-08d57020-3089-4070-99ac-535b46bf11dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-aab987a6-04d6-44e0-9532-63446afcc557,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-24c00124-99cf-4916-8e3f-032b989b763e,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-e4864869-3b7f-4e5c-b407-66b2293ea343,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-7775a5b0-87b7-4ca7-a1a9-b117dd16b9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-6196aa4a-7399-4a66-9718-b817fdc3de42,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942623834-172.17.0.12-1595383339379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46411,DS-6d279aca-53d5-45f1-9aa5-d8d2e695ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-f19348d6-cdc4-4448-b233-9d970f26e827,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-08d57020-3089-4070-99ac-535b46bf11dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-aab987a6-04d6-44e0-9532-63446afcc557,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-24c00124-99cf-4916-8e3f-032b989b763e,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-e4864869-3b7f-4e5c-b407-66b2293ea343,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-7775a5b0-87b7-4ca7-a1a9-b117dd16b9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-6196aa4a-7399-4a66-9718-b817fdc3de42,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345128473-172.17.0.12-1595383406266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42716,DS-9b142e37-a583-4a64-b11c-f6cc545619a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-de60d27d-777e-475b-9432-87616d7ede4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-fe3ea625-0312-4b4f-bed5-2a3295d3d287,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-e927ecbe-bd2b-41c6-ab72-01ec1bc1442f,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-3107fde9-0432-4ed0-8489-11e6a0be1ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-6665dd9c-372b-44b2-832a-2dadcdcfa54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-4ef51966-036d-47dc-9a75-37126d82d5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-93bacd13-17ea-4572-8207-3e355678456e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345128473-172.17.0.12-1595383406266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42716,DS-9b142e37-a583-4a64-b11c-f6cc545619a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-de60d27d-777e-475b-9432-87616d7ede4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-fe3ea625-0312-4b4f-bed5-2a3295d3d287,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-e927ecbe-bd2b-41c6-ab72-01ec1bc1442f,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-3107fde9-0432-4ed0-8489-11e6a0be1ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-6665dd9c-372b-44b2-832a-2dadcdcfa54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-4ef51966-036d-47dc-9a75-37126d82d5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-93bacd13-17ea-4572-8207-3e355678456e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705086484-172.17.0.12-1595383473734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-378fe0f2-20e4-43ba-960d-f7538da8dca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-d9c44f26-d47c-4a84-8b2a-27f0292e32d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-0abbfef5-6597-4db9-8b73-5b102822a317,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-bdc5fe7b-8b10-4983-bb20-7fbd2670d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-14386653-60b2-4a2a-9007-f85c697b20af,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-1daecebd-c4ee-466e-83b1-d741e2a72685,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-534ac9f0-21dd-49d4-8272-923a6a81787e,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-6ae58ce9-44d7-43ff-a71e-ba59c32f03d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705086484-172.17.0.12-1595383473734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-378fe0f2-20e4-43ba-960d-f7538da8dca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-d9c44f26-d47c-4a84-8b2a-27f0292e32d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-0abbfef5-6597-4db9-8b73-5b102822a317,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-bdc5fe7b-8b10-4983-bb20-7fbd2670d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-14386653-60b2-4a2a-9007-f85c697b20af,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-1daecebd-c4ee-466e-83b1-d741e2a72685,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-534ac9f0-21dd-49d4-8272-923a6a81787e,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-6ae58ce9-44d7-43ff-a71e-ba59c32f03d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184443206-172.17.0.12-1595383731600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-61504b81-edc4-47a3-a7ad-9f60a63fbbce,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-0f8d952d-88f6-43a0-b17f-5fd536d9ec75,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-730d91a6-615d-41cd-9bb5-10db0307b155,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-72417e15-0715-4502-b3a4-6db254332a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-43944e9e-3922-4403-a380-56792fabf24d,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-123fc494-3b35-45f8-8962-3334b8722f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-9099feb0-a833-4d5a-9704-f13c3eaa3794,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-f7f9ccf5-d688-4887-a96b-264958f44d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184443206-172.17.0.12-1595383731600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-61504b81-edc4-47a3-a7ad-9f60a63fbbce,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-0f8d952d-88f6-43a0-b17f-5fd536d9ec75,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-730d91a6-615d-41cd-9bb5-10db0307b155,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-72417e15-0715-4502-b3a4-6db254332a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-43944e9e-3922-4403-a380-56792fabf24d,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-123fc494-3b35-45f8-8962-3334b8722f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-9099feb0-a833-4d5a-9704-f13c3eaa3794,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-f7f9ccf5-d688-4887-a96b-264958f44d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498774465-172.17.0.12-1595383833169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39525,DS-b8aa324b-30d3-40a8-b56d-2385134b2084,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-77743f50-2238-4acc-b8ae-cbd86b599312,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-3b4ab7ca-c1e3-4da7-a382-b6d7bc39b73d,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-dd838266-c479-4a4c-a75e-e72bb4d8585f,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-b3067704-75f3-447e-84fc-5337821d6912,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-9ea57d78-0584-45ba-8b00-aac30e060e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-2d4fc53c-c1ff-4717-9afa-89a52352e989,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-bd71cb80-2b65-4a20-813f-c335e44d5c0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498774465-172.17.0.12-1595383833169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39525,DS-b8aa324b-30d3-40a8-b56d-2385134b2084,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-77743f50-2238-4acc-b8ae-cbd86b599312,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-3b4ab7ca-c1e3-4da7-a382-b6d7bc39b73d,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-dd838266-c479-4a4c-a75e-e72bb4d8585f,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-b3067704-75f3-447e-84fc-5337821d6912,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-9ea57d78-0584-45ba-8b00-aac30e060e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-2d4fc53c-c1ff-4717-9afa-89a52352e989,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-bd71cb80-2b65-4a20-813f-c335e44d5c0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317526861-172.17.0.12-1595383976472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33882,DS-45dca7ce-3ec8-4e44-90e0-49400eb68aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-6b8a93f0-2989-417d-87d9-309a52a21280,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-81419f73-2ec5-42dd-b3f9-0f2c40635c37,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-6acacb4b-45ec-4b7a-a83a-14506b0ba6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-54fb915d-7238-4018-bd2f-d4b78d1eba97,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-7f8a4ebe-acc9-4022-8212-81f820dad60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-d0c00104-58b5-4787-8f90-5d2fc98a2902,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-652e6b75-58b7-47a0-8644-1085b3136d25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317526861-172.17.0.12-1595383976472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33882,DS-45dca7ce-3ec8-4e44-90e0-49400eb68aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-6b8a93f0-2989-417d-87d9-309a52a21280,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-81419f73-2ec5-42dd-b3f9-0f2c40635c37,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-6acacb4b-45ec-4b7a-a83a-14506b0ba6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-54fb915d-7238-4018-bd2f-d4b78d1eba97,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-7f8a4ebe-acc9-4022-8212-81f820dad60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-d0c00104-58b5-4787-8f90-5d2fc98a2902,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-652e6b75-58b7-47a0-8644-1085b3136d25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306068695-172.17.0.12-1595384046183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38001,DS-76d897bf-5832-46b0-baed-105b176657ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-2f4c46bd-ad36-4dd7-8aab-0fabfa594c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-f97303c2-db66-441e-a3bf-f6d67618a818,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-b7d6a049-e9ec-4fde-97cc-64648676c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-8e4e3502-929e-4a0b-86bd-ecdd34c93378,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-709d5747-ae18-46a0-8c37-d7d61ee2ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-dd032a21-612c-4ed2-baa7-ab1ed77371fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-17bc05b6-971a-4d91-a844-b2a8ddbaee5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306068695-172.17.0.12-1595384046183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38001,DS-76d897bf-5832-46b0-baed-105b176657ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-2f4c46bd-ad36-4dd7-8aab-0fabfa594c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-f97303c2-db66-441e-a3bf-f6d67618a818,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-b7d6a049-e9ec-4fde-97cc-64648676c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-8e4e3502-929e-4a0b-86bd-ecdd34c93378,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-709d5747-ae18-46a0-8c37-d7d61ee2ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-dd032a21-612c-4ed2-baa7-ab1ed77371fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-17bc05b6-971a-4d91-a844-b2a8ddbaee5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285998720-172.17.0.12-1595384146815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-7c73db9f-e97d-45f2-9a50-2ec1748a6772,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-4419f54e-c0cd-44b4-b434-e7da8555914f,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-e4e91873-5766-470c-8b4f-d96e1556425c,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-f020e7ed-be09-4257-b500-bda884ea35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-174e8e93-e947-49c2-9ec4-80608f67d507,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-92cda3aa-1972-403a-8189-5dcef941fa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-cce1d6a0-1c94-4a88-8a68-bc4f8aa4cde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-c94205e3-d10c-4e52-b0e5-1a0c5a8674ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285998720-172.17.0.12-1595384146815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-7c73db9f-e97d-45f2-9a50-2ec1748a6772,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-4419f54e-c0cd-44b4-b434-e7da8555914f,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-e4e91873-5766-470c-8b4f-d96e1556425c,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-f020e7ed-be09-4257-b500-bda884ea35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-174e8e93-e947-49c2-9ec4-80608f67d507,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-92cda3aa-1972-403a-8189-5dcef941fa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-cce1d6a0-1c94-4a88-8a68-bc4f8aa4cde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-c94205e3-d10c-4e52-b0e5-1a0c5a8674ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742684054-172.17.0.12-1595384355508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41573,DS-518c0de8-9261-482b-8d6f-d191bab7d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-ee491ca0-eee0-4ec1-8499-a52327deb0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-6e93b6fd-b522-4a98-b6ce-78769f9b4c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-650f9501-8925-4973-a9d8-28cf942d44f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-2d0ee94f-18bf-4b09-bacd-9e0a81c63f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-98ca7fa7-4b88-4002-ad3e-de36307a53cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-631d5a0a-cab1-4126-9a47-92bb3d095a88,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-b231a179-15b4-4099-9f3c-b985859f8d6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742684054-172.17.0.12-1595384355508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41573,DS-518c0de8-9261-482b-8d6f-d191bab7d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-ee491ca0-eee0-4ec1-8499-a52327deb0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-6e93b6fd-b522-4a98-b6ce-78769f9b4c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-650f9501-8925-4973-a9d8-28cf942d44f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-2d0ee94f-18bf-4b09-bacd-9e0a81c63f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-98ca7fa7-4b88-4002-ad3e-de36307a53cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-631d5a0a-cab1-4126-9a47-92bb3d095a88,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-b231a179-15b4-4099-9f3c-b985859f8d6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81662496-172.17.0.12-1595384453979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-88889115-4457-4c37-8d39-c61e7c0b4716,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-cecd4d1a-649c-4428-af34-15914c797dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-df65ca40-d441-4370-a8cf-c51bf778bfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-24311e02-bd4f-44f7-980a-97d89f104d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-4779512f-9e99-490e-b33d-81dee7848472,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-966b274b-5bab-4daa-bea4-bf4e5e8b3b77,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-73faf2af-746e-4972-a846-c9d802a8af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-0be1372c-5687-4c41-923b-fac10642102c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81662496-172.17.0.12-1595384453979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-88889115-4457-4c37-8d39-c61e7c0b4716,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-cecd4d1a-649c-4428-af34-15914c797dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-df65ca40-d441-4370-a8cf-c51bf778bfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-24311e02-bd4f-44f7-980a-97d89f104d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-4779512f-9e99-490e-b33d-81dee7848472,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-966b274b-5bab-4daa-bea4-bf4e5e8b3b77,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-73faf2af-746e-4972-a846-c9d802a8af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-0be1372c-5687-4c41-923b-fac10642102c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795256899-172.17.0.12-1595384615276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-4dd9cc60-2df1-4e53-af30-5924178c3e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-45560622-ba55-4bad-a6f8-c2c2416338fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-d56d2e91-efa3-4eb4-ad2d-349244d538e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-7367cbbf-933e-4726-836d-f5a665e84c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-f11e1904-040e-4dfb-9000-04c51918d550,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-d7e4a763-35f3-4a6f-978b-849ba6965cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-5c9551b2-f82b-405a-a97d-6713f1955db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-7c769807-d3ce-4f7f-a91c-14d0a81e304f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795256899-172.17.0.12-1595384615276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-4dd9cc60-2df1-4e53-af30-5924178c3e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-45560622-ba55-4bad-a6f8-c2c2416338fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-d56d2e91-efa3-4eb4-ad2d-349244d538e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-7367cbbf-933e-4726-836d-f5a665e84c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-f11e1904-040e-4dfb-9000-04c51918d550,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-d7e4a763-35f3-4a6f-978b-849ba6965cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-5c9551b2-f82b-405a-a97d-6713f1955db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-7c769807-d3ce-4f7f-a91c-14d0a81e304f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532743555-172.17.0.12-1595384776017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-a25900bd-74c6-492c-85a4-dd8145c7974b,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-62995582-afc2-4504-9fc7-4e34b41a8bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-41770354-af00-43d1-9fd0-e6c3fdc794d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-b4c6a444-c883-4bc0-a440-5505adf95150,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-d87499db-92a4-4d7d-bdb4-8603be883864,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-2d531905-a03d-45f9-b134-9905b080f67b,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-4e2794e5-1298-4127-91fe-8ef645ca7e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-1d43332e-d4ca-462f-85fa-e5cbc3065fcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532743555-172.17.0.12-1595384776017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-a25900bd-74c6-492c-85a4-dd8145c7974b,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-62995582-afc2-4504-9fc7-4e34b41a8bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-41770354-af00-43d1-9fd0-e6c3fdc794d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-b4c6a444-c883-4bc0-a440-5505adf95150,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-d87499db-92a4-4d7d-bdb4-8603be883864,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-2d531905-a03d-45f9-b134-9905b080f67b,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-4e2794e5-1298-4127-91fe-8ef645ca7e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-1d43332e-d4ca-462f-85fa-e5cbc3065fcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110435807-172.17.0.12-1595384809729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38728,DS-33a3d8d2-d9cb-49c9-b919-17dbb6208fff,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-5ec68a33-55e3-4865-a2ef-d9357b314421,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-c01a105e-76b8-4560-84a9-c59e0e490dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-332d7b25-302f-4883-a7f7-e75dcb6af05f,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-82051fbe-e1c7-450e-8152-d1a53f7e5c33,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-c63d10e7-98b1-49c1-a71d-5b7cb3ce7d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-e9b64716-0038-4699-bcd7-20a32cbbb26a,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-c4643d07-3d4d-4ae7-9ecf-043bb7a45867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110435807-172.17.0.12-1595384809729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38728,DS-33a3d8d2-d9cb-49c9-b919-17dbb6208fff,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-5ec68a33-55e3-4865-a2ef-d9357b314421,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-c01a105e-76b8-4560-84a9-c59e0e490dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-332d7b25-302f-4883-a7f7-e75dcb6af05f,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-82051fbe-e1c7-450e-8152-d1a53f7e5c33,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-c63d10e7-98b1-49c1-a71d-5b7cb3ce7d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-e9b64716-0038-4699-bcd7-20a32cbbb26a,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-c4643d07-3d4d-4ae7-9ecf-043bb7a45867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251611041-172.17.0.12-1595384977708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46653,DS-a8f7e8b6-4236-4de6-acfd-7024db30a445,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-422ac40f-7495-405c-a5ce-c9c25d70ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-5c87bdc8-6ca2-4f2f-827d-91d631c6a77e,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-f8942cc1-3a92-4bb4-a8d8-af27a328a484,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-65c01cd7-7f1c-4c2d-a027-c8c184d46f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-c5c51e55-a874-4814-a48b-50524de57d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-587ba40e-f8f8-4007-a9a8-7bc62026beee,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-b0dc7999-4339-47ae-9585-c48daf935c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251611041-172.17.0.12-1595384977708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46653,DS-a8f7e8b6-4236-4de6-acfd-7024db30a445,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-422ac40f-7495-405c-a5ce-c9c25d70ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-5c87bdc8-6ca2-4f2f-827d-91d631c6a77e,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-f8942cc1-3a92-4bb4-a8d8-af27a328a484,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-65c01cd7-7f1c-4c2d-a027-c8c184d46f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-c5c51e55-a874-4814-a48b-50524de57d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-587ba40e-f8f8-4007-a9a8-7bc62026beee,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-b0dc7999-4339-47ae-9585-c48daf935c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302079778-172.17.0.12-1595385399157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40771,DS-1c111bc7-a6dd-41ba-9ece-e9916158520c,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-edf6f82f-a33e-49da-bd85-df0fd8eb0114,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-585695cd-8b94-49c9-a46a-50f4537f4cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-006e2579-40f9-4447-9aac-47a716f1269e,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-954eda5e-7ca6-413f-afe7-4509b7b047f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-e1f10339-b040-44a3-b5b1-018166946ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-10e982d6-42d3-4436-b632-c02d1bb2d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-3ceb1bd8-2ace-47dc-b3cc-e88c8d85989e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302079778-172.17.0.12-1595385399157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40771,DS-1c111bc7-a6dd-41ba-9ece-e9916158520c,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-edf6f82f-a33e-49da-bd85-df0fd8eb0114,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-585695cd-8b94-49c9-a46a-50f4537f4cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-006e2579-40f9-4447-9aac-47a716f1269e,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-954eda5e-7ca6-413f-afe7-4509b7b047f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-e1f10339-b040-44a3-b5b1-018166946ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-10e982d6-42d3-4436-b632-c02d1bb2d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-3ceb1bd8-2ace-47dc-b3cc-e88c8d85989e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564401172-172.17.0.12-1595385565715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-446b7344-42f8-4132-b7c6-95515bff618b,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-b23a72fa-5f3a-40d6-bf23-bbba33bb9425,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-febee7d5-f199-41b4-89aa-bc21a475d284,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-a2aee4ce-459c-4a8a-a8c1-8d9759e334e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-19a06175-a9c3-430c-a994-0e4c93bc9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-0248994b-5698-43ad-94fb-935c2089d7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-27e4d109-1070-4ad8-b30c-74f79310d0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-11f70c62-a762-42ac-84a0-e8b08b268604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564401172-172.17.0.12-1595385565715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-446b7344-42f8-4132-b7c6-95515bff618b,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-b23a72fa-5f3a-40d6-bf23-bbba33bb9425,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-febee7d5-f199-41b4-89aa-bc21a475d284,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-a2aee4ce-459c-4a8a-a8c1-8d9759e334e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-19a06175-a9c3-430c-a994-0e4c93bc9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-0248994b-5698-43ad-94fb-935c2089d7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-27e4d109-1070-4ad8-b30c-74f79310d0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-11f70c62-a762-42ac-84a0-e8b08b268604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593656248-172.17.0.12-1595385637299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-cca649cc-7014-4b7a-bfa0-9482f661d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-46cb0277-4286-4078-ab1f-41a4444eec17,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-459e06aa-8b02-4151-a873-9bb51a99e9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-d3048802-aeab-45c5-879c-9dfd57ba2e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-48b4969e-a06d-41b0-96bd-5cf9827e644c,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-002e09c8-e454-4c1a-b14f-26a5a4e31fee,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-f42bbb31-bc24-4538-a775-360d5cf490d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-6833ea53-f90f-4bfe-bcd2-0c827708ac39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593656248-172.17.0.12-1595385637299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-cca649cc-7014-4b7a-bfa0-9482f661d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-46cb0277-4286-4078-ab1f-41a4444eec17,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-459e06aa-8b02-4151-a873-9bb51a99e9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-d3048802-aeab-45c5-879c-9dfd57ba2e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-48b4969e-a06d-41b0-96bd-5cf9827e644c,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-002e09c8-e454-4c1a-b14f-26a5a4e31fee,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-f42bbb31-bc24-4538-a775-360d5cf490d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-6833ea53-f90f-4bfe-bcd2-0c827708ac39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190398803-172.17.0.12-1595385669694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-a91e3162-0b1e-4e7f-b158-826dee9bc925,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-bcc028bf-2c59-41ca-86f1-b83c3bb1afbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a040479e-a1c1-4b4e-bbd2-2f91d2bf43af,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-fc5c19d1-544a-4ff7-b53a-a74e3ab4b595,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-2d668683-76cd-4174-90a8-2342e49a0e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-ae97eff4-0ee0-4538-89a0-10cbf72fc4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-a305c2be-723e-4ee1-92d3-bef2d869e81c,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-03219522-8b48-41b3-8187-19e93cde6a3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190398803-172.17.0.12-1595385669694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-a91e3162-0b1e-4e7f-b158-826dee9bc925,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-bcc028bf-2c59-41ca-86f1-b83c3bb1afbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a040479e-a1c1-4b4e-bbd2-2f91d2bf43af,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-fc5c19d1-544a-4ff7-b53a-a74e3ab4b595,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-2d668683-76cd-4174-90a8-2342e49a0e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-ae97eff4-0ee0-4538-89a0-10cbf72fc4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-a305c2be-723e-4ee1-92d3-bef2d869e81c,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-03219522-8b48-41b3-8187-19e93cde6a3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186561700-172.17.0.12-1595385699380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40672,DS-129c8f00-43ee-408f-809e-00bec450d65b,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-59dc4a69-3184-45ee-bf2f-54c75898c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-bbbbdc9c-98b9-4be2-8f4c-f6de9f7b4c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-7cfaf24b-5e26-4804-a8ec-b1abbdc7d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-bced331f-30de-432e-9fe5-92f875edcc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-1acacc36-403b-439b-9b20-9940db18d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-0041e1d3-2e53-4cb8-9516-f2481eb9780d,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-d37c04b0-621b-4a5f-ac01-eafcb3689724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186561700-172.17.0.12-1595385699380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40672,DS-129c8f00-43ee-408f-809e-00bec450d65b,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-59dc4a69-3184-45ee-bf2f-54c75898c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-bbbbdc9c-98b9-4be2-8f4c-f6de9f7b4c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-7cfaf24b-5e26-4804-a8ec-b1abbdc7d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-bced331f-30de-432e-9fe5-92f875edcc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-1acacc36-403b-439b-9b20-9940db18d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-0041e1d3-2e53-4cb8-9516-f2481eb9780d,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-d37c04b0-621b-4a5f-ac01-eafcb3689724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947248694-172.17.0.12-1595385793828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-91808ae8-eb46-441c-bfc0-d47f8bbb5f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-cf1f4add-bfe7-49fc-8d53-b97882c9990d,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-c084bb17-6bcf-4ad7-bca7-aeac39ac28a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-ba1f150f-4d6e-44f7-ae70-410674cb15ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-cecdb220-b33d-43f1-a25a-2f5d8f5ef9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-2dcc9111-b9d1-4024-9f42-1a09f35f397b,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-51ceb65d-3504-4366-9bbb-671238e8916a,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-2c63596d-b784-4428-884b-06bd19799a3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947248694-172.17.0.12-1595385793828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-91808ae8-eb46-441c-bfc0-d47f8bbb5f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-cf1f4add-bfe7-49fc-8d53-b97882c9990d,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-c084bb17-6bcf-4ad7-bca7-aeac39ac28a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-ba1f150f-4d6e-44f7-ae70-410674cb15ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-cecdb220-b33d-43f1-a25a-2f5d8f5ef9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-2dcc9111-b9d1-4024-9f42-1a09f35f397b,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-51ceb65d-3504-4366-9bbb-671238e8916a,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-2c63596d-b784-4428-884b-06bd19799a3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904004169-172.17.0.12-1595385992289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43701,DS-a650ec04-e25b-4d0e-b7e1-5451a9c385d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-6f25c994-68d9-47c5-aa10-b8d87490f8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-8dcff5b5-7dee-4d25-b99e-61dfe0fb53de,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-f1d6230a-c1b2-437d-a62f-48948bec7a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-e0968900-f777-4a27-a83b-a40fd1be73f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-9711200a-05b5-435e-85d4-32c35eb58284,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-9b3e1bde-e173-4941-aeb4-828f13f88726,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-3434309b-17ad-4213-bbd9-dd2edd3cd09c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904004169-172.17.0.12-1595385992289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43701,DS-a650ec04-e25b-4d0e-b7e1-5451a9c385d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-6f25c994-68d9-47c5-aa10-b8d87490f8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-8dcff5b5-7dee-4d25-b99e-61dfe0fb53de,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-f1d6230a-c1b2-437d-a62f-48948bec7a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-e0968900-f777-4a27-a83b-a40fd1be73f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-9711200a-05b5-435e-85d4-32c35eb58284,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-9b3e1bde-e173-4941-aeb4-828f13f88726,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-3434309b-17ad-4213-bbd9-dd2edd3cd09c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712081771-172.17.0.12-1595386124875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38085,DS-4d587184-720d-44e1-a1e2-f75b861565d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-f0e71c3e-0eb2-48ff-9c02-ba592f27a578,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-e6965092-c65d-499a-8c69-fca6ecd39f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-249ad480-9a4e-4b4c-a34c-b32edd7a1585,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-72352fff-a611-4706-af60-e2084d813ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-49113f5e-0223-4846-bf1f-c27eec5c7583,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-4f6dfdf3-42aa-4f88-81e2-7cc189bc286e,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-af834cf5-0a88-46b4-a2ae-7cb4f9d04860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712081771-172.17.0.12-1595386124875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38085,DS-4d587184-720d-44e1-a1e2-f75b861565d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-f0e71c3e-0eb2-48ff-9c02-ba592f27a578,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-e6965092-c65d-499a-8c69-fca6ecd39f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-249ad480-9a4e-4b4c-a34c-b32edd7a1585,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-72352fff-a611-4706-af60-e2084d813ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-49113f5e-0223-4846-bf1f-c27eec5c7583,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-4f6dfdf3-42aa-4f88-81e2-7cc189bc286e,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-af834cf5-0a88-46b4-a2ae-7cb4f9d04860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5062
