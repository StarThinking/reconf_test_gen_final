reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940520312-172.17.0.4-1595388016455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33816,DS-2b1396dc-8a78-49f6-99fb-fcca4387915b,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-64e9e16c-283c-41da-a44d-36fb5d97b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-e305fdbd-de59-4f38-92a8-15540ac914e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-bf1726e1-5515-4964-8454-25b61f62a071,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-b9194a65-5465-452b-a98a-e225bf197d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-6d1be7d2-6e96-488e-af23-d7b630f3ccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-f1e00f00-96f6-4e4f-87ff-1da98f254745,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-6f3aa0e6-1c93-4dd5-8711-d3bf384fbef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940520312-172.17.0.4-1595388016455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33816,DS-2b1396dc-8a78-49f6-99fb-fcca4387915b,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-64e9e16c-283c-41da-a44d-36fb5d97b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-e305fdbd-de59-4f38-92a8-15540ac914e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-bf1726e1-5515-4964-8454-25b61f62a071,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-b9194a65-5465-452b-a98a-e225bf197d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-6d1be7d2-6e96-488e-af23-d7b630f3ccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-f1e00f00-96f6-4e4f-87ff-1da98f254745,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-6f3aa0e6-1c93-4dd5-8711-d3bf384fbef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375444244-172.17.0.4-1595388479279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39971,DS-942f5978-fe1e-42a2-aa99-69613c7af299,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-54b0f7d7-007d-443a-b419-bfa6bff8bea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-d706488d-d170-40ad-a11e-a82dbfc1d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-6f3afc30-48b2-43dc-92bd-2e9079b320ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-bee23344-2a0c-42e6-bd86-531d40d654d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-856673fe-b7b0-47da-ac07-28452deb2899,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-606ad408-2800-4a69-b5c6-36c73634d293,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-2b158848-803b-44c6-8308-579e1bf29f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375444244-172.17.0.4-1595388479279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39971,DS-942f5978-fe1e-42a2-aa99-69613c7af299,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-54b0f7d7-007d-443a-b419-bfa6bff8bea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-d706488d-d170-40ad-a11e-a82dbfc1d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-6f3afc30-48b2-43dc-92bd-2e9079b320ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-bee23344-2a0c-42e6-bd86-531d40d654d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-856673fe-b7b0-47da-ac07-28452deb2899,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-606ad408-2800-4a69-b5c6-36c73634d293,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-2b158848-803b-44c6-8308-579e1bf29f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468881968-172.17.0.4-1595388763227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-08435631-49a8-4447-9162-dff06e1ebaad,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-534b3127-a43b-4bd6-8ed9-f3907f821390,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-856ab7fc-3731-4aa6-980f-64d9a74fed73,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-42f8e80b-bf54-42ed-9a7f-dd543d94ed17,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-d1460a5c-8bef-4729-9f9e-fd07c7c58107,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-477047aa-6714-4cbe-ba76-e43ee8534814,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-157c7262-9183-43f3-b590-8c7c9f29f0db,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-1dc50036-c95d-4b7b-a619-e541e8784358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468881968-172.17.0.4-1595388763227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-08435631-49a8-4447-9162-dff06e1ebaad,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-534b3127-a43b-4bd6-8ed9-f3907f821390,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-856ab7fc-3731-4aa6-980f-64d9a74fed73,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-42f8e80b-bf54-42ed-9a7f-dd543d94ed17,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-d1460a5c-8bef-4729-9f9e-fd07c7c58107,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-477047aa-6714-4cbe-ba76-e43ee8534814,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-157c7262-9183-43f3-b590-8c7c9f29f0db,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-1dc50036-c95d-4b7b-a619-e541e8784358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253829025-172.17.0.4-1595389162006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-1c3f6a1c-52c6-4da9-b7b3-f2fc409d7b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-e12a048f-b4ed-43a3-9e0e-a269d187a84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-a7e7ab4b-6fe4-4b4e-8ba2-21d42a502903,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-2e65b9ba-aab9-4a5c-8b9d-e2903c36b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-00066992-82d6-40a6-95ca-29267074465c,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-0f83a2c2-1269-44e5-91a9-b525bc07e182,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-37629647-3efd-4901-bb44-7303a1f29b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-8a35de50-ac91-4f87-9e50-c483839e94ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253829025-172.17.0.4-1595389162006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-1c3f6a1c-52c6-4da9-b7b3-f2fc409d7b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-e12a048f-b4ed-43a3-9e0e-a269d187a84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-a7e7ab4b-6fe4-4b4e-8ba2-21d42a502903,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-2e65b9ba-aab9-4a5c-8b9d-e2903c36b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-00066992-82d6-40a6-95ca-29267074465c,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-0f83a2c2-1269-44e5-91a9-b525bc07e182,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-37629647-3efd-4901-bb44-7303a1f29b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-8a35de50-ac91-4f87-9e50-c483839e94ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944366159-172.17.0.4-1595389452145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40884,DS-bd52b4fa-dacd-46bd-b7e0-c30cdded3123,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-29041416-c95e-4e51-b8f0-c983f04ff1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-9ff5f119-2321-484f-abe4-c2b9b62b7414,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-dd657853-2965-4d6c-8b0d-7ea0fda19a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-bd98ffdc-c0a5-455d-bc4d-3f77f44d6e24,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-158d1baa-ef9c-45c6-a050-0a16829cacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-d5e3b1d6-e9f1-4694-b873-a8e23ce3927b,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-0710d830-97b7-44a1-b8ad-3bbd321b9d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944366159-172.17.0.4-1595389452145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40884,DS-bd52b4fa-dacd-46bd-b7e0-c30cdded3123,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-29041416-c95e-4e51-b8f0-c983f04ff1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-9ff5f119-2321-484f-abe4-c2b9b62b7414,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-dd657853-2965-4d6c-8b0d-7ea0fda19a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-bd98ffdc-c0a5-455d-bc4d-3f77f44d6e24,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-158d1baa-ef9c-45c6-a050-0a16829cacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-d5e3b1d6-e9f1-4694-b873-a8e23ce3927b,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-0710d830-97b7-44a1-b8ad-3bbd321b9d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308534971-172.17.0.4-1595389508511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-7fee2347-f909-4098-bd22-5f4bdd03fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-b795b868-97ee-4f27-92ff-ecd7f63ed66b,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-bb8776f2-8698-4209-b873-4e3a994c42e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-d2f2524c-35c0-4f51-adf1-f7f0d04e1f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-2ea61218-04c8-47a0-8dec-6334f563d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-c58b4e80-22ba-47fa-88f3-4ff8078dd51d,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-25ebf38f-6717-4e2e-b2a5-18fe14778cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-98744602-6dd6-4850-93e1-342a83de8345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308534971-172.17.0.4-1595389508511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-7fee2347-f909-4098-bd22-5f4bdd03fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-b795b868-97ee-4f27-92ff-ecd7f63ed66b,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-bb8776f2-8698-4209-b873-4e3a994c42e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-d2f2524c-35c0-4f51-adf1-f7f0d04e1f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-2ea61218-04c8-47a0-8dec-6334f563d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-c58b4e80-22ba-47fa-88f3-4ff8078dd51d,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-25ebf38f-6717-4e2e-b2a5-18fe14778cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-98744602-6dd6-4850-93e1-342a83de8345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404518095-172.17.0.4-1595389609163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-83c415c1-f29a-481e-b21e-9ec40139c8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-a1775ac3-e2f4-4f45-8fa7-dbd3261c842a,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-7235bba4-dcf2-4208-b543-547fc0a49ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-b2f08465-f57a-47b3-add3-a30e22b57325,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-d32d430c-108f-4c1d-8d41-ad954372d214,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-4b93c7c6-2cad-46b0-a314-e7de162ca580,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b42a8945-ed33-4964-803a-a4b2bda7f0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-2e047799-3be5-460f-8306-9d4123452831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404518095-172.17.0.4-1595389609163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-83c415c1-f29a-481e-b21e-9ec40139c8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-a1775ac3-e2f4-4f45-8fa7-dbd3261c842a,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-7235bba4-dcf2-4208-b543-547fc0a49ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-b2f08465-f57a-47b3-add3-a30e22b57325,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-d32d430c-108f-4c1d-8d41-ad954372d214,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-4b93c7c6-2cad-46b0-a314-e7de162ca580,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b42a8945-ed33-4964-803a-a4b2bda7f0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-2e047799-3be5-460f-8306-9d4123452831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84579075-172.17.0.4-1595390171756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-e7dc5fb8-bb21-4777-bec9-7edb2afadc98,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-ecc7d795-43bd-4a6a-9b30-8d17134fac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-911a6627-cb3d-4116-8e0b-b316b6c55b78,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-14560375-1d50-41f8-a4cd-7d2888eb6fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-1ad81e40-7840-4a0a-9941-a7aa2e5ed5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-f05bbf6c-34d1-44dc-a3a4-a31b136f2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-edeb83ac-39e8-4a7f-8097-8c1ae4b6aaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-b235f633-f324-4350-befc-b00198ddb365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84579075-172.17.0.4-1595390171756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-e7dc5fb8-bb21-4777-bec9-7edb2afadc98,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-ecc7d795-43bd-4a6a-9b30-8d17134fac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-911a6627-cb3d-4116-8e0b-b316b6c55b78,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-14560375-1d50-41f8-a4cd-7d2888eb6fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-1ad81e40-7840-4a0a-9941-a7aa2e5ed5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-f05bbf6c-34d1-44dc-a3a4-a31b136f2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-edeb83ac-39e8-4a7f-8097-8c1ae4b6aaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-b235f633-f324-4350-befc-b00198ddb365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330787008-172.17.0.4-1595390271849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39444,DS-ec4026ee-095b-4cbc-96c1-4b58163f06bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-9a6bc182-6f08-4184-9beb-1f4ea3c17d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-5a602a10-2047-4bbc-a09b-ae4aef80cb22,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-ad9cf3fa-0651-4d8e-8dfa-c82af11f38a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-3a6ec17a-71e9-4cc2-b2ea-3897be78e949,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-36309255-a7cf-4d55-a4dd-67af8e56996e,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-35deab27-1e70-4c71-8c1b-f5a607695f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-9809a656-c3af-496f-87ed-7b0fd1536908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330787008-172.17.0.4-1595390271849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39444,DS-ec4026ee-095b-4cbc-96c1-4b58163f06bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-9a6bc182-6f08-4184-9beb-1f4ea3c17d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-5a602a10-2047-4bbc-a09b-ae4aef80cb22,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-ad9cf3fa-0651-4d8e-8dfa-c82af11f38a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-3a6ec17a-71e9-4cc2-b2ea-3897be78e949,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-36309255-a7cf-4d55-a4dd-67af8e56996e,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-35deab27-1e70-4c71-8c1b-f5a607695f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-9809a656-c3af-496f-87ed-7b0fd1536908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503484563-172.17.0.4-1595390907139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41338,DS-0d169154-c8d7-4203-a91f-623d991c690c,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-cd56eb3f-42cf-4b26-a36d-20ef0ca7348f,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-fe4f2abf-709c-4f9a-9357-414a4890e537,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-2abfd642-2f40-4296-81da-c25db7110d79,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-39740ae9-629d-455e-a6bf-3ab636dd006f,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-799d5335-a6d6-4cd7-acd6-87c7fa82d719,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-dfe73f1d-b6ea-4669-b475-e6e299e71ded,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-9b2350ef-f7e2-4726-9ed3-01ecbd39b06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503484563-172.17.0.4-1595390907139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41338,DS-0d169154-c8d7-4203-a91f-623d991c690c,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-cd56eb3f-42cf-4b26-a36d-20ef0ca7348f,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-fe4f2abf-709c-4f9a-9357-414a4890e537,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-2abfd642-2f40-4296-81da-c25db7110d79,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-39740ae9-629d-455e-a6bf-3ab636dd006f,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-799d5335-a6d6-4cd7-acd6-87c7fa82d719,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-dfe73f1d-b6ea-4669-b475-e6e299e71ded,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-9b2350ef-f7e2-4726-9ed3-01ecbd39b06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457796762-172.17.0.4-1595391073612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-ed4dc4a3-65f7-4d55-bba4-531079feabba,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-ca4ab566-0627-491f-8404-12780bc45cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-d31f780e-191e-4df8-aacc-b1c97ca26041,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-8113b94b-a328-490b-b00f-4a0fe7bc1123,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-768f0315-b5f5-47a7-9769-9aac5deca594,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-5959567b-004b-41ac-82b5-98e9fda06245,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-34bf3f5b-e3de-466e-99dd-be599b4045f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-df9a2d8f-8ba6-45b4-8978-39377cf74891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457796762-172.17.0.4-1595391073612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-ed4dc4a3-65f7-4d55-bba4-531079feabba,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-ca4ab566-0627-491f-8404-12780bc45cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-d31f780e-191e-4df8-aacc-b1c97ca26041,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-8113b94b-a328-490b-b00f-4a0fe7bc1123,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-768f0315-b5f5-47a7-9769-9aac5deca594,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-5959567b-004b-41ac-82b5-98e9fda06245,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-34bf3f5b-e3de-466e-99dd-be599b4045f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-df9a2d8f-8ba6-45b4-8978-39377cf74891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205709003-172.17.0.4-1595391182990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34053,DS-9485e210-2d07-4a0a-9078-01e8461d16b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-2f5c6d07-3b4e-4830-a9a7-57dd7f583791,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-c84a4203-b4a9-46d4-9125-124b12116dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-569462c9-2aba-425e-9efc-547ffc952c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-39d96f17-552e-46ab-9fc7-a9f81f86a995,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-8519605b-26ae-412f-9c2b-b96c70a100ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-c9783790-93f5-4c38-840c-ca06e6373ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-c173a2f9-e294-42b5-94f0-0df5250b9076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205709003-172.17.0.4-1595391182990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34053,DS-9485e210-2d07-4a0a-9078-01e8461d16b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-2f5c6d07-3b4e-4830-a9a7-57dd7f583791,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-c84a4203-b4a9-46d4-9125-124b12116dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-569462c9-2aba-425e-9efc-547ffc952c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-39d96f17-552e-46ab-9fc7-a9f81f86a995,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-8519605b-26ae-412f-9c2b-b96c70a100ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-c9783790-93f5-4c38-840c-ca06e6373ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-c173a2f9-e294-42b5-94f0-0df5250b9076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839464926-172.17.0.4-1595391322965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-3ae8d5ac-4959-4fd9-83be-39c5ee63e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-227fe21e-01cd-4d26-8083-509a5ae3f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-5eb4a2b3-facf-4229-8b7a-35d5942e4f47,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-a7dc30aa-3fa6-4b62-ac49-d6a1ee6113e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-d036d281-fa46-44db-bf31-6af8318ceed4,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-c7c0bb52-bd21-4e24-87ce-5ec833c353a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-dfe4ca39-9c29-46d1-8a95-3a1a1dcb2624,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-5ffa1379-665c-4a85-9e3e-5e319979214b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839464926-172.17.0.4-1595391322965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-3ae8d5ac-4959-4fd9-83be-39c5ee63e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-227fe21e-01cd-4d26-8083-509a5ae3f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-5eb4a2b3-facf-4229-8b7a-35d5942e4f47,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-a7dc30aa-3fa6-4b62-ac49-d6a1ee6113e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-d036d281-fa46-44db-bf31-6af8318ceed4,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-c7c0bb52-bd21-4e24-87ce-5ec833c353a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-dfe4ca39-9c29-46d1-8a95-3a1a1dcb2624,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-5ffa1379-665c-4a85-9e3e-5e319979214b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1902671100-172.17.0.4-1595391351168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-a721f2f7-5b32-4c38-b818-9adfa579fd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-665232a0-e1b4-4492-b45f-078affd1f279,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-09ba9acd-e784-4fc6-b8ef-96d12d04036d,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-1f27ea90-cf47-4138-89dd-863044bf8ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-afe4b8e7-b28e-4479-b3b2-a9b42da37536,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-11853c29-17bd-48c6-9b34-c1b339eebf15,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-d040da08-a06b-41c4-8ae1-ff353448d046,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-96dd8281-e908-4de1-ae00-595efa224ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1902671100-172.17.0.4-1595391351168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-a721f2f7-5b32-4c38-b818-9adfa579fd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-665232a0-e1b4-4492-b45f-078affd1f279,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-09ba9acd-e784-4fc6-b8ef-96d12d04036d,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-1f27ea90-cf47-4138-89dd-863044bf8ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-afe4b8e7-b28e-4479-b3b2-a9b42da37536,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-11853c29-17bd-48c6-9b34-c1b339eebf15,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-d040da08-a06b-41c4-8ae1-ff353448d046,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-96dd8281-e908-4de1-ae00-595efa224ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679381060-172.17.0.4-1595391377714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44944,DS-56f26663-5017-4f59-8134-7624ae20adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-3eeaf4fb-2d74-4fbd-9afe-2f01c7f0b8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-18fd944f-cc7a-4308-98dc-11da6e47d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-ae02fe02-34c4-436e-ab01-fc3753658fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-6b5d061c-ecf8-43f0-9d83-ed7170e5de3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-2111b891-ad3b-4f27-be29-f0b1d0544c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-c2f71b44-2676-44a9-81e5-78e31a30ceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-ec1c7aad-9b2a-4819-a566-e205aa9915bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679381060-172.17.0.4-1595391377714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44944,DS-56f26663-5017-4f59-8134-7624ae20adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-3eeaf4fb-2d74-4fbd-9afe-2f01c7f0b8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-18fd944f-cc7a-4308-98dc-11da6e47d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-ae02fe02-34c4-436e-ab01-fc3753658fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-6b5d061c-ecf8-43f0-9d83-ed7170e5de3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-2111b891-ad3b-4f27-be29-f0b1d0544c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-c2f71b44-2676-44a9-81e5-78e31a30ceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-ec1c7aad-9b2a-4819-a566-e205aa9915bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240487394-172.17.0.4-1595391452645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38162,DS-8318c6f7-bc71-4e96-9fe1-b9d8fb01b190,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-05c4f4e8-9de8-4723-b2f0-55b480fcd078,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-9fb22436-8c34-4c13-96c8-8afd01498130,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-9a4ac136-fd82-45c3-b3a8-e3ae517c8215,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-c053b9f7-8e30-4068-b356-4cf043495eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-b13f0108-909d-425a-a0d1-eda34aa08b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-6e093c37-5c6e-4624-90fb-7e8a3c23f7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-5cd78cee-8bdd-4585-921a-24c801649666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240487394-172.17.0.4-1595391452645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38162,DS-8318c6f7-bc71-4e96-9fe1-b9d8fb01b190,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-05c4f4e8-9de8-4723-b2f0-55b480fcd078,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-9fb22436-8c34-4c13-96c8-8afd01498130,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-9a4ac136-fd82-45c3-b3a8-e3ae517c8215,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-c053b9f7-8e30-4068-b356-4cf043495eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-b13f0108-909d-425a-a0d1-eda34aa08b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-6e093c37-5c6e-4624-90fb-7e8a3c23f7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-5cd78cee-8bdd-4585-921a-24c801649666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473731091-172.17.0.4-1595391752406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36460,DS-63158828-8789-4334-8493-d7dbf029787c,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-18bf5b7e-83f8-461b-a1dc-4a71eb53c2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-e4c61684-c17e-4c50-a7fb-8aa7d511cbab,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-7eb598b2-c1dd-46fc-8f3c-1dfe87ecadf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-6d4a7293-7106-4e6a-a4e1-12d2fe127f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-1350e6fa-76bd-45d4-b33e-2c2f8584c714,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-44a43385-9484-4120-95c8-52b752249700,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-974d8051-2709-4b3f-a6b1-dca868028043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473731091-172.17.0.4-1595391752406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36460,DS-63158828-8789-4334-8493-d7dbf029787c,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-18bf5b7e-83f8-461b-a1dc-4a71eb53c2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-e4c61684-c17e-4c50-a7fb-8aa7d511cbab,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-7eb598b2-c1dd-46fc-8f3c-1dfe87ecadf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-6d4a7293-7106-4e6a-a4e1-12d2fe127f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-1350e6fa-76bd-45d4-b33e-2c2f8584c714,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-44a43385-9484-4120-95c8-52b752249700,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-974d8051-2709-4b3f-a6b1-dca868028043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180521024-172.17.0.4-1595391963601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-17c6ea8d-7239-47fd-8202-d9bc3fd76dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-0e3497b0-c2e8-4b69-8947-4f0bc8d91644,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-ab5a866b-eddd-4232-a18d-33ccf8319a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-9708df33-7c3a-40ab-af54-2eeec0563d61,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-290cd9ce-e4a3-4ff8-9cc6-bc9bf1aa92aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-d3dadc3f-2677-4109-824d-d5b5e33417bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-4f3b73d8-f0e9-42da-9503-bd977c23a459,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-feddf9e4-4723-446e-afcf-c46effca2e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180521024-172.17.0.4-1595391963601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-17c6ea8d-7239-47fd-8202-d9bc3fd76dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-0e3497b0-c2e8-4b69-8947-4f0bc8d91644,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-ab5a866b-eddd-4232-a18d-33ccf8319a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-9708df33-7c3a-40ab-af54-2eeec0563d61,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-290cd9ce-e4a3-4ff8-9cc6-bc9bf1aa92aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-d3dadc3f-2677-4109-824d-d5b5e33417bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-4f3b73d8-f0e9-42da-9503-bd977c23a459,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-feddf9e4-4723-446e-afcf-c46effca2e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537841116-172.17.0.4-1595392247995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-c6dd2663-e19c-4624-a30f-260314c4739e,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-9687b9cb-0b70-4e79-9636-95913bd49097,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-e319b9d5-130c-4d33-bc3c-a1d0c300e797,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-dc3d75f9-5bb6-47dc-b453-fc3affe9e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-2812c169-5af2-4ebe-a553-dfa68233f496,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-5e107d15-05ea-4a73-84ce-ea0fa7d77fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-568e6916-ee27-468e-b9f7-ab3ac5a738eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-b834d068-b595-4ccf-ad3e-42f0f60ce30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537841116-172.17.0.4-1595392247995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-c6dd2663-e19c-4624-a30f-260314c4739e,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-9687b9cb-0b70-4e79-9636-95913bd49097,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-e319b9d5-130c-4d33-bc3c-a1d0c300e797,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-dc3d75f9-5bb6-47dc-b453-fc3affe9e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-2812c169-5af2-4ebe-a553-dfa68233f496,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-5e107d15-05ea-4a73-84ce-ea0fa7d77fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-568e6916-ee27-468e-b9f7-ab3ac5a738eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-b834d068-b595-4ccf-ad3e-42f0f60ce30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445243454-172.17.0.4-1595392530296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-02015cfc-9564-44d0-a5e1-9216f5967482,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-d189e7b7-2cdd-4c17-b2de-b02411af1bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-c43560ed-364a-459f-acc9-bc3dcd26ff45,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-10b0a4e6-8153-40f3-8463-6c9f9945ccc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-02fc7c27-7f34-46e7-88b2-9853086009d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-caf37278-5b40-4b42-aa1f-4bad6d462a73,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-bfaf9e83-2565-4535-bfae-4f76bf95024e,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-2b57502c-8f83-4d1a-b92e-d41b6cf0c14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445243454-172.17.0.4-1595392530296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-02015cfc-9564-44d0-a5e1-9216f5967482,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-d189e7b7-2cdd-4c17-b2de-b02411af1bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-c43560ed-364a-459f-acc9-bc3dcd26ff45,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-10b0a4e6-8153-40f3-8463-6c9f9945ccc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-02fc7c27-7f34-46e7-88b2-9853086009d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-caf37278-5b40-4b42-aa1f-4bad6d462a73,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-bfaf9e83-2565-4535-bfae-4f76bf95024e,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-2b57502c-8f83-4d1a-b92e-d41b6cf0c14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5107
