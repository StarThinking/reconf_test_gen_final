reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952138529-172.17.0.16-1595410961861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45843,DS-7cd7360f-40ba-4e63-b932-5f71840421ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-568e08af-0578-45db-befe-d0ec5b648152,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-8479e64b-02d2-4eb4-87a9-58005b360d06,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-f9436015-6a3a-438f-9aa4-c7a29a4c143b,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-e4b2917a-480c-4a21-be60-5c2efe30f2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-41ab6ff3-1b19-45dd-9d33-eae309c7c107,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-2c0c7208-ac26-4809-a741-6cf7bc5585c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-b1bae3df-278c-46b3-a904-8fc5f15e2282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952138529-172.17.0.16-1595410961861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45843,DS-7cd7360f-40ba-4e63-b932-5f71840421ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-568e08af-0578-45db-befe-d0ec5b648152,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-8479e64b-02d2-4eb4-87a9-58005b360d06,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-f9436015-6a3a-438f-9aa4-c7a29a4c143b,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-e4b2917a-480c-4a21-be60-5c2efe30f2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-41ab6ff3-1b19-45dd-9d33-eae309c7c107,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-2c0c7208-ac26-4809-a741-6cf7bc5585c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-b1bae3df-278c-46b3-a904-8fc5f15e2282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950833447-172.17.0.16-1595410994549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37740,DS-903e40b1-e4b3-4b68-a013-bcb9e0ef7104,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-3d190f58-5497-4dc6-9654-9d635e2cc024,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-0f57f966-b71a-45ca-a2c4-20086cedd159,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-49cf5254-f799-4658-b508-4dcc2b4a34a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-976eb0e1-9a78-40bd-b7da-6dd3c968e914,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-b63526b8-a94c-4b08-98e2-18c3f136e458,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-d972f10f-4d8d-4ee9-a65d-8090c9250f19,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-3277bc6c-fb0d-4053-ac9c-de11daf3dfb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950833447-172.17.0.16-1595410994549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37740,DS-903e40b1-e4b3-4b68-a013-bcb9e0ef7104,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-3d190f58-5497-4dc6-9654-9d635e2cc024,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-0f57f966-b71a-45ca-a2c4-20086cedd159,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-49cf5254-f799-4658-b508-4dcc2b4a34a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-976eb0e1-9a78-40bd-b7da-6dd3c968e914,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-b63526b8-a94c-4b08-98e2-18c3f136e458,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-d972f10f-4d8d-4ee9-a65d-8090c9250f19,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-3277bc6c-fb0d-4053-ac9c-de11daf3dfb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731394908-172.17.0.16-1595411938319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40518,DS-22a6592a-8d44-4681-a585-dc994a59c038,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-974e0e0c-3e15-4b13-b770-97151f8a1ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-442b18a8-c821-4298-8ea7-762b16bf2e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-7cec757f-25f2-4536-91bb-809634b215e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-3bd8e22d-97eb-4826-b0a6-b9aae2a433f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-661d1d82-81ab-412b-97d7-5c29e0097d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-1fc736b1-736d-4ef3-a40c-07ee70f9748b,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-bb04f0ae-d0c0-4434-8478-d73833b8de4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731394908-172.17.0.16-1595411938319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40518,DS-22a6592a-8d44-4681-a585-dc994a59c038,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-974e0e0c-3e15-4b13-b770-97151f8a1ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-442b18a8-c821-4298-8ea7-762b16bf2e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-7cec757f-25f2-4536-91bb-809634b215e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-3bd8e22d-97eb-4826-b0a6-b9aae2a433f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-661d1d82-81ab-412b-97d7-5c29e0097d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-1fc736b1-736d-4ef3-a40c-07ee70f9748b,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-bb04f0ae-d0c0-4434-8478-d73833b8de4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156169780-172.17.0.16-1595412042438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35235,DS-4084399f-4aa9-40ca-8434-1c0da924cecc,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-04bd0f30-b312-4b42-b802-34d0820f1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-9ff5d57d-e6e1-4eca-9b93-a49da1788d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-da9c5b46-f5eb-4559-95b0-34ad5bf461d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-bd822105-16dd-49bf-b9ac-73e58168f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-50d6314c-ec5a-436a-8865-eb23acdfff89,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-b8d06a4c-0181-4912-b507-0b7598c04f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-18e6fb0e-9de7-42bc-bd95-a97f3eb58962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156169780-172.17.0.16-1595412042438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35235,DS-4084399f-4aa9-40ca-8434-1c0da924cecc,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-04bd0f30-b312-4b42-b802-34d0820f1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-9ff5d57d-e6e1-4eca-9b93-a49da1788d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-da9c5b46-f5eb-4559-95b0-34ad5bf461d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-bd822105-16dd-49bf-b9ac-73e58168f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-50d6314c-ec5a-436a-8865-eb23acdfff89,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-b8d06a4c-0181-4912-b507-0b7598c04f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-18e6fb0e-9de7-42bc-bd95-a97f3eb58962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716745027-172.17.0.16-1595412146167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-8f08fc7f-e02e-4323-b808-ddcdcd0b4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-f1395843-645c-490b-9fda-227b428c72ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-1c87c51d-41ec-4522-aa79-55b7b31aca26,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-055f594e-7592-47cf-b20f-4c93ee22e095,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-87c6267d-a897-4372-929e-55c4ffb618d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-0a8917c5-e67f-4cc8-ba67-94c783086ade,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-375a69d7-7433-4ffa-a569-bffa92476402,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-af6dd61d-997a-466c-aa1a-2808be786682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716745027-172.17.0.16-1595412146167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-8f08fc7f-e02e-4323-b808-ddcdcd0b4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-f1395843-645c-490b-9fda-227b428c72ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-1c87c51d-41ec-4522-aa79-55b7b31aca26,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-055f594e-7592-47cf-b20f-4c93ee22e095,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-87c6267d-a897-4372-929e-55c4ffb618d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-0a8917c5-e67f-4cc8-ba67-94c783086ade,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-375a69d7-7433-4ffa-a569-bffa92476402,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-af6dd61d-997a-466c-aa1a-2808be786682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706837076-172.17.0.16-1595412177260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34913,DS-781feda0-8b49-41b7-90ff-53de76a74204,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-7b02d937-e17a-490e-ab5e-6b5d76ddd873,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-3f06c52d-f290-4b87-875e-c1a52266ae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-fc2182ec-0ac4-4347-b25a-9418d519ba26,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-40d1922a-95d8-4c0c-a9d3-bd24e43fab7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-bbd1062b-3046-461d-a99a-3002427870ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-663e718a-55df-423c-afbc-0b3da9b3a8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-313005f9-2cc2-4d30-974c-ec36ef916c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706837076-172.17.0.16-1595412177260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34913,DS-781feda0-8b49-41b7-90ff-53de76a74204,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-7b02d937-e17a-490e-ab5e-6b5d76ddd873,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-3f06c52d-f290-4b87-875e-c1a52266ae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-fc2182ec-0ac4-4347-b25a-9418d519ba26,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-40d1922a-95d8-4c0c-a9d3-bd24e43fab7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-bbd1062b-3046-461d-a99a-3002427870ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-663e718a-55df-423c-afbc-0b3da9b3a8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-313005f9-2cc2-4d30-974c-ec36ef916c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242787591-172.17.0.16-1595412245630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-041336ba-ecb1-4486-ba24-887bb55c76de,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-e08541e3-1e1c-4748-8d5f-558c6509fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-7ba1fcc4-6ab9-4fda-88f2-7568a692bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-8e4a5c27-2bab-486f-a45c-b1a21c912daf,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-06f7e24f-d06c-4910-9526-33329f85d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-6cf44c22-6e7b-4928-ad1c-f718c52afb87,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-fe8a339b-aca3-4a4c-ad9b-4e9d1d629304,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-fdd328f7-8460-4b07-bcb8-3a09d0e428ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242787591-172.17.0.16-1595412245630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-041336ba-ecb1-4486-ba24-887bb55c76de,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-e08541e3-1e1c-4748-8d5f-558c6509fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-7ba1fcc4-6ab9-4fda-88f2-7568a692bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-8e4a5c27-2bab-486f-a45c-b1a21c912daf,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-06f7e24f-d06c-4910-9526-33329f85d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-6cf44c22-6e7b-4928-ad1c-f718c52afb87,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-fe8a339b-aca3-4a4c-ad9b-4e9d1d629304,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-fdd328f7-8460-4b07-bcb8-3a09d0e428ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865465707-172.17.0.16-1595412622988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-2dfc0bbd-6f9b-43ca-80a3-9ff5e4c9d27e,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-a3d0d8b4-ee06-4cae-9560-53347e94cc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-d2b473f1-dd11-4dae-af13-07502278d6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-40cbda6e-e9da-4abc-bd57-8545f37f6ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-c2d756a4-e0f7-4a6b-a45c-0662c377a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-8c8cdd0f-af32-4cb0-ae9a-c79cac49c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-04e2c041-27f6-4245-aa0e-9432b50d12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-b257d4e5-d4cf-4cc9-a3b7-73077795cb9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865465707-172.17.0.16-1595412622988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-2dfc0bbd-6f9b-43ca-80a3-9ff5e4c9d27e,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-a3d0d8b4-ee06-4cae-9560-53347e94cc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-d2b473f1-dd11-4dae-af13-07502278d6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-40cbda6e-e9da-4abc-bd57-8545f37f6ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-c2d756a4-e0f7-4a6b-a45c-0662c377a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-8c8cdd0f-af32-4cb0-ae9a-c79cac49c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-04e2c041-27f6-4245-aa0e-9432b50d12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-b257d4e5-d4cf-4cc9-a3b7-73077795cb9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211753283-172.17.0.16-1595412656847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44390,DS-4f628236-3afe-4b7c-b324-5c0fd0a15954,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-3456610f-eec5-4ede-9aa1-853418bd87ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-5cc6439c-6207-49da-99a1-45f7511db346,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-76737c00-8f0a-41cb-9115-c1e612b1a661,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-ad38ef6e-9bed-41f3-830a-28d9842c38d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-281952f1-de3b-4337-81a2-c11da79b1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-05fd5b52-d107-4f1d-8238-94a37eb4225f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-ae6e9266-6a75-4c49-acc1-9c5329c8eeb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211753283-172.17.0.16-1595412656847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44390,DS-4f628236-3afe-4b7c-b324-5c0fd0a15954,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-3456610f-eec5-4ede-9aa1-853418bd87ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-5cc6439c-6207-49da-99a1-45f7511db346,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-76737c00-8f0a-41cb-9115-c1e612b1a661,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-ad38ef6e-9bed-41f3-830a-28d9842c38d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-281952f1-de3b-4337-81a2-c11da79b1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-05fd5b52-d107-4f1d-8238-94a37eb4225f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-ae6e9266-6a75-4c49-acc1-9c5329c8eeb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519707209-172.17.0.16-1595412725180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-f1ac3afb-0bfd-4b61-937b-620204efecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-cf67b371-70a9-45ff-b852-a87237c406ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-59a5b813-4db8-426a-b78c-eca77abf35fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-b6696b8c-d754-436a-ac48-8418e450dd49,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-0968756b-dfa3-4170-b8c6-eb7eaf118212,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-3502ac19-2cb7-41f7-bf3b-27ac31612120,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-6807e84f-975b-4b20-82d8-d1b0ec90c48c,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-e4ee960b-9c4f-48c5-8d07-275df7e8fc8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519707209-172.17.0.16-1595412725180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-f1ac3afb-0bfd-4b61-937b-620204efecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-cf67b371-70a9-45ff-b852-a87237c406ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-59a5b813-4db8-426a-b78c-eca77abf35fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-b6696b8c-d754-436a-ac48-8418e450dd49,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-0968756b-dfa3-4170-b8c6-eb7eaf118212,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-3502ac19-2cb7-41f7-bf3b-27ac31612120,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-6807e84f-975b-4b20-82d8-d1b0ec90c48c,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-e4ee960b-9c4f-48c5-8d07-275df7e8fc8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691927148-172.17.0.16-1595412868021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-837b53d6-a7da-4567-81e2-9338274a307c,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-92f51d88-8497-48a2-a65d-7bf94b734ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-423e071b-4b05-436a-8ef5-1582b53c9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-4a913f60-2b8a-473c-9d0e-441fff58eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-3075784e-4064-4313-a2bd-b5b6b478dce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-d92a58ee-7def-43e0-8e7a-ae568c736f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-6d8a4bc2-e231-4e2d-b6ad-bbb26d5ed2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-3ab867fa-8378-4004-a85a-40f258d5fd5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691927148-172.17.0.16-1595412868021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-837b53d6-a7da-4567-81e2-9338274a307c,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-92f51d88-8497-48a2-a65d-7bf94b734ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-423e071b-4b05-436a-8ef5-1582b53c9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-4a913f60-2b8a-473c-9d0e-441fff58eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-3075784e-4064-4313-a2bd-b5b6b478dce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-d92a58ee-7def-43e0-8e7a-ae568c736f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-6d8a4bc2-e231-4e2d-b6ad-bbb26d5ed2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-3ab867fa-8378-4004-a85a-40f258d5fd5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176722512-172.17.0.16-1595412903779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38950,DS-e97d7a7b-2680-4087-b5c7-0c21d88a5f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-d694e4d4-9880-4897-9638-0878024336af,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-63044a37-bb37-4208-90a4-25ed2b021f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-9e041e48-ca5a-491a-b43f-f8d8c0adeb48,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-efe9d169-aaee-4a3f-8339-9a26b2036f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-d4543191-f96d-41d5-ae3e-3a5b58f10768,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-2dd441dc-5f40-42ec-a567-b3a29ed5d2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-5f495172-6c1e-4eae-a894-0e9579e8c509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176722512-172.17.0.16-1595412903779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38950,DS-e97d7a7b-2680-4087-b5c7-0c21d88a5f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-d694e4d4-9880-4897-9638-0878024336af,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-63044a37-bb37-4208-90a4-25ed2b021f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-9e041e48-ca5a-491a-b43f-f8d8c0adeb48,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-efe9d169-aaee-4a3f-8339-9a26b2036f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-d4543191-f96d-41d5-ae3e-3a5b58f10768,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-2dd441dc-5f40-42ec-a567-b3a29ed5d2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-5f495172-6c1e-4eae-a894-0e9579e8c509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131957720-172.17.0.16-1595413773367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-a3e42144-662a-447c-8178-45c2ff7c3920,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-e8e12da8-6bf9-4709-9a2b-55f3496cd389,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-60603c3f-5f60-45d1-897f-e964fa597950,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-92cf2d5b-d939-458d-85b8-34c254336940,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-5588c27e-5baf-4e00-968d-9ae65e4f5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-a6512b78-1bd3-4fed-bd0b-4cf95e915b91,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-d0129075-008a-483f-87c1-b4342dc2895c,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-de613496-63fd-4630-bd08-a78dee8308f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131957720-172.17.0.16-1595413773367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-a3e42144-662a-447c-8178-45c2ff7c3920,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-e8e12da8-6bf9-4709-9a2b-55f3496cd389,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-60603c3f-5f60-45d1-897f-e964fa597950,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-92cf2d5b-d939-458d-85b8-34c254336940,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-5588c27e-5baf-4e00-968d-9ae65e4f5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-a6512b78-1bd3-4fed-bd0b-4cf95e915b91,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-d0129075-008a-483f-87c1-b4342dc2895c,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-de613496-63fd-4630-bd08-a78dee8308f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119294570-172.17.0.16-1595413843383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37991,DS-dbb60a52-09a8-450f-8387-08409a0a00b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-57a43bdf-720c-48c7-b55b-07679eed6c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-cddaf731-ce87-4c19-a203-d4884b84af56,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-015d7841-ca48-4f90-a420-a9f396f9ff62,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-b80b53bc-8d3a-4de1-ab93-a17466708ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-5b587f7d-ca58-43b4-bbd8-5c11a9ee4107,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-a3765fe5-6b67-47f2-b7f9-757ba17437e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-cfaf5f8a-1325-455b-ae6c-6e586e38d6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119294570-172.17.0.16-1595413843383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37991,DS-dbb60a52-09a8-450f-8387-08409a0a00b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-57a43bdf-720c-48c7-b55b-07679eed6c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-cddaf731-ce87-4c19-a203-d4884b84af56,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-015d7841-ca48-4f90-a420-a9f396f9ff62,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-b80b53bc-8d3a-4de1-ab93-a17466708ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-5b587f7d-ca58-43b4-bbd8-5c11a9ee4107,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-a3765fe5-6b67-47f2-b7f9-757ba17437e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-cfaf5f8a-1325-455b-ae6c-6e586e38d6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647956202-172.17.0.16-1595414348745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33346,DS-da2af20d-4a65-45fb-b119-7dbac039c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-460ead96-507f-4738-977c-e0957a2b24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-305f7a7a-2d47-4d45-9195-60d8169e3d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-870ddc61-9388-4a4f-855e-7612268a6966,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-d2b81253-f1f4-41f5-b296-4718cd1a0f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-64c96a74-6611-4bcd-8ecd-69f1673a1296,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-462456df-7e0c-4fbb-9bb5-c1b79194596c,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-954619d3-ad74-44d2-8233-1a886e9a53ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647956202-172.17.0.16-1595414348745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33346,DS-da2af20d-4a65-45fb-b119-7dbac039c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-460ead96-507f-4738-977c-e0957a2b24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-305f7a7a-2d47-4d45-9195-60d8169e3d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-870ddc61-9388-4a4f-855e-7612268a6966,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-d2b81253-f1f4-41f5-b296-4718cd1a0f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-64c96a74-6611-4bcd-8ecd-69f1673a1296,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-462456df-7e0c-4fbb-9bb5-c1b79194596c,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-954619d3-ad74-44d2-8233-1a886e9a53ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537991625-172.17.0.16-1595414380657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-2ef74ab0-7356-4556-ad72-d236bfadb54f,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-543ee3ed-347f-4231-be28-abbdaea59e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-c71b2ed6-cec3-43e7-8ba0-b6ffc2ce7495,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-7ba97fac-0bad-4087-a8c9-5749ef01dc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-2a97fc0a-8157-480e-9509-9aabff7b27c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-d6e4f470-7f2b-4298-926e-35c2507c168d,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-8d0543ee-b477-4ce9-b915-cf893ab66d38,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-b2a27137-c140-483f-a67e-ff9f928e7ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537991625-172.17.0.16-1595414380657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-2ef74ab0-7356-4556-ad72-d236bfadb54f,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-543ee3ed-347f-4231-be28-abbdaea59e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-c71b2ed6-cec3-43e7-8ba0-b6ffc2ce7495,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-7ba97fac-0bad-4087-a8c9-5749ef01dc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-2a97fc0a-8157-480e-9509-9aabff7b27c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-d6e4f470-7f2b-4298-926e-35c2507c168d,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-8d0543ee-b477-4ce9-b915-cf893ab66d38,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-b2a27137-c140-483f-a67e-ff9f928e7ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604750366-172.17.0.16-1595414410772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43498,DS-cb33c6fc-8220-4588-939b-56b0d65e6c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-b9472c7f-447b-479d-9e9b-7e33958a8298,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-25aae40b-114c-4dab-9c96-fbd0c4020aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-8ed31394-9ef6-4738-96b2-99878c5fad37,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-36ff54f3-7a46-4e79-b1bd-2056ec6f575f,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-444233f1-9979-4ef6-991f-8e865b4253c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-3c822a76-4df2-45ac-a27a-c22c9507c515,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-219d7107-472c-4ad4-9ddd-0ddf24e72317,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604750366-172.17.0.16-1595414410772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43498,DS-cb33c6fc-8220-4588-939b-56b0d65e6c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-b9472c7f-447b-479d-9e9b-7e33958a8298,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-25aae40b-114c-4dab-9c96-fbd0c4020aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-8ed31394-9ef6-4738-96b2-99878c5fad37,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-36ff54f3-7a46-4e79-b1bd-2056ec6f575f,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-444233f1-9979-4ef6-991f-8e865b4253c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-3c822a76-4df2-45ac-a27a-c22c9507c515,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-219d7107-472c-4ad4-9ddd-0ddf24e72317,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477411823-172.17.0.16-1595415048053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34701,DS-70efbc44-c683-4c29-9d04-d46f1063c462,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-d3762e91-8b22-4c82-befd-7a7e03365a29,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-adff2cbd-5cef-4c1b-94e0-347bde3fa08d,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-b45c37f8-2e1a-4f36-96b1-62cb8fdc3bba,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-e79c0901-20de-4717-9ca7-6cdd829efdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-642890b4-7f28-40a2-af31-9a1b8509aa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-ee600b83-71bd-46f7-9109-0ac02a7323c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-203c06f9-6b45-4ab3-b47e-363b3ffddd5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477411823-172.17.0.16-1595415048053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34701,DS-70efbc44-c683-4c29-9d04-d46f1063c462,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-d3762e91-8b22-4c82-befd-7a7e03365a29,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-adff2cbd-5cef-4c1b-94e0-347bde3fa08d,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-b45c37f8-2e1a-4f36-96b1-62cb8fdc3bba,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-e79c0901-20de-4717-9ca7-6cdd829efdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-642890b4-7f28-40a2-af31-9a1b8509aa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-ee600b83-71bd-46f7-9109-0ac02a7323c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-203c06f9-6b45-4ab3-b47e-363b3ffddd5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108606684-172.17.0.16-1595415201205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-c6977a82-ee9a-4f19-abbb-e7977766281a,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-8e7357ae-e25a-414f-839f-3d9c383a39ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-6489ad6b-4ce6-4ac4-9d02-dd7d4b632d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-38a55e97-840f-40a2-af8b-bdf6ed53e708,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-2bfa88fe-9c70-47e2-885e-40ba56eb01af,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-ae31d108-8992-474e-b999-ae5ab768cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-88855c89-d171-4971-9d00-4e83ee0fd317,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-dd578fd8-2b13-4188-8418-cef9240dcfbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108606684-172.17.0.16-1595415201205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-c6977a82-ee9a-4f19-abbb-e7977766281a,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-8e7357ae-e25a-414f-839f-3d9c383a39ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-6489ad6b-4ce6-4ac4-9d02-dd7d4b632d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-38a55e97-840f-40a2-af8b-bdf6ed53e708,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-2bfa88fe-9c70-47e2-885e-40ba56eb01af,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-ae31d108-8992-474e-b999-ae5ab768cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-88855c89-d171-4971-9d00-4e83ee0fd317,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-dd578fd8-2b13-4188-8418-cef9240dcfbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531239210-172.17.0.16-1595415501248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-087b9349-6b4e-4e15-bf88-c88a1bd60249,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-137b6221-a197-44d9-95fb-de973a760f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-87c00430-37bd-41de-924a-e15feed82969,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-18d435b3-a663-4df2-9192-a486b785a77e,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-3d7af986-e937-44a1-8287-ca7e32999f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-3786bd0b-d5a8-4dff-b4ad-9c6238d8b310,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-76441464-2e09-496e-82b4-85f712730dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-4ecc58e2-0bc1-4629-a718-169ec5673d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531239210-172.17.0.16-1595415501248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-087b9349-6b4e-4e15-bf88-c88a1bd60249,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-137b6221-a197-44d9-95fb-de973a760f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-87c00430-37bd-41de-924a-e15feed82969,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-18d435b3-a663-4df2-9192-a486b785a77e,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-3d7af986-e937-44a1-8287-ca7e32999f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-3786bd0b-d5a8-4dff-b4ad-9c6238d8b310,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-76441464-2e09-496e-82b4-85f712730dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-4ecc58e2-0bc1-4629-a718-169ec5673d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654900936-172.17.0.16-1595415604128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34143,DS-c93eb038-0e78-419d-bb37-41a046919568,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-e46a312f-11e0-4641-8e6c-38d0e2c07474,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-db8ea89e-e190-4625-abe6-adcd65065f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-7449673f-3d60-40db-9e53-2ed552002517,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-1687b9ea-c99e-4a0a-8e98-39ea4091a070,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-c7b76895-2d97-48e0-9874-dc8c982fbd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-18d2e774-2f93-4631-8713-0c49dbf9b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-a5f7e5ce-6d52-45c4-aa63-0a304f46de82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654900936-172.17.0.16-1595415604128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34143,DS-c93eb038-0e78-419d-bb37-41a046919568,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-e46a312f-11e0-4641-8e6c-38d0e2c07474,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-db8ea89e-e190-4625-abe6-adcd65065f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-7449673f-3d60-40db-9e53-2ed552002517,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-1687b9ea-c99e-4a0a-8e98-39ea4091a070,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-c7b76895-2d97-48e0-9874-dc8c982fbd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-18d2e774-2f93-4631-8713-0c49dbf9b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-a5f7e5ce-6d52-45c4-aa63-0a304f46de82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5208
