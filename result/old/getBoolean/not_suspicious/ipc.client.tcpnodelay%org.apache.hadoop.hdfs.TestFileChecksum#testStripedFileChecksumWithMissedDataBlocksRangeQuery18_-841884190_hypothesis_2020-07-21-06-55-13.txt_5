reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442397781-172.17.0.14-1595314670645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40316,DS-38c2012b-5879-4838-8bd0-4708e6eeadd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-256a8f85-1a91-4b2f-8b95-3b4f4c0da101,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-670321b2-598d-44ba-a7f4-5518334ef04f,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-771152c6-ab7e-493e-8ac6-c7ce3cdaf88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-ffc1ab3a-8483-4d33-8fff-247256460245,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-f1433e70-1315-4bff-9914-77127bced75a,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-c0441574-1095-4f04-8688-02d9de713136,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-5ada4e7d-ec29-41da-8e74-c2cbfc8cd102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442397781-172.17.0.14-1595314670645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40316,DS-38c2012b-5879-4838-8bd0-4708e6eeadd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-256a8f85-1a91-4b2f-8b95-3b4f4c0da101,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-670321b2-598d-44ba-a7f4-5518334ef04f,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-771152c6-ab7e-493e-8ac6-c7ce3cdaf88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-ffc1ab3a-8483-4d33-8fff-247256460245,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-f1433e70-1315-4bff-9914-77127bced75a,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-c0441574-1095-4f04-8688-02d9de713136,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-5ada4e7d-ec29-41da-8e74-c2cbfc8cd102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062725056-172.17.0.14-1595315090283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-4576cc30-820e-41a0-8260-bbb3ee2a43ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-ddff80d4-ec6c-42c5-a8cc-d2aab7d0f962,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-50b34ee5-2410-4ec9-b1b7-09852e0e08a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-527f5562-a378-4eef-927a-8c5bd5cbfb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-38ea7c18-df1e-40c5-81b1-75178d2b8b79,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-bf804aa7-ecdb-400b-a55e-8c605b5bab97,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-527c43f7-d170-4f2f-a503-6a9a8f32b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-4aeeb2f7-483e-4af1-b07c-b33767099e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062725056-172.17.0.14-1595315090283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-4576cc30-820e-41a0-8260-bbb3ee2a43ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-ddff80d4-ec6c-42c5-a8cc-d2aab7d0f962,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-50b34ee5-2410-4ec9-b1b7-09852e0e08a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-527f5562-a378-4eef-927a-8c5bd5cbfb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-38ea7c18-df1e-40c5-81b1-75178d2b8b79,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-bf804aa7-ecdb-400b-a55e-8c605b5bab97,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-527c43f7-d170-4f2f-a503-6a9a8f32b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-4aeeb2f7-483e-4af1-b07c-b33767099e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79031699-172.17.0.14-1595315738287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44550,DS-7c3c3d22-ae81-4a53-ac83-16e783a32bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-7b473a69-f00b-4409-9774-f881877bca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-effec11e-d739-4b94-a745-f0365b7893ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-19e0e89b-ea60-441b-abdf-ab905a7630dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-4822b7a0-23c2-4ed6-ac2f-826da6bb6a11,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-aa7c673d-64d4-4931-a906-b921dc3f5701,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-2d520542-89df-4d87-877b-38bff377fa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-fa4e2c43-b175-4304-bdab-0950345af1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79031699-172.17.0.14-1595315738287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44550,DS-7c3c3d22-ae81-4a53-ac83-16e783a32bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-7b473a69-f00b-4409-9774-f881877bca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-effec11e-d739-4b94-a745-f0365b7893ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-19e0e89b-ea60-441b-abdf-ab905a7630dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-4822b7a0-23c2-4ed6-ac2f-826da6bb6a11,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-aa7c673d-64d4-4931-a906-b921dc3f5701,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-2d520542-89df-4d87-877b-38bff377fa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-fa4e2c43-b175-4304-bdab-0950345af1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472616543-172.17.0.14-1595316239018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-790f0c45-3c27-4cfd-8d5d-96e2cebbec79,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-3a469a90-dbe8-4e3c-9f88-5da55bc24869,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-82f349cd-f549-4c37-b165-993ffd1e9559,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-6cc85bbc-f71a-43f0-b775-9ab571d2d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ee674572-00fc-4430-8a38-c486262c36dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-7b8cc6e9-7cda-4c68-b6ad-b4137fc222b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-5df1c58f-1337-4d4a-b033-23b8ac825333,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-b351fb4a-3823-4ca4-a60c-3116e5860262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472616543-172.17.0.14-1595316239018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-790f0c45-3c27-4cfd-8d5d-96e2cebbec79,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-3a469a90-dbe8-4e3c-9f88-5da55bc24869,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-82f349cd-f549-4c37-b165-993ffd1e9559,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-6cc85bbc-f71a-43f0-b775-9ab571d2d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ee674572-00fc-4430-8a38-c486262c36dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-7b8cc6e9-7cda-4c68-b6ad-b4137fc222b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-5df1c58f-1337-4d4a-b033-23b8ac825333,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-b351fb4a-3823-4ca4-a60c-3116e5860262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871485545-172.17.0.14-1595316341255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-3b480402-ac78-4de5-8af8-6a790323a269,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-8f18cded-5ff0-4f08-a386-36558e95d570,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-c7bb862b-3e9c-4bfa-b56f-2496983c4eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-b97620b9-9d1a-463f-af61-57cae13aa51e,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-3c2448ce-be16-422d-afd7-42c4d86b952a,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-9adbab33-9bbc-4954-8323-dbc214da90bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-af9bbbcf-2984-457d-95e4-0fde20b534ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-d5dbcba3-5aec-4944-834b-b862a70df3f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871485545-172.17.0.14-1595316341255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-3b480402-ac78-4de5-8af8-6a790323a269,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-8f18cded-5ff0-4f08-a386-36558e95d570,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-c7bb862b-3e9c-4bfa-b56f-2496983c4eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-b97620b9-9d1a-463f-af61-57cae13aa51e,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-3c2448ce-be16-422d-afd7-42c4d86b952a,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-9adbab33-9bbc-4954-8323-dbc214da90bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-af9bbbcf-2984-457d-95e4-0fde20b534ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-d5dbcba3-5aec-4944-834b-b862a70df3f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957870296-172.17.0.14-1595316484047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40374,DS-970b6537-66ff-4a9b-9f97-63cc3b0a85f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-81100265-db3f-4606-ac3b-3196c507ac1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-6ae2b04f-96ad-4b6f-bc7b-2af12040b6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-d14925d9-278d-4e61-bfbc-3846f40dcc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-212cdf1b-584e-4c01-bf13-33cd4800da4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-323c62ce-09d3-4d8c-b5e4-92b3a900e003,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-d268a670-5180-4ea4-95ad-28541516eed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-1ab3c08a-9a84-4a1c-acbb-4d7ea438229c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957870296-172.17.0.14-1595316484047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40374,DS-970b6537-66ff-4a9b-9f97-63cc3b0a85f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-81100265-db3f-4606-ac3b-3196c507ac1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-6ae2b04f-96ad-4b6f-bc7b-2af12040b6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-d14925d9-278d-4e61-bfbc-3846f40dcc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-212cdf1b-584e-4c01-bf13-33cd4800da4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-323c62ce-09d3-4d8c-b5e4-92b3a900e003,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-d268a670-5180-4ea4-95ad-28541516eed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-1ab3c08a-9a84-4a1c-acbb-4d7ea438229c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636401579-172.17.0.14-1595316619493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42521,DS-0a4a3448-7409-4978-a09b-9906a734ec57,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-23ff8030-0c92-4c3b-bdbc-22ad9a719e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-07adee67-48c1-4c5d-a382-59802affde84,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-cf4150de-3757-407d-a266-054d030e8f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-426b58f1-4e23-403d-875b-1a778013b999,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-11978160-9562-4cd4-a5b2-5a0dc3b50a26,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-62b5302e-74fb-49ae-9dda-a4854a762b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-6aa07f33-80d3-46aa-9800-914abc8ea02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636401579-172.17.0.14-1595316619493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42521,DS-0a4a3448-7409-4978-a09b-9906a734ec57,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-23ff8030-0c92-4c3b-bdbc-22ad9a719e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-07adee67-48c1-4c5d-a382-59802affde84,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-cf4150de-3757-407d-a266-054d030e8f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-426b58f1-4e23-403d-875b-1a778013b999,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-11978160-9562-4cd4-a5b2-5a0dc3b50a26,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-62b5302e-74fb-49ae-9dda-a4854a762b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-6aa07f33-80d3-46aa-9800-914abc8ea02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628443531-172.17.0.14-1595316974770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40887,DS-71803847-d669-439b-a502-fe3a34eb2f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-ca6b5b15-413f-4944-8ad7-7071212e3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-af405695-ad89-4356-b535-9c814446dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-1e3bb49a-0cab-4c26-92d0-6c292c2403fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-9f707a67-abc3-4258-99d4-e38df681dc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-2c1225c4-574e-4096-b17b-41f9fb51fb57,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-31166340-4587-4ca3-a9e7-1c282c4bd0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-e18a9e13-9884-407d-a667-90db017c32dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628443531-172.17.0.14-1595316974770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40887,DS-71803847-d669-439b-a502-fe3a34eb2f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-ca6b5b15-413f-4944-8ad7-7071212e3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-af405695-ad89-4356-b535-9c814446dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-1e3bb49a-0cab-4c26-92d0-6c292c2403fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-9f707a67-abc3-4258-99d4-e38df681dc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-2c1225c4-574e-4096-b17b-41f9fb51fb57,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-31166340-4587-4ca3-a9e7-1c282c4bd0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-e18a9e13-9884-407d-a667-90db017c32dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311517250-172.17.0.14-1595317240605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36496,DS-d9b8eb34-a3b7-4ddd-b936-948d6d72d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-03d36391-c8aa-47a2-8819-2b30a19ffbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-bdfa019f-d919-4b7d-9e8c-46c9d2a1560e,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-a0e4efb6-1ac2-4707-a011-32001d999ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-0b1f36c7-1f1c-4b7d-bdbb-b6527f0a0ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-98bde1c7-f86c-46ce-908f-d688e78bb89b,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-1cae5b58-caea-4ccc-a6d2-a6ee6d02c1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-cc5fe104-564a-44ef-83b5-491b8d04c0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311517250-172.17.0.14-1595317240605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36496,DS-d9b8eb34-a3b7-4ddd-b936-948d6d72d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-03d36391-c8aa-47a2-8819-2b30a19ffbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-bdfa019f-d919-4b7d-9e8c-46c9d2a1560e,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-a0e4efb6-1ac2-4707-a011-32001d999ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-0b1f36c7-1f1c-4b7d-bdbb-b6527f0a0ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-98bde1c7-f86c-46ce-908f-d688e78bb89b,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-1cae5b58-caea-4ccc-a6d2-a6ee6d02c1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-cc5fe104-564a-44ef-83b5-491b8d04c0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281323976-172.17.0.14-1595317436756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-ab7c6578-dbe1-4807-9b6c-b7bd2b3ca0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-c219b496-db58-456f-81ab-237bbabde34e,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-0a2256c4-03f3-4abf-854d-be7269a8f36c,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-3c16f9dd-4f2f-4d83-b7bc-6f7afb6547b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-a179d638-c8cf-4cb5-acac-12beeeda98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-6b0f119d-ddcd-4221-bee9-6912c677fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-acf021d8-98b6-401b-b2ac-16b3a435afcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-38816481-4e94-46ed-8cb0-02bba59920ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281323976-172.17.0.14-1595317436756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-ab7c6578-dbe1-4807-9b6c-b7bd2b3ca0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-c219b496-db58-456f-81ab-237bbabde34e,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-0a2256c4-03f3-4abf-854d-be7269a8f36c,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-3c16f9dd-4f2f-4d83-b7bc-6f7afb6547b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-a179d638-c8cf-4cb5-acac-12beeeda98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-6b0f119d-ddcd-4221-bee9-6912c677fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-acf021d8-98b6-401b-b2ac-16b3a435afcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-38816481-4e94-46ed-8cb0-02bba59920ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045200601-172.17.0.14-1595317510769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42677,DS-457723e2-ac58-4ed8-8f79-b47302bc53d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-3ca40ef9-a7a9-4c31-ae5b-c7f581fc65a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-368da9fe-c9ad-4735-a005-19115fb3f449,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-0299a839-c4a8-4449-8937-8eca8bc18287,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-c9df9efe-78a7-4b5a-a0ee-b4c9cf5506e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-82c15546-46d7-420c-9475-d544b5b095b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-d1f14200-e8b3-49f6-8fa1-e9e119d2bfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-b88c0c42-f791-4980-80ba-3c63129982f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045200601-172.17.0.14-1595317510769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42677,DS-457723e2-ac58-4ed8-8f79-b47302bc53d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-3ca40ef9-a7a9-4c31-ae5b-c7f581fc65a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-368da9fe-c9ad-4735-a005-19115fb3f449,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-0299a839-c4a8-4449-8937-8eca8bc18287,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-c9df9efe-78a7-4b5a-a0ee-b4c9cf5506e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-82c15546-46d7-420c-9475-d544b5b095b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-d1f14200-e8b3-49f6-8fa1-e9e119d2bfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-b88c0c42-f791-4980-80ba-3c63129982f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899278227-172.17.0.14-1595317614088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-e0ce73ac-6ff5-43c6-b882-89eedcb35020,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-e97f5008-a27f-461e-a233-65201ece7788,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-4ed0c84d-46db-4f87-99c6-892e99af60d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-d1ed0d5d-010f-4c31-9c85-feda31f3f11e,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-98fca68e-c1bf-4936-b687-9a93b797394d,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-d5c2ad52-defc-4ce0-b5b4-3806ebe0a414,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-94f6153a-1908-4b38-824b-b85d92252753,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-086b4a8c-625e-424f-b579-c0dedf21d8e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899278227-172.17.0.14-1595317614088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-e0ce73ac-6ff5-43c6-b882-89eedcb35020,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-e97f5008-a27f-461e-a233-65201ece7788,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-4ed0c84d-46db-4f87-99c6-892e99af60d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-d1ed0d5d-010f-4c31-9c85-feda31f3f11e,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-98fca68e-c1bf-4936-b687-9a93b797394d,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-d5c2ad52-defc-4ce0-b5b4-3806ebe0a414,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-94f6153a-1908-4b38-824b-b85d92252753,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-086b4a8c-625e-424f-b579-c0dedf21d8e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914599279-172.17.0.14-1595317757578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-8efaaf2e-a83f-4037-b57b-54f2135c85b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-ee694d24-c3d0-43b5-bdc5-07a65ff52b12,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-59d0408c-c259-4604-87ca-a75579fe9254,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-ee7362a6-9bee-4d2f-b93c-c5769961776b,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-3109f14a-b8ef-4e72-8675-8f4408647223,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-7d416178-dec5-4dcb-8ac8-a7927593a178,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-fe498bd5-f520-4ea5-8b62-71a301c62288,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-7518000d-5992-4293-963d-19f4f27dff7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914599279-172.17.0.14-1595317757578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-8efaaf2e-a83f-4037-b57b-54f2135c85b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-ee694d24-c3d0-43b5-bdc5-07a65ff52b12,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-59d0408c-c259-4604-87ca-a75579fe9254,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-ee7362a6-9bee-4d2f-b93c-c5769961776b,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-3109f14a-b8ef-4e72-8675-8f4408647223,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-7d416178-dec5-4dcb-8ac8-a7927593a178,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-fe498bd5-f520-4ea5-8b62-71a301c62288,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-7518000d-5992-4293-963d-19f4f27dff7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200632081-172.17.0.14-1595318517406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-7874fc17-6a42-4110-bef2-9d15f8c82c94,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-0007ef50-9d71-4e6b-a6ed-d5498b4cfc07,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-643f92b4-600c-4b09-8016-d136c773c5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-3538d386-e728-4aaf-a33c-ac6d1be7bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-a3deb171-0e4e-436e-a4c1-6b41225a0d91,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-2cff781b-2dd4-4948-85c2-32206a3232ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-a25e239c-5077-4d66-a8a9-d0009e241d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-571aa7c3-f8fa-41d2-80cd-21eca2e21198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200632081-172.17.0.14-1595318517406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-7874fc17-6a42-4110-bef2-9d15f8c82c94,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-0007ef50-9d71-4e6b-a6ed-d5498b4cfc07,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-643f92b4-600c-4b09-8016-d136c773c5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-3538d386-e728-4aaf-a33c-ac6d1be7bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-a3deb171-0e4e-436e-a4c1-6b41225a0d91,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-2cff781b-2dd4-4948-85c2-32206a3232ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-a25e239c-5077-4d66-a8a9-d0009e241d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-571aa7c3-f8fa-41d2-80cd-21eca2e21198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513043155-172.17.0.14-1595318585587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-928540b9-4b16-4de4-8e8b-7698f95f12a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-cb0ceadb-483f-463d-826b-73a37066f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-a5f52be3-d4a7-416b-a7e0-d58c794da7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-52f1d363-9657-435e-846a-a3189712a6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-cf42d77b-2eac-4915-98c2-f4a8356da5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-7a0ff10f-2740-4d5d-ba3e-4360006c1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-96c549dd-79a5-4efa-a1de-8143be7ac9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-32a75d35-d6d8-4dab-b553-120a08b49662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513043155-172.17.0.14-1595318585587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-928540b9-4b16-4de4-8e8b-7698f95f12a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-cb0ceadb-483f-463d-826b-73a37066f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-a5f52be3-d4a7-416b-a7e0-d58c794da7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-52f1d363-9657-435e-846a-a3189712a6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-cf42d77b-2eac-4915-98c2-f4a8356da5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-7a0ff10f-2740-4d5d-ba3e-4360006c1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-96c549dd-79a5-4efa-a1de-8143be7ac9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-32a75d35-d6d8-4dab-b553-120a08b49662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57839249-172.17.0.14-1595318908582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43371,DS-69b22bad-aede-46e3-9e43-3797fbcb6be6,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-5c2f229d-6f4c-4e13-8cb1-496fe0df5a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-e2782133-07ba-41ad-9699-c4d932264a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-020f0622-6838-4357-85c9-f0588d4d206d,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-cd9460b9-190d-49ea-8b4a-87f80b6acb63,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-d4b20555-64bf-410a-b69b-e77c9729264b,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-79ff91d2-aa5f-4160-8eb3-a39e896d68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-14936e84-ad55-47dd-80ea-9f22c1871130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57839249-172.17.0.14-1595318908582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43371,DS-69b22bad-aede-46e3-9e43-3797fbcb6be6,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-5c2f229d-6f4c-4e13-8cb1-496fe0df5a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-e2782133-07ba-41ad-9699-c4d932264a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-020f0622-6838-4357-85c9-f0588d4d206d,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-cd9460b9-190d-49ea-8b4a-87f80b6acb63,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-d4b20555-64bf-410a-b69b-e77c9729264b,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-79ff91d2-aa5f-4160-8eb3-a39e896d68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-14936e84-ad55-47dd-80ea-9f22c1871130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534595192-172.17.0.14-1595318970190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35166,DS-cd27b009-8326-4ca3-a520-efcbde3295f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-4061d78b-315b-4eb1-9487-5f60ccfc511a,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-5cea8164-5006-477f-83c7-760bcfca51e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-eeeb54e3-6e10-4831-b07e-5b481f3fd39d,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-16f9ea9c-36b6-40d5-aead-8ecc3db8d56e,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-5bf3898b-b7fb-43bf-a70a-314cefec5c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-7e3c6440-55ae-4a86-80c3-da20e633c8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-33123d95-8092-4caf-b394-21d8911c0b14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534595192-172.17.0.14-1595318970190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35166,DS-cd27b009-8326-4ca3-a520-efcbde3295f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-4061d78b-315b-4eb1-9487-5f60ccfc511a,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-5cea8164-5006-477f-83c7-760bcfca51e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-eeeb54e3-6e10-4831-b07e-5b481f3fd39d,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-16f9ea9c-36b6-40d5-aead-8ecc3db8d56e,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-5bf3898b-b7fb-43bf-a70a-314cefec5c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-7e3c6440-55ae-4a86-80c3-da20e633c8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-33123d95-8092-4caf-b394-21d8911c0b14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511007452-172.17.0.14-1595319317852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-12d1f7ac-8330-4bc9-bde3-02b1249ed421,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-292b4b6b-5368-45d4-a7f0-1194d13479f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-5c24fec7-c05a-4c18-95e5-ef8a3aec81ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-d2af94d5-c551-4564-93f1-361dee41688a,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-024584bc-d8fa-44b5-853b-b30cf4181007,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-57e2931c-613a-48b5-877c-f28e567cbf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-7d648ab1-95bc-4906-8e47-4d0da3aa6f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-d7c04908-0d86-4c0d-8dfa-4bdd2850dd6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511007452-172.17.0.14-1595319317852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-12d1f7ac-8330-4bc9-bde3-02b1249ed421,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-292b4b6b-5368-45d4-a7f0-1194d13479f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-5c24fec7-c05a-4c18-95e5-ef8a3aec81ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-d2af94d5-c551-4564-93f1-361dee41688a,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-024584bc-d8fa-44b5-853b-b30cf4181007,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-57e2931c-613a-48b5-877c-f28e567cbf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-7d648ab1-95bc-4906-8e47-4d0da3aa6f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-d7c04908-0d86-4c0d-8dfa-4bdd2850dd6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072408322-172.17.0.14-1595319436510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-501c6988-0915-47f6-ab52-6d77c194a472,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-ba88ed23-39a4-4acc-9708-f927d24884d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-23e77107-14ed-432f-b360-af88b68ecc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-e4e85c89-09b0-466b-808a-092eb165fd67,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-35b3249f-b6e2-49e1-8bdf-d79311b2589f,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-1b8888bd-4b1b-4705-b4d6-0a71b958bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-1a754faf-6b1c-431d-9824-2a2124d92702,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-fbe90af7-d628-4b8b-90a8-fc9947b11a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072408322-172.17.0.14-1595319436510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-501c6988-0915-47f6-ab52-6d77c194a472,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-ba88ed23-39a4-4acc-9708-f927d24884d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-23e77107-14ed-432f-b360-af88b68ecc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-e4e85c89-09b0-466b-808a-092eb165fd67,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-35b3249f-b6e2-49e1-8bdf-d79311b2589f,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-1b8888bd-4b1b-4705-b4d6-0a71b958bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-1a754faf-6b1c-431d-9824-2a2124d92702,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-fbe90af7-d628-4b8b-90a8-fc9947b11a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539755344-172.17.0.14-1595319509500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-71341f80-fbf6-48de-a8c7-5f85e01c6abb,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-29bc780e-8230-48dc-a044-2ef64d1abdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-3043c8c8-49f0-4059-b249-a5ee8bca0576,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-ce94bcce-a726-4ab9-bcd8-eebf3a12fe67,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-72d5069b-a11a-4b9b-bf7d-085af76b3ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-c29eea58-19a8-4acf-8629-3e8d11aebace,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-3c3771fb-37d5-4698-a488-72da93ff49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-c782197b-1ef5-4fa4-9b42-f6875403e0a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539755344-172.17.0.14-1595319509500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-71341f80-fbf6-48de-a8c7-5f85e01c6abb,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-29bc780e-8230-48dc-a044-2ef64d1abdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-3043c8c8-49f0-4059-b249-a5ee8bca0576,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-ce94bcce-a726-4ab9-bcd8-eebf3a12fe67,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-72d5069b-a11a-4b9b-bf7d-085af76b3ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-c29eea58-19a8-4acf-8629-3e8d11aebace,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-3c3771fb-37d5-4698-a488-72da93ff49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-c782197b-1ef5-4fa4-9b42-f6875403e0a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5238
