reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399667822-172.17.0.6-1595323441134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38719,DS-b17871e0-1f34-4265-b507-af451a48cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-860a7ac1-2034-4343-81b7-f7555d89ed56,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-5f163bcd-e4a1-4591-84b9-364fadd2fa80,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-508d311e-fc86-4288-8479-ac94df04962f,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-0dd1afb8-65c3-4f35-ae25-0342a549014c,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-27f8309f-3c1e-47c4-b828-51f755828b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-c2692fc1-f8fc-4ad9-ab20-155818995bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-7bb54b3c-a591-4185-9fc0-4e38ab4bc0d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399667822-172.17.0.6-1595323441134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38719,DS-b17871e0-1f34-4265-b507-af451a48cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-860a7ac1-2034-4343-81b7-f7555d89ed56,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-5f163bcd-e4a1-4591-84b9-364fadd2fa80,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-508d311e-fc86-4288-8479-ac94df04962f,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-0dd1afb8-65c3-4f35-ae25-0342a549014c,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-27f8309f-3c1e-47c4-b828-51f755828b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-c2692fc1-f8fc-4ad9-ab20-155818995bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-7bb54b3c-a591-4185-9fc0-4e38ab4bc0d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109508040-172.17.0.6-1595323617011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-806fa057-509f-4009-95e6-bf6e2c17263b,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-7b1d840f-7c4d-4ff2-adf8-ba3202fd03d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-1295c09d-e4e1-4c77-93a4-dc3ef3aaa5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-0cd1f22b-04a6-499b-8439-9fcd24d3a957,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-facd0cef-87dd-41d7-8192-690fe8c5e195,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-73039aad-0776-4b31-9a8e-539144c45ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-75408f3e-f3ae-4121-a48c-30f8cf29e731,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-579277a1-1f96-4856-9ffa-e184bded9e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109508040-172.17.0.6-1595323617011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-806fa057-509f-4009-95e6-bf6e2c17263b,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-7b1d840f-7c4d-4ff2-adf8-ba3202fd03d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-1295c09d-e4e1-4c77-93a4-dc3ef3aaa5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-0cd1f22b-04a6-499b-8439-9fcd24d3a957,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-facd0cef-87dd-41d7-8192-690fe8c5e195,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-73039aad-0776-4b31-9a8e-539144c45ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-75408f3e-f3ae-4121-a48c-30f8cf29e731,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-579277a1-1f96-4856-9ffa-e184bded9e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274818930-172.17.0.6-1595323722936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-d137faa4-a2e8-484e-8cd4-84f4126dd911,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-5c2ed959-dc0a-46dd-accb-bdad9e93eb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-9e1df98f-add2-4fe9-9e51-47f272be20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-b0cf5672-5c31-4459-9229-239a7787f379,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-7a3d7daa-25b2-44bd-9f3f-2ff4ff9edca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-9104b400-7794-4db3-afea-24b0ac86b1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-385284fd-4a1f-4dad-8a43-96c8b467decd,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-5fbb4595-0104-423c-bda9-4fe594c34269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274818930-172.17.0.6-1595323722936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-d137faa4-a2e8-484e-8cd4-84f4126dd911,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-5c2ed959-dc0a-46dd-accb-bdad9e93eb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-9e1df98f-add2-4fe9-9e51-47f272be20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-b0cf5672-5c31-4459-9229-239a7787f379,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-7a3d7daa-25b2-44bd-9f3f-2ff4ff9edca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-9104b400-7794-4db3-afea-24b0ac86b1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-385284fd-4a1f-4dad-8a43-96c8b467decd,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-5fbb4595-0104-423c-bda9-4fe594c34269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946118250-172.17.0.6-1595324219998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-c4f89695-1f15-4e4c-9b20-b57f86458653,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-22b03c68-ed21-446d-8ab0-98aded0de105,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-7755e763-73f0-4e8a-a460-b8081b63e037,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-b7fb0324-faaa-4a78-91ef-bada43eaaf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-68c46aa0-8b8c-4a62-8079-07f5926acad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-0fd86621-90f0-45cc-ab25-dcb1ea2bd79e,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-817fb539-4182-439f-a4ed-e447e30b7cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-2177fbe1-0ca0-442b-a6de-f2bc562eaadb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946118250-172.17.0.6-1595324219998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-c4f89695-1f15-4e4c-9b20-b57f86458653,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-22b03c68-ed21-446d-8ab0-98aded0de105,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-7755e763-73f0-4e8a-a460-b8081b63e037,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-b7fb0324-faaa-4a78-91ef-bada43eaaf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-68c46aa0-8b8c-4a62-8079-07f5926acad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-0fd86621-90f0-45cc-ab25-dcb1ea2bd79e,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-817fb539-4182-439f-a4ed-e447e30b7cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-2177fbe1-0ca0-442b-a6de-f2bc562eaadb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231554839-172.17.0.6-1595324248921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34574,DS-2e648b78-a8c9-4ba8-bfc6-5a69d01293a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-4924014c-913f-45a0-9c06-0d4957dad324,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-5e494f5c-78ce-4983-82c9-ffc77dcba8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-e02bc667-2bfe-4344-9f69-a8dc063ce967,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-d38ff038-f978-44be-92ba-b24c46d7ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-898b5ed8-2be3-41b3-aaaf-3f798daaf427,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-14d6a797-d81a-4fc8-8d4f-c114a9b09435,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-6683ce0c-33b3-413b-8c9e-751a8f0960e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231554839-172.17.0.6-1595324248921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34574,DS-2e648b78-a8c9-4ba8-bfc6-5a69d01293a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-4924014c-913f-45a0-9c06-0d4957dad324,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-5e494f5c-78ce-4983-82c9-ffc77dcba8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-e02bc667-2bfe-4344-9f69-a8dc063ce967,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-d38ff038-f978-44be-92ba-b24c46d7ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-898b5ed8-2be3-41b3-aaaf-3f798daaf427,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-14d6a797-d81a-4fc8-8d4f-c114a9b09435,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-6683ce0c-33b3-413b-8c9e-751a8f0960e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109439218-172.17.0.6-1595324814080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44042,DS-ea9f3840-ca98-45ba-9472-8d46fb606671,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-ff58db1f-65e6-49d3-add1-a1b62278349d,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-0d94384e-360d-47eb-90a8-751e4c6642d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-902fda22-ec4a-4413-9bf9-c3d90b870579,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-60400b72-8408-4720-ab7e-1660f7a48492,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-ec2235b4-dae9-40a8-8815-2cd841292b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-b207f3a6-8a31-44a6-8e51-35045eac3a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-d2d863b7-3e12-4222-8d9e-750a3e9faaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109439218-172.17.0.6-1595324814080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44042,DS-ea9f3840-ca98-45ba-9472-8d46fb606671,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-ff58db1f-65e6-49d3-add1-a1b62278349d,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-0d94384e-360d-47eb-90a8-751e4c6642d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-902fda22-ec4a-4413-9bf9-c3d90b870579,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-60400b72-8408-4720-ab7e-1660f7a48492,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-ec2235b4-dae9-40a8-8815-2cd841292b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-b207f3a6-8a31-44a6-8e51-35045eac3a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-d2d863b7-3e12-4222-8d9e-750a3e9faaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220498965-172.17.0.6-1595324993850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43928,DS-8171da7d-950b-48a9-8371-a026442274ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-d06c1597-1c61-4b48-b079-699925e59872,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-91dc8588-4887-4896-bd99-835f9b68f37f,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-f175c14a-9b50-4ea4-a73b-b8f97ab4f323,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-8e6f151b-9881-4760-b8fb-3020717b961f,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-04896e5c-ca53-4d37-bc98-9b9d2ac92a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-6ebf4aeb-d5d5-4c56-a111-42f4ba5673f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-69218392-3581-44ce-9db0-0f71c8c9e43f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220498965-172.17.0.6-1595324993850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43928,DS-8171da7d-950b-48a9-8371-a026442274ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-d06c1597-1c61-4b48-b079-699925e59872,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-91dc8588-4887-4896-bd99-835f9b68f37f,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-f175c14a-9b50-4ea4-a73b-b8f97ab4f323,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-8e6f151b-9881-4760-b8fb-3020717b961f,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-04896e5c-ca53-4d37-bc98-9b9d2ac92a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-6ebf4aeb-d5d5-4c56-a111-42f4ba5673f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-69218392-3581-44ce-9db0-0f71c8c9e43f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464101550-172.17.0.6-1595325068279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-867820f9-2e4e-421c-9054-6e9c4ad516a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-76421ec0-1df1-4d5d-9934-e75df8a20c27,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-5dffcbc9-6681-4473-a51c-d125b3280fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-4f807969-1f59-4a60-aeb7-8f65ccd08993,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-2acce8b2-336a-4a2f-b5e7-ed99c16bd35f,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-da35cd5f-b567-46e6-86d0-31a7b27424c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-c2e0b881-364f-49cf-8ba4-c512fe859ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-fdf57c7b-dc01-4a0f-8cb4-b6b0c0be88b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464101550-172.17.0.6-1595325068279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-867820f9-2e4e-421c-9054-6e9c4ad516a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-76421ec0-1df1-4d5d-9934-e75df8a20c27,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-5dffcbc9-6681-4473-a51c-d125b3280fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-4f807969-1f59-4a60-aeb7-8f65ccd08993,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-2acce8b2-336a-4a2f-b5e7-ed99c16bd35f,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-da35cd5f-b567-46e6-86d0-31a7b27424c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-c2e0b881-364f-49cf-8ba4-c512fe859ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-fdf57c7b-dc01-4a0f-8cb4-b6b0c0be88b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259089595-172.17.0.6-1595325515912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-f96e037f-e88a-455e-97f2-b707ea6db13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-0d9f0251-4b0d-4c3c-9cd8-8d3909c2c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-044b69de-cc04-4928-95c4-f5dd77cbe686,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-cba48d73-775c-40f5-bce9-cb26dbd7a845,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-48957eb5-1a63-4f42-a22d-ccebe84f7cad,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-81edd446-bc9a-4bd7-85a9-ef89cecbd96e,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-bf39035c-cccf-4509-adad-fbf1208aba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-e2db6987-1793-4940-a301-c71516b7e57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259089595-172.17.0.6-1595325515912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-f96e037f-e88a-455e-97f2-b707ea6db13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-0d9f0251-4b0d-4c3c-9cd8-8d3909c2c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-044b69de-cc04-4928-95c4-f5dd77cbe686,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-cba48d73-775c-40f5-bce9-cb26dbd7a845,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-48957eb5-1a63-4f42-a22d-ccebe84f7cad,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-81edd446-bc9a-4bd7-85a9-ef89cecbd96e,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-bf39035c-cccf-4509-adad-fbf1208aba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-e2db6987-1793-4940-a301-c71516b7e57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20604514-172.17.0.6-1595325832550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-b1c8c8f7-45e3-4065-83e7-3b39c29020cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-ffa93905-8287-4f0a-b857-19a19bfe7f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-c1963ffa-3679-4ab0-8ed1-53cc0d1ef8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-98c847c3-b7ed-44e4-8457-661690da1714,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-81bc3609-f4c6-4934-9d7e-97c40c5e8850,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-b4c49e1a-fdbb-4855-9a00-ab17550b2bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-cb599d1d-7608-4ad7-bd11-73435febe1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-1f2b1794-ddfa-44c1-ac54-bff8847a5fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20604514-172.17.0.6-1595325832550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-b1c8c8f7-45e3-4065-83e7-3b39c29020cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-ffa93905-8287-4f0a-b857-19a19bfe7f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-c1963ffa-3679-4ab0-8ed1-53cc0d1ef8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-98c847c3-b7ed-44e4-8457-661690da1714,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-81bc3609-f4c6-4934-9d7e-97c40c5e8850,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-b4c49e1a-fdbb-4855-9a00-ab17550b2bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-cb599d1d-7608-4ad7-bd11-73435febe1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-1f2b1794-ddfa-44c1-ac54-bff8847a5fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972433310-172.17.0.6-1595325868573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-a0e98086-c21c-48b4-a40b-1a55f2ee6452,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-d5485932-0fc7-49d1-9ddd-135ebece26a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-0f49585c-d92c-4e31-a423-b93c6467e346,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-066c6a1e-8311-4338-9466-7b09f46ab530,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-84406c90-6f0a-4fdd-8348-18aec9d6f5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-f4d6677f-e869-460a-a4d0-36202a49de28,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-ad4e64dd-5518-4624-b86d-224b3f7a9eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-cadeb7f1-7d2b-437c-abb9-4f20321f1701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972433310-172.17.0.6-1595325868573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-a0e98086-c21c-48b4-a40b-1a55f2ee6452,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-d5485932-0fc7-49d1-9ddd-135ebece26a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-0f49585c-d92c-4e31-a423-b93c6467e346,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-066c6a1e-8311-4338-9466-7b09f46ab530,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-84406c90-6f0a-4fdd-8348-18aec9d6f5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-f4d6677f-e869-460a-a4d0-36202a49de28,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-ad4e64dd-5518-4624-b86d-224b3f7a9eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-cadeb7f1-7d2b-437c-abb9-4f20321f1701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280398349-172.17.0.6-1595326245267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38602,DS-52ccfde2-9a42-46d8-ac01-61d33894681d,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-e45c857c-1556-4ca3-ab1b-648ecdffa0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-9534d992-0032-4a8f-a50e-08cc2f85fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-2abad368-5ba2-465f-bc19-83e93d909c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-d19de4ad-d136-4329-9186-b508ba35a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-0e1c2863-f1a4-46d1-8863-09c68291efd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-e2520532-ec0c-4876-98d7-7e6565086641,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-7e76de77-cf25-4036-97d1-68afba35c105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280398349-172.17.0.6-1595326245267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38602,DS-52ccfde2-9a42-46d8-ac01-61d33894681d,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-e45c857c-1556-4ca3-ab1b-648ecdffa0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-9534d992-0032-4a8f-a50e-08cc2f85fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-2abad368-5ba2-465f-bc19-83e93d909c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-d19de4ad-d136-4329-9186-b508ba35a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-0e1c2863-f1a4-46d1-8863-09c68291efd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-e2520532-ec0c-4876-98d7-7e6565086641,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-7e76de77-cf25-4036-97d1-68afba35c105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057457576-172.17.0.6-1595326352893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32805,DS-a9fcac65-1fb5-4454-b5ba-3c3414abaf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-09be2973-1a64-48fb-9101-d2e25d86c737,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-3d2b9478-648f-4896-b717-0465423e7f19,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-3a62af80-164b-4b67-b860-ccbba1733b95,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-d31723f8-837f-4e0e-8f91-02f52147bce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-9a1bbbf5-9b03-48c6-8922-2fa42e39fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-4b4fd260-e377-48d7-a08a-14fc3fb21a21,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-da52bf97-8c56-48d9-bdc6-817ae8102b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057457576-172.17.0.6-1595326352893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32805,DS-a9fcac65-1fb5-4454-b5ba-3c3414abaf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-09be2973-1a64-48fb-9101-d2e25d86c737,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-3d2b9478-648f-4896-b717-0465423e7f19,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-3a62af80-164b-4b67-b860-ccbba1733b95,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-d31723f8-837f-4e0e-8f91-02f52147bce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-9a1bbbf5-9b03-48c6-8922-2fa42e39fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-4b4fd260-e377-48d7-a08a-14fc3fb21a21,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-da52bf97-8c56-48d9-bdc6-817ae8102b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728598927-172.17.0.6-1595327073872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42560,DS-cd764250-cb79-4382-a540-2f766c17b173,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-d62a8db3-6699-4daf-975f-e45f2381b1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-6b812c51-e34a-4e95-8701-60c66d8d468c,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-7a391e12-e2f8-406f-bbaf-ce39f1bfe835,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-7dc31f98-bb9f-4d95-a627-5a96f3a60e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-d3f16497-ee9d-43a7-a116-bea70eb3f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-a1d89264-5392-4b01-9392-75762ebaa490,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-c509d4a8-5e4e-4607-9636-cf41abbb6b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728598927-172.17.0.6-1595327073872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42560,DS-cd764250-cb79-4382-a540-2f766c17b173,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-d62a8db3-6699-4daf-975f-e45f2381b1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-6b812c51-e34a-4e95-8701-60c66d8d468c,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-7a391e12-e2f8-406f-bbaf-ce39f1bfe835,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-7dc31f98-bb9f-4d95-a627-5a96f3a60e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-d3f16497-ee9d-43a7-a116-bea70eb3f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-a1d89264-5392-4b01-9392-75762ebaa490,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-c509d4a8-5e4e-4607-9636-cf41abbb6b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432850057-172.17.0.6-1595327489457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-b3a784e8-b0bc-4c48-aa30-1c90e7794013,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-157f1319-4065-4a4b-a7cb-26af9e9e596e,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-66d22c1f-4c27-4443-b8b7-82ec5ae5fa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-0f666749-b096-4512-8fe2-d7a269a52ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-5e59dc59-be0f-4ab4-a441-a4aad69dd06c,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d42b90fa-b22d-41bc-a020-4bf164629ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-c3fc9e8e-95b1-4776-a222-82e874ac7469,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-696a7219-10b6-4683-bc8c-baa3e75a9a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432850057-172.17.0.6-1595327489457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-b3a784e8-b0bc-4c48-aa30-1c90e7794013,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-157f1319-4065-4a4b-a7cb-26af9e9e596e,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-66d22c1f-4c27-4443-b8b7-82ec5ae5fa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-0f666749-b096-4512-8fe2-d7a269a52ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-5e59dc59-be0f-4ab4-a441-a4aad69dd06c,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d42b90fa-b22d-41bc-a020-4bf164629ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-c3fc9e8e-95b1-4776-a222-82e874ac7469,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-696a7219-10b6-4683-bc8c-baa3e75a9a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878913580-172.17.0.6-1595327715127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35626,DS-34899c3e-5b0f-47ef-bc7c-9daf67b53744,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-1d083e33-0e15-4ba6-aabc-502e88ed8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-e21b34df-30b7-408f-8a1e-48248874b186,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-a47daf22-65ee-47eb-b477-09ce321312a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-246787c2-c413-49df-9322-03b54b0b26b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-efe82735-3f1a-43c1-ac55-5bff5405b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-3b5146cc-b502-4e55-8070-f64abfc84eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-3ce74089-0a9a-4005-979a-f122ae85df20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878913580-172.17.0.6-1595327715127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35626,DS-34899c3e-5b0f-47ef-bc7c-9daf67b53744,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-1d083e33-0e15-4ba6-aabc-502e88ed8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-e21b34df-30b7-408f-8a1e-48248874b186,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-a47daf22-65ee-47eb-b477-09ce321312a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-246787c2-c413-49df-9322-03b54b0b26b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-efe82735-3f1a-43c1-ac55-5bff5405b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-3b5146cc-b502-4e55-8070-f64abfc84eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-3ce74089-0a9a-4005-979a-f122ae85df20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5632
