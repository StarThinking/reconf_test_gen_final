reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419786363-172.17.0.18-1595364840515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38056,DS-8b0cec67-aca5-41d5-a3f9-dcbfa7bf17b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-3a223c92-7e7c-42eb-90d8-e72eef956bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-d6f14307-95ae-439b-83cf-e0a78b48d8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-0156003a-3a7e-4fc8-a4b8-80f029ee4bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-93552704-0668-4473-813b-61e0c33034d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-7a26bf69-b968-4fa4-b014-badc1dfd55f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-a6cf3e84-f97c-4733-9520-e9868adc8ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-dfb43a5f-5ee7-4e4f-83c0-4fecb71f921a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419786363-172.17.0.18-1595364840515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38056,DS-8b0cec67-aca5-41d5-a3f9-dcbfa7bf17b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-3a223c92-7e7c-42eb-90d8-e72eef956bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-d6f14307-95ae-439b-83cf-e0a78b48d8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-0156003a-3a7e-4fc8-a4b8-80f029ee4bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-93552704-0668-4473-813b-61e0c33034d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-7a26bf69-b968-4fa4-b014-badc1dfd55f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-a6cf3e84-f97c-4733-9520-e9868adc8ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-dfb43a5f-5ee7-4e4f-83c0-4fecb71f921a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035530400-172.17.0.18-1595365137007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41793,DS-c0b0aa2e-b4c6-4be1-b6ed-e141c5cc4b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-893e3363-f39e-4e98-87dd-8fc9d718ae75,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-ec4347fd-27bb-4415-b096-9691f2837bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-81d7f0fb-4b9e-4049-9304-b4044bacc097,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-7926af9a-db1c-4785-b21c-032235e6fd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-573d5223-98dc-4934-b551-b367360d94e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-aacc0b94-1dbe-48a5-a990-6c33d56a82ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-9f2e92db-4c43-458d-8a92-f72fd3fe1072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035530400-172.17.0.18-1595365137007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41793,DS-c0b0aa2e-b4c6-4be1-b6ed-e141c5cc4b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-893e3363-f39e-4e98-87dd-8fc9d718ae75,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-ec4347fd-27bb-4415-b096-9691f2837bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-81d7f0fb-4b9e-4049-9304-b4044bacc097,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-7926af9a-db1c-4785-b21c-032235e6fd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-573d5223-98dc-4934-b551-b367360d94e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-aacc0b94-1dbe-48a5-a990-6c33d56a82ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-9f2e92db-4c43-458d-8a92-f72fd3fe1072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363326890-172.17.0.18-1595365455117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40284,DS-e877cf2d-5471-431c-a858-15cd42bdb80e,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-176fa411-9605-43ca-b8dc-e3f9c2f823d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-646a56f4-1d95-45fa-8f94-3e72bad6096e,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-9add3948-a3c0-41b9-b99f-ef57038912da,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-8300b7af-8914-4bfc-aec5-0538eed6b483,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-ff1b26a5-8d06-422e-bb32-775f0d4a5365,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-eaa84ac1-f7af-439c-b153-544385d45efa,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-116c4ea0-6107-4563-9ade-3f6903f9cf6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363326890-172.17.0.18-1595365455117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40284,DS-e877cf2d-5471-431c-a858-15cd42bdb80e,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-176fa411-9605-43ca-b8dc-e3f9c2f823d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-646a56f4-1d95-45fa-8f94-3e72bad6096e,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-9add3948-a3c0-41b9-b99f-ef57038912da,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-8300b7af-8914-4bfc-aec5-0538eed6b483,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-ff1b26a5-8d06-422e-bb32-775f0d4a5365,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-eaa84ac1-f7af-439c-b153-544385d45efa,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-116c4ea0-6107-4563-9ade-3f6903f9cf6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815155462-172.17.0.18-1595365544801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40432,DS-069b26d3-89b8-4931-8836-8b6ece763fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-614310f5-7674-4507-a8b3-c175991658fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-6091acc7-7cbe-40f1-838c-4ae40ea4573b,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-23a0c0fe-76d2-4e47-8f4c-bbb10e2e63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-1771dc48-cae3-4858-a333-41691240880b,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-90d7e155-2f0a-44f1-b3eb-a126a58878b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-0aed9951-c088-477f-8277-eeaed46373c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-9a9d5554-ed07-4e5b-9a69-1b9ec2e8c09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815155462-172.17.0.18-1595365544801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40432,DS-069b26d3-89b8-4931-8836-8b6ece763fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-614310f5-7674-4507-a8b3-c175991658fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-6091acc7-7cbe-40f1-838c-4ae40ea4573b,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-23a0c0fe-76d2-4e47-8f4c-bbb10e2e63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-1771dc48-cae3-4858-a333-41691240880b,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-90d7e155-2f0a-44f1-b3eb-a126a58878b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-0aed9951-c088-477f-8277-eeaed46373c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-9a9d5554-ed07-4e5b-9a69-1b9ec2e8c09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035579612-172.17.0.18-1595366638518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35273,DS-45d3a089-e3a6-43cb-bc1a-ec751a5ca3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-4e68d2f2-beda-4ea3-bac9-a183c446cd26,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-e85ad105-e5a2-46cd-bb21-304742f9d9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-ee6f36c3-e6e5-4ff9-9e83-b39813358b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-64fde5a8-c546-4440-8d8e-a1ca525b61b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-176863ba-5695-43e6-9d15-f95854600625,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-1543a713-666c-452f-843a-6502ab55d2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-2703f748-f6d6-48ec-a020-551994726fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035579612-172.17.0.18-1595366638518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35273,DS-45d3a089-e3a6-43cb-bc1a-ec751a5ca3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-4e68d2f2-beda-4ea3-bac9-a183c446cd26,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-e85ad105-e5a2-46cd-bb21-304742f9d9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-ee6f36c3-e6e5-4ff9-9e83-b39813358b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-64fde5a8-c546-4440-8d8e-a1ca525b61b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-176863ba-5695-43e6-9d15-f95854600625,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-1543a713-666c-452f-843a-6502ab55d2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-2703f748-f6d6-48ec-a020-551994726fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947442569-172.17.0.18-1595366684896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-757a4094-60c8-4a38-bc27-cbffe915fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-76efee17-de28-42e0-ab0f-79edd6dab5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-e89872a1-46ec-469b-95c4-536e81b7ec55,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-78b6878c-845d-403e-bba0-b5279e999dac,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-cc99678a-58da-4977-a5d0-654d37a30888,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-59eb1743-7609-44d1-b3dd-d136f8b0ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-789a74c5-abcf-48e7-bbf6-f02fd36842fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-aa28da57-4bf1-4899-a931-44f1fb109100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947442569-172.17.0.18-1595366684896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-757a4094-60c8-4a38-bc27-cbffe915fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-76efee17-de28-42e0-ab0f-79edd6dab5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-e89872a1-46ec-469b-95c4-536e81b7ec55,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-78b6878c-845d-403e-bba0-b5279e999dac,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-cc99678a-58da-4977-a5d0-654d37a30888,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-59eb1743-7609-44d1-b3dd-d136f8b0ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-789a74c5-abcf-48e7-bbf6-f02fd36842fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-aa28da57-4bf1-4899-a931-44f1fb109100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517989672-172.17.0.18-1595366779540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39202,DS-d045243a-95b8-4b2c-bab9-d3b3c037e22d,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-0955617a-536f-488b-a1d6-9a88ed172469,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-75636dbb-eac4-46bb-b48e-b80b0027006d,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-16b9f7f9-c814-43e4-84c4-c29b2c91d411,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-0a094892-f815-4cea-ad43-c90d278420ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-7740e2a4-8ef0-449e-92c2-38849490b006,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-cb957d6e-9349-4391-a723-5ea914d0d748,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-e6fe4b39-d1e2-4172-a8f1-d65a8e9cf552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517989672-172.17.0.18-1595366779540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39202,DS-d045243a-95b8-4b2c-bab9-d3b3c037e22d,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-0955617a-536f-488b-a1d6-9a88ed172469,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-75636dbb-eac4-46bb-b48e-b80b0027006d,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-16b9f7f9-c814-43e4-84c4-c29b2c91d411,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-0a094892-f815-4cea-ad43-c90d278420ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-7740e2a4-8ef0-449e-92c2-38849490b006,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-cb957d6e-9349-4391-a723-5ea914d0d748,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-e6fe4b39-d1e2-4172-a8f1-d65a8e9cf552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073316644-172.17.0.18-1595366816861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-e2b1b586-715f-4308-a718-ee2ccb4f2f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-21b09bad-463b-4c4f-a599-bc11345eea84,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-db21d658-f794-4def-9515-cd0e909edcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-d056f292-a90d-4899-81a2-babc1f289f04,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-2cc9acc5-7c0e-4ca2-ae9e-39cac538c622,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-b2b06140-be81-4b8a-b574-3a97d608a2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-8e06393d-473a-4878-ac6d-29f42f79fbef,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-d79868ad-d18f-4967-85fe-61911316e0df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073316644-172.17.0.18-1595366816861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-e2b1b586-715f-4308-a718-ee2ccb4f2f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-21b09bad-463b-4c4f-a599-bc11345eea84,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-db21d658-f794-4def-9515-cd0e909edcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-d056f292-a90d-4899-81a2-babc1f289f04,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-2cc9acc5-7c0e-4ca2-ae9e-39cac538c622,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-b2b06140-be81-4b8a-b574-3a97d608a2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-8e06393d-473a-4878-ac6d-29f42f79fbef,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-d79868ad-d18f-4967-85fe-61911316e0df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912141987-172.17.0.18-1595366909542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-ba457f8d-f7d8-4e09-a307-3a030629f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-793e104d-2ae2-4bf3-91f1-5a91fd7011ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-f2b4bd81-32e8-4df3-9b90-24f64eb0d455,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-618c60c5-5eb0-4fec-a7cc-4490b7640414,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-93cda57b-76a6-4a68-a108-9f529fbe830e,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-4a1432c2-84c3-4add-9dff-3866c46aeaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-bc49ebc4-e127-4218-8109-9bb0a6f1f355,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-cace2abe-8803-4a67-a2ee-07b1203181ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912141987-172.17.0.18-1595366909542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-ba457f8d-f7d8-4e09-a307-3a030629f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-793e104d-2ae2-4bf3-91f1-5a91fd7011ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-f2b4bd81-32e8-4df3-9b90-24f64eb0d455,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-618c60c5-5eb0-4fec-a7cc-4490b7640414,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-93cda57b-76a6-4a68-a108-9f529fbe830e,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-4a1432c2-84c3-4add-9dff-3866c46aeaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-bc49ebc4-e127-4218-8109-9bb0a6f1f355,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-cace2abe-8803-4a67-a2ee-07b1203181ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146006783-172.17.0.18-1595366984991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-49dfae62-7f4c-4f8d-878a-e34665ac7701,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-a3321fc9-5a9c-49a5-80c0-67d2f7cf960e,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-695cdb70-8786-4130-ba87-28041ee58a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-c59e435e-7ad7-48e7-abc0-9844a832ce01,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-dcc2e0c5-a72d-45ee-a717-21a02213804d,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-07ce7f03-3306-4b70-b81e-7e3091ef1bee,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-7cf08945-0e3d-44a8-ba78-a576608330a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-d3d9d7d5-7fb9-49b4-b214-28f10b8c9af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146006783-172.17.0.18-1595366984991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-49dfae62-7f4c-4f8d-878a-e34665ac7701,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-a3321fc9-5a9c-49a5-80c0-67d2f7cf960e,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-695cdb70-8786-4130-ba87-28041ee58a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-c59e435e-7ad7-48e7-abc0-9844a832ce01,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-dcc2e0c5-a72d-45ee-a717-21a02213804d,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-07ce7f03-3306-4b70-b81e-7e3091ef1bee,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-7cf08945-0e3d-44a8-ba78-a576608330a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-d3d9d7d5-7fb9-49b4-b214-28f10b8c9af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421677172-172.17.0.18-1595367480708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41941,DS-05d8a2ec-3a7a-4369-9c3b-9dd4b6700f30,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-a8c9f2cb-9f89-4933-bb57-5e5731295827,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-bd7c4e7b-8fab-41c9-9532-537f2a5dda2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-f40961b6-ff26-40ec-a66f-cdd60c351e16,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-bce2117d-8075-4756-8c55-84809a3c38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-e06dff17-d2df-42d1-a8ae-c688598fcd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-539de224-fc45-44e7-9e4e-8b4b20063ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-f7c156e6-9d2a-450b-837e-6375bb9e72e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421677172-172.17.0.18-1595367480708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41941,DS-05d8a2ec-3a7a-4369-9c3b-9dd4b6700f30,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-a8c9f2cb-9f89-4933-bb57-5e5731295827,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-bd7c4e7b-8fab-41c9-9532-537f2a5dda2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-f40961b6-ff26-40ec-a66f-cdd60c351e16,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-bce2117d-8075-4756-8c55-84809a3c38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-e06dff17-d2df-42d1-a8ae-c688598fcd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-539de224-fc45-44e7-9e4e-8b4b20063ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-f7c156e6-9d2a-450b-837e-6375bb9e72e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904220665-172.17.0.18-1595367870721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39503,DS-a40bfc69-7922-49e9-a5b6-7e81e10584e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-38d7a9f4-0bdc-4841-b21c-a7fd979c2063,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-39db2496-dd12-44bc-bd94-a706e95ac8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-20870936-50dc-4169-a0fa-ea84604b7931,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-2a99e129-afe6-44f4-b01a-03f3e9c6cc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-b5017632-4eab-4fdc-97de-94684b428ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-1e147145-ac97-473a-8f7e-5c27cf031987,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-b24e110d-7208-493d-9438-d012997abd62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904220665-172.17.0.18-1595367870721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39503,DS-a40bfc69-7922-49e9-a5b6-7e81e10584e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-38d7a9f4-0bdc-4841-b21c-a7fd979c2063,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-39db2496-dd12-44bc-bd94-a706e95ac8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-20870936-50dc-4169-a0fa-ea84604b7931,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-2a99e129-afe6-44f4-b01a-03f3e9c6cc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-b5017632-4eab-4fdc-97de-94684b428ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-1e147145-ac97-473a-8f7e-5c27cf031987,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-b24e110d-7208-493d-9438-d012997abd62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216593216-172.17.0.18-1595368312141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-25836000-a28a-41d3-9611-24f42adbe09d,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-e35b57f1-afae-4879-bf3d-6355ae6e5ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-ea2e7d54-0f5c-4acd-bab5-953eddd1f738,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-2df14e8f-b07c-49e5-9d5b-5614df9fb446,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-35b40ec4-f41f-4d4b-a61c-c8c41aee8542,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-e63d503e-89cc-4f70-97ea-ab2c65464d98,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-ee5d9e38-753c-476e-83f4-f88a21dd921b,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-e12c2c93-0b31-4e6d-92e7-06c68db80f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216593216-172.17.0.18-1595368312141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-25836000-a28a-41d3-9611-24f42adbe09d,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-e35b57f1-afae-4879-bf3d-6355ae6e5ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-ea2e7d54-0f5c-4acd-bab5-953eddd1f738,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-2df14e8f-b07c-49e5-9d5b-5614df9fb446,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-35b40ec4-f41f-4d4b-a61c-c8c41aee8542,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-e63d503e-89cc-4f70-97ea-ab2c65464d98,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-ee5d9e38-753c-476e-83f4-f88a21dd921b,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-e12c2c93-0b31-4e6d-92e7-06c68db80f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314227367-172.17.0.18-1595368858577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-9909ba3e-1be3-45d2-998f-6493e81c293d,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-63e5be35-4856-4abb-b9ce-768e68cc21a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-d9c410d2-38d7-46bc-a376-87c4115456a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-704cc517-65bc-4617-947b-3b947c993dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-e60cc23b-7a5f-44a1-a8e5-719c750a5889,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-56050ec2-1edd-4cfc-905d-6cee738cd3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-4af07511-383c-495a-8362-7b3cb4ccaab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-a4b7a440-f065-42aa-aa00-5e1b3b7501af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314227367-172.17.0.18-1595368858577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-9909ba3e-1be3-45d2-998f-6493e81c293d,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-63e5be35-4856-4abb-b9ce-768e68cc21a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-d9c410d2-38d7-46bc-a376-87c4115456a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-704cc517-65bc-4617-947b-3b947c993dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-e60cc23b-7a5f-44a1-a8e5-719c750a5889,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-56050ec2-1edd-4cfc-905d-6cee738cd3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-4af07511-383c-495a-8362-7b3cb4ccaab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-a4b7a440-f065-42aa-aa00-5e1b3b7501af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157921640-172.17.0.18-1595369134183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-bb1facef-d216-4f4b-a630-ea14eac407c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-a502c711-23f3-4275-97cb-64ce6e2d52bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-1bcd4142-4804-41f9-be2c-16914f825590,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-9f483b0d-40c8-4a2d-ad03-3760d1037b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-f6cbf233-4d51-49b6-8f53-0b475c9239a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-c648044e-2f77-40a3-949c-55945322e81f,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-bf2ea58e-5b64-482b-bde7-aa253353bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-322e1159-e4e4-4ed2-b2d8-9051adba77bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157921640-172.17.0.18-1595369134183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-bb1facef-d216-4f4b-a630-ea14eac407c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-a502c711-23f3-4275-97cb-64ce6e2d52bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-1bcd4142-4804-41f9-be2c-16914f825590,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-9f483b0d-40c8-4a2d-ad03-3760d1037b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-f6cbf233-4d51-49b6-8f53-0b475c9239a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-c648044e-2f77-40a3-949c-55945322e81f,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-bf2ea58e-5b64-482b-bde7-aa253353bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-322e1159-e4e4-4ed2-b2d8-9051adba77bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732581356-172.17.0.18-1595369222375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46259,DS-f38b5e49-c6da-478f-a2cb-494760fe0f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-71c9741d-ed28-40e8-b57d-fc87c161a344,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-48f687f3-4bcf-4c34-9a84-2db4964643d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-94c960b1-c27f-4d69-90bd-850e805775c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-6faf5a49-3914-4ae4-9262-654360f9dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-e0bd823d-1a2e-4367-beab-2ffcd6cae96a,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-a1b8e172-29e7-4054-9819-70ee080e4358,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-0d895e93-922a-42ef-9fb5-8243308c0954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732581356-172.17.0.18-1595369222375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46259,DS-f38b5e49-c6da-478f-a2cb-494760fe0f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-71c9741d-ed28-40e8-b57d-fc87c161a344,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-48f687f3-4bcf-4c34-9a84-2db4964643d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-94c960b1-c27f-4d69-90bd-850e805775c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-6faf5a49-3914-4ae4-9262-654360f9dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-e0bd823d-1a2e-4367-beab-2ffcd6cae96a,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-a1b8e172-29e7-4054-9819-70ee080e4358,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-0d895e93-922a-42ef-9fb5-8243308c0954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872157538-172.17.0.18-1595369447048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-74dfdb6f-78b8-4864-a4cb-d009ee94ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-89e47ba5-d252-4a9c-a28c-968d0704c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-212b8452-550b-4c7b-830f-63ba97f66336,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-17494b4b-8473-4ac1-a8cb-12807d57d5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-a77775f1-ad17-4707-92e1-f18e407c9598,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-2775dd98-ad14-47db-9165-26aa3dfe533f,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-0ceb3838-676e-45d4-9f54-e1475b991ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-8195fc87-38f8-46ac-b111-bc594aa84f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872157538-172.17.0.18-1595369447048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-74dfdb6f-78b8-4864-a4cb-d009ee94ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-89e47ba5-d252-4a9c-a28c-968d0704c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-212b8452-550b-4c7b-830f-63ba97f66336,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-17494b4b-8473-4ac1-a8cb-12807d57d5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-a77775f1-ad17-4707-92e1-f18e407c9598,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-2775dd98-ad14-47db-9165-26aa3dfe533f,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-0ceb3838-676e-45d4-9f54-e1475b991ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-8195fc87-38f8-46ac-b111-bc594aa84f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954827194-172.17.0.18-1595370321796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-cbc995c3-2723-4a0c-bea0-bf510f504d66,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-5d4ad8c1-79db-4856-9569-3c25acd3657a,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-5497108d-35d7-42ab-a7f9-c10a1b481369,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-7ec469bf-35cb-476b-804e-dcde3e92b1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-c474c857-09e0-4aa9-875a-516f16f5775f,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-d742913e-810f-4248-b26a-a3a712b969d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-cbaf39ca-34c9-4b57-9055-9e4da4952300,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-97558c06-8a67-4aa7-bf8e-57b48bc0ed86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954827194-172.17.0.18-1595370321796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-cbc995c3-2723-4a0c-bea0-bf510f504d66,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-5d4ad8c1-79db-4856-9569-3c25acd3657a,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-5497108d-35d7-42ab-a7f9-c10a1b481369,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-7ec469bf-35cb-476b-804e-dcde3e92b1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-c474c857-09e0-4aa9-875a-516f16f5775f,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-d742913e-810f-4248-b26a-a3a712b969d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-cbaf39ca-34c9-4b57-9055-9e4da4952300,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-97558c06-8a67-4aa7-bf8e-57b48bc0ed86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547202725-172.17.0.18-1595370879500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-f726e0c4-d32a-4bb4-9288-e9f674d15efb,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-6e352be8-2d4a-4a97-9bab-bc8dbffad362,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-00c49191-4c03-4496-882c-4474e0fbe0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-996c1296-4a7e-49c1-943c-23b2f30b5ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-f937f453-cdc7-47a7-aef8-24f32df2421c,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-cc386afe-9cb7-4110-a46f-ce520cbd1730,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-f66be654-0f39-441e-bbf2-d52ce02bf8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-e629d22e-229e-4a27-8054-d1c3946fcc0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547202725-172.17.0.18-1595370879500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-f726e0c4-d32a-4bb4-9288-e9f674d15efb,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-6e352be8-2d4a-4a97-9bab-bc8dbffad362,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-00c49191-4c03-4496-882c-4474e0fbe0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-996c1296-4a7e-49c1-943c-23b2f30b5ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-f937f453-cdc7-47a7-aef8-24f32df2421c,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-cc386afe-9cb7-4110-a46f-ce520cbd1730,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-f66be654-0f39-441e-bbf2-d52ce02bf8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-e629d22e-229e-4a27-8054-d1c3946fcc0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6739
