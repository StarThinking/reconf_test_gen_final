reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977066451-172.17.0.21-1595312128904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40168,DS-d89e17b2-d1f2-4c55-a87d-10bd44d72808,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-ab499e4b-c3ac-470a-874b-2213c713bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-4205e5e0-f912-452c-8c3b-b7f5e8865d36,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-e0d2003f-9842-4bf6-b66c-4888dd941226,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-4ba573f6-c03f-44a0-a6c0-5ca372a3e986,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-a177e79a-324d-4c04-97ca-9e9b81621da0,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-a6e21945-81c6-4630-a7d9-f8ff835f4a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-d1bcf8f5-92cc-414d-937d-73f11a44d746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977066451-172.17.0.21-1595312128904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40168,DS-d89e17b2-d1f2-4c55-a87d-10bd44d72808,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-ab499e4b-c3ac-470a-874b-2213c713bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-4205e5e0-f912-452c-8c3b-b7f5e8865d36,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-e0d2003f-9842-4bf6-b66c-4888dd941226,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-4ba573f6-c03f-44a0-a6c0-5ca372a3e986,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-a177e79a-324d-4c04-97ca-9e9b81621da0,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-a6e21945-81c6-4630-a7d9-f8ff835f4a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-d1bcf8f5-92cc-414d-937d-73f11a44d746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026736835-172.17.0.21-1595312170000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36650,DS-d926e0aa-a82d-436d-bd07-e0a9b5472f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-ee121ac7-b4d3-4c40-8d7d-e383edbe62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-c51d87c9-bdfe-401f-be86-1318b1a66ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-a034a9f3-d347-4740-80b2-9c1939ee6a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-24339f4a-8c22-4ade-88d2-c6faae5c9a51,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-091b2606-0973-42dc-a9fc-77999ae6559d,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-64ccbe05-bfae-48fd-a9f1-31ff5b91bf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-64148197-8474-41d9-9b67-af8e1c8f512f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026736835-172.17.0.21-1595312170000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36650,DS-d926e0aa-a82d-436d-bd07-e0a9b5472f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-ee121ac7-b4d3-4c40-8d7d-e383edbe62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-c51d87c9-bdfe-401f-be86-1318b1a66ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-a034a9f3-d347-4740-80b2-9c1939ee6a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-24339f4a-8c22-4ade-88d2-c6faae5c9a51,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-091b2606-0973-42dc-a9fc-77999ae6559d,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-64ccbe05-bfae-48fd-a9f1-31ff5b91bf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-64148197-8474-41d9-9b67-af8e1c8f512f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896630107-172.17.0.21-1595312447396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43485,DS-23303cec-8e3e-4715-b93a-cbcad86a1b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-0f07548c-b98b-42c2-b097-c4bf37d02014,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-99d7ce63-6aba-4fb9-9ca5-4b28fcf9349b,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-444de23f-73f1-4e48-8a62-4f99ffe95308,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-627a212e-00a2-494b-975d-dc0c169c06e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-eb63025d-2f59-40c8-bf51-308d8bb8da7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-19219f38-ee5a-427c-b924-2a4ff483e24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-69fcfc5c-62ae-4fac-bc8b-931bea32a5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896630107-172.17.0.21-1595312447396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43485,DS-23303cec-8e3e-4715-b93a-cbcad86a1b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-0f07548c-b98b-42c2-b097-c4bf37d02014,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-99d7ce63-6aba-4fb9-9ca5-4b28fcf9349b,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-444de23f-73f1-4e48-8a62-4f99ffe95308,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-627a212e-00a2-494b-975d-dc0c169c06e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-eb63025d-2f59-40c8-bf51-308d8bb8da7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-19219f38-ee5a-427c-b924-2a4ff483e24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-69fcfc5c-62ae-4fac-bc8b-931bea32a5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-187213443-172.17.0.21-1595312579061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46211,DS-700a325b-2ea3-4c35-89e2-ea825dd108e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-cf9f0b6f-6f42-4b0d-915f-ca0e0915ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-d99b7c65-76e9-4672-a36c-87e918d55ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-8478fcf2-f507-40f4-9369-d6c843ab6f37,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-e860ff7c-f7ab-444d-a1ab-fb19b4bf9636,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-3251d1e1-61a0-45bd-9d6b-462a68e63f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-4da7d797-d733-48ba-ac0e-4680f2a5c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-0f4fc608-5927-4150-ad9f-850ae74b1f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-187213443-172.17.0.21-1595312579061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46211,DS-700a325b-2ea3-4c35-89e2-ea825dd108e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-cf9f0b6f-6f42-4b0d-915f-ca0e0915ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-d99b7c65-76e9-4672-a36c-87e918d55ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-8478fcf2-f507-40f4-9369-d6c843ab6f37,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-e860ff7c-f7ab-444d-a1ab-fb19b4bf9636,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-3251d1e1-61a0-45bd-9d6b-462a68e63f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-4da7d797-d733-48ba-ac0e-4680f2a5c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-0f4fc608-5927-4150-ad9f-850ae74b1f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050003320-172.17.0.21-1595313317990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-bfaa41d5-0f54-40e0-aa70-5458b40e0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-8d60a484-a14d-48f0-947f-aab2b967361b,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-90c245ae-2b04-4246-8b23-3337ae7b0783,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-f4b1f611-008a-47a6-86c3-50fc5db42543,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-5b70a3bf-8cae-496f-bbe5-418e39d95654,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-1e0a0b75-cda4-48cb-bc43-3131c81e42d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-5fbd70ea-286a-457a-9388-a664c6348da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-fd0c3b0c-c0fc-4fc2-a905-7a784b62a821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050003320-172.17.0.21-1595313317990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-bfaa41d5-0f54-40e0-aa70-5458b40e0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-8d60a484-a14d-48f0-947f-aab2b967361b,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-90c245ae-2b04-4246-8b23-3337ae7b0783,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-f4b1f611-008a-47a6-86c3-50fc5db42543,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-5b70a3bf-8cae-496f-bbe5-418e39d95654,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-1e0a0b75-cda4-48cb-bc43-3131c81e42d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-5fbd70ea-286a-457a-9388-a664c6348da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-fd0c3b0c-c0fc-4fc2-a905-7a784b62a821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433323825-172.17.0.21-1595313534508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37793,DS-aa90d8c5-87ad-4efe-8456-bff27f6f1876,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-c0985b1a-7b1f-4d3d-bc59-cb314ca8b372,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-1b309736-a82f-473e-9ec4-5398eddff542,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-7093c89b-5c41-4d30-8a0f-df4047d4422f,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-fedd44bb-a29e-4f27-a7e5-9f4976d6b750,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-0bb457b2-a426-4232-8ecf-d1c4fdc8cb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-d7f56e3d-ded4-4208-a3c9-b3fdfe9c30f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-e3916402-77b2-4277-bbac-d3cf1fd46f9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433323825-172.17.0.21-1595313534508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37793,DS-aa90d8c5-87ad-4efe-8456-bff27f6f1876,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-c0985b1a-7b1f-4d3d-bc59-cb314ca8b372,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-1b309736-a82f-473e-9ec4-5398eddff542,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-7093c89b-5c41-4d30-8a0f-df4047d4422f,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-fedd44bb-a29e-4f27-a7e5-9f4976d6b750,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-0bb457b2-a426-4232-8ecf-d1c4fdc8cb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-d7f56e3d-ded4-4208-a3c9-b3fdfe9c30f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-e3916402-77b2-4277-bbac-d3cf1fd46f9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594195306-172.17.0.21-1595313970154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34238,DS-fabdca3f-7f47-47ca-866f-47435e8248c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-a97138ad-5fa4-48bd-b99a-20fc0173460e,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-2679171d-c160-46f8-a8ba-0d2995b57b69,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-26743129-dfee-4b95-a716-d0c2dad911f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-72336951-7093-4126-adf6-9f78b803b800,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-7591dace-a26e-4bc4-a512-e1f10622a648,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-edbfdace-757b-4e6a-88f4-ef17369c219c,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-c5294e90-583c-4361-a930-b7d32c0055e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594195306-172.17.0.21-1595313970154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34238,DS-fabdca3f-7f47-47ca-866f-47435e8248c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-a97138ad-5fa4-48bd-b99a-20fc0173460e,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-2679171d-c160-46f8-a8ba-0d2995b57b69,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-26743129-dfee-4b95-a716-d0c2dad911f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-72336951-7093-4126-adf6-9f78b803b800,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-7591dace-a26e-4bc4-a512-e1f10622a648,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-edbfdace-757b-4e6a-88f4-ef17369c219c,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-c5294e90-583c-4361-a930-b7d32c0055e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916110234-172.17.0.21-1595314509806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-9c2ecbc7-a6c9-4029-a84a-5829beebe638,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-322f89be-528c-4796-9d4d-408b952a8292,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-6b2e43f7-ae00-426e-80c1-758838a760bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-fc83777b-2243-414a-a61f-2b626cf7fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-4a5fd9b0-945e-415f-8894-4c069bf7d371,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-38828190-32f8-49c3-b2dd-78894119326d,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-5480d6bb-3519-4f96-88cc-811e6b085181,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-e13a325c-1849-4c92-afa2-5504719129e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916110234-172.17.0.21-1595314509806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33946,DS-9c2ecbc7-a6c9-4029-a84a-5829beebe638,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-322f89be-528c-4796-9d4d-408b952a8292,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-6b2e43f7-ae00-426e-80c1-758838a760bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-fc83777b-2243-414a-a61f-2b626cf7fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-4a5fd9b0-945e-415f-8894-4c069bf7d371,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-38828190-32f8-49c3-b2dd-78894119326d,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-5480d6bb-3519-4f96-88cc-811e6b085181,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-e13a325c-1849-4c92-afa2-5504719129e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177502794-172.17.0.21-1595315148046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-4c5836b5-5d52-4e9f-8db3-64c40afc9778,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-81f98404-fb38-46cc-ac9d-ef610f16798d,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-0169a184-d9ba-4be3-98e0-fac1d0a2ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-bad86144-b632-4411-b372-f0d9dcaf9ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-1db08fa2-7e86-45ce-99cc-b8dc6ab5791e,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-055baba7-bbde-4bda-8c3b-7d7d28b90a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-026358ed-76bd-44c0-9c79-5e3c8f9ba497,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-a34a8bc7-506d-404e-afea-98a2b3ee3c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177502794-172.17.0.21-1595315148046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-4c5836b5-5d52-4e9f-8db3-64c40afc9778,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-81f98404-fb38-46cc-ac9d-ef610f16798d,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-0169a184-d9ba-4be3-98e0-fac1d0a2ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-bad86144-b632-4411-b372-f0d9dcaf9ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-1db08fa2-7e86-45ce-99cc-b8dc6ab5791e,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-055baba7-bbde-4bda-8c3b-7d7d28b90a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-026358ed-76bd-44c0-9c79-5e3c8f9ba497,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-a34a8bc7-506d-404e-afea-98a2b3ee3c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924046163-172.17.0.21-1595315266189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-a6b43c91-a237-4ba0-baf3-b72edd92e5be,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-068206c6-84bc-4e43-859d-418864c0abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-45ca1b96-365c-47df-a66a-d98a995b3a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-efac7a7d-fffb-4206-ac82-4dd873509bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-bc542be6-8182-41c5-b8b3-3f3d5dabfc79,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-7fa60412-4fe5-47aa-afc4-95cdeb88137e,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-ffce0bf8-6474-4b62-ad31-ad77d73932c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-f4cce07d-1fd3-4d7f-ac63-4e6e5c358347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924046163-172.17.0.21-1595315266189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-a6b43c91-a237-4ba0-baf3-b72edd92e5be,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-068206c6-84bc-4e43-859d-418864c0abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-45ca1b96-365c-47df-a66a-d98a995b3a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-efac7a7d-fffb-4206-ac82-4dd873509bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-bc542be6-8182-41c5-b8b3-3f3d5dabfc79,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-7fa60412-4fe5-47aa-afc4-95cdeb88137e,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-ffce0bf8-6474-4b62-ad31-ad77d73932c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-f4cce07d-1fd3-4d7f-ac63-4e6e5c358347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573182185-172.17.0.21-1595315646288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-47a269a9-c419-42a0-823f-649db5087a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-468261dc-68c8-41d3-bab2-e2d24a7cbc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-20d9130c-e68b-4aff-869b-3e9f2596c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-f613fdcc-6eb6-48ce-8396-50b09a7d9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-3108847b-d586-4f88-81bd-7f298ae0c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-28e7d8ec-1ad0-4979-a81d-681ab0d60f93,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-7bbb2199-6d03-40ee-93ed-db3b69947e75,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-8877ccc5-e960-47bc-b010-e2e2b2eb94dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573182185-172.17.0.21-1595315646288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-47a269a9-c419-42a0-823f-649db5087a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-468261dc-68c8-41d3-bab2-e2d24a7cbc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-20d9130c-e68b-4aff-869b-3e9f2596c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-f613fdcc-6eb6-48ce-8396-50b09a7d9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-3108847b-d586-4f88-81bd-7f298ae0c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-28e7d8ec-1ad0-4979-a81d-681ab0d60f93,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-7bbb2199-6d03-40ee-93ed-db3b69947e75,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-8877ccc5-e960-47bc-b010-e2e2b2eb94dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682136027-172.17.0.21-1595315685827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-4bb3af43-a86a-4310-8dbf-cf6a3ced4992,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-39b87bcf-e0b4-4d2a-ab1d-b53747b661aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-2d8d922e-7c32-4974-90c4-fbad91e7b18b,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-963dfdc3-cecb-4512-8f17-c48ede70514a,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-1e2d227f-ceac-4c78-afbc-80666546759c,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-7c99d911-120c-4829-8402-44833bc96f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-272a8f3c-7a52-4ba6-9694-7474ddf71a63,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-be0cc5a1-2ef3-4ec3-a861-3aeb26ace319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682136027-172.17.0.21-1595315685827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-4bb3af43-a86a-4310-8dbf-cf6a3ced4992,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-39b87bcf-e0b4-4d2a-ab1d-b53747b661aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-2d8d922e-7c32-4974-90c4-fbad91e7b18b,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-963dfdc3-cecb-4512-8f17-c48ede70514a,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-1e2d227f-ceac-4c78-afbc-80666546759c,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-7c99d911-120c-4829-8402-44833bc96f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-272a8f3c-7a52-4ba6-9694-7474ddf71a63,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-be0cc5a1-2ef3-4ec3-a861-3aeb26ace319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635634944-172.17.0.21-1595316218091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34276,DS-d6a09033-b343-4e45-8ec1-f825dbc32d70,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-dc67c6f8-f581-4384-b463-1ce9d02ce54a,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-920ce23a-9aa1-4e18-bfbd-076844293a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-721d47c6-3c40-418c-952d-a3653d06e3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-9e6f2dd0-b102-4fb3-8660-a55a43d57c11,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-ce290571-a78b-496c-97a1-e575972e527f,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-00c698f0-4e22-4ddc-b92f-b1505ceee0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-e8b54b38-d673-4535-94e4-ede91cdc5a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635634944-172.17.0.21-1595316218091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34276,DS-d6a09033-b343-4e45-8ec1-f825dbc32d70,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-dc67c6f8-f581-4384-b463-1ce9d02ce54a,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-920ce23a-9aa1-4e18-bfbd-076844293a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-721d47c6-3c40-418c-952d-a3653d06e3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-9e6f2dd0-b102-4fb3-8660-a55a43d57c11,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-ce290571-a78b-496c-97a1-e575972e527f,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-00c698f0-4e22-4ddc-b92f-b1505ceee0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-e8b54b38-d673-4535-94e4-ede91cdc5a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032470255-172.17.0.21-1595316491063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-21f94b62-8b9c-4047-865f-bf28e7be2e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-c1c5d4aa-36fc-4654-9985-9e7429f90ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-594bbc72-cc58-4ed3-83ff-d3e814a5d4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-58a6b43e-869b-4ffb-af03-ff7b430c4f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-038b35e1-dea0-4abe-8c77-c265487c787d,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-b8d0054f-06f9-42da-b135-54f06a12d982,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-9d074500-ab49-4a01-be72-e523ea7d5bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-83447ee4-6f76-4939-aadd-c2075715f02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032470255-172.17.0.21-1595316491063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-21f94b62-8b9c-4047-865f-bf28e7be2e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-c1c5d4aa-36fc-4654-9985-9e7429f90ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-594bbc72-cc58-4ed3-83ff-d3e814a5d4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-58a6b43e-869b-4ffb-af03-ff7b430c4f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-038b35e1-dea0-4abe-8c77-c265487c787d,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-b8d0054f-06f9-42da-b135-54f06a12d982,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-9d074500-ab49-4a01-be72-e523ea7d5bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-83447ee4-6f76-4939-aadd-c2075715f02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6579
