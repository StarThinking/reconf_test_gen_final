reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094127518-172.17.0.11-1595359835937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43661,DS-6f595e36-0055-4b7a-a70a-e136534c2ada,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-da535475-46e5-4e73-8389-0ee47d05eef3,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-50b95840-ac82-4f83-acba-11671d172840,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-229be8b9-d3e2-458b-8db3-6c9e780a5048,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-a78c4f75-ea8f-46c7-b91d-fdf42204357f,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-aead86e7-b69c-41a9-9a1d-4abda460cbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-20b0b39d-3e1a-4b25-8438-1c34abf8f230,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-01cadc40-14d6-428d-931d-5b84e380a115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094127518-172.17.0.11-1595359835937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43661,DS-6f595e36-0055-4b7a-a70a-e136534c2ada,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-da535475-46e5-4e73-8389-0ee47d05eef3,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-50b95840-ac82-4f83-acba-11671d172840,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-229be8b9-d3e2-458b-8db3-6c9e780a5048,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-a78c4f75-ea8f-46c7-b91d-fdf42204357f,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-aead86e7-b69c-41a9-9a1d-4abda460cbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-20b0b39d-3e1a-4b25-8438-1c34abf8f230,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-01cadc40-14d6-428d-931d-5b84e380a115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382710648-172.17.0.11-1595359904713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45513,DS-ed2a3bb0-b446-41a1-bfc0-7fb0a6ca5094,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-866589a8-1040-4508-aea1-d3e4afab65dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-32643bba-b85d-4403-bf32-000f60eb3ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-fb7837f0-dd43-4e62-8b28-132dd6c92212,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-377dd51f-497e-44eb-8e94-71745a68b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-94ada848-51fe-460b-888f-8ac5f88d555a,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-2b568ddb-564a-4b39-ad2f-418f0f31da69,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-898ed7c5-59c6-4a8e-9bce-c81af06c3a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382710648-172.17.0.11-1595359904713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45513,DS-ed2a3bb0-b446-41a1-bfc0-7fb0a6ca5094,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-866589a8-1040-4508-aea1-d3e4afab65dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-32643bba-b85d-4403-bf32-000f60eb3ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-fb7837f0-dd43-4e62-8b28-132dd6c92212,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-377dd51f-497e-44eb-8e94-71745a68b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-94ada848-51fe-460b-888f-8ac5f88d555a,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-2b568ddb-564a-4b39-ad2f-418f0f31da69,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-898ed7c5-59c6-4a8e-9bce-c81af06c3a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105145616-172.17.0.11-1595360337600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-eb07152e-315f-4e61-a94e-4dae89f05cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-14f2d60a-fb37-4ab9-8aee-4011116ac551,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-6b3bf739-d584-41fc-a635-ef75d4422cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-79723ee7-52c9-4c88-953f-a84b0b6930d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-8075eaa9-d9c5-4f44-881d-f086aa275fea,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-b030625b-cd3d-46ae-a5b5-bdea30bfe248,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-b15f4eea-9e64-4c38-86cc-788b7c4fc2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-d0478d31-adb0-4dee-b746-1aaeeb28541e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105145616-172.17.0.11-1595360337600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-eb07152e-315f-4e61-a94e-4dae89f05cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-14f2d60a-fb37-4ab9-8aee-4011116ac551,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-6b3bf739-d584-41fc-a635-ef75d4422cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-79723ee7-52c9-4c88-953f-a84b0b6930d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-8075eaa9-d9c5-4f44-881d-f086aa275fea,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-b030625b-cd3d-46ae-a5b5-bdea30bfe248,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-b15f4eea-9e64-4c38-86cc-788b7c4fc2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-d0478d31-adb0-4dee-b746-1aaeeb28541e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322933160-172.17.0.11-1595360716806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38179,DS-cb992908-b138-4beb-b9b5-64eaacfaa5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-474d623e-12ab-4a67-8aa1-671e688d438a,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-5a326aaf-8061-4841-b4a6-124ec5622211,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-84031882-b1ef-4592-ad4e-ca1553ef517a,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-ce3359ff-efc8-470b-ac5c-2e7722138c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-468884f6-4664-4b65-8a76-121e9c8925a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-e85236ac-7349-4755-b25e-03aa4ac68bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-6effee3f-b366-49b8-a2e1-75cf51748d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322933160-172.17.0.11-1595360716806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38179,DS-cb992908-b138-4beb-b9b5-64eaacfaa5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-474d623e-12ab-4a67-8aa1-671e688d438a,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-5a326aaf-8061-4841-b4a6-124ec5622211,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-84031882-b1ef-4592-ad4e-ca1553ef517a,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-ce3359ff-efc8-470b-ac5c-2e7722138c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-468884f6-4664-4b65-8a76-121e9c8925a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-e85236ac-7349-4755-b25e-03aa4ac68bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-6effee3f-b366-49b8-a2e1-75cf51748d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254371660-172.17.0.11-1595360786002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36404,DS-2f03f4fd-9f3c-47e6-8d1b-c3d8ad23f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-31d690ad-a7a6-4249-8d64-fcce0d660da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-ee2350e0-47a2-4c9d-ac2d-d745a79938d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-319766d0-1c7d-4470-aaea-02362f370800,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-54fd37e2-6058-4181-a2c6-6aae645feadb,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-cf87bbb9-8a0b-4674-a145-53d9573f8d01,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-92055a2d-b6b4-4b4e-a555-f95d9477c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-9dd7484b-8b48-41e7-bd45-67090b2d2445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254371660-172.17.0.11-1595360786002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36404,DS-2f03f4fd-9f3c-47e6-8d1b-c3d8ad23f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-31d690ad-a7a6-4249-8d64-fcce0d660da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-ee2350e0-47a2-4c9d-ac2d-d745a79938d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-319766d0-1c7d-4470-aaea-02362f370800,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-54fd37e2-6058-4181-a2c6-6aae645feadb,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-cf87bbb9-8a0b-4674-a145-53d9573f8d01,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-92055a2d-b6b4-4b4e-a555-f95d9477c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-9dd7484b-8b48-41e7-bd45-67090b2d2445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342706592-172.17.0.11-1595361142153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-b16c7dcd-0a72-4d22-9ebd-e755bbee7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-ce2cb808-0c6b-47ca-ad3b-ba63276bf1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-b2c6002d-0fdb-4101-be15-662f8c1c89e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-7f8f2403-71a1-4c8b-8d3a-0d1e3334c3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-6e8c4b4c-b7e0-46ba-b4c6-3e406f24ade9,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-310440e9-362a-4f26-a297-cb6396dc80a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-8462315a-e021-4642-bcef-3c86fdb8cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-65b1146e-ddfd-4979-81e2-cd022e0886f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342706592-172.17.0.11-1595361142153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-b16c7dcd-0a72-4d22-9ebd-e755bbee7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-ce2cb808-0c6b-47ca-ad3b-ba63276bf1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-b2c6002d-0fdb-4101-be15-662f8c1c89e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-7f8f2403-71a1-4c8b-8d3a-0d1e3334c3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-6e8c4b4c-b7e0-46ba-b4c6-3e406f24ade9,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-310440e9-362a-4f26-a297-cb6396dc80a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-8462315a-e021-4642-bcef-3c86fdb8cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-65b1146e-ddfd-4979-81e2-cd022e0886f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599096106-172.17.0.11-1595361748159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44594,DS-ace1448e-e538-4fc6-8fc6-c237179d227e,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-8c53e7d2-ae45-4c3e-8ab1-0ff87f0c0497,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-75a14120-3e69-4d8f-9eb6-fee49a905e64,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-3db70ec7-0a1d-4467-8c29-f9fb2a15593c,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-8eebb54d-40f2-47e4-a4fd-a816fba13c60,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-f66ec98f-d6c0-41a0-b270-e27982b42001,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-8edfcb5d-1fd2-4b47-94c0-1a1a45c35401,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-9358cf6f-bca3-43cf-941d-97e9b04aae19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599096106-172.17.0.11-1595361748159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44594,DS-ace1448e-e538-4fc6-8fc6-c237179d227e,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-8c53e7d2-ae45-4c3e-8ab1-0ff87f0c0497,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-75a14120-3e69-4d8f-9eb6-fee49a905e64,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-3db70ec7-0a1d-4467-8c29-f9fb2a15593c,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-8eebb54d-40f2-47e4-a4fd-a816fba13c60,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-f66ec98f-d6c0-41a0-b270-e27982b42001,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-8edfcb5d-1fd2-4b47-94c0-1a1a45c35401,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-9358cf6f-bca3-43cf-941d-97e9b04aae19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558860918-172.17.0.11-1595361840064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37337,DS-442b99ad-875c-48e8-8925-140378aaff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-0c02a0dc-8a92-4931-ae9b-28a83b3a00e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-f7b33455-11d6-49d2-877f-64e86c3ceb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-369e3fce-3d4f-43e4-b2b2-41c3646a7b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-3c3ea7fc-aeff-422a-b92f-afaff3821e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-c65175d0-9577-4634-a09a-7b04aa39d938,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-5e087fc4-9a14-409c-8979-d8716ff295a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-ab26d7e8-5657-439a-b57c-a1bac4f0613c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558860918-172.17.0.11-1595361840064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37337,DS-442b99ad-875c-48e8-8925-140378aaff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-0c02a0dc-8a92-4931-ae9b-28a83b3a00e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-f7b33455-11d6-49d2-877f-64e86c3ceb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-369e3fce-3d4f-43e4-b2b2-41c3646a7b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-3c3ea7fc-aeff-422a-b92f-afaff3821e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-c65175d0-9577-4634-a09a-7b04aa39d938,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-5e087fc4-9a14-409c-8979-d8716ff295a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-ab26d7e8-5657-439a-b57c-a1bac4f0613c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006242201-172.17.0.11-1595362248053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-4f4b770c-fe43-4f55-9dfb-a0852c2e49c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-405a40bf-8d66-471f-a763-06e52cc033a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-0d5ba2ca-d842-4cf3-b8fd-1a13ac72d2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-8e79bb47-4a90-47bc-a6fe-db65c141c79e,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-62de5395-4dcd-4237-9da5-058a48fb5309,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-9b01e5f4-c65f-441e-95c1-8eafa0569996,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-9b5979f3-9b97-46e1-9427-9f0a2961fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-070b3a6b-e722-4a05-a015-fd1d1e1caaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006242201-172.17.0.11-1595362248053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37186,DS-4f4b770c-fe43-4f55-9dfb-a0852c2e49c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-405a40bf-8d66-471f-a763-06e52cc033a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-0d5ba2ca-d842-4cf3-b8fd-1a13ac72d2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-8e79bb47-4a90-47bc-a6fe-db65c141c79e,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-62de5395-4dcd-4237-9da5-058a48fb5309,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-9b01e5f4-c65f-441e-95c1-8eafa0569996,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-9b5979f3-9b97-46e1-9427-9f0a2961fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-070b3a6b-e722-4a05-a015-fd1d1e1caaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282467181-172.17.0.11-1595362656250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-cc2a308a-e796-4e97-b357-73701bb71842,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-d8e6bfa0-0ed5-467f-b005-03c97c17e64b,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-95efb402-39cd-4b71-94e5-9239b41b8a37,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-f5f4fd90-5128-48f3-9ed6-4a80664ce701,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-dc2fcc8a-04ce-48e4-bca7-1fe3aa5ee0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-cb27a05f-85e1-4844-9a99-ed01a6401775,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-863df777-0f88-4b42-91da-480d4ad05a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-b5877bd9-e72b-4d99-91fc-c5e760365562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282467181-172.17.0.11-1595362656250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-cc2a308a-e796-4e97-b357-73701bb71842,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-d8e6bfa0-0ed5-467f-b005-03c97c17e64b,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-95efb402-39cd-4b71-94e5-9239b41b8a37,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-f5f4fd90-5128-48f3-9ed6-4a80664ce701,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-dc2fcc8a-04ce-48e4-bca7-1fe3aa5ee0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-cb27a05f-85e1-4844-9a99-ed01a6401775,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-863df777-0f88-4b42-91da-480d4ad05a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-b5877bd9-e72b-4d99-91fc-c5e760365562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560875562-172.17.0.11-1595362887445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33195,DS-dcad33be-0a7d-48c2-b2bb-df6d82da46f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-789fede9-6323-47ae-98b1-fd85b1bdbede,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-38b548a0-91f0-4d61-aa92-8998c6ac2593,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-447be68e-80b0-4139-adc6-36363a1df783,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-cc92ce9b-73a5-4fec-9b93-9dffd8a9daac,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-e739bf82-fbfc-49ae-82eb-d925a32d8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-64afcbc5-addc-4d10-9182-a6c7c8295695,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-ea1092cc-5ee8-43a8-bf8e-62e9dfa945c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560875562-172.17.0.11-1595362887445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33195,DS-dcad33be-0a7d-48c2-b2bb-df6d82da46f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-789fede9-6323-47ae-98b1-fd85b1bdbede,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-38b548a0-91f0-4d61-aa92-8998c6ac2593,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-447be68e-80b0-4139-adc6-36363a1df783,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-cc92ce9b-73a5-4fec-9b93-9dffd8a9daac,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-e739bf82-fbfc-49ae-82eb-d925a32d8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-64afcbc5-addc-4d10-9182-a6c7c8295695,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-ea1092cc-5ee8-43a8-bf8e-62e9dfa945c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828068723-172.17.0.11-1595362975833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-2089aa1a-f04a-4c61-9e60-ba5bbe8ed584,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-23fc9245-5835-4fe3-b15f-77c3176b275b,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-e1344d12-cdd8-4f75-95ef-6a7859e9277c,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-d7a95fa6-90d3-4224-b4be-6ae9680560cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-a202789d-8e8a-4da3-9326-c48c73921791,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-fc8cef20-c863-435e-ad27-58e9ba4367c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-7aed37e6-f05f-4ca0-8750-0255e75f26db,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-c7890b3b-9a68-4b92-8f6d-ab14aaf62bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828068723-172.17.0.11-1595362975833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-2089aa1a-f04a-4c61-9e60-ba5bbe8ed584,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-23fc9245-5835-4fe3-b15f-77c3176b275b,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-e1344d12-cdd8-4f75-95ef-6a7859e9277c,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-d7a95fa6-90d3-4224-b4be-6ae9680560cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-a202789d-8e8a-4da3-9326-c48c73921791,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-fc8cef20-c863-435e-ad27-58e9ba4367c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-7aed37e6-f05f-4ca0-8750-0255e75f26db,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-c7890b3b-9a68-4b92-8f6d-ab14aaf62bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486271089-172.17.0.11-1595363360939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42559,DS-82637cb0-45e3-4b2c-8003-87aa76023fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-0621cd54-07b2-404b-aacd-a90c4e88194d,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-46952a40-cfcc-45e0-821b-eec7b93d473a,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-51ecdd19-80ec-40a3-914e-7c95aac47626,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-0ec55ed5-e888-4f5f-b21d-eeb3d2f7b407,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-cfb273e4-b2e5-457c-866b-f31022ed98c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-b08af7e0-de05-4209-996f-a586755da56c,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-0ce55465-1c2d-4528-8248-061cdbedef0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486271089-172.17.0.11-1595363360939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42559,DS-82637cb0-45e3-4b2c-8003-87aa76023fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-0621cd54-07b2-404b-aacd-a90c4e88194d,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-46952a40-cfcc-45e0-821b-eec7b93d473a,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-51ecdd19-80ec-40a3-914e-7c95aac47626,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-0ec55ed5-e888-4f5f-b21d-eeb3d2f7b407,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-cfb273e4-b2e5-457c-866b-f31022ed98c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-b08af7e0-de05-4209-996f-a586755da56c,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-0ce55465-1c2d-4528-8248-061cdbedef0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006297298-172.17.0.11-1595363664674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-185c9938-abac-4e84-9008-8c747d4ebfff,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-cbd3dd0a-1f42-4124-87ef-1ebebeed89b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-3e94832a-8183-402f-b216-10964e1ded1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-3f97b06d-f26b-4d7b-b3ce-3ece89ebbd76,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-6c5b8860-b46e-4a18-a3eb-fead246b1d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-f9eec37b-b3af-4387-ae3c-5ccb3afd604f,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-883e3cc6-ba79-4e3c-887a-274c644a0ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-02c60309-f226-4e91-acbe-49cbbc00dad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006297298-172.17.0.11-1595363664674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-185c9938-abac-4e84-9008-8c747d4ebfff,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-cbd3dd0a-1f42-4124-87ef-1ebebeed89b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-3e94832a-8183-402f-b216-10964e1ded1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-3f97b06d-f26b-4d7b-b3ce-3ece89ebbd76,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-6c5b8860-b46e-4a18-a3eb-fead246b1d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-f9eec37b-b3af-4387-ae3c-5ccb3afd604f,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-883e3cc6-ba79-4e3c-887a-274c644a0ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-02c60309-f226-4e91-acbe-49cbbc00dad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115599343-172.17.0.11-1595363776870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-b051b2bf-1233-48d6-a054-22878c932270,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-d60c1e34-4901-4edf-97c4-99c122c296a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-fd7a9ba2-97a5-4fcd-8e73-6c958ba12e79,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-2fd55915-effe-4afc-ad12-ceb149f8098e,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-11a28202-1bd3-4262-98fc-9985cfb524d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-124dceca-d54e-496c-b10e-35626ee6ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-a72614f0-ebf6-406a-939e-7ea0d6676432,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-67f42bfe-2e37-4510-a0dd-fcea76ee5acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115599343-172.17.0.11-1595363776870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-b051b2bf-1233-48d6-a054-22878c932270,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-d60c1e34-4901-4edf-97c4-99c122c296a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-fd7a9ba2-97a5-4fcd-8e73-6c958ba12e79,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-2fd55915-effe-4afc-ad12-ceb149f8098e,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-11a28202-1bd3-4262-98fc-9985cfb524d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-124dceca-d54e-496c-b10e-35626ee6ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-a72614f0-ebf6-406a-939e-7ea0d6676432,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-67f42bfe-2e37-4510-a0dd-fcea76ee5acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117356448-172.17.0.11-1595364133422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-746fd8e3-fb48-4b09-b7ce-913c53231df1,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-d76deb91-4528-494b-8de7-6bc29b0fcd21,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-fe416522-32d5-4c89-a0ab-c467ca7e3512,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-6be007ee-5d6c-4320-9bcd-73f41bf9a3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-b9837b58-e8ea-401f-a1cd-bb0b2efe99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-571fd91b-1c46-4e88-adab-364a833632ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-5f7d20e4-0126-42bb-9fb0-868564f11ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-61136589-14c3-4cd9-ad9c-ce45571f4067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117356448-172.17.0.11-1595364133422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-746fd8e3-fb48-4b09-b7ce-913c53231df1,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-d76deb91-4528-494b-8de7-6bc29b0fcd21,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-fe416522-32d5-4c89-a0ab-c467ca7e3512,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-6be007ee-5d6c-4320-9bcd-73f41bf9a3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-b9837b58-e8ea-401f-a1cd-bb0b2efe99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-571fd91b-1c46-4e88-adab-364a833632ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-5f7d20e4-0126-42bb-9fb0-868564f11ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-61136589-14c3-4cd9-ad9c-ce45571f4067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419701965-172.17.0.11-1595364167585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-dd190b28-67fa-443f-b87b-b801f32e6303,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-1f936d1b-229a-4183-9273-231b4baca56d,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-9ae33166-09c1-4fa9-aad7-4e039d8a3259,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-eb8da48d-79ce-4669-9c9a-31ab9b116104,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-dc39996e-d32e-4654-9b31-ccb48fd13a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-b0f7ed32-8144-42b6-a599-ebcdaf98068c,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-3a3b3b3c-68c3-4d44-af07-48e26e34edc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-fa13ca80-b9d8-436e-a7fe-da6770008f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419701965-172.17.0.11-1595364167585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-dd190b28-67fa-443f-b87b-b801f32e6303,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-1f936d1b-229a-4183-9273-231b4baca56d,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-9ae33166-09c1-4fa9-aad7-4e039d8a3259,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-eb8da48d-79ce-4669-9c9a-31ab9b116104,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-dc39996e-d32e-4654-9b31-ccb48fd13a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-b0f7ed32-8144-42b6-a599-ebcdaf98068c,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-3a3b3b3c-68c3-4d44-af07-48e26e34edc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-fa13ca80-b9d8-436e-a7fe-da6770008f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5029
