reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648410977-172.17.0.5-1595421474402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38239,DS-3ea1b067-231a-43d9-990f-06f38380784e,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-e17fbeb1-773b-4375-86a6-22d4bc01e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-f9539bb0-4fe6-46fd-9956-778d31478801,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-e4a6e10e-e6aa-4dc0-87f5-0f4136d83138,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-f6a66bca-80b8-4fc1-b296-28ec3f6415ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-10374d96-1390-49f6-a008-cba9ba0b731a,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-7449c518-10f2-400d-bf8d-9213848c1e23,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-85956636-e3d9-4c3c-8f38-23f620de220d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648410977-172.17.0.5-1595421474402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38239,DS-3ea1b067-231a-43d9-990f-06f38380784e,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-e17fbeb1-773b-4375-86a6-22d4bc01e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-f9539bb0-4fe6-46fd-9956-778d31478801,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-e4a6e10e-e6aa-4dc0-87f5-0f4136d83138,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-f6a66bca-80b8-4fc1-b296-28ec3f6415ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-10374d96-1390-49f6-a008-cba9ba0b731a,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-7449c518-10f2-400d-bf8d-9213848c1e23,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-85956636-e3d9-4c3c-8f38-23f620de220d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693415959-172.17.0.5-1595421664202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44316,DS-2c7c7709-9307-42fd-9107-7826a7e64fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-30ce9ec4-4a78-4527-bee8-f23c4feea50c,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-5af104c7-f02c-4c17-a9db-70396c1bbb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-ab62683c-15aa-4dd1-92ac-9330459e1907,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-9bc48a06-80dc-49a2-bdbe-a85b9361fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-5055f5a0-87a2-4023-832b-503fd57d912f,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-d9d46df2-62c8-4ed5-8d8b-588afa55c468,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-f20996e4-69d3-4157-8991-074cad7dfd50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693415959-172.17.0.5-1595421664202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44316,DS-2c7c7709-9307-42fd-9107-7826a7e64fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-30ce9ec4-4a78-4527-bee8-f23c4feea50c,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-5af104c7-f02c-4c17-a9db-70396c1bbb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-ab62683c-15aa-4dd1-92ac-9330459e1907,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-9bc48a06-80dc-49a2-bdbe-a85b9361fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-5055f5a0-87a2-4023-832b-503fd57d912f,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-d9d46df2-62c8-4ed5-8d8b-588afa55c468,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-f20996e4-69d3-4157-8991-074cad7dfd50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834544610-172.17.0.5-1595421905410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-c0a2f73a-0188-409c-bcd8-2abc3c01c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-63982ff9-7d68-4d00-b251-487d2b8efc86,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-02b9ea7e-a530-4ad2-9a9f-3ae3bbf48a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-21bcc4f0-e12f-4909-9a22-f55daa82c388,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-26eb308e-b6da-478c-b1cb-2f4d341cbdda,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-f8300f57-3418-495d-b6bb-8f6b85c719eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-27b48ecb-25ef-4a8f-97e1-16276668f184,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-381d64fe-ff50-4d3a-b97f-5077b7969276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834544610-172.17.0.5-1595421905410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-c0a2f73a-0188-409c-bcd8-2abc3c01c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-63982ff9-7d68-4d00-b251-487d2b8efc86,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-02b9ea7e-a530-4ad2-9a9f-3ae3bbf48a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-21bcc4f0-e12f-4909-9a22-f55daa82c388,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-26eb308e-b6da-478c-b1cb-2f4d341cbdda,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-f8300f57-3418-495d-b6bb-8f6b85c719eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-27b48ecb-25ef-4a8f-97e1-16276668f184,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-381d64fe-ff50-4d3a-b97f-5077b7969276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605215047-172.17.0.5-1595422016409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-761853b7-c95c-4369-b5d3-c901ee2a3708,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-01eec882-4a01-48b2-b614-a50a5c8b6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-4806acfe-f039-4e04-bda2-78917f4ebdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-fc2a5672-8197-405d-9352-a4cbba80f796,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-916c78cd-62ca-4ec5-af1d-4710c6d8fcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-1347e775-58f4-4461-82b1-7eb09158a342,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-1318276d-bd6d-46ac-be91-eb2402008dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-09007f1f-7a83-4bfe-ad57-872e1aced2ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605215047-172.17.0.5-1595422016409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-761853b7-c95c-4369-b5d3-c901ee2a3708,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-01eec882-4a01-48b2-b614-a50a5c8b6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-4806acfe-f039-4e04-bda2-78917f4ebdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-fc2a5672-8197-405d-9352-a4cbba80f796,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-916c78cd-62ca-4ec5-af1d-4710c6d8fcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-1347e775-58f4-4461-82b1-7eb09158a342,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-1318276d-bd6d-46ac-be91-eb2402008dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-09007f1f-7a83-4bfe-ad57-872e1aced2ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292093903-172.17.0.5-1595422045242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43633,DS-5d35679c-8e6e-4c9c-b3f3-e424a564192f,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-c6153b22-f8c6-4a6b-a627-ead39b34c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-b0cde44c-d910-48d3-bfdd-3f4c552b8b66,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-874d29d9-cfed-4839-b20c-3d5c3988dbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-10f69153-c3bd-4989-8039-2782378581fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-4dfd3cdd-149c-4051-b073-fe6fe0dc1281,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-9599474b-e71f-4def-9ed5-a36b369c0d59,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-0e4ed051-2bed-4894-be1d-ddbb91583de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292093903-172.17.0.5-1595422045242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43633,DS-5d35679c-8e6e-4c9c-b3f3-e424a564192f,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-c6153b22-f8c6-4a6b-a627-ead39b34c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-b0cde44c-d910-48d3-bfdd-3f4c552b8b66,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-874d29d9-cfed-4839-b20c-3d5c3988dbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-10f69153-c3bd-4989-8039-2782378581fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-4dfd3cdd-149c-4051-b073-fe6fe0dc1281,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-9599474b-e71f-4def-9ed5-a36b369c0d59,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-0e4ed051-2bed-4894-be1d-ddbb91583de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882757668-172.17.0.5-1595422237384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36099,DS-f74a084d-8e36-4a0c-b758-4699d384c49a,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-b6f07224-b31f-41c4-9b19-cf757e281a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-ffa8481d-ebd9-4a8b-9b70-8a83122de7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-50ae004c-c1a8-444b-b8a3-ba8e7b5a0a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-76af2adf-a8e2-420a-9a07-e05d75935389,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-9ff32fc4-646f-4d45-b183-7b1b5b2e8fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-857213e8-ccc7-479f-953d-b6470b22262e,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-3689a421-3c07-4af0-9bab-27f04ad9e430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882757668-172.17.0.5-1595422237384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36099,DS-f74a084d-8e36-4a0c-b758-4699d384c49a,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-b6f07224-b31f-41c4-9b19-cf757e281a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-ffa8481d-ebd9-4a8b-9b70-8a83122de7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-50ae004c-c1a8-444b-b8a3-ba8e7b5a0a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-76af2adf-a8e2-420a-9a07-e05d75935389,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-9ff32fc4-646f-4d45-b183-7b1b5b2e8fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-857213e8-ccc7-479f-953d-b6470b22262e,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-3689a421-3c07-4af0-9bab-27f04ad9e430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487956605-172.17.0.5-1595422379956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34644,DS-ee553d99-6346-4820-a757-8b6ccd305b21,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-69f47ae8-96a0-4468-be7f-7f136e1b7a13,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-0ad62317-3622-48c0-bdd0-3d7aaa7bbafa,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-202153e2-eaaa-4fb8-b2cd-e629ce4c77cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-cc55919e-3d65-4db3-811c-f909a00b1422,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-191542d5-7d61-4b66-b506-23adb84608ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-1a6149cd-eebc-4e73-8eee-8e688ab22314,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-aa13d36d-a264-4675-b60a-7148ffca4dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487956605-172.17.0.5-1595422379956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34644,DS-ee553d99-6346-4820-a757-8b6ccd305b21,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-69f47ae8-96a0-4468-be7f-7f136e1b7a13,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-0ad62317-3622-48c0-bdd0-3d7aaa7bbafa,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-202153e2-eaaa-4fb8-b2cd-e629ce4c77cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-cc55919e-3d65-4db3-811c-f909a00b1422,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-191542d5-7d61-4b66-b506-23adb84608ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-1a6149cd-eebc-4e73-8eee-8e688ab22314,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-aa13d36d-a264-4675-b60a-7148ffca4dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966259409-172.17.0.5-1595422477458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-8ab1e22c-a0ab-4cba-8d7d-a4ada794a824,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-7dc766e5-010f-4054-adc8-c9ce0406527a,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-fe98dc3b-5aa3-4f76-8935-41e7e9c6b5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-0cf47918-b583-480c-b65c-41bd6184fc53,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-34843a8a-6ea7-437f-9c51-40f7dc0a8447,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-76bbbfcc-9af3-436d-a59a-b01fa4e3554f,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-db899273-d57e-4ee7-b5d2-d98dbbde4033,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-a631ab73-e538-4dab-a125-38c7a632dc67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966259409-172.17.0.5-1595422477458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-8ab1e22c-a0ab-4cba-8d7d-a4ada794a824,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-7dc766e5-010f-4054-adc8-c9ce0406527a,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-fe98dc3b-5aa3-4f76-8935-41e7e9c6b5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-0cf47918-b583-480c-b65c-41bd6184fc53,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-34843a8a-6ea7-437f-9c51-40f7dc0a8447,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-76bbbfcc-9af3-436d-a59a-b01fa4e3554f,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-db899273-d57e-4ee7-b5d2-d98dbbde4033,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-a631ab73-e538-4dab-a125-38c7a632dc67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560103859-172.17.0.5-1595422655065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-ed910d53-61b5-43d2-9624-55e406a05cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-2ea7e315-0384-4dd5-a317-a7815708cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-1528f712-c818-40f3-b5af-673304963893,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-d5a69515-3350-4a5c-9597-43ab0d2539e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-434efa46-b4d7-498e-86ec-b4a00b358dea,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-f15ef5f8-49ff-4a9e-b59f-b92f095f6524,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-d0869c80-e7e4-496c-901d-597c0c948616,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-5f1ae181-a036-4483-b0cf-565024d03fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560103859-172.17.0.5-1595422655065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-ed910d53-61b5-43d2-9624-55e406a05cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-2ea7e315-0384-4dd5-a317-a7815708cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-1528f712-c818-40f3-b5af-673304963893,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-d5a69515-3350-4a5c-9597-43ab0d2539e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-434efa46-b4d7-498e-86ec-b4a00b358dea,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-f15ef5f8-49ff-4a9e-b59f-b92f095f6524,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-d0869c80-e7e4-496c-901d-597c0c948616,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-5f1ae181-a036-4483-b0cf-565024d03fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179038206-172.17.0.5-1595422736855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-d0dd8f42-3e18-4169-b9b6-e866af2e64b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-b067f02d-06bc-4856-8351-789f8c97796a,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-1d8be17c-518d-4018-a379-dc2749c9a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-39e0db5d-57ec-498c-a1cd-76a8715376dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-ecd79325-9cd8-43b0-a977-3786aa899db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-c524065d-5a64-4c7d-98ff-813c037890d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-430c06ab-79c3-447f-94b6-74996935b3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-66f0851d-03c8-45ed-b82e-fc33fe8db5a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179038206-172.17.0.5-1595422736855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-d0dd8f42-3e18-4169-b9b6-e866af2e64b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-b067f02d-06bc-4856-8351-789f8c97796a,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-1d8be17c-518d-4018-a379-dc2749c9a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-39e0db5d-57ec-498c-a1cd-76a8715376dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-ecd79325-9cd8-43b0-a977-3786aa899db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-c524065d-5a64-4c7d-98ff-813c037890d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-430c06ab-79c3-447f-94b6-74996935b3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-66f0851d-03c8-45ed-b82e-fc33fe8db5a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440705599-172.17.0.5-1595422801983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42520,DS-68c01b65-3aad-4b25-ab9b-c735d0750118,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-4aa2b5eb-dd74-463b-8dbb-145e5b7fe891,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-99bb7c46-9227-4ebe-9008-c982b1cbfcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-d7949f3c-7f4d-40c0-930e-be87d599322a,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-e574b0ec-6196-49c5-b8e7-d09965fca07b,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-7182099e-e26a-4e61-b463-3e9ecf1d6077,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-f21b991a-ac79-4f84-80d9-4fd9764d9202,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-0468fc3a-3351-4774-9403-36a71700089e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440705599-172.17.0.5-1595422801983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42520,DS-68c01b65-3aad-4b25-ab9b-c735d0750118,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-4aa2b5eb-dd74-463b-8dbb-145e5b7fe891,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-99bb7c46-9227-4ebe-9008-c982b1cbfcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-d7949f3c-7f4d-40c0-930e-be87d599322a,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-e574b0ec-6196-49c5-b8e7-d09965fca07b,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-7182099e-e26a-4e61-b463-3e9ecf1d6077,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-f21b991a-ac79-4f84-80d9-4fd9764d9202,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-0468fc3a-3351-4774-9403-36a71700089e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857394624-172.17.0.5-1595422932874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39068,DS-1984d83f-cbaa-42ab-a669-e5f66636faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-284d97f1-cf1a-4431-aa43-27a3c2591b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-0adce312-864d-4158-8932-baae127941e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-b2e7516d-7a2d-4bc5-ae3f-0b6004c6e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-22a6c256-4b57-4037-bfb0-f0987ae5832d,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-bd096285-3655-4e39-b73c-3a5109dc3be3,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-d237b0fe-d873-4257-92fc-a92c6febe2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-723941bc-6c0e-417d-9be6-cc66cf4c790b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857394624-172.17.0.5-1595422932874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39068,DS-1984d83f-cbaa-42ab-a669-e5f66636faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-284d97f1-cf1a-4431-aa43-27a3c2591b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-0adce312-864d-4158-8932-baae127941e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-b2e7516d-7a2d-4bc5-ae3f-0b6004c6e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-22a6c256-4b57-4037-bfb0-f0987ae5832d,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-bd096285-3655-4e39-b73c-3a5109dc3be3,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-d237b0fe-d873-4257-92fc-a92c6febe2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-723941bc-6c0e-417d-9be6-cc66cf4c790b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361377084-172.17.0.5-1595423030176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-f38c677c-14cc-40b5-889b-687ea61e9964,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-f075a88f-dbfa-4399-bc35-09333b36784a,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-12900fc6-c6bb-4dc2-9be9-0bcb3b4c7473,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-3daadf38-75c4-47c8-adad-6ecefc5f7009,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-04eef85a-79bd-44a0-a16b-079c2981c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-0d448dc3-43ec-43b6-86c7-e64ad14c4c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-9b0970de-e3fe-4220-be5d-bf18bb975936,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-996941d5-b5f2-451a-9ec0-2e2c09065978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361377084-172.17.0.5-1595423030176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-f38c677c-14cc-40b5-889b-687ea61e9964,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-f075a88f-dbfa-4399-bc35-09333b36784a,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-12900fc6-c6bb-4dc2-9be9-0bcb3b4c7473,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-3daadf38-75c4-47c8-adad-6ecefc5f7009,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-04eef85a-79bd-44a0-a16b-079c2981c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-0d448dc3-43ec-43b6-86c7-e64ad14c4c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-9b0970de-e3fe-4220-be5d-bf18bb975936,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-996941d5-b5f2-451a-9ec0-2e2c09065978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276498602-172.17.0.5-1595423111795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-37607bc2-f699-402d-ac28-07f1f2b856f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-b113b2e4-56de-4e6d-a318-d278167da1df,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-042b0251-b0de-48bb-a541-4c306fd065de,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-80753e01-4818-4e57-b296-6d56ae8466fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-b7c1613a-2468-4364-9f5e-9dd29e21e1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-3979a389-1430-402e-a219-dfae2e488943,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-7899851c-249d-4b95-b27f-c6b68fba7ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-f0a4fa5d-b9b3-409a-a6e5-b1a6c36cd72f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276498602-172.17.0.5-1595423111795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-37607bc2-f699-402d-ac28-07f1f2b856f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-b113b2e4-56de-4e6d-a318-d278167da1df,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-042b0251-b0de-48bb-a541-4c306fd065de,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-80753e01-4818-4e57-b296-6d56ae8466fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-b7c1613a-2468-4364-9f5e-9dd29e21e1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-3979a389-1430-402e-a219-dfae2e488943,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-7899851c-249d-4b95-b27f-c6b68fba7ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-f0a4fa5d-b9b3-409a-a6e5-b1a6c36cd72f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177232186-172.17.0.5-1595423127870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38180,DS-1be343d0-e6f7-412e-be96-1cc8fa65307e,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-974879c5-b90d-4109-b092-563a572de480,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-1c8d52c6-4756-48d9-b9bd-102d0fe1dbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-9e8f7870-36ee-410f-881c-628480c70e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-91b84806-bfbc-4d11-b427-17c7d2699e21,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-5f726665-3496-44fd-b1d2-aaf956c82bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-d8ccc067-fcdb-4b64-84ff-630f3ca07aec,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-19c8b484-e76d-4054-b584-a247cdc3c8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177232186-172.17.0.5-1595423127870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38180,DS-1be343d0-e6f7-412e-be96-1cc8fa65307e,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-974879c5-b90d-4109-b092-563a572de480,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-1c8d52c6-4756-48d9-b9bd-102d0fe1dbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-9e8f7870-36ee-410f-881c-628480c70e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-91b84806-bfbc-4d11-b427-17c7d2699e21,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-5f726665-3496-44fd-b1d2-aaf956c82bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-d8ccc067-fcdb-4b64-84ff-630f3ca07aec,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-19c8b484-e76d-4054-b584-a247cdc3c8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469671054-172.17.0.5-1595423374277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39231,DS-ac77c4ac-5992-4f7c-a2d7-5aa2fdceb83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-d8e3fb47-5865-4575-9072-91ea3c096944,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-b0a4ab0b-7c8e-452a-87bf-d3f5de158363,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-6ea63a4e-48d6-44e8-8716-bdc35fd1ce35,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-5930fcea-85c5-4604-825c-3148b1ab74ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-569c7a43-2a41-42ee-a22e-5aa76cbd6ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-ccb1d7fd-fca1-4362-bf3b-c9a2d97169fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-e2a12ede-1c12-4b90-8e0c-2e1453ac2dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469671054-172.17.0.5-1595423374277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39231,DS-ac77c4ac-5992-4f7c-a2d7-5aa2fdceb83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-d8e3fb47-5865-4575-9072-91ea3c096944,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-b0a4ab0b-7c8e-452a-87bf-d3f5de158363,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-6ea63a4e-48d6-44e8-8716-bdc35fd1ce35,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-5930fcea-85c5-4604-825c-3148b1ab74ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-569c7a43-2a41-42ee-a22e-5aa76cbd6ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-ccb1d7fd-fca1-4362-bf3b-c9a2d97169fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-e2a12ede-1c12-4b90-8e0c-2e1453ac2dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547155713-172.17.0.5-1595423554611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-0e477424-917a-44ea-bdc9-5de4516896fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-d6a4b48e-7567-4500-a0f8-d79a12ca77ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-35d94c00-e109-4d7e-b454-cdb5f66daacb,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-09dcffb0-dd92-42d8-be53-2248c5f25636,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-eeec3d8c-31b2-4f14-aa35-25928e3c5046,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-0e7a62d9-bb47-457f-984c-dd22e58745ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-6a27f552-0f98-48b0-b248-c0c7d3a18b61,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-61de2d3d-9ae2-4840-8ea2-7c12fa828286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547155713-172.17.0.5-1595423554611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-0e477424-917a-44ea-bdc9-5de4516896fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-d6a4b48e-7567-4500-a0f8-d79a12ca77ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-35d94c00-e109-4d7e-b454-cdb5f66daacb,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-09dcffb0-dd92-42d8-be53-2248c5f25636,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-eeec3d8c-31b2-4f14-aa35-25928e3c5046,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-0e7a62d9-bb47-457f-984c-dd22e58745ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-6a27f552-0f98-48b0-b248-c0c7d3a18b61,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-61de2d3d-9ae2-4840-8ea2-7c12fa828286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485612937-172.17.0.5-1595423896053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-be97b080-ed11-4938-aba5-4bc8f52c6f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-d8baecbe-2442-46f9-9a5a-2854fbf4ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-d8302574-b502-42cf-b20c-ee69cb8774ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-d382fa69-99fe-4baf-9b8c-d9ba01171325,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-2e169f3f-d221-4fbe-8686-3dbe6e9752a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-0a37cd4c-0186-4de4-8dbf-946e1e0ef2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-a9361a51-f896-4cd7-ac44-c48b74c25b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-44656560-6ca9-47fd-a9dc-85094aa1dbaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485612937-172.17.0.5-1595423896053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-be97b080-ed11-4938-aba5-4bc8f52c6f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-d8baecbe-2442-46f9-9a5a-2854fbf4ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-d8302574-b502-42cf-b20c-ee69cb8774ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-d382fa69-99fe-4baf-9b8c-d9ba01171325,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-2e169f3f-d221-4fbe-8686-3dbe6e9752a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-0a37cd4c-0186-4de4-8dbf-946e1e0ef2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-a9361a51-f896-4cd7-ac44-c48b74c25b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-44656560-6ca9-47fd-a9dc-85094aa1dbaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 3108
