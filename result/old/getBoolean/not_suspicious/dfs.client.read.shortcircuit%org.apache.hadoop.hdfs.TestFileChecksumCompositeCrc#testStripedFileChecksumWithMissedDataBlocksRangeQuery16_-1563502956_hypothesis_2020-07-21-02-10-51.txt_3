reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049366361-172.17.0.7-1595298000286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41886,DS-b5fbbe56-4505-4d18-b51a-029286f72e86,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-8ea32833-5b70-435b-951b-3e413239b8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-fd20869a-8d49-4b7d-bd45-1d469c3a334c,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-508e4a97-03f8-4580-99fb-c2812157e443,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-a4db49cc-5b87-477b-aba2-44f2ace6fb18,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-b578ae44-f45b-4b6a-ade8-f3b37bdf1125,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-8fe20e93-8a37-4b1f-a2db-84eba2682095,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-df7ff4d1-ffb5-4d1c-9992-1ef35c4deaa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049366361-172.17.0.7-1595298000286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41886,DS-b5fbbe56-4505-4d18-b51a-029286f72e86,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-8ea32833-5b70-435b-951b-3e413239b8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-fd20869a-8d49-4b7d-bd45-1d469c3a334c,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-508e4a97-03f8-4580-99fb-c2812157e443,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-a4db49cc-5b87-477b-aba2-44f2ace6fb18,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-b578ae44-f45b-4b6a-ade8-f3b37bdf1125,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-8fe20e93-8a37-4b1f-a2db-84eba2682095,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-df7ff4d1-ffb5-4d1c-9992-1ef35c4deaa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824976363-172.17.0.7-1595298496207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39259,DS-fbc3267c-9e14-4eed-9d86-4db2ff1dd1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-2a6d624e-4d14-4dbb-a0ae-fd6bfa9ead4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-894d8850-3933-4084-a341-f29ef4f9989b,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-2e514390-c8ed-4724-81a7-fcc3ea9c2972,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-afcae510-9594-4fef-8934-009d93a63e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5738bca9-55a5-4b2c-9288-2793f992d6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-5941a339-264c-4963-99e6-ceacb8162503,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-9714c82d-b1bf-497c-a750-4712dac9cc2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824976363-172.17.0.7-1595298496207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39259,DS-fbc3267c-9e14-4eed-9d86-4db2ff1dd1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-2a6d624e-4d14-4dbb-a0ae-fd6bfa9ead4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-894d8850-3933-4084-a341-f29ef4f9989b,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-2e514390-c8ed-4724-81a7-fcc3ea9c2972,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-afcae510-9594-4fef-8934-009d93a63e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5738bca9-55a5-4b2c-9288-2793f992d6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-5941a339-264c-4963-99e6-ceacb8162503,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-9714c82d-b1bf-497c-a750-4712dac9cc2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825730430-172.17.0.7-1595298617055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-93104187-4bbb-4737-82dc-56913bf65607,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-510db77c-cf4b-46cc-8529-601d04ccad44,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-9fef6882-afd8-4f71-8d82-82d71a2cb231,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-61b0de5e-3d5d-4ebe-8e9d-55d984fdf79c,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-ccb2114f-6a0c-4359-b33e-1b0b827f758c,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-0e1ee118-c37b-4dcc-b3bc-0d4e2b6e1e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-96995d24-29b5-44ce-8c90-f58572525544,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-e64157a7-6e7e-41ea-8266-3d7c5bd452fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825730430-172.17.0.7-1595298617055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-93104187-4bbb-4737-82dc-56913bf65607,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-510db77c-cf4b-46cc-8529-601d04ccad44,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-9fef6882-afd8-4f71-8d82-82d71a2cb231,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-61b0de5e-3d5d-4ebe-8e9d-55d984fdf79c,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-ccb2114f-6a0c-4359-b33e-1b0b827f758c,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-0e1ee118-c37b-4dcc-b3bc-0d4e2b6e1e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-96995d24-29b5-44ce-8c90-f58572525544,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-e64157a7-6e7e-41ea-8266-3d7c5bd452fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213989040-172.17.0.7-1595298652430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41481,DS-27ec6cd9-e6b1-4bf4-aa45-0996fece2cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-bcc5c13a-fdcb-4d80-beac-6a0523674a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-a6c6e38b-dd99-45cc-ba49-3bd3f5a9fc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-383b47b9-88b4-4cbf-8611-caed5974e0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-f80cfb71-afe5-4984-9e77-3a08dcdd4abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-36dff7da-6a29-40a2-a43f-65dc95b7a9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-6c7ef687-1a97-477d-bc77-fb971c1e6cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-9e1c752e-693f-4345-bb40-f13bbfc324ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213989040-172.17.0.7-1595298652430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41481,DS-27ec6cd9-e6b1-4bf4-aa45-0996fece2cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-bcc5c13a-fdcb-4d80-beac-6a0523674a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-a6c6e38b-dd99-45cc-ba49-3bd3f5a9fc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-383b47b9-88b4-4cbf-8611-caed5974e0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-f80cfb71-afe5-4984-9e77-3a08dcdd4abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-36dff7da-6a29-40a2-a43f-65dc95b7a9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-6c7ef687-1a97-477d-bc77-fb971c1e6cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-9e1c752e-693f-4345-bb40-f13bbfc324ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117840660-172.17.0.7-1595298846474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37182,DS-6ab0b87e-edbb-4300-bf6d-08d514480d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-729bba04-bc8a-4077-99a3-74c2035e8e09,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-a8c9df84-0445-46f2-8aa9-461a75acd6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-d83a030a-b716-4949-8583-aa201c58a369,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-c0a3d970-b468-4f0e-ba18-80d2652b697a,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-4814fabb-e582-4392-a2e0-11d7855d6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-fa6eea48-8bf8-4afc-9772-f08909343df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-787f9a00-be4b-4252-a382-98c9373829b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117840660-172.17.0.7-1595298846474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37182,DS-6ab0b87e-edbb-4300-bf6d-08d514480d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-729bba04-bc8a-4077-99a3-74c2035e8e09,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-a8c9df84-0445-46f2-8aa9-461a75acd6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-d83a030a-b716-4949-8583-aa201c58a369,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-c0a3d970-b468-4f0e-ba18-80d2652b697a,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-4814fabb-e582-4392-a2e0-11d7855d6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-fa6eea48-8bf8-4afc-9772-f08909343df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-787f9a00-be4b-4252-a382-98c9373829b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991770816-172.17.0.7-1595299450090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38403,DS-4443cc58-4146-4330-8043-974a350ede75,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-27c00d2c-d113-42e9-ae3a-17139d1f1714,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-af5890d6-61bb-47b5-9e24-4e8164418cac,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-5cc711b2-4dd4-46ed-9910-e8215b1fbdde,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-4ffe09ff-63ed-4c6e-973c-05b7dced8cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-0269f31d-add1-492c-a9a9-5e20e303330a,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-062736f9-299d-43f5-aaa0-9f039413e30f,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-34d49fbf-a0f8-4434-9edd-752f74537dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991770816-172.17.0.7-1595299450090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38403,DS-4443cc58-4146-4330-8043-974a350ede75,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-27c00d2c-d113-42e9-ae3a-17139d1f1714,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-af5890d6-61bb-47b5-9e24-4e8164418cac,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-5cc711b2-4dd4-46ed-9910-e8215b1fbdde,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-4ffe09ff-63ed-4c6e-973c-05b7dced8cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-0269f31d-add1-492c-a9a9-5e20e303330a,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-062736f9-299d-43f5-aaa0-9f039413e30f,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-34d49fbf-a0f8-4434-9edd-752f74537dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614372381-172.17.0.7-1595299769745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-9e3b8ebc-2fa1-404f-ab73-8ec763531233,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-6a5058ee-be6d-4414-b45b-7251e78662ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-4839dbc4-cc14-4020-be54-aef28b3a71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-3fe88243-7644-47ea-9397-33826432f3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-dee2b60f-0d53-4f9a-ac2f-1498d9055664,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-67117529-049c-4ea0-b81e-eff9a6d644c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-43129c0a-13af-4282-97b7-691b046af38f,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-72111325-9a85-43f0-a39d-2407d904386d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614372381-172.17.0.7-1595299769745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-9e3b8ebc-2fa1-404f-ab73-8ec763531233,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-6a5058ee-be6d-4414-b45b-7251e78662ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-4839dbc4-cc14-4020-be54-aef28b3a71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-3fe88243-7644-47ea-9397-33826432f3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-dee2b60f-0d53-4f9a-ac2f-1498d9055664,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-67117529-049c-4ea0-b81e-eff9a6d644c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-43129c0a-13af-4282-97b7-691b046af38f,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-72111325-9a85-43f0-a39d-2407d904386d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332037049-172.17.0.7-1595299807465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-5e0cea2a-2d47-4be5-aa48-ce2837063ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-145037dd-c52a-4f85-9fa3-3f0d61a35220,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-3130535d-ea19-488d-ab62-d498548a3691,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-459911e7-149b-4cc1-b18c-e4b2573fcea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-95568d56-6333-48cd-84a2-35dbc71c6ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-bd917ac0-dc7b-43b9-b5b9-b7704e86aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-d2db6d3a-e460-445d-8234-3a88932bee06,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-de561f61-5352-4201-8ec3-b2a62b82142d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332037049-172.17.0.7-1595299807465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-5e0cea2a-2d47-4be5-aa48-ce2837063ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-145037dd-c52a-4f85-9fa3-3f0d61a35220,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-3130535d-ea19-488d-ab62-d498548a3691,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-459911e7-149b-4cc1-b18c-e4b2573fcea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-95568d56-6333-48cd-84a2-35dbc71c6ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-bd917ac0-dc7b-43b9-b5b9-b7704e86aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-d2db6d3a-e460-445d-8234-3a88932bee06,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-de561f61-5352-4201-8ec3-b2a62b82142d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680473170-172.17.0.7-1595299838583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43520,DS-514464c5-2260-4cd7-9a32-dffba67966fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-b2f904f5-d79c-4e04-bf77-f871d038cef9,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-e4713df9-88e2-489e-83f8-bd1e18d927e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-aa1c3f1e-d317-437d-854f-72b4ffc3dae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-1d482415-3a75-4756-9986-ae6297541f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-584ed4ea-c130-4de6-a0a4-b11fe7066b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-e41bc577-cd7e-45c5-b567-ac7b4101fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-5353e620-70b2-49c1-afa2-46cdbae62b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680473170-172.17.0.7-1595299838583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43520,DS-514464c5-2260-4cd7-9a32-dffba67966fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-b2f904f5-d79c-4e04-bf77-f871d038cef9,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-e4713df9-88e2-489e-83f8-bd1e18d927e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-aa1c3f1e-d317-437d-854f-72b4ffc3dae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-1d482415-3a75-4756-9986-ae6297541f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-584ed4ea-c130-4de6-a0a4-b11fe7066b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-e41bc577-cd7e-45c5-b567-ac7b4101fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-5353e620-70b2-49c1-afa2-46cdbae62b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87460726-172.17.0.7-1595300129588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-d9eb4d10-0161-4194-843e-62d8cce522ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-817ebe93-197c-49de-8629-73c65b129846,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-35181deb-473e-4bc0-bc8b-a74b36071379,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-530ac378-0dcc-4c5a-8831-ce3855e136df,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-788aa475-a75e-4afa-8df3-d2d5a9e19f94,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-2fd70d38-b8dd-42a5-bfbf-854f926ddeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-6ca034a9-ebaa-4040-8ea0-cf9f9372dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-58a71d7f-e80a-469c-8918-2f9ca6a4e7e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87460726-172.17.0.7-1595300129588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-d9eb4d10-0161-4194-843e-62d8cce522ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-817ebe93-197c-49de-8629-73c65b129846,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-35181deb-473e-4bc0-bc8b-a74b36071379,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-530ac378-0dcc-4c5a-8831-ce3855e136df,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-788aa475-a75e-4afa-8df3-d2d5a9e19f94,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-2fd70d38-b8dd-42a5-bfbf-854f926ddeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-6ca034a9-ebaa-4040-8ea0-cf9f9372dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-58a71d7f-e80a-469c-8918-2f9ca6a4e7e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068289866-172.17.0.7-1595300222911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-6566cee7-c469-44ec-a70e-555ac5f5fb85,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-1ff81e84-d002-4758-b3a2-9baa1aaa3732,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-cd9ee296-61a5-43b9-8f8f-3f40174b9daa,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-1b260721-7736-4972-9778-cfcee1f86977,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-2364abba-b5db-4847-b94d-e8cb7c962cac,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-cb73611a-a002-4c8a-a0e3-0ae58ca5338f,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-a8c3b9c4-3564-49ad-a03f-7917b82f76e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-a0270977-82bd-4e54-af10-127418c9bba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068289866-172.17.0.7-1595300222911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-6566cee7-c469-44ec-a70e-555ac5f5fb85,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-1ff81e84-d002-4758-b3a2-9baa1aaa3732,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-cd9ee296-61a5-43b9-8f8f-3f40174b9daa,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-1b260721-7736-4972-9778-cfcee1f86977,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-2364abba-b5db-4847-b94d-e8cb7c962cac,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-cb73611a-a002-4c8a-a0e3-0ae58ca5338f,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-a8c3b9c4-3564-49ad-a03f-7917b82f76e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-a0270977-82bd-4e54-af10-127418c9bba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459930893-172.17.0.7-1595300261456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-938e308b-016b-476e-a35f-064264848dad,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-d7d5d2d0-49c0-4491-bafd-bac363296f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-d9304278-cb89-4536-9f5e-f378f8d5b554,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-dbcf4f05-650f-44b1-9ae8-0cc283026f36,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-8ff68800-a728-4095-b48a-1f92d3e6f893,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-263204e2-a4a3-4424-9f9d-e18f2e3bfe12,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-ce1856bc-ab8a-4fbf-90bc-3b82b7575bee,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-ff15d83d-6a0e-4ab9-8919-03e6aced07b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459930893-172.17.0.7-1595300261456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-938e308b-016b-476e-a35f-064264848dad,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-d7d5d2d0-49c0-4491-bafd-bac363296f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-d9304278-cb89-4536-9f5e-f378f8d5b554,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-dbcf4f05-650f-44b1-9ae8-0cc283026f36,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-8ff68800-a728-4095-b48a-1f92d3e6f893,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-263204e2-a4a3-4424-9f9d-e18f2e3bfe12,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-ce1856bc-ab8a-4fbf-90bc-3b82b7575bee,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-ff15d83d-6a0e-4ab9-8919-03e6aced07b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5954059-172.17.0.7-1595300847609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-dcf26c01-c34c-4977-8be7-6e7c4dbfc0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-8e6db67d-880e-413d-9ac9-5b7990eca213,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-f26ec988-541f-4999-903a-0c43c30ab187,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-8c4da476-0b69-42ca-b215-b21e71c1e87e,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-38fe9ae6-dad5-4c81-a200-583614e1917d,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-c89c4186-7eac-4464-9613-a10b5ba4202d,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-ba172896-68dc-466c-bbc3-1a46aa50484d,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-36f19c6d-9b24-4aa0-8ca9-7c4ca9fc8471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5954059-172.17.0.7-1595300847609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-dcf26c01-c34c-4977-8be7-6e7c4dbfc0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-8e6db67d-880e-413d-9ac9-5b7990eca213,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-f26ec988-541f-4999-903a-0c43c30ab187,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-8c4da476-0b69-42ca-b215-b21e71c1e87e,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-38fe9ae6-dad5-4c81-a200-583614e1917d,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-c89c4186-7eac-4464-9613-a10b5ba4202d,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-ba172896-68dc-466c-bbc3-1a46aa50484d,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-36f19c6d-9b24-4aa0-8ca9-7c4ca9fc8471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337839930-172.17.0.7-1595301198674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-c1bb6274-9570-42a9-8204-256164256b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-e3b527e1-5116-4169-ad82-339ceedd789d,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-1320d109-0c99-4458-ab89-20b49f117da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-5f463a9c-584a-43e4-9ad2-6afdf2eafb20,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-dedc9fe1-c21f-4153-8dcc-9871eed60c66,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-1412b209-36df-4382-bc16-05b66730d08e,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-4ca00fd5-52c4-4cdd-bf4a-5f692590a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-1567082f-0a61-4732-a631-f6bd25718139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337839930-172.17.0.7-1595301198674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-c1bb6274-9570-42a9-8204-256164256b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-e3b527e1-5116-4169-ad82-339ceedd789d,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-1320d109-0c99-4458-ab89-20b49f117da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-5f463a9c-584a-43e4-9ad2-6afdf2eafb20,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-dedc9fe1-c21f-4153-8dcc-9871eed60c66,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-1412b209-36df-4382-bc16-05b66730d08e,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-4ca00fd5-52c4-4cdd-bf4a-5f692590a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-1567082f-0a61-4732-a631-f6bd25718139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096301807-172.17.0.7-1595301469710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34946,DS-3d130aa7-a9e6-4688-9aa9-9c03305aac13,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-dc44f060-eb25-44c4-bd70-0c77c92b35f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-3a351782-5b43-4502-b329-aa7f17a4229f,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-0c7cfe48-3cf8-4f1d-8ea8-043aa54e7841,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-f0d1aa2b-c319-496d-99de-7eb4d885e1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-d5b11495-1e68-4f55-900c-b04e8f79fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-e5fb864a-ff45-4066-85b8-3e168f3022ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-9f3a27c9-3bb1-42ed-8050-7437757d4fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096301807-172.17.0.7-1595301469710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34946,DS-3d130aa7-a9e6-4688-9aa9-9c03305aac13,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-dc44f060-eb25-44c4-bd70-0c77c92b35f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-3a351782-5b43-4502-b329-aa7f17a4229f,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-0c7cfe48-3cf8-4f1d-8ea8-043aa54e7841,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-f0d1aa2b-c319-496d-99de-7eb4d885e1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-d5b11495-1e68-4f55-900c-b04e8f79fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-e5fb864a-ff45-4066-85b8-3e168f3022ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-9f3a27c9-3bb1-42ed-8050-7437757d4fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418606771-172.17.0.7-1595301750523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-67d38e76-c073-4802-9c79-a37b964ba048,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-0c3d22ad-e0f5-4108-bcec-30a4dc6a5e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-ab36a677-b09b-4a3f-a08a-6c3ba5ef907b,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-1aaa2364-efa6-4cca-8ee4-82cbc3a21164,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-4ae2f72a-a84d-415d-aa0a-494f684ab7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-c44b773f-d7af-4167-b816-fcc2288b1145,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-1fd8c9be-12b7-479b-936e-9e0c5b1c3c37,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-2a4592d5-02e0-4f46-ba3c-3dfdd7afb84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418606771-172.17.0.7-1595301750523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-67d38e76-c073-4802-9c79-a37b964ba048,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-0c3d22ad-e0f5-4108-bcec-30a4dc6a5e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-ab36a677-b09b-4a3f-a08a-6c3ba5ef907b,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-1aaa2364-efa6-4cca-8ee4-82cbc3a21164,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-4ae2f72a-a84d-415d-aa0a-494f684ab7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-c44b773f-d7af-4167-b816-fcc2288b1145,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-1fd8c9be-12b7-479b-936e-9e0c5b1c3c37,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-2a4592d5-02e0-4f46-ba3c-3dfdd7afb84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199279848-172.17.0.7-1595301814470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-44e2d731-b429-4b8c-bddd-e7ff87fe802a,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-4ede8992-a29b-4369-af20-d8ecd406190e,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-96c03844-9347-4f1c-9067-904509439244,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-8bdab883-f6d3-448a-96e2-5fba5df92aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-a416b3f7-c768-4b11-8658-5c1c1e84c7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-51fc9c2b-ba59-4c50-86e5-b66e2dfe29d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-83062920-cc41-4b3c-ae8e-2596bb058bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-a644f7c7-ca9b-4f17-87af-9083c31dcb21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199279848-172.17.0.7-1595301814470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-44e2d731-b429-4b8c-bddd-e7ff87fe802a,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-4ede8992-a29b-4369-af20-d8ecd406190e,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-96c03844-9347-4f1c-9067-904509439244,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-8bdab883-f6d3-448a-96e2-5fba5df92aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-a416b3f7-c768-4b11-8658-5c1c1e84c7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-51fc9c2b-ba59-4c50-86e5-b66e2dfe29d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-83062920-cc41-4b3c-ae8e-2596bb058bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-a644f7c7-ca9b-4f17-87af-9083c31dcb21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3116808-172.17.0.7-1595301880728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41192,DS-b36146ee-2907-4429-8c32-8a378860b762,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-347f0765-f012-4204-b3ca-2b6757f6dda0,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-a218f5bd-bd8f-4d1f-a6f5-f48ffebc3f34,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-3889782b-ec6c-4a0b-b095-ce69f20d4e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-fe486b5a-753d-4223-bd0b-c45d3b01e4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-16513428-ff12-433b-9f3c-8eb6b6a2c2da,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-57a21b14-928a-45f6-a88a-4a0e1beb6e31,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-32157a8b-a67f-4a44-bbc5-d37e6bab6404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3116808-172.17.0.7-1595301880728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41192,DS-b36146ee-2907-4429-8c32-8a378860b762,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-347f0765-f012-4204-b3ca-2b6757f6dda0,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-a218f5bd-bd8f-4d1f-a6f5-f48ffebc3f34,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-3889782b-ec6c-4a0b-b095-ce69f20d4e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-fe486b5a-753d-4223-bd0b-c45d3b01e4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-16513428-ff12-433b-9f3c-8eb6b6a2c2da,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-57a21b14-928a-45f6-a88a-4a0e1beb6e31,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-32157a8b-a67f-4a44-bbc5-d37e6bab6404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5143
