reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752799182-172.17.0.18-1595374499858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44998,DS-44f8305e-f8a2-4210-9683-5e8005ce2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-121e8f6c-9543-4932-a521-982fadf80f75,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-5ed7f709-db2c-4c54-b28b-7bb4ac229968,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-cdf14460-7f9c-4144-88a6-4311de390630,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-b908baea-f6f6-4977-9d5e-c5f80344b7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-d05bd9ee-a95e-4593-90fa-798de59cd076,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-a603d1e6-d051-401a-8bd8-12bbaad98a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-2b86d024-c741-473f-889d-6fd9a4a27bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752799182-172.17.0.18-1595374499858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44998,DS-44f8305e-f8a2-4210-9683-5e8005ce2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-121e8f6c-9543-4932-a521-982fadf80f75,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-5ed7f709-db2c-4c54-b28b-7bb4ac229968,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-cdf14460-7f9c-4144-88a6-4311de390630,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-b908baea-f6f6-4977-9d5e-c5f80344b7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-d05bd9ee-a95e-4593-90fa-798de59cd076,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-a603d1e6-d051-401a-8bd8-12bbaad98a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-2b86d024-c741-473f-889d-6fd9a4a27bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401331150-172.17.0.18-1595374641725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46805,DS-76397e10-410e-4248-980a-cbd7127d1ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-fd098c5a-ed40-4725-bf77-8cb32f2ed459,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-c3ee3cab-df27-461f-b767-178f67e20d63,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-b1b7ed08-397b-42bd-b878-b1e2d80677ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-32b95831-17f5-43c0-bc47-4e4d22274cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-62abf678-0973-4568-b793-24e82de2b460,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-52be3408-618b-4b96-83b4-867d12fc41f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-ba870d30-25ba-4c57-9dcf-4fcb3c05aed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401331150-172.17.0.18-1595374641725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46805,DS-76397e10-410e-4248-980a-cbd7127d1ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-fd098c5a-ed40-4725-bf77-8cb32f2ed459,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-c3ee3cab-df27-461f-b767-178f67e20d63,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-b1b7ed08-397b-42bd-b878-b1e2d80677ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-32b95831-17f5-43c0-bc47-4e4d22274cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-62abf678-0973-4568-b793-24e82de2b460,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-52be3408-618b-4b96-83b4-867d12fc41f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-ba870d30-25ba-4c57-9dcf-4fcb3c05aed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001339801-172.17.0.18-1595375013628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-4eb57f07-7b09-404d-863a-845c1731f6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-3857ef73-5ace-4259-8e94-042e4282b688,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-15c0c745-ec3c-45c3-957d-9c62395843c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-6a8b92b9-b2a6-483f-a88a-c793248dcc05,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-6d0b39f1-461a-4838-992f-f26dd5a35fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-df710912-852a-48aa-8d06-0b4afc61e871,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-41ad355c-247d-4ceb-81c1-fcecdc8bfd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-93fd5286-f45c-497e-abd9-879a94187582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001339801-172.17.0.18-1595375013628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-4eb57f07-7b09-404d-863a-845c1731f6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-3857ef73-5ace-4259-8e94-042e4282b688,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-15c0c745-ec3c-45c3-957d-9c62395843c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-6a8b92b9-b2a6-483f-a88a-c793248dcc05,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-6d0b39f1-461a-4838-992f-f26dd5a35fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-df710912-852a-48aa-8d06-0b4afc61e871,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-41ad355c-247d-4ceb-81c1-fcecdc8bfd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-93fd5286-f45c-497e-abd9-879a94187582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767565225-172.17.0.18-1595375074634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-7c4c811c-9144-4bf4-8a69-84a1064d6c73,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-f144c720-5942-4d7a-a0ff-f6f68cd0d0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-460f7b79-2129-45ef-8c34-03ef2963128f,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-aec9e2a1-bd80-407d-8b53-a1653cf50dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-34eb5159-82fa-4a32-9d8d-9a626d527d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-b10b71bb-9ea3-4539-90d6-ada85b1ffc73,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-3c55fbe0-af81-436e-a543-ad0967c7121f,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-767f66d7-aaa7-4b39-89f0-fc0d97811c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767565225-172.17.0.18-1595375074634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-7c4c811c-9144-4bf4-8a69-84a1064d6c73,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-f144c720-5942-4d7a-a0ff-f6f68cd0d0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-460f7b79-2129-45ef-8c34-03ef2963128f,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-aec9e2a1-bd80-407d-8b53-a1653cf50dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-34eb5159-82fa-4a32-9d8d-9a626d527d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-b10b71bb-9ea3-4539-90d6-ada85b1ffc73,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-3c55fbe0-af81-436e-a543-ad0967c7121f,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-767f66d7-aaa7-4b39-89f0-fc0d97811c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081268091-172.17.0.18-1595375511585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-056b2f47-df71-4453-bf6e-9675e6cd97e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-927e3408-8419-4a42-a650-c846f011644e,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-006701b7-8ebb-45e8-aee1-d9cf513d41b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-036a67b8-2aa7-4b59-ac51-f03aa099592c,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-75781811-cf69-4278-a124-077131eb0b01,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-cbc55a5f-d75e-4878-85b4-29768854d1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-e1be9011-af00-4145-86ad-7c428cee4a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-7babc8ed-99cc-409e-9e7c-84440dce0862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081268091-172.17.0.18-1595375511585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-056b2f47-df71-4453-bf6e-9675e6cd97e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-927e3408-8419-4a42-a650-c846f011644e,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-006701b7-8ebb-45e8-aee1-d9cf513d41b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-036a67b8-2aa7-4b59-ac51-f03aa099592c,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-75781811-cf69-4278-a124-077131eb0b01,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-cbc55a5f-d75e-4878-85b4-29768854d1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-e1be9011-af00-4145-86ad-7c428cee4a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-7babc8ed-99cc-409e-9e7c-84440dce0862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963290334-172.17.0.18-1595375577401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34683,DS-3bfe48a0-c0f9-421b-a7d5-309c57b2f2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-e69a5ed3-1694-4c51-8bba-42963e9f1e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-7f1e6053-7a14-4aa7-9284-b0c416c7fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-fd021052-1c75-421c-bfc8-cef224333067,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-b4a4924c-ac87-4bb5-9fa4-9bb5dc0e0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-d68b7ed6-161e-47b8-b0d2-d8975ab05120,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-ffa5f91d-1046-4521-9b86-f5882b6532ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-8bca42ed-db95-4bc2-ba3f-5465285ed30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963290334-172.17.0.18-1595375577401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34683,DS-3bfe48a0-c0f9-421b-a7d5-309c57b2f2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-e69a5ed3-1694-4c51-8bba-42963e9f1e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-7f1e6053-7a14-4aa7-9284-b0c416c7fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-fd021052-1c75-421c-bfc8-cef224333067,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-b4a4924c-ac87-4bb5-9fa4-9bb5dc0e0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-d68b7ed6-161e-47b8-b0d2-d8975ab05120,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-ffa5f91d-1046-4521-9b86-f5882b6532ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-8bca42ed-db95-4bc2-ba3f-5465285ed30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424097137-172.17.0.18-1595375606248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-4c9c1b1f-02ec-4786-8986-989854bc213c,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-ead87c3d-b56d-41e9-b02c-608b63f2f1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-70459395-7e42-41a5-ad60-4fc6e0dd04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-6b0162bb-a21a-400a-a7f5-74332bda3429,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-412b9eda-01fa-462d-8685-904a024692e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-5f61aed4-0a9d-414f-ba38-e4e602c1e443,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-82f51039-a121-493b-95ab-b2e924741179,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-c5968ca0-2f34-4c4d-806c-fd044c1211f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424097137-172.17.0.18-1595375606248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-4c9c1b1f-02ec-4786-8986-989854bc213c,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-ead87c3d-b56d-41e9-b02c-608b63f2f1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-70459395-7e42-41a5-ad60-4fc6e0dd04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-6b0162bb-a21a-400a-a7f5-74332bda3429,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-412b9eda-01fa-462d-8685-904a024692e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-5f61aed4-0a9d-414f-ba38-e4e602c1e443,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-82f51039-a121-493b-95ab-b2e924741179,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-c5968ca0-2f34-4c4d-806c-fd044c1211f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466847746-172.17.0.18-1595375872120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42848,DS-c3f2ee37-3877-4c25-95b7-9e05ac56c23d,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-0417a863-a76e-4e38-a935-50b219a4c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-4327576b-9241-4ccb-b01d-e8674523d755,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-4a1e7450-5490-4a29-a965-22bdca1ca4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-a8724d87-373d-40b8-a04b-80488b64e2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-a293ca40-28a3-4417-a391-051a1a804f49,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-89bf8542-d901-4764-bf15-b368e6d66f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-bc6bbfc7-95be-42b6-b9b2-d8cf71b756be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466847746-172.17.0.18-1595375872120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42848,DS-c3f2ee37-3877-4c25-95b7-9e05ac56c23d,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-0417a863-a76e-4e38-a935-50b219a4c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-4327576b-9241-4ccb-b01d-e8674523d755,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-4a1e7450-5490-4a29-a965-22bdca1ca4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-a8724d87-373d-40b8-a04b-80488b64e2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-a293ca40-28a3-4417-a391-051a1a804f49,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-89bf8542-d901-4764-bf15-b368e6d66f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-bc6bbfc7-95be-42b6-b9b2-d8cf71b756be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013171556-172.17.0.18-1595376108938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-b7f140e2-7df5-40fe-8526-8734821e88d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-6cbb0f00-8517-407b-8bb7-7bdf87e4b0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-53c73e5b-c14d-47c2-95c3-a14b1f2e106d,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-adb4aefe-fe3b-49fa-8bd8-ea58baa8eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-fbed45a1-04cb-413e-a6e3-d82d38d50ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-b09c3186-ab1e-4aad-aa57-615330b99455,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-8417c70e-43df-4cdd-b437-8743ce18938f,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-0a0a2b2d-9a7d-4b0a-959b-12537c3c7048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013171556-172.17.0.18-1595376108938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-b7f140e2-7df5-40fe-8526-8734821e88d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-6cbb0f00-8517-407b-8bb7-7bdf87e4b0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-53c73e5b-c14d-47c2-95c3-a14b1f2e106d,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-adb4aefe-fe3b-49fa-8bd8-ea58baa8eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-fbed45a1-04cb-413e-a6e3-d82d38d50ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-b09c3186-ab1e-4aad-aa57-615330b99455,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-8417c70e-43df-4cdd-b437-8743ce18938f,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-0a0a2b2d-9a7d-4b0a-959b-12537c3c7048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566188729-172.17.0.18-1595376369028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44416,DS-9857bdc0-e505-4170-81e4-2e95adcc6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-e61b186c-5711-4562-adce-af517e25afb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-1bb4543f-a8c3-4672-a574-903b402ac2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-81ccca81-6db0-4832-9c36-42ea62bd90b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-d9c6d9df-cbc7-4973-940e-594f4320d668,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-138065da-aee6-41e2-ba77-4a6b43d0a237,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-38b766c7-5c38-4e6a-97d3-460ccaaa45a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-a40029d9-d8b8-4564-b634-8751a8df9d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566188729-172.17.0.18-1595376369028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44416,DS-9857bdc0-e505-4170-81e4-2e95adcc6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-e61b186c-5711-4562-adce-af517e25afb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-1bb4543f-a8c3-4672-a574-903b402ac2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-81ccca81-6db0-4832-9c36-42ea62bd90b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-d9c6d9df-cbc7-4973-940e-594f4320d668,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-138065da-aee6-41e2-ba77-4a6b43d0a237,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-38b766c7-5c38-4e6a-97d3-460ccaaa45a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-a40029d9-d8b8-4564-b634-8751a8df9d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69705156-172.17.0.18-1595376400196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45675,DS-dfeaf08b-1a95-429e-b947-1e708e0eb3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-922e4310-da82-42d5-b255-00338dbcacdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-9a5dd9c3-88a8-41c9-8fb9-d95590df08e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-3a8924db-16fa-42f9-857b-5a27e1bf5f32,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-4aea494f-d840-4db9-9d9f-333c6c08fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-7d5a3b33-4f95-482f-8903-67a50569638a,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-5d8099cc-c9d0-4766-9871-e8ef28edccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-59b60647-d537-4384-8cbe-74989e966a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69705156-172.17.0.18-1595376400196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45675,DS-dfeaf08b-1a95-429e-b947-1e708e0eb3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-922e4310-da82-42d5-b255-00338dbcacdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-9a5dd9c3-88a8-41c9-8fb9-d95590df08e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-3a8924db-16fa-42f9-857b-5a27e1bf5f32,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-4aea494f-d840-4db9-9d9f-333c6c08fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-7d5a3b33-4f95-482f-8903-67a50569638a,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-5d8099cc-c9d0-4766-9871-e8ef28edccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-59b60647-d537-4384-8cbe-74989e966a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422778550-172.17.0.18-1595376905622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-4f8eb543-b7f4-4cef-966f-f4ccf41825fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-f9a6c678-f2d9-4153-97f5-d6b2101ed28c,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-86789c6d-e2cc-4605-b231-2011112f2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-6b40d8cf-0f35-4153-9942-f5d441f9d055,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-3eea93d7-767f-40d5-b756-a8b86ef2e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-66949057-c5b2-4466-8157-f9b8f5a1667f,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-3c7d5cbd-ac4b-4557-a3f0-38d0136a0e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-63b3952d-8dc0-4ec1-acd1-f77fadc3c3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422778550-172.17.0.18-1595376905622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-4f8eb543-b7f4-4cef-966f-f4ccf41825fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-f9a6c678-f2d9-4153-97f5-d6b2101ed28c,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-86789c6d-e2cc-4605-b231-2011112f2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-6b40d8cf-0f35-4153-9942-f5d441f9d055,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-3eea93d7-767f-40d5-b756-a8b86ef2e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-66949057-c5b2-4466-8157-f9b8f5a1667f,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-3c7d5cbd-ac4b-4557-a3f0-38d0136a0e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-63b3952d-8dc0-4ec1-acd1-f77fadc3c3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641121131-172.17.0.18-1595376972872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-85537af1-84c5-402f-952a-b8e751f5c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-4e4dd08a-4edb-4f99-830d-3f05d7d52076,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-5be031ec-1124-4d55-b6aa-f34064df4716,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-9b54c497-d762-4d47-8a99-d5b9bcafe73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-233d353b-74a8-419e-b268-e19becea590f,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-db7061fc-73ff-447a-a61a-ad759f6670d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-23d9abd9-a9a2-431d-895f-443046ba72b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-12fae4ec-ac33-49f6-a71b-ebdb8de3554a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641121131-172.17.0.18-1595376972872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-85537af1-84c5-402f-952a-b8e751f5c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-4e4dd08a-4edb-4f99-830d-3f05d7d52076,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-5be031ec-1124-4d55-b6aa-f34064df4716,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-9b54c497-d762-4d47-8a99-d5b9bcafe73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-233d353b-74a8-419e-b268-e19becea590f,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-db7061fc-73ff-447a-a61a-ad759f6670d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-23d9abd9-a9a2-431d-895f-443046ba72b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-12fae4ec-ac33-49f6-a71b-ebdb8de3554a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634847312-172.17.0.18-1595377163713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-20f39178-43b5-4496-8b91-1d79009f30af,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-a01d9a9d-7bed-4e6b-acec-bb6ca62f8679,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-a0a4780c-6658-4b47-b120-04cb3969adcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-a90f2f21-07d0-486d-9b6b-4bdfefc1f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-17d01179-fa36-4429-b259-16e3577f5e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-2489509b-b5c3-4406-ae90-ce04a9d31cad,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-bb995521-641e-4bf7-90f1-c326fe26e788,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-9d32dbea-a73b-430c-840e-87d8fe4ecbf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634847312-172.17.0.18-1595377163713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-20f39178-43b5-4496-8b91-1d79009f30af,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-a01d9a9d-7bed-4e6b-acec-bb6ca62f8679,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-a0a4780c-6658-4b47-b120-04cb3969adcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-a90f2f21-07d0-486d-9b6b-4bdfefc1f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-17d01179-fa36-4429-b259-16e3577f5e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-2489509b-b5c3-4406-ae90-ce04a9d31cad,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-bb995521-641e-4bf7-90f1-c326fe26e788,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-9d32dbea-a73b-430c-840e-87d8fe4ecbf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589371501-172.17.0.18-1595377725935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39462,DS-783025da-05be-49d2-bfd8-7e97309779e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-a3c3548b-17f5-47c4-8472-58a7edfd9c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-afb0f8ab-81ea-4ddd-9ce4-593eb8c6f433,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-afadfa61-3d9c-4b00-9176-b292a8882884,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-780a8009-e778-42fb-a995-9ab1b76175df,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-0749aaa1-444e-4c91-95c1-0561ac1be9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-8c7c5d08-1d7a-4b6c-8d4d-eff8e39aad15,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-a814a8e1-3ce8-4938-98db-1b6f3caf39c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589371501-172.17.0.18-1595377725935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39462,DS-783025da-05be-49d2-bfd8-7e97309779e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-a3c3548b-17f5-47c4-8472-58a7edfd9c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-afb0f8ab-81ea-4ddd-9ce4-593eb8c6f433,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-afadfa61-3d9c-4b00-9176-b292a8882884,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-780a8009-e778-42fb-a995-9ab1b76175df,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-0749aaa1-444e-4c91-95c1-0561ac1be9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-8c7c5d08-1d7a-4b6c-8d4d-eff8e39aad15,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-a814a8e1-3ce8-4938-98db-1b6f3caf39c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77430680-172.17.0.18-1595378288905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41298,DS-2d4c722f-04d2-413e-8303-8eef0f1e743a,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-d085e2b0-a9fc-4bcf-b626-d6c1c0ac05df,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-1063b34b-74d1-4187-8a28-eca60c3240a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-32117a4b-7732-46c6-9c55-e4315c2818af,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-7f2b4611-9403-4978-8e39-ef3d36b484e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-45d362b6-1aa4-4a8d-b77e-2d11a6be2359,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-c7142d3c-c4cf-4d13-a597-f8ae59fdf90a,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-2c2a1454-086b-4e31-a5a2-eb446845a627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77430680-172.17.0.18-1595378288905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41298,DS-2d4c722f-04d2-413e-8303-8eef0f1e743a,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-d085e2b0-a9fc-4bcf-b626-d6c1c0ac05df,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-1063b34b-74d1-4187-8a28-eca60c3240a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-32117a4b-7732-46c6-9c55-e4315c2818af,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-7f2b4611-9403-4978-8e39-ef3d36b484e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-45d362b6-1aa4-4a8d-b77e-2d11a6be2359,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-c7142d3c-c4cf-4d13-a597-f8ae59fdf90a,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-2c2a1454-086b-4e31-a5a2-eb446845a627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401627031-172.17.0.18-1595378347073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-77c3e129-f509-4459-a550-22bbfb5422ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-39794609-70d8-4eb9-8302-9a478cf8c24e,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-0d7ae641-751f-4315-aa6f-ce9ca9a3f824,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-9673b33b-95c4-4796-9c4f-a12b7c9a8a92,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-03493892-0388-4807-963d-0d192c835350,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-c7a6d5fd-ad7f-4f0c-a269-4c688def4eef,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-29727ee8-c76e-4425-b99d-5ba40fc8341d,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-8eff8d57-4e15-4dad-a3c5-4c5e4cb926bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401627031-172.17.0.18-1595378347073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-77c3e129-f509-4459-a550-22bbfb5422ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-39794609-70d8-4eb9-8302-9a478cf8c24e,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-0d7ae641-751f-4315-aa6f-ce9ca9a3f824,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-9673b33b-95c4-4796-9c4f-a12b7c9a8a92,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-03493892-0388-4807-963d-0d192c835350,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-c7a6d5fd-ad7f-4f0c-a269-4c688def4eef,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-29727ee8-c76e-4425-b99d-5ba40fc8341d,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-8eff8d57-4e15-4dad-a3c5-4c5e4cb926bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35021890-172.17.0.18-1595378481561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-6d762a27-a5b6-4f11-bbcd-966261aef9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-10cc240d-ef4c-48e6-b5e5-077fe61e1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-4a6a2c1b-f8ed-47cc-84d4-5c2a19e1e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-de9618b6-b3f3-4771-9834-1c2f28764f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-648220c3-9b97-4e41-ba1d-c62c73b69d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-0ba01f35-49fd-43f0-9522-c12734a31d65,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-a70aac1b-2b2a-4b98-912a-8b76926e13d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-458d6d6a-aa8f-4992-9866-5702354e09c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35021890-172.17.0.18-1595378481561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-6d762a27-a5b6-4f11-bbcd-966261aef9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-10cc240d-ef4c-48e6-b5e5-077fe61e1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-4a6a2c1b-f8ed-47cc-84d4-5c2a19e1e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-de9618b6-b3f3-4771-9834-1c2f28764f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-648220c3-9b97-4e41-ba1d-c62c73b69d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-0ba01f35-49fd-43f0-9522-c12734a31d65,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-a70aac1b-2b2a-4b98-912a-8b76926e13d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-458d6d6a-aa8f-4992-9866-5702354e09c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943809624-172.17.0.18-1595378542805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-24addb6c-3b50-4db6-8ff8-eb094bfdaf69,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-7c1ac0ea-fdec-44dc-b45d-cdff13e4b104,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-1907f027-1434-439a-ae39-19308cc34604,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-3ee963b9-3034-4a95-85af-0f9085821d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-847da1c1-938f-48b0-ba6e-2f9f5af7b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-ae29f94e-0be8-475b-acec-bc9547a306ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-86abed20-8603-4a01-a7b2-f8035da08184,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-8eeebc1c-d7da-4670-8bf7-cc9d9ccd9b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943809624-172.17.0.18-1595378542805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-24addb6c-3b50-4db6-8ff8-eb094bfdaf69,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-7c1ac0ea-fdec-44dc-b45d-cdff13e4b104,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-1907f027-1434-439a-ae39-19308cc34604,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-3ee963b9-3034-4a95-85af-0f9085821d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-847da1c1-938f-48b0-ba6e-2f9f5af7b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-ae29f94e-0be8-475b-acec-bc9547a306ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-86abed20-8603-4a01-a7b2-f8035da08184,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-8eeebc1c-d7da-4670-8bf7-cc9d9ccd9b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110588984-172.17.0.18-1595378795642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35632,DS-4f0e4277-d349-4efb-af69-38e0b136ba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-2726040f-3018-45fe-ae94-a8cf367c47f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-9949e70b-3bc3-482c-83f7-ccf8c14254d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-a4f05a01-4200-4dfd-944c-3029456f7d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-0d489e92-a995-4dcc-a82b-14aec6128b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-16cf80ae-9c63-4eab-a66f-360f999890e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-401aff92-294a-4579-b762-d4f9c57aa01b,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-3d56812f-8b5d-4017-9b18-bab4032ff589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110588984-172.17.0.18-1595378795642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35632,DS-4f0e4277-d349-4efb-af69-38e0b136ba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-2726040f-3018-45fe-ae94-a8cf367c47f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-9949e70b-3bc3-482c-83f7-ccf8c14254d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-a4f05a01-4200-4dfd-944c-3029456f7d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-0d489e92-a995-4dcc-a82b-14aec6128b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-16cf80ae-9c63-4eab-a66f-360f999890e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-401aff92-294a-4579-b762-d4f9c57aa01b,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-3d56812f-8b5d-4017-9b18-bab4032ff589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435875808-172.17.0.18-1595378823028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33168,DS-d8eb995e-18a3-44ad-8e5f-2779e5b14827,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-f26e02fe-d4b3-4c3b-adb8-5fa2f7691180,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-aa29473a-6bd9-4097-ba57-ea8811187a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-eb250b30-1f14-4175-9cbc-37722d1f1f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-4d2ee2ff-21c0-475b-9fea-b1827012959f,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-d5debc1a-75a8-43bf-8abd-6874a89f5128,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-d91ec06b-50c8-44d2-997b-2d8c37fc1f74,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-93db8be4-6677-451b-82e7-5913538833b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435875808-172.17.0.18-1595378823028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33168,DS-d8eb995e-18a3-44ad-8e5f-2779e5b14827,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-f26e02fe-d4b3-4c3b-adb8-5fa2f7691180,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-aa29473a-6bd9-4097-ba57-ea8811187a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-eb250b30-1f14-4175-9cbc-37722d1f1f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-4d2ee2ff-21c0-475b-9fea-b1827012959f,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-d5debc1a-75a8-43bf-8abd-6874a89f5128,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-d91ec06b-50c8-44d2-997b-2d8c37fc1f74,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-93db8be4-6677-451b-82e7-5913538833b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168187759-172.17.0.18-1595379082902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43751,DS-87977bbc-6185-4d6e-9d17-711fe478bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-16757039-01c1-44d2-970c-fb1113a30e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-1bbe7243-6b6b-48b8-af6c-4c4e4ce33095,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-d1dd65c7-364a-4e03-9b64-95001a507fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-f96b9c00-2385-4e83-a637-d41948a7d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-ce223caa-d0df-4912-8a59-bb17a37c5041,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-152514bd-b951-4421-bca2-b360101bb40b,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-c8db4bd3-aa76-4c40-89b4-6bec17c31890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168187759-172.17.0.18-1595379082902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43751,DS-87977bbc-6185-4d6e-9d17-711fe478bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-16757039-01c1-44d2-970c-fb1113a30e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-1bbe7243-6b6b-48b8-af6c-4c4e4ce33095,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-d1dd65c7-364a-4e03-9b64-95001a507fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-f96b9c00-2385-4e83-a637-d41948a7d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-ce223caa-d0df-4912-8a59-bb17a37c5041,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-152514bd-b951-4421-bca2-b360101bb40b,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-c8db4bd3-aa76-4c40-89b4-6bec17c31890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4967
