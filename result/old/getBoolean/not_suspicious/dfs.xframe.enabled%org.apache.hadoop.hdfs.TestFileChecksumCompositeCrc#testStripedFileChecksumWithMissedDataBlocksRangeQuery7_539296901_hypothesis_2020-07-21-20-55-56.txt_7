reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353933526-172.17.0.2-1595365116538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-1232c5ad-9272-43d8-9e47-4215c32f9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-c8ccddaa-8f19-4f20-b69d-cef4738ac0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-95dd48bb-4dfb-4e99-a03b-6fd2ac35636c,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-56e73da0-176b-4677-9e16-d1de74feed70,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-445cf429-4a86-45bc-9eeb-721e436b8e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-943b4fbf-2127-423e-97fd-84c412855393,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-8fd3dd8c-3601-4722-b910-22d8bfaf7d39,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-1f0e2d88-9041-42cb-b0af-04f8a2a17079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353933526-172.17.0.2-1595365116538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-1232c5ad-9272-43d8-9e47-4215c32f9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-c8ccddaa-8f19-4f20-b69d-cef4738ac0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-95dd48bb-4dfb-4e99-a03b-6fd2ac35636c,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-56e73da0-176b-4677-9e16-d1de74feed70,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-445cf429-4a86-45bc-9eeb-721e436b8e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-943b4fbf-2127-423e-97fd-84c412855393,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-8fd3dd8c-3601-4722-b910-22d8bfaf7d39,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-1f0e2d88-9041-42cb-b0af-04f8a2a17079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567289174-172.17.0.2-1595365264994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-f05ffbab-2bcf-4dd8-b07b-f0f15c1d540d,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-dcbea081-0c85-448d-a268-991885af1a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-22b64701-4e0f-4731-843d-ef00cc403500,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-4f18f7d3-57b9-4a27-a69b-9b5af1de7d25,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-cf61e10e-ac60-4d26-9eb9-3dbb4a48b8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-9e73ef05-17cb-45c9-8085-60e5690287ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-6684d858-aeaf-4788-974c-d79af5d536c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-b3916d10-3c37-4216-ae1b-3257c4622807,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567289174-172.17.0.2-1595365264994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-f05ffbab-2bcf-4dd8-b07b-f0f15c1d540d,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-dcbea081-0c85-448d-a268-991885af1a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-22b64701-4e0f-4731-843d-ef00cc403500,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-4f18f7d3-57b9-4a27-a69b-9b5af1de7d25,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-cf61e10e-ac60-4d26-9eb9-3dbb4a48b8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-9e73ef05-17cb-45c9-8085-60e5690287ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-6684d858-aeaf-4788-974c-d79af5d536c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-b3916d10-3c37-4216-ae1b-3257c4622807,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722878493-172.17.0.2-1595365302580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-20525065-ca66-4dca-8cec-1758ad4f3a65,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-0d0093e2-26b8-4c58-a33e-ef5112a9d687,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-47ba19b9-36ab-428b-bf68-4415a061b8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-0cd5c4d1-137e-4d15-ba74-1036510bf187,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-93e2f0ec-3c88-4160-871d-155eed6e38c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-cdd1ab2a-6b4d-400a-8dc3-4344b931c8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-8116ba17-5d26-416d-ad66-6925634f5c10,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-51a9295a-07b2-4930-9476-0fe8666d1022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722878493-172.17.0.2-1595365302580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-20525065-ca66-4dca-8cec-1758ad4f3a65,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-0d0093e2-26b8-4c58-a33e-ef5112a9d687,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-47ba19b9-36ab-428b-bf68-4415a061b8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-0cd5c4d1-137e-4d15-ba74-1036510bf187,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-93e2f0ec-3c88-4160-871d-155eed6e38c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-cdd1ab2a-6b4d-400a-8dc3-4344b931c8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-8116ba17-5d26-416d-ad66-6925634f5c10,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-51a9295a-07b2-4930-9476-0fe8666d1022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533841361-172.17.0.2-1595365342052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45404,DS-9b77648a-4799-4b27-8e49-1f2851b8c1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-76b7206d-ec96-46da-ba41-cbd06dcbf92c,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-b1ca3e67-8a70-4430-badf-ea88f7f8f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-4beb497f-71d7-4f22-b760-c508a93f8616,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-78e7e408-8ff1-49cf-ac93-22582551166c,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-63252169-4fb4-4ded-8c07-9c91b647c351,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-4387a8e7-9fdb-4c0d-9277-41608fc32741,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-b0e8c19e-c8c0-4850-a57a-40fd36cd388b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533841361-172.17.0.2-1595365342052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45404,DS-9b77648a-4799-4b27-8e49-1f2851b8c1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-76b7206d-ec96-46da-ba41-cbd06dcbf92c,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-b1ca3e67-8a70-4430-badf-ea88f7f8f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-4beb497f-71d7-4f22-b760-c508a93f8616,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-78e7e408-8ff1-49cf-ac93-22582551166c,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-63252169-4fb4-4ded-8c07-9c91b647c351,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-4387a8e7-9fdb-4c0d-9277-41608fc32741,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-b0e8c19e-c8c0-4850-a57a-40fd36cd388b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553811721-172.17.0.2-1595365654767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36115,DS-fda9ee6b-ff97-4e02-b2cf-0fa18e6b5920,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-0eac2488-53b1-4823-a2d2-765d70924d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-99f89426-9e65-420b-956f-1df586c4a730,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-f4dd65f2-3719-43a3-b472-8fec244e96ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-365b2eec-aa11-446c-87e5-62ad4f2c24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-f33fd4d8-0856-48dd-9f68-f69c8b93a4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-8da7be8a-8bcc-43dc-a686-9cffc65e119b,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-e6a40d20-b74d-49a8-a146-ec37c5f30053,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553811721-172.17.0.2-1595365654767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36115,DS-fda9ee6b-ff97-4e02-b2cf-0fa18e6b5920,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-0eac2488-53b1-4823-a2d2-765d70924d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-99f89426-9e65-420b-956f-1df586c4a730,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-f4dd65f2-3719-43a3-b472-8fec244e96ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-365b2eec-aa11-446c-87e5-62ad4f2c24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-f33fd4d8-0856-48dd-9f68-f69c8b93a4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-8da7be8a-8bcc-43dc-a686-9cffc65e119b,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-e6a40d20-b74d-49a8-a146-ec37c5f30053,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512208727-172.17.0.2-1595365687952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-4d3da5aa-027c-414e-adae-087f6000c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-edb51daa-ee2d-4a8a-9638-658d0491c302,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-29e6acd2-813d-4087-a146-7124e81d4d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-2f8c45a6-0882-4a86-baa8-de943ee78329,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-702a75e9-cd29-4a53-89df-2b38d6b7c7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-0b48e5a8-37bd-4559-8338-da7921f9fedb,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-27f064a9-7c62-4062-8226-f4198171faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-aa23f8ca-0640-4a77-a7cc-1538fcd3f203,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512208727-172.17.0.2-1595365687952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-4d3da5aa-027c-414e-adae-087f6000c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-edb51daa-ee2d-4a8a-9638-658d0491c302,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-29e6acd2-813d-4087-a146-7124e81d4d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-2f8c45a6-0882-4a86-baa8-de943ee78329,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-702a75e9-cd29-4a53-89df-2b38d6b7c7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-0b48e5a8-37bd-4559-8338-da7921f9fedb,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-27f064a9-7c62-4062-8226-f4198171faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-aa23f8ca-0640-4a77-a7cc-1538fcd3f203,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545044577-172.17.0.2-1595366097442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-aacaadc2-7dad-40ba-a140-ceb2632761fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-5458541f-bb30-4b6b-932f-708144d4c3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-387c9ab6-dbc1-4142-a268-6830309bae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-ec31e544-2e26-4c44-90ba-e9dad11d94e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-113a6e6f-84d6-44d1-9e57-a1abeb2a50b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-3abfc99f-0e55-4d4a-b703-bf80955a68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-6325937d-186b-4fb5-9705-031b4da58976,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-1da78995-da01-4328-a149-1fb3a8fc77ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545044577-172.17.0.2-1595366097442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-aacaadc2-7dad-40ba-a140-ceb2632761fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-5458541f-bb30-4b6b-932f-708144d4c3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-387c9ab6-dbc1-4142-a268-6830309bae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-ec31e544-2e26-4c44-90ba-e9dad11d94e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-113a6e6f-84d6-44d1-9e57-a1abeb2a50b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-3abfc99f-0e55-4d4a-b703-bf80955a68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-6325937d-186b-4fb5-9705-031b4da58976,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-1da78995-da01-4328-a149-1fb3a8fc77ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656746474-172.17.0.2-1595366225792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33207,DS-ebf19393-8595-4c48-a9c0-7ce1405cc185,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-acaaa960-a6ea-4fdc-8c1c-c915d4eeb40a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-48f5b281-4161-4988-a766-c3cab4c7091c,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-42b7a4e4-a592-4302-aad6-ecf121519191,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-8826db89-4cc3-4b5f-b633-37b1a9a7909d,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-679c6709-cb2b-41bc-a332-e27904755bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-3e5242a9-1228-4f59-8661-160f6785762c,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-1d77f4a0-7558-4ab6-bb91-1ed739eba8c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656746474-172.17.0.2-1595366225792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33207,DS-ebf19393-8595-4c48-a9c0-7ce1405cc185,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-acaaa960-a6ea-4fdc-8c1c-c915d4eeb40a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-48f5b281-4161-4988-a766-c3cab4c7091c,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-42b7a4e4-a592-4302-aad6-ecf121519191,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-8826db89-4cc3-4b5f-b633-37b1a9a7909d,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-679c6709-cb2b-41bc-a332-e27904755bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-3e5242a9-1228-4f59-8661-160f6785762c,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-1d77f4a0-7558-4ab6-bb91-1ed739eba8c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716779987-172.17.0.2-1595366356199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-92bc1ba0-9e95-4574-8ac3-d6dbcbb3903b,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-b6c9a065-7426-4c47-ac88-4d4f25bba30e,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-aad775b6-ebd8-40a9-8b77-3d03a23e0ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-fe3071f5-119c-4c2d-a570-dcc7d12963ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-c5983fe9-9c90-46ac-80b5-12d9606a8e74,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-4e032376-a028-4e4c-9526-e827f60f7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-4998add5-7227-45a4-ae67-00a2b39761d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-14f0c397-b8a5-4e59-85f9-7e4989bc236b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716779987-172.17.0.2-1595366356199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-92bc1ba0-9e95-4574-8ac3-d6dbcbb3903b,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-b6c9a065-7426-4c47-ac88-4d4f25bba30e,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-aad775b6-ebd8-40a9-8b77-3d03a23e0ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-fe3071f5-119c-4c2d-a570-dcc7d12963ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-c5983fe9-9c90-46ac-80b5-12d9606a8e74,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-4e032376-a028-4e4c-9526-e827f60f7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-4998add5-7227-45a4-ae67-00a2b39761d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-14f0c397-b8a5-4e59-85f9-7e4989bc236b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944000861-172.17.0.2-1595366700513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45701,DS-52b2749e-9f55-4398-96c1-fd88650a2774,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-83cbc960-d977-41d5-8812-90a06c49832c,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-7dd0dc89-d8f6-4bc1-a1f3-3eb6268f75e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-995f1630-d2a4-43da-bd44-dbbc022f3e83,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-71e926f4-67ac-4296-afdd-46582d7afb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-516649a7-a9b5-4b71-bee0-09089ea0a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-0b42598d-037b-41f9-8b2e-2bd15de1dc43,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-abd9e8b9-c758-4b61-b2ec-7a95810ee3c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944000861-172.17.0.2-1595366700513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45701,DS-52b2749e-9f55-4398-96c1-fd88650a2774,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-83cbc960-d977-41d5-8812-90a06c49832c,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-7dd0dc89-d8f6-4bc1-a1f3-3eb6268f75e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-995f1630-d2a4-43da-bd44-dbbc022f3e83,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-71e926f4-67ac-4296-afdd-46582d7afb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-516649a7-a9b5-4b71-bee0-09089ea0a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-0b42598d-037b-41f9-8b2e-2bd15de1dc43,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-abd9e8b9-c758-4b61-b2ec-7a95810ee3c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719252859-172.17.0.2-1595366745275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40423,DS-f143cc3d-1f97-4db9-b017-ed858056534a,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-142ecb16-a132-4707-86ab-b5ee4d8a6f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-332905cb-6ea5-4e7d-87d0-5a9bc444977f,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-70eb65ff-9cbf-4b11-9a99-565bdad5971e,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-6c7fe836-2c38-4382-9728-e1ade71e042c,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-f24f8f00-bc3a-47f3-b483-ec8976168a81,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-3bcbfe3f-28fa-4ad9-b7c2-6cab450ed520,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-56ee978d-94f4-46b6-96e7-27efe40e5920,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719252859-172.17.0.2-1595366745275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40423,DS-f143cc3d-1f97-4db9-b017-ed858056534a,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-142ecb16-a132-4707-86ab-b5ee4d8a6f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-332905cb-6ea5-4e7d-87d0-5a9bc444977f,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-70eb65ff-9cbf-4b11-9a99-565bdad5971e,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-6c7fe836-2c38-4382-9728-e1ade71e042c,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-f24f8f00-bc3a-47f3-b483-ec8976168a81,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-3bcbfe3f-28fa-4ad9-b7c2-6cab450ed520,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-56ee978d-94f4-46b6-96e7-27efe40e5920,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868595668-172.17.0.2-1595366798176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44532,DS-a2e6680a-80ec-4d5c-933f-236886c2cfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-50708c3d-c291-45bb-b9ec-857a1feb53a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-fd8da0db-810a-4a71-85c8-c5ec2ec5708f,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-98c84fbb-6d3e-4792-b853-0779d9f7a3be,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-32bf2ad2-5f1e-4b81-a47c-2b9309a58846,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-a023234d-9a66-4068-860f-a4068d00477c,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-0d513140-4016-435f-b46b-a62b5bbc5b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-cfd20774-c64e-4dbb-9630-5ab552694e81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868595668-172.17.0.2-1595366798176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44532,DS-a2e6680a-80ec-4d5c-933f-236886c2cfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-50708c3d-c291-45bb-b9ec-857a1feb53a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-fd8da0db-810a-4a71-85c8-c5ec2ec5708f,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-98c84fbb-6d3e-4792-b853-0779d9f7a3be,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-32bf2ad2-5f1e-4b81-a47c-2b9309a58846,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-a023234d-9a66-4068-860f-a4068d00477c,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-0d513140-4016-435f-b46b-a62b5bbc5b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-cfd20774-c64e-4dbb-9630-5ab552694e81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910499654-172.17.0.2-1595366835423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-d05accfb-7c67-46c7-a6e2-16e8c790740d,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-e5778069-48d1-4ce6-bab7-c1e32c191856,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-90a4d9bd-62dc-40ac-8882-f2c2f1d259bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-4f8b951d-b8b6-4adf-886f-19c1f875e2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-3d69a0ae-4eed-4712-9d53-3efef63c27b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-0b735d83-afae-4aef-a114-ef532c1e4a38,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-eef94671-c30c-48ad-a2d3-440c9562c15c,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-64e76516-a1fa-408f-b84e-0b018dcd36b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910499654-172.17.0.2-1595366835423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-d05accfb-7c67-46c7-a6e2-16e8c790740d,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-e5778069-48d1-4ce6-bab7-c1e32c191856,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-90a4d9bd-62dc-40ac-8882-f2c2f1d259bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-4f8b951d-b8b6-4adf-886f-19c1f875e2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-3d69a0ae-4eed-4712-9d53-3efef63c27b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-0b735d83-afae-4aef-a114-ef532c1e4a38,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-eef94671-c30c-48ad-a2d3-440c9562c15c,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-64e76516-a1fa-408f-b84e-0b018dcd36b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255949116-172.17.0.2-1595367010876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-6b904867-bdf4-49c7-b8b3-3dc97f16683d,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-0cfd8b71-f4f2-40d3-acaf-19395bf151a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-c2757b04-4808-4531-a9fb-9e6b34dd028d,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-8c97a986-fd7c-4112-8533-988af7c7f52c,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-67aa0bcd-eb50-40ca-aba8-0e67bc63b4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-34b50a1a-c798-4b25-93b0-c97e5eea6912,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-cc8e8552-54df-46c5-9ae7-1588d9e76f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-b80bb6f8-6174-4d80-b8ae-d97f75170d35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255949116-172.17.0.2-1595367010876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-6b904867-bdf4-49c7-b8b3-3dc97f16683d,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-0cfd8b71-f4f2-40d3-acaf-19395bf151a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-c2757b04-4808-4531-a9fb-9e6b34dd028d,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-8c97a986-fd7c-4112-8533-988af7c7f52c,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-67aa0bcd-eb50-40ca-aba8-0e67bc63b4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-34b50a1a-c798-4b25-93b0-c97e5eea6912,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-cc8e8552-54df-46c5-9ae7-1588d9e76f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-b80bb6f8-6174-4d80-b8ae-d97f75170d35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330232590-172.17.0.2-1595367110129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44669,DS-d9a8f77f-8be3-4f31-9045-6ad0efaafcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-aaf1788b-1ab1-4536-8c2a-ee5ec173294d,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-e770c6fb-1bd8-47d5-96ac-6ef08ecb49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-560d16f7-faa9-45b9-a96f-d8cb3055140c,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-87493af5-c009-4167-ba9f-6a974b7370ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-eacd5614-be83-4afe-b98f-d0fcd52727a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-b0539117-786f-4562-8fc2-5bcce8060c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-d9ead47f-63fe-445e-87c9-e0b7a44b9dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330232590-172.17.0.2-1595367110129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44669,DS-d9a8f77f-8be3-4f31-9045-6ad0efaafcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-aaf1788b-1ab1-4536-8c2a-ee5ec173294d,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-e770c6fb-1bd8-47d5-96ac-6ef08ecb49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-560d16f7-faa9-45b9-a96f-d8cb3055140c,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-87493af5-c009-4167-ba9f-6a974b7370ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-eacd5614-be83-4afe-b98f-d0fcd52727a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-b0539117-786f-4562-8fc2-5bcce8060c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-d9ead47f-63fe-445e-87c9-e0b7a44b9dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636493809-172.17.0.2-1595367859538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37368,DS-2f8f3715-b2af-4df1-970d-a6f0d447e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-1dab4c4b-883a-4322-8737-d1e02850ef22,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-513b7773-7403-4766-b1c0-f89936cbcdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-33011d1f-9700-4b67-b301-5f941cd8b91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-106ad426-6737-43dc-8b5c-a611790bfe22,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-bd1bb135-9449-45e1-9620-c1f0ef39cdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-12843b62-65cc-450d-a775-ab83810e04b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-ac12e8b1-75a3-4a1b-ae93-31d7ee5ac779,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636493809-172.17.0.2-1595367859538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37368,DS-2f8f3715-b2af-4df1-970d-a6f0d447e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-1dab4c4b-883a-4322-8737-d1e02850ef22,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-513b7773-7403-4766-b1c0-f89936cbcdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-33011d1f-9700-4b67-b301-5f941cd8b91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-106ad426-6737-43dc-8b5c-a611790bfe22,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-bd1bb135-9449-45e1-9620-c1f0ef39cdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-12843b62-65cc-450d-a775-ab83810e04b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-ac12e8b1-75a3-4a1b-ae93-31d7ee5ac779,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585997328-172.17.0.2-1595368024270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-1102f8a7-1934-42fa-a0b9-501711d02c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-14dc1aec-d25e-4a06-be86-2ec98ec86fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-4e9c5190-c240-4bf2-ab9f-9a1393dc949d,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-358c0308-3f43-473e-9e0a-d7ca0298526d,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-9f36f57b-e27d-44aa-94e5-00956bd39b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-0bd2ffbc-8b03-4bb7-bcea-2ba6bcea3032,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-5e5d6b00-8758-4201-9515-9d0e75d24bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-9841e085-7342-40cc-b083-4382aa5b7352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585997328-172.17.0.2-1595368024270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-1102f8a7-1934-42fa-a0b9-501711d02c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-14dc1aec-d25e-4a06-be86-2ec98ec86fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-4e9c5190-c240-4bf2-ab9f-9a1393dc949d,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-358c0308-3f43-473e-9e0a-d7ca0298526d,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-9f36f57b-e27d-44aa-94e5-00956bd39b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-0bd2ffbc-8b03-4bb7-bcea-2ba6bcea3032,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-5e5d6b00-8758-4201-9515-9d0e75d24bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-9841e085-7342-40cc-b083-4382aa5b7352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235524168-172.17.0.2-1595368213291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35838,DS-d2b2397d-2cec-4240-947b-8c466b99a1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-3acaf1f3-8690-484d-9253-1598404f651c,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-09f99a53-1b6f-490a-badc-fc83cd6ca6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-9116be10-fb3a-401f-906c-e30e4e76826e,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-c41bc07b-4827-4b71-9d8b-e13e69c78eac,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-e58e4710-4f49-4090-a843-828e72c67ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-1be6cf47-e6f2-4299-990e-5bff580da767,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-3421d161-406c-43e5-866b-f103083fbc45,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235524168-172.17.0.2-1595368213291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35838,DS-d2b2397d-2cec-4240-947b-8c466b99a1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-3acaf1f3-8690-484d-9253-1598404f651c,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-09f99a53-1b6f-490a-badc-fc83cd6ca6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-9116be10-fb3a-401f-906c-e30e4e76826e,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-c41bc07b-4827-4b71-9d8b-e13e69c78eac,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-e58e4710-4f49-4090-a843-828e72c67ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-1be6cf47-e6f2-4299-990e-5bff580da767,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-3421d161-406c-43e5-866b-f103083fbc45,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095787429-172.17.0.2-1595368365060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-8f5ea42f-d02f-4de8-b2e2-aee9d606fbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-2e4625a0-6e27-493a-a306-2bf211f62cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-86ee48a7-dc46-47c2-9622-b1359514eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-06833025-5c93-402b-9e29-ce373dc15262,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-5da839fb-c001-46eb-abcd-3496d819df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-7eadffde-3a82-4513-8213-ce555ad1b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-340b2d8b-03d0-4c45-8104-93cdd3e31212,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-1ab2ebd3-775c-4b34-808c-a5c930ae1628,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095787429-172.17.0.2-1595368365060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-8f5ea42f-d02f-4de8-b2e2-aee9d606fbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-2e4625a0-6e27-493a-a306-2bf211f62cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-86ee48a7-dc46-47c2-9622-b1359514eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-06833025-5c93-402b-9e29-ce373dc15262,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-5da839fb-c001-46eb-abcd-3496d819df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-7eadffde-3a82-4513-8213-ce555ad1b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-340b2d8b-03d0-4c45-8104-93cdd3e31212,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-1ab2ebd3-775c-4b34-808c-a5c930ae1628,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053863726-172.17.0.2-1595368468992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38128,DS-bddd9951-bb5d-49ef-878a-ccf46146965e,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-136a15c1-3c6c-49ac-9bd4-f1381c2b53d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-2f512c21-6b92-43f3-8050-17b687f6de06,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-580157a3-e38a-44b6-b4b4-d613375f36e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-257b6efa-d8ea-4f1c-a8f8-1e57bc31776b,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-05150247-01ff-49ba-86d4-4826fc998db3,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-88fc5255-3cde-47ea-bc4e-72887d6923dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-d33271a9-b0a5-48f7-848a-4ac39c887ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053863726-172.17.0.2-1595368468992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38128,DS-bddd9951-bb5d-49ef-878a-ccf46146965e,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-136a15c1-3c6c-49ac-9bd4-f1381c2b53d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-2f512c21-6b92-43f3-8050-17b687f6de06,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-580157a3-e38a-44b6-b4b4-d613375f36e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-257b6efa-d8ea-4f1c-a8f8-1e57bc31776b,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-05150247-01ff-49ba-86d4-4826fc998db3,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-88fc5255-3cde-47ea-bc4e-72887d6923dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-d33271a9-b0a5-48f7-848a-4ac39c887ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140946164-172.17.0.2-1595368591966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-83fef741-66fe-4428-b817-7718b9064e13,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-dc1034dd-89e4-4ad6-973e-1f64211afa26,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-839193af-89a4-4277-8e03-1563890a6ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-e36d87a8-a6c3-48ce-9976-82a489280861,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-fe8e803b-3e65-468e-920b-13d0e6a8dd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-579ac9ba-9dc2-443b-ada5-82a5932ff40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-158e4b64-306f-4df5-9f82-6d28d6b21db5,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-961d6217-15cc-4665-bad5-9cdf68bbf3ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140946164-172.17.0.2-1595368591966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-83fef741-66fe-4428-b817-7718b9064e13,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-dc1034dd-89e4-4ad6-973e-1f64211afa26,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-839193af-89a4-4277-8e03-1563890a6ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-e36d87a8-a6c3-48ce-9976-82a489280861,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-fe8e803b-3e65-468e-920b-13d0e6a8dd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-579ac9ba-9dc2-443b-ada5-82a5932ff40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-158e4b64-306f-4df5-9f82-6d28d6b21db5,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-961d6217-15cc-4665-bad5-9cdf68bbf3ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583528587-172.17.0.2-1595368944492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38657,DS-a58794ad-e943-4351-8519-51d3cd1ce521,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-081fa9dc-1c66-480b-b54c-2036a40993ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-eb53bf6d-3c01-40ae-848b-6134ab9f1f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-f8578633-3498-4467-a274-584686c948d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-469b8ee9-232d-42f7-9c39-8a366d89d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-5e04dd44-aa2a-40dd-93d1-1533be1654aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-3b8b0319-4cb3-4a81-8f5f-9a854edabe44,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-e0fb4b85-0b23-4658-a50c-0d7301520b32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583528587-172.17.0.2-1595368944492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38657,DS-a58794ad-e943-4351-8519-51d3cd1ce521,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-081fa9dc-1c66-480b-b54c-2036a40993ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-eb53bf6d-3c01-40ae-848b-6134ab9f1f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-f8578633-3498-4467-a274-584686c948d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-469b8ee9-232d-42f7-9c39-8a366d89d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-5e04dd44-aa2a-40dd-93d1-1533be1654aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-3b8b0319-4cb3-4a81-8f5f-9a854edabe44,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-e0fb4b85-0b23-4658-a50c-0d7301520b32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769987630-172.17.0.2-1595369086406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-3bd79fe3-3e85-4224-a349-cc2bf5d7c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-3e7fb145-99d6-4fbc-84d9-c8e0ca2c6316,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-e2563d1f-0dec-4b3e-a8a5-24fb70355b57,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-0600ee20-9d48-4a47-8c2e-7d419bb6343b,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-f767acf2-6485-4b6c-bc69-a80056ab8614,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-fdbb026a-4166-4762-90b1-cc610cb76746,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-2bfc20a3-8ae3-4515-9c19-a16b13c68297,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-bc988390-de38-4026-9383-d38488be0473,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769987630-172.17.0.2-1595369086406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-3bd79fe3-3e85-4224-a349-cc2bf5d7c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-3e7fb145-99d6-4fbc-84d9-c8e0ca2c6316,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-e2563d1f-0dec-4b3e-a8a5-24fb70355b57,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-0600ee20-9d48-4a47-8c2e-7d419bb6343b,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-f767acf2-6485-4b6c-bc69-a80056ab8614,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-fdbb026a-4166-4762-90b1-cc610cb76746,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-2bfc20a3-8ae3-4515-9c19-a16b13c68297,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-bc988390-de38-4026-9383-d38488be0473,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721503481-172.17.0.2-1595369130739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40088,DS-c8f12727-ba49-4d14-b09d-af93c862f9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-c2ffaa09-09b2-483c-ae3a-f51c9495b3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-45d74d8e-9191-452f-a9b7-305e91d8f16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-d6ecbb13-345b-4f14-9200-ca8e8d4b9ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-eadc5ab4-24b2-42a4-9b18-53334463ac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-96734cfa-0f73-4cfa-b653-0d742380099e,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-2f4d5c9c-bca0-470e-b0f8-72cf47a12b76,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-e9f34bd8-1292-45d5-99c3-9005ad3c154f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721503481-172.17.0.2-1595369130739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40088,DS-c8f12727-ba49-4d14-b09d-af93c862f9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-c2ffaa09-09b2-483c-ae3a-f51c9495b3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-45d74d8e-9191-452f-a9b7-305e91d8f16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-d6ecbb13-345b-4f14-9200-ca8e8d4b9ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-eadc5ab4-24b2-42a4-9b18-53334463ac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-96734cfa-0f73-4cfa-b653-0d742380099e,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-2f4d5c9c-bca0-470e-b0f8-72cf47a12b76,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-e9f34bd8-1292-45d5-99c3-9005ad3c154f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093635409-172.17.0.2-1595369670108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38028,DS-82471235-b939-4ff2-a7ba-edbe0e068eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-a5c03022-fd3a-4911-9a86-2fe47bb67402,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-40f00fc3-34f0-4df0-9393-5b3885a9c4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-83375b87-ce1c-445e-8c2f-570170faa544,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-63398865-6c3a-4c47-bee9-3ffc621b3bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-2a21580f-e7a1-46bb-b1dc-b4d4902c0d34,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-743f4350-3be9-42ba-9f6b-2c27cab4767a,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-3009ffb3-93e3-4a84-a460-40264c851abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093635409-172.17.0.2-1595369670108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38028,DS-82471235-b939-4ff2-a7ba-edbe0e068eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-a5c03022-fd3a-4911-9a86-2fe47bb67402,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-40f00fc3-34f0-4df0-9393-5b3885a9c4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-83375b87-ce1c-445e-8c2f-570170faa544,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-63398865-6c3a-4c47-bee9-3ffc621b3bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-2a21580f-e7a1-46bb-b1dc-b4d4902c0d34,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-743f4350-3be9-42ba-9f6b-2c27cab4767a,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-3009ffb3-93e3-4a84-a460-40264c851abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664871313-172.17.0.2-1595370353606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-ce096213-91f1-47ba-9928-2438c3a51405,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-1c4b6530-9af8-4e5b-92e0-0ab68e22ec7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-dc4ff1dc-dfd4-49c3-b784-e327e3e970dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-f978ca28-3d87-4f65-8437-00ad4559a299,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-9d2e3b58-ef7e-4c30-8de1-bdc4ef8dd411,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-6e69f1c7-d631-4623-b899-0a1655f458cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-e84a085b-9cf9-4124-a5ad-44f8c7e25160,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-6ed561b9-22ce-4653-8a95-0f2b19209286,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664871313-172.17.0.2-1595370353606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-ce096213-91f1-47ba-9928-2438c3a51405,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-1c4b6530-9af8-4e5b-92e0-0ab68e22ec7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-dc4ff1dc-dfd4-49c3-b784-e327e3e970dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-f978ca28-3d87-4f65-8437-00ad4559a299,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-9d2e3b58-ef7e-4c30-8de1-bdc4ef8dd411,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-6e69f1c7-d631-4623-b899-0a1655f458cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-e84a085b-9cf9-4124-a5ad-44f8c7e25160,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-6ed561b9-22ce-4653-8a95-0f2b19209286,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078607587-172.17.0.2-1595370575312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45990,DS-152826e5-c7c9-4bed-a92a-8da3141d3fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-697d199b-ba24-4f34-8026-7adf55a99c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-257d5d0c-63b1-4f6f-ae76-e4d1d321b1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-7eb33b1d-6092-42b0-a0a5-35d5d34d2b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-f73f0b03-246e-4137-a2a1-27ac195f09fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-0fef30f0-296d-4a0a-8f9b-3914ec355c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-7ede6271-0388-4a51-9237-fb1d4670267c,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-22d17e0c-db1b-449f-aafe-bb4c0437978e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078607587-172.17.0.2-1595370575312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45990,DS-152826e5-c7c9-4bed-a92a-8da3141d3fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-697d199b-ba24-4f34-8026-7adf55a99c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-257d5d0c-63b1-4f6f-ae76-e4d1d321b1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-7eb33b1d-6092-42b0-a0a5-35d5d34d2b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-f73f0b03-246e-4137-a2a1-27ac195f09fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-0fef30f0-296d-4a0a-8f9b-3914ec355c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-7ede6271-0388-4a51-9237-fb1d4670267c,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-22d17e0c-db1b-449f-aafe-bb4c0437978e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520676009-172.17.0.2-1595370833087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-954761ef-4e27-4cea-ba5a-a2c91c5e693b,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-ba4b70d1-472e-421e-8770-99e2c65896c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-7b9c83eb-263b-4a4f-856a-11d56a56a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-4c60d66c-083f-427f-ba6d-a3b15d27f260,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-e88fc70c-74dd-48c9-a966-8ff41ff95719,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-769624a3-e54a-4d32-88cf-18297ca3be29,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-bd0be0e3-886a-4e55-b27b-44e79a91bf26,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-2bee766f-36de-4781-a4f1-e5516a2614ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520676009-172.17.0.2-1595370833087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-954761ef-4e27-4cea-ba5a-a2c91c5e693b,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-ba4b70d1-472e-421e-8770-99e2c65896c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-7b9c83eb-263b-4a4f-856a-11d56a56a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-4c60d66c-083f-427f-ba6d-a3b15d27f260,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-e88fc70c-74dd-48c9-a966-8ff41ff95719,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-769624a3-e54a-4d32-88cf-18297ca3be29,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-bd0be0e3-886a-4e55-b27b-44e79a91bf26,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-2bee766f-36de-4781-a4f1-e5516a2614ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144101990-172.17.0.2-1595370959393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32776,DS-f530b8b0-608c-41e6-86ba-8ffe1f151b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-163307a9-cba1-4699-a441-4039268697bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-cc812fea-c13a-4cf2-8404-3a1678d9e9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-5c606e70-42b6-47ea-896f-6cda038bcd21,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-c1de1a26-3bc6-4a23-bcde-743482a69885,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-168b0607-6782-42ec-8647-e496acda3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-08bdaf40-2766-4b12-8e59-d63bfb68730e,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-78ebac1c-c35d-4ee0-85dc-1809a4f391f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144101990-172.17.0.2-1595370959393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32776,DS-f530b8b0-608c-41e6-86ba-8ffe1f151b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-163307a9-cba1-4699-a441-4039268697bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-cc812fea-c13a-4cf2-8404-3a1678d9e9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-5c606e70-42b6-47ea-896f-6cda038bcd21,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-c1de1a26-3bc6-4a23-bcde-743482a69885,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-168b0607-6782-42ec-8647-e496acda3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-08bdaf40-2766-4b12-8e59-d63bfb68730e,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-78ebac1c-c35d-4ee0-85dc-1809a4f391f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508062332-172.17.0.2-1595371011686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43199,DS-8ff7c930-9b06-4567-8764-f8552964e934,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-7812b36a-844e-4000-ae89-29e105e7d197,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-7b8dd961-6fb6-44d3-b048-f94fa9b1dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-61abd16d-8018-47e9-ae48-c797762f9ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-e1ff9a82-1418-4b8d-8376-433e26576d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-013997bc-6bc4-4c2c-b6e4-71e5b2915405,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-0e6e860a-fb9f-4648-b4d7-e1ba2d014b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-7521b6cd-17e0-475b-b826-af274e2f8e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508062332-172.17.0.2-1595371011686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43199,DS-8ff7c930-9b06-4567-8764-f8552964e934,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-7812b36a-844e-4000-ae89-29e105e7d197,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-7b8dd961-6fb6-44d3-b048-f94fa9b1dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-61abd16d-8018-47e9-ae48-c797762f9ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-e1ff9a82-1418-4b8d-8376-433e26576d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-013997bc-6bc4-4c2c-b6e4-71e5b2915405,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-0e6e860a-fb9f-4648-b4d7-e1ba2d014b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-7521b6cd-17e0-475b-b826-af274e2f8e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036628794-172.17.0.2-1595371060249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45389,DS-8b5cedd9-8402-4509-9f66-9bfdc082b156,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-84b5bf24-1baa-483f-aa0f-44e665d5d5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-284e4e9e-f68d-4e2e-bed1-f0289f6e0c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-8388c5a1-7125-49d5-9f22-c9e310af02f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-54e34ca7-4193-451c-872b-f234b0c2f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-2789918b-d337-407b-999f-6aa877e7b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-d1db2e41-e97a-4266-b372-aa8a9854bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-215d16c3-c3a0-40a8-9a87-862e905d7334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036628794-172.17.0.2-1595371060249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45389,DS-8b5cedd9-8402-4509-9f66-9bfdc082b156,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-84b5bf24-1baa-483f-aa0f-44e665d5d5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-284e4e9e-f68d-4e2e-bed1-f0289f6e0c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-8388c5a1-7125-49d5-9f22-c9e310af02f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-54e34ca7-4193-451c-872b-f234b0c2f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-2789918b-d337-407b-999f-6aa877e7b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-d1db2e41-e97a-4266-b372-aa8a9854bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-215d16c3-c3a0-40a8-9a87-862e905d7334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328235897-172.17.0.2-1595371144993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45029,DS-c45e527d-e084-4426-a58b-b2dafc83cd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-be4da4ae-860c-441a-97f7-cafd7abc2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-de738d2a-dd65-43ba-b4d6-64330337f9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-dfa18c4e-cb88-4b06-b7a7-9128ebd71826,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-67280695-67b1-4997-b1a3-dc9cd002bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-d1614801-750f-4438-b048-fde944388ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-94fca4db-cd22-4c3c-bbc4-815e814f63a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-80c86e62-3885-4ce3-8afa-91e66b1a46d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328235897-172.17.0.2-1595371144993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45029,DS-c45e527d-e084-4426-a58b-b2dafc83cd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-be4da4ae-860c-441a-97f7-cafd7abc2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-de738d2a-dd65-43ba-b4d6-64330337f9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-dfa18c4e-cb88-4b06-b7a7-9128ebd71826,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-67280695-67b1-4997-b1a3-dc9cd002bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-d1614801-750f-4438-b048-fde944388ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-94fca4db-cd22-4c3c-bbc4-815e814f63a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-80c86e62-3885-4ce3-8afa-91e66b1a46d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668535605-172.17.0.2-1595371186182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-3e904da6-6a01-44ca-b65c-12a41d5d004e,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-cc9f5f59-2409-4127-8672-69da53f85088,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-8e0a4bf6-6054-4c90-9045-1a77c41c8775,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-58a870d7-b57c-4015-a8bb-f38bd77aa517,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-52301841-391b-4b3e-9ced-a3e6428a2546,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-9bb238db-6d71-40e1-b088-55819aa395d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-8c4e8aa8-8495-43be-8311-d95d695b7d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-f5dd8d41-4dd3-4a16-b682-a4830c0ffc23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668535605-172.17.0.2-1595371186182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-3e904da6-6a01-44ca-b65c-12a41d5d004e,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-cc9f5f59-2409-4127-8672-69da53f85088,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-8e0a4bf6-6054-4c90-9045-1a77c41c8775,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-58a870d7-b57c-4015-a8bb-f38bd77aa517,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-52301841-391b-4b3e-9ced-a3e6428a2546,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-9bb238db-6d71-40e1-b088-55819aa395d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-8c4e8aa8-8495-43be-8311-d95d695b7d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-f5dd8d41-4dd3-4a16-b682-a4830c0ffc23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990908718-172.17.0.2-1595371266459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-79ed08d5-b920-4044-a2da-88c76481cabf,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-c98f1f6a-0e54-4d68-bb20-b90dcac65704,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-23041ed0-ebcd-4129-99b1-ec8af1d8fc23,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-e4ed2f52-e5f4-4f12-822f-731c96d2ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-9d52fd39-e027-4f1c-9c93-ee3a92d876a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-02daa34b-6b99-4551-a960-887bf9d02f78,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-61f83c92-8390-49d8-8116-fb2f4fb5c0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-e748ebd0-cda8-4dd1-8eba-539c51fae67b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990908718-172.17.0.2-1595371266459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-79ed08d5-b920-4044-a2da-88c76481cabf,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-c98f1f6a-0e54-4d68-bb20-b90dcac65704,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-23041ed0-ebcd-4129-99b1-ec8af1d8fc23,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-e4ed2f52-e5f4-4f12-822f-731c96d2ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-9d52fd39-e027-4f1c-9c93-ee3a92d876a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-02daa34b-6b99-4551-a960-887bf9d02f78,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-61f83c92-8390-49d8-8116-fb2f4fb5c0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-e748ebd0-cda8-4dd1-8eba-539c51fae67b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81692814-172.17.0.2-1595371354965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44083,DS-d2ca8eed-9466-4b14-8fda-acf39269bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-a28f5eaa-f527-4b46-8695-91118f71eee4,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-6e8f1537-2594-4ccb-ab2d-8ebc8d3263db,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-204d13d4-9209-4f47-8a06-58e52c9d5195,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-c07b6939-1002-4013-856b-1c0a0b0a2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-e812afcf-9480-462e-a174-9222b7d87c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-61ff3159-c420-406f-8305-03348c04f723,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-7a6a77c5-ab5a-456d-8325-1a0bb0d61a5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81692814-172.17.0.2-1595371354965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44083,DS-d2ca8eed-9466-4b14-8fda-acf39269bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-a28f5eaa-f527-4b46-8695-91118f71eee4,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-6e8f1537-2594-4ccb-ab2d-8ebc8d3263db,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-204d13d4-9209-4f47-8a06-58e52c9d5195,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-c07b6939-1002-4013-856b-1c0a0b0a2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-e812afcf-9480-462e-a174-9222b7d87c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-61ff3159-c420-406f-8305-03348c04f723,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-7a6a77c5-ab5a-456d-8325-1a0bb0d61a5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127652461-172.17.0.2-1595371473942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35196,DS-ba532445-6b13-4b45-a238-740bf5fbd084,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-fdd7a64a-3f4a-4097-a4e5-051a4c42a9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-c8ffe99c-9381-4045-a173-c6e83a7e2f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-cf6fd31e-c6fb-4504-8636-9762b0c01788,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-50247971-4c45-44b9-8783-29400f386ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-72da3038-2a37-4952-8cea-ef97dbc1d290,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-99463029-de46-40aa-8e99-7e5672ca2cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-ffd3b902-3263-4aa0-9ecc-f03120eb0075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127652461-172.17.0.2-1595371473942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35196,DS-ba532445-6b13-4b45-a238-740bf5fbd084,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-fdd7a64a-3f4a-4097-a4e5-051a4c42a9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-c8ffe99c-9381-4045-a173-c6e83a7e2f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-cf6fd31e-c6fb-4504-8636-9762b0c01788,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-50247971-4c45-44b9-8783-29400f386ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-72da3038-2a37-4952-8cea-ef97dbc1d290,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-99463029-de46-40aa-8e99-7e5672ca2cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-ffd3b902-3263-4aa0-9ecc-f03120eb0075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12565876-172.17.0.2-1595371509249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-94c66794-63ba-4cbc-9f67-aea20b3fa797,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-a8365e8f-bf77-4f94-ab91-1dbbba734246,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-cf67fbd3-4428-47dc-b425-df23a14bc0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-521f323c-b7c5-43c2-9b8e-a53af3b5b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-0197d56a-e47a-476f-8ce3-35dd42fa4823,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-a4750da0-473c-4ca0-a56e-068b5291b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-7642f7b2-0ba4-4fbc-bc4d-9a829cb35973,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-c61ba5b6-6d01-4579-ba8e-dead3a9d0f92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12565876-172.17.0.2-1595371509249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-94c66794-63ba-4cbc-9f67-aea20b3fa797,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-a8365e8f-bf77-4f94-ab91-1dbbba734246,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-cf67fbd3-4428-47dc-b425-df23a14bc0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-521f323c-b7c5-43c2-9b8e-a53af3b5b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-0197d56a-e47a-476f-8ce3-35dd42fa4823,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-a4750da0-473c-4ca0-a56e-068b5291b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-7642f7b2-0ba4-4fbc-bc4d-9a829cb35973,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-c61ba5b6-6d01-4579-ba8e-dead3a9d0f92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 6773
