reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352190845-172.17.0.4-1595328858313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-c7ac9f79-a1dc-4798-b999-631e1f387110,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-fe6f6c12-ac31-4064-af54-342e2aec728a,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-8e46dec0-8d2d-41ff-be31-faad697e7670,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-bb1cf0ee-9271-482b-8c00-da9ee3bc259c,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-faee09d0-2ba8-4723-849c-2291af348af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-9ce57101-9690-4b1f-88fa-0881bb4c2d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-ebe87aa6-9856-4318-b115-855b48cbc712,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-a11684e2-537b-406b-9b9e-ef49224d1b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352190845-172.17.0.4-1595328858313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-c7ac9f79-a1dc-4798-b999-631e1f387110,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-fe6f6c12-ac31-4064-af54-342e2aec728a,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-8e46dec0-8d2d-41ff-be31-faad697e7670,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-bb1cf0ee-9271-482b-8c00-da9ee3bc259c,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-faee09d0-2ba8-4723-849c-2291af348af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-9ce57101-9690-4b1f-88fa-0881bb4c2d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-ebe87aa6-9856-4318-b115-855b48cbc712,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-a11684e2-537b-406b-9b9e-ef49224d1b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945519039-172.17.0.4-1595328894928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43825,DS-4d25870d-3ecc-4399-8d61-cca0aa495259,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-b45f725f-16c4-4d66-8674-6702dbf28e62,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-7829e5e2-ebd2-4c96-b0c7-653fd5a95578,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-8a5cd02a-3ef0-41f9-b3d9-5650f29b4c29,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-5d4d03f2-4ac5-4e3f-8474-73d9b405c4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-6a877e38-670f-4a2b-a893-e2f9eef4727b,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-5bf1d609-b782-4a41-b3d0-d0ac4d50bcae,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-2dc3e67d-a547-4c07-88b0-674a8a8dfabf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945519039-172.17.0.4-1595328894928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43825,DS-4d25870d-3ecc-4399-8d61-cca0aa495259,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-b45f725f-16c4-4d66-8674-6702dbf28e62,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-7829e5e2-ebd2-4c96-b0c7-653fd5a95578,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-8a5cd02a-3ef0-41f9-b3d9-5650f29b4c29,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-5d4d03f2-4ac5-4e3f-8474-73d9b405c4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-6a877e38-670f-4a2b-a893-e2f9eef4727b,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-5bf1d609-b782-4a41-b3d0-d0ac4d50bcae,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-2dc3e67d-a547-4c07-88b0-674a8a8dfabf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365789602-172.17.0.4-1595329300851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46113,DS-0c157103-d004-4f45-9180-2eaf8cc2513b,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-ca14edf2-dd15-41d6-aa37-d8347ef78503,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-61bbacde-c012-44d2-87c0-7927743fa858,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-1f3ad4b3-ef57-4395-8c72-413f2e0d765a,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-84705bba-0ec9-4331-98a8-0069ab217e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-ac4173b0-47c7-4e96-a8d3-8c7fbb40e3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-51015381-0df9-459c-ac84-4014667c27cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-f9baa706-c01a-49b6-9531-7abac003edf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365789602-172.17.0.4-1595329300851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46113,DS-0c157103-d004-4f45-9180-2eaf8cc2513b,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-ca14edf2-dd15-41d6-aa37-d8347ef78503,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-61bbacde-c012-44d2-87c0-7927743fa858,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-1f3ad4b3-ef57-4395-8c72-413f2e0d765a,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-84705bba-0ec9-4331-98a8-0069ab217e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-ac4173b0-47c7-4e96-a8d3-8c7fbb40e3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-51015381-0df9-459c-ac84-4014667c27cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-f9baa706-c01a-49b6-9531-7abac003edf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628954994-172.17.0.4-1595329382188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42950,DS-b0a21456-4d0d-49d9-b636-2b151c736174,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-59794fd3-ae1b-4450-80a9-3cad4930b864,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-ea91e1b1-7212-409d-90ef-cdb1af869c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-118afb73-12f4-4ca8-9c3f-3dc8a94dd14f,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-322cd48c-d1c3-46b5-8295-28c170b11aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-a5b4cf43-5f22-4b3f-a14d-2c84395591dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-201117cb-339d-48ab-a536-f2cb7c088699,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-3377afda-2564-4865-ae93-6ae9ba35b4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628954994-172.17.0.4-1595329382188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42950,DS-b0a21456-4d0d-49d9-b636-2b151c736174,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-59794fd3-ae1b-4450-80a9-3cad4930b864,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-ea91e1b1-7212-409d-90ef-cdb1af869c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-118afb73-12f4-4ca8-9c3f-3dc8a94dd14f,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-322cd48c-d1c3-46b5-8295-28c170b11aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-a5b4cf43-5f22-4b3f-a14d-2c84395591dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-201117cb-339d-48ab-a536-f2cb7c088699,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-3377afda-2564-4865-ae93-6ae9ba35b4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020692827-172.17.0.4-1595329453098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38876,DS-dcc1d79c-b6b4-4cbf-9d30-48b329108078,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-9fd86471-c4e9-4b0f-833a-9c1e1c2dbe08,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-e0ca13b5-72ad-41cb-83a3-7ddfedf9551f,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-5aa8f508-baab-4594-94a1-a41e5de93ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-49e4e4de-6b78-408b-b4fa-91d4b4a18293,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-b1cea482-8e4d-4ef8-bfd0-a58be0086740,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-355733af-39fc-485f-8ca1-fda84c781e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-7c0e17bb-a450-42d7-b8bc-5744c5d54871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020692827-172.17.0.4-1595329453098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38876,DS-dcc1d79c-b6b4-4cbf-9d30-48b329108078,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-9fd86471-c4e9-4b0f-833a-9c1e1c2dbe08,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-e0ca13b5-72ad-41cb-83a3-7ddfedf9551f,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-5aa8f508-baab-4594-94a1-a41e5de93ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-49e4e4de-6b78-408b-b4fa-91d4b4a18293,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-b1cea482-8e4d-4ef8-bfd0-a58be0086740,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-355733af-39fc-485f-8ca1-fda84c781e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-7c0e17bb-a450-42d7-b8bc-5744c5d54871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835980485-172.17.0.4-1595329567275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-2a791c66-3378-4ab4-952b-7d1015ba3059,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-1a51c400-ff7f-4bb7-971d-e19abfa23ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-4ebe444e-99b9-4c83-86e9-8970aa51058f,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-9070ac22-acc2-4938-a6a3-687cfac709dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-65315feb-7409-4166-954b-a5cc3bbaa760,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-979f8ad8-27e0-40ba-aaa7-53e7cf02b291,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-06738ca7-50b4-4d5a-9c6f-a65e1b9a64d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-c580608e-b585-460a-be24-e69cdaf69d0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835980485-172.17.0.4-1595329567275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-2a791c66-3378-4ab4-952b-7d1015ba3059,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-1a51c400-ff7f-4bb7-971d-e19abfa23ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-4ebe444e-99b9-4c83-86e9-8970aa51058f,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-9070ac22-acc2-4938-a6a3-687cfac709dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-65315feb-7409-4166-954b-a5cc3bbaa760,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-979f8ad8-27e0-40ba-aaa7-53e7cf02b291,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-06738ca7-50b4-4d5a-9c6f-a65e1b9a64d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-c580608e-b585-460a-be24-e69cdaf69d0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702091850-172.17.0.4-1595329927832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38258,DS-337f6cd2-32a3-4b1e-91ff-712d76609be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-9581f7de-ef1e-4530-9e20-ef15a5329773,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-53bba2fc-3ed1-463e-abeb-cbcff1ec17be,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-c7c0d6c1-24e9-4536-906d-f219962b1260,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-b1ca0157-3e19-4f3f-8a23-e616c62a82a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-a2ad5d9e-be1c-4e20-86c8-6f8bfa95e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-fa9c0261-8788-4ac2-825b-3d06d24a7039,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-7d78a9b6-e830-4624-ad76-51fb27afbca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702091850-172.17.0.4-1595329927832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38258,DS-337f6cd2-32a3-4b1e-91ff-712d76609be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-9581f7de-ef1e-4530-9e20-ef15a5329773,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-53bba2fc-3ed1-463e-abeb-cbcff1ec17be,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-c7c0d6c1-24e9-4536-906d-f219962b1260,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-b1ca0157-3e19-4f3f-8a23-e616c62a82a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-a2ad5d9e-be1c-4e20-86c8-6f8bfa95e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-fa9c0261-8788-4ac2-825b-3d06d24a7039,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-7d78a9b6-e830-4624-ad76-51fb27afbca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221591734-172.17.0.4-1595330040264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-35310164-7fd1-4e27-a69a-5734f02d4025,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-2916095a-1088-4a59-b7f8-d203cd76716b,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-da077d93-91a9-4ef5-ba8f-827f611520f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-9a0b936b-60c3-4b78-817c-c2bb788a3bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-68b186bf-9302-4283-aa44-2a7f2c167c79,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-cef142da-6b6a-4446-a9dc-ecdebe78c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-6e8ec67c-8e1c-495a-b1bc-8e95bed307d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-daa7974a-267b-4713-98f8-51107f2da801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221591734-172.17.0.4-1595330040264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-35310164-7fd1-4e27-a69a-5734f02d4025,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-2916095a-1088-4a59-b7f8-d203cd76716b,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-da077d93-91a9-4ef5-ba8f-827f611520f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-9a0b936b-60c3-4b78-817c-c2bb788a3bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-68b186bf-9302-4283-aa44-2a7f2c167c79,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-cef142da-6b6a-4446-a9dc-ecdebe78c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-6e8ec67c-8e1c-495a-b1bc-8e95bed307d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-daa7974a-267b-4713-98f8-51107f2da801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263868126-172.17.0.4-1595330231447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-aaf540ee-fab8-4ed7-98ce-2b2949abeeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-0e91b281-65e8-46f1-9780-6c2c0a26f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-40c40d52-61b1-4784-9505-8034d1ccd669,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-6713076e-5cb2-4d3c-91ab-7694f2ba9767,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-c502d375-ac99-499b-8921-b61e4f0d19ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-152e4915-b582-4a80-ab15-408609bf36bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-30ea367e-d8fa-49bf-86d8-00f7c80be6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-bf690218-4e48-4f90-a349-973f0583a382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263868126-172.17.0.4-1595330231447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-aaf540ee-fab8-4ed7-98ce-2b2949abeeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-0e91b281-65e8-46f1-9780-6c2c0a26f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-40c40d52-61b1-4784-9505-8034d1ccd669,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-6713076e-5cb2-4d3c-91ab-7694f2ba9767,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-c502d375-ac99-499b-8921-b61e4f0d19ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-152e4915-b582-4a80-ab15-408609bf36bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-30ea367e-d8fa-49bf-86d8-00f7c80be6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-bf690218-4e48-4f90-a349-973f0583a382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443434851-172.17.0.4-1595331032144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36497,DS-369bad2e-19bd-4094-be01-842a5acd098e,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-5283647a-cbe3-4417-a733-4d521915cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-d27f1617-3f5b-4667-8b74-a89dd5ac363d,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-124192db-7488-4e0a-9ec1-5ea1336d6cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-e11d091f-4374-42a5-b24b-39d5dc73ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-479b8105-2043-434f-a99f-f6a42cd215cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-758dba2c-d294-45c5-b622-cd81d2dfbe2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-b359a483-a911-4891-9eff-7b7117ec2731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443434851-172.17.0.4-1595331032144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36497,DS-369bad2e-19bd-4094-be01-842a5acd098e,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-5283647a-cbe3-4417-a733-4d521915cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-d27f1617-3f5b-4667-8b74-a89dd5ac363d,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-124192db-7488-4e0a-9ec1-5ea1336d6cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-e11d091f-4374-42a5-b24b-39d5dc73ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-479b8105-2043-434f-a99f-f6a42cd215cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-758dba2c-d294-45c5-b622-cd81d2dfbe2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-b359a483-a911-4891-9eff-7b7117ec2731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866030614-172.17.0.4-1595331176385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-f97f1ee1-7b44-428d-8c9a-532a0051637b,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-2efaae68-35ce-4a63-b763-8582cc8341f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-24fc352d-0e8c-4895-9088-6186c3185c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-23201e1b-ecda-4536-828c-d46b90f1243b,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-6403a237-608b-4220-bdfc-ef0ec97cbd87,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-f4845c92-b1d9-4b5d-a30b-1f4eb30a02b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-f6297aa4-ff00-4c5a-b006-504eb34a2bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-665bcf8f-12af-4f50-a664-2a9e528ef71d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866030614-172.17.0.4-1595331176385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-f97f1ee1-7b44-428d-8c9a-532a0051637b,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-2efaae68-35ce-4a63-b763-8582cc8341f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-24fc352d-0e8c-4895-9088-6186c3185c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-23201e1b-ecda-4536-828c-d46b90f1243b,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-6403a237-608b-4220-bdfc-ef0ec97cbd87,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-f4845c92-b1d9-4b5d-a30b-1f4eb30a02b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-f6297aa4-ff00-4c5a-b006-504eb34a2bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-665bcf8f-12af-4f50-a664-2a9e528ef71d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386150443-172.17.0.4-1595331214649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-339642ef-16e4-4206-8181-23cb5e00f13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-9fccd361-6175-4c5f-8a00-68a4158fede9,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-434232be-3b89-4802-8078-842c4960080b,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-99efe031-4a3b-4f03-aaf2-db366b4ca80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-8edf1d7f-11be-4a39-bbe3-907135c1ef69,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-34ba50a8-0b58-4df8-8f79-216e6a5830a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-35f210c8-0d4a-40ec-8ae4-0fe61535905e,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-099ee909-ae25-4808-8bd0-136819f13fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386150443-172.17.0.4-1595331214649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-339642ef-16e4-4206-8181-23cb5e00f13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-9fccd361-6175-4c5f-8a00-68a4158fede9,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-434232be-3b89-4802-8078-842c4960080b,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-99efe031-4a3b-4f03-aaf2-db366b4ca80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-8edf1d7f-11be-4a39-bbe3-907135c1ef69,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-34ba50a8-0b58-4df8-8f79-216e6a5830a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-35f210c8-0d4a-40ec-8ae4-0fe61535905e,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-099ee909-ae25-4808-8bd0-136819f13fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263088460-172.17.0.4-1595331503236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-ea09f6ce-a73e-4551-b470-b5826a33f7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-ce2dfeea-74a9-4fea-bf7f-deb96ce58366,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-d31d414f-203b-46ec-9798-83b5f30e5fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-5e3e7ccd-ca03-4abb-a08f-c68823d02469,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-55989e85-bb4e-4d83-9b0f-ac97571fba97,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-362f64dc-b5ff-4256-95cb-aa1c2287e8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-8dc3f457-b6cc-42f0-b71e-5d1fd25844ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-a0b027dc-0452-486d-833c-43e9db40c672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263088460-172.17.0.4-1595331503236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-ea09f6ce-a73e-4551-b470-b5826a33f7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-ce2dfeea-74a9-4fea-bf7f-deb96ce58366,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-d31d414f-203b-46ec-9798-83b5f30e5fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-5e3e7ccd-ca03-4abb-a08f-c68823d02469,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-55989e85-bb4e-4d83-9b0f-ac97571fba97,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-362f64dc-b5ff-4256-95cb-aa1c2287e8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-8dc3f457-b6cc-42f0-b71e-5d1fd25844ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-a0b027dc-0452-486d-833c-43e9db40c672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278973456-172.17.0.4-1595331837526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39823,DS-fae4d3b2-1b1b-4204-bfec-760e8ef29cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-ea41f6ff-dab2-4c9e-8300-9440fda57d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-7fb94d5e-152d-486c-99db-f089ae7d69c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-51693835-3cb6-4e9e-a3ab-0cb4fbb95a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-108ef8df-0125-4374-87e5-89258c00a088,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-d8abb9de-895c-49d2-bab3-20d600de2a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-82d413a9-49ad-4ca2-ab0a-93f60741e8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-e12f85f9-706e-4ff5-9bbc-3af01bd022b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278973456-172.17.0.4-1595331837526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39823,DS-fae4d3b2-1b1b-4204-bfec-760e8ef29cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-ea41f6ff-dab2-4c9e-8300-9440fda57d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-7fb94d5e-152d-486c-99db-f089ae7d69c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-51693835-3cb6-4e9e-a3ab-0cb4fbb95a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-108ef8df-0125-4374-87e5-89258c00a088,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-d8abb9de-895c-49d2-bab3-20d600de2a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-82d413a9-49ad-4ca2-ab0a-93f60741e8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-e12f85f9-706e-4ff5-9bbc-3af01bd022b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409992290-172.17.0.4-1595332062969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-77b7c468-d72b-4604-8103-68950c1f8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-3751da43-7adb-432a-8ea8-9228a927f9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-9d0864be-75d9-424d-bade-0b454d2fe4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-48b781e2-7015-479d-b7b3-3e7c52b1417c,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-4446b86c-21a8-43ee-9633-4c04c052bb14,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-35b47fa6-9ec7-4119-9cb8-c4baee248a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-be96453b-bb22-4a5a-a79e-6f574d9cb16f,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-9edce3a3-dc66-4c4f-a85f-68cc48f8c2e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409992290-172.17.0.4-1595332062969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-77b7c468-d72b-4604-8103-68950c1f8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-3751da43-7adb-432a-8ea8-9228a927f9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-9d0864be-75d9-424d-bade-0b454d2fe4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-48b781e2-7015-479d-b7b3-3e7c52b1417c,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-4446b86c-21a8-43ee-9633-4c04c052bb14,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-35b47fa6-9ec7-4119-9cb8-c4baee248a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-be96453b-bb22-4a5a-a79e-6f574d9cb16f,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-9edce3a3-dc66-4c4f-a85f-68cc48f8c2e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032616735-172.17.0.4-1595332212604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-93895588-6ed8-4755-8026-9e471e8acd62,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-d01f5df3-ff3a-403f-ad5e-bf8b22f9c0df,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-626210b0-01b2-4528-b261-7aed93a4127a,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-4dea5bd1-2f86-46dc-b97d-c101961f9131,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-5fa92e0a-ce30-49f0-8853-53d99c514e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-a9d3ec18-6e9b-441a-8be9-1bca74240c43,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-5caff013-4942-4400-8442-68731afe6aef,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-b9e69124-71d4-48be-bf69-27917a5faccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032616735-172.17.0.4-1595332212604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-93895588-6ed8-4755-8026-9e471e8acd62,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-d01f5df3-ff3a-403f-ad5e-bf8b22f9c0df,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-626210b0-01b2-4528-b261-7aed93a4127a,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-4dea5bd1-2f86-46dc-b97d-c101961f9131,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-5fa92e0a-ce30-49f0-8853-53d99c514e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-a9d3ec18-6e9b-441a-8be9-1bca74240c43,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-5caff013-4942-4400-8442-68731afe6aef,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-b9e69124-71d4-48be-bf69-27917a5faccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482782779-172.17.0.4-1595332421170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43576,DS-3c5b3488-dc09-488f-aa91-0b52de33608f,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-844e7d8a-0253-4bfb-93a9-400cd9ce2fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-6b2d3f44-02b2-4a30-9364-3fe712ba0b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-b7f49d76-4384-4a88-9f88-c124ec60b364,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-6612e6bd-d293-40b6-b678-ad8df5967f50,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-bc0487f0-06fe-402c-a204-786c1a13029c,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-75bdb273-e4e8-4c80-b6d5-9cbf3429d3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-0c613a3a-c67b-455c-b8d0-66ca9f8197b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482782779-172.17.0.4-1595332421170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43576,DS-3c5b3488-dc09-488f-aa91-0b52de33608f,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-844e7d8a-0253-4bfb-93a9-400cd9ce2fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-6b2d3f44-02b2-4a30-9364-3fe712ba0b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-b7f49d76-4384-4a88-9f88-c124ec60b364,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-6612e6bd-d293-40b6-b678-ad8df5967f50,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-bc0487f0-06fe-402c-a204-786c1a13029c,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-75bdb273-e4e8-4c80-b6d5-9cbf3429d3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-0c613a3a-c67b-455c-b8d0-66ca9f8197b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523830451-172.17.0.4-1595332975451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-b9773490-86bb-4b8c-bb26-9cb195772dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-dc16a945-9ff1-49b9-b5cc-a8c42209e262,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-56a395fc-7379-4cd1-b76e-38a7b877dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-4605f29a-820d-4607-a1f1-0e2b6ad35580,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-ed2d7898-33be-409c-8c03-6f14f113c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-2b3bf11c-a60f-4982-aa52-e5ea6a912b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-6d44c5c8-35cc-4839-b225-5d421905fa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-794fa295-5a95-4590-b805-f9b4aecf5773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523830451-172.17.0.4-1595332975451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-b9773490-86bb-4b8c-bb26-9cb195772dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-dc16a945-9ff1-49b9-b5cc-a8c42209e262,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-56a395fc-7379-4cd1-b76e-38a7b877dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-4605f29a-820d-4607-a1f1-0e2b6ad35580,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-ed2d7898-33be-409c-8c03-6f14f113c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-2b3bf11c-a60f-4982-aa52-e5ea6a912b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-6d44c5c8-35cc-4839-b225-5d421905fa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-794fa295-5a95-4590-b805-f9b4aecf5773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246275473-172.17.0.4-1595333157108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42322,DS-5e4e0d24-2582-49f2-b343-c4a02a398a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-1c762243-6605-4a54-ac87-8c89080c9096,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-fdc5fd8b-8562-4290-b1b8-218509703438,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-fe155eac-05fd-4495-9442-e75410c0ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-e838271d-ff80-4618-9ec8-844710fc95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-f4a27d00-c586-4c53-b29f-7a085f36c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-89fac471-14bd-41d2-bec1-f858b12eb4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-26555226-8004-4479-b2c7-347205f4aff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246275473-172.17.0.4-1595333157108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42322,DS-5e4e0d24-2582-49f2-b343-c4a02a398a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-1c762243-6605-4a54-ac87-8c89080c9096,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-fdc5fd8b-8562-4290-b1b8-218509703438,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-fe155eac-05fd-4495-9442-e75410c0ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-e838271d-ff80-4618-9ec8-844710fc95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-f4a27d00-c586-4c53-b29f-7a085f36c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-89fac471-14bd-41d2-bec1-f858b12eb4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-26555226-8004-4479-b2c7-347205f4aff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437308873-172.17.0.4-1595333194494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-8ab8da78-781e-44fa-9f26-8de69fa537c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-cff4aec9-1b20-4ba8-98e0-c6662cfc9327,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-5b956133-fd93-4b7d-839d-7fb724b8769f,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-96c0ef14-e1ef-4990-aed6-fe4a71510680,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-523a5f59-5925-4cd3-9f0b-4bb4f7ba828f,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-7bf345ae-cd02-48b6-9914-2de5da98f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-a56a399e-d3ef-4e81-bb19-960b583bd4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-1534430c-d45b-40eb-bb11-406d7516044a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437308873-172.17.0.4-1595333194494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-8ab8da78-781e-44fa-9f26-8de69fa537c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-cff4aec9-1b20-4ba8-98e0-c6662cfc9327,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-5b956133-fd93-4b7d-839d-7fb724b8769f,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-96c0ef14-e1ef-4990-aed6-fe4a71510680,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-523a5f59-5925-4cd3-9f0b-4bb4f7ba828f,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-7bf345ae-cd02-48b6-9914-2de5da98f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-a56a399e-d3ef-4e81-bb19-960b583bd4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-1534430c-d45b-40eb-bb11-406d7516044a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041330527-172.17.0.4-1595333300900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41104,DS-f03973e0-8110-4221-947f-db90a34957f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-71cad2cd-1e3b-4472-bf4c-375bf7b0b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-ab0aa058-f4a6-4113-8a40-7499e6b56edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-f590c4e7-0f7e-4c74-8e60-086c9a9fe5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-4da77acf-7c99-41cf-88f0-c5934768a32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-56668a50-39a5-44c0-b314-bd7b97a435d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-3447290a-b431-4306-8ee9-ae22e6349a30,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-d288af03-1532-41e9-8a22-f2b810d8637a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041330527-172.17.0.4-1595333300900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41104,DS-f03973e0-8110-4221-947f-db90a34957f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-71cad2cd-1e3b-4472-bf4c-375bf7b0b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-ab0aa058-f4a6-4113-8a40-7499e6b56edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-f590c4e7-0f7e-4c74-8e60-086c9a9fe5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-4da77acf-7c99-41cf-88f0-c5934768a32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-56668a50-39a5-44c0-b314-bd7b97a435d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-3447290a-b431-4306-8ee9-ae22e6349a30,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-d288af03-1532-41e9-8a22-f2b810d8637a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5627
