reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600636439-172.17.0.18-1595359638611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40255,DS-28411188-e721-4bbe-b127-cd724b056edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-96db38ef-9604-4265-a836-5b2646b07a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-fbd8d97d-ff31-4b96-a9be-b8bc05dbd9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-25eff350-2463-4245-9b12-cc0565df91b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-b6957b34-1219-4fc1-9138-81b171ef426b,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-77dce4a2-2dc7-46c7-91c7-1178ae201281,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-30a0d80e-c029-431d-b8b6-32dacb05e0be,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-07b8e57e-c4f4-4437-b11e-bedef80ecbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600636439-172.17.0.18-1595359638611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40255,DS-28411188-e721-4bbe-b127-cd724b056edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-96db38ef-9604-4265-a836-5b2646b07a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-fbd8d97d-ff31-4b96-a9be-b8bc05dbd9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-25eff350-2463-4245-9b12-cc0565df91b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-b6957b34-1219-4fc1-9138-81b171ef426b,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-77dce4a2-2dc7-46c7-91c7-1178ae201281,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-30a0d80e-c029-431d-b8b6-32dacb05e0be,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-07b8e57e-c4f4-4437-b11e-bedef80ecbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239286432-172.17.0.18-1595359711800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33501,DS-ad7d5102-18f0-4cc4-80b7-bc0a748cc0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-9e5c5c40-5615-465a-9b6d-4f7bff9bdd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-d1801ccd-3769-4830-a388-8767abe9e581,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-e352954f-87b4-4444-bacb-4e3c14e42fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-0317402d-b960-47b7-a3dc-8b127273d82b,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-26f92db4-5d50-458d-8ef6-cee269ece7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-88796b7b-b9cb-4cb2-b91d-3707deecb01b,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-fe2207df-7a73-4d0b-bb1e-92ada03ce5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239286432-172.17.0.18-1595359711800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33501,DS-ad7d5102-18f0-4cc4-80b7-bc0a748cc0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-9e5c5c40-5615-465a-9b6d-4f7bff9bdd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-d1801ccd-3769-4830-a388-8767abe9e581,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-e352954f-87b4-4444-bacb-4e3c14e42fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-0317402d-b960-47b7-a3dc-8b127273d82b,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-26f92db4-5d50-458d-8ef6-cee269ece7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-88796b7b-b9cb-4cb2-b91d-3707deecb01b,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-fe2207df-7a73-4d0b-bb1e-92ada03ce5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410927929-172.17.0.18-1595359906717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35219,DS-ac8b9ff4-41c4-453c-93cb-5ea9a3815a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-02d5f830-b6b8-4030-926f-657248c9f425,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-4c79e099-0c93-459a-9154-d7f7bbf96210,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-32c1e41e-aeff-4e14-8991-1c53dd035964,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-29976850-dade-4545-ac49-7a77bd7a75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-08d29dbe-baf6-473a-ae49-970db85332d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-5510f355-5067-46af-a6b9-aa5e68720cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-a92184e6-eb64-490e-8e6a-6ef8a4e2e65b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410927929-172.17.0.18-1595359906717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35219,DS-ac8b9ff4-41c4-453c-93cb-5ea9a3815a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-02d5f830-b6b8-4030-926f-657248c9f425,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-4c79e099-0c93-459a-9154-d7f7bbf96210,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-32c1e41e-aeff-4e14-8991-1c53dd035964,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-29976850-dade-4545-ac49-7a77bd7a75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-08d29dbe-baf6-473a-ae49-970db85332d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-5510f355-5067-46af-a6b9-aa5e68720cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-a92184e6-eb64-490e-8e6a-6ef8a4e2e65b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545052859-172.17.0.18-1595360536977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40113,DS-f1326fa6-83c0-412e-94d5-514b9da967c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-f3081b7a-bb62-4567-96c2-2b610ecc01f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-12190ea2-c797-49a8-908b-3a81626d6faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-0d904bd1-9553-4c85-b526-a731bf34bdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-ece5bbba-0072-4829-9a84-da4a3c1b8635,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-5bbf3572-759d-4d0a-ac9a-ca99bd8ffddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-e6fc7126-24d5-4483-b181-28153c10c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-d1be1c9a-1690-4e62-962c-7158d53aadab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545052859-172.17.0.18-1595360536977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40113,DS-f1326fa6-83c0-412e-94d5-514b9da967c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-f3081b7a-bb62-4567-96c2-2b610ecc01f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-12190ea2-c797-49a8-908b-3a81626d6faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-0d904bd1-9553-4c85-b526-a731bf34bdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-ece5bbba-0072-4829-9a84-da4a3c1b8635,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-5bbf3572-759d-4d0a-ac9a-ca99bd8ffddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-e6fc7126-24d5-4483-b181-28153c10c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-d1be1c9a-1690-4e62-962c-7158d53aadab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891100319-172.17.0.18-1595360841891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41446,DS-bbc167f3-b2f6-4748-bfdb-7785e42fcf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-edf0d9aa-c7cb-4c40-b391-2832cfc49b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-aa7cc17f-3555-4fdf-9a5c-defe17b24fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-ac801cf9-93a0-4d73-9334-06492a0920fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-5ba1d8b4-2ced-49dc-ad3e-7d59747b030e,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-85f1666f-1e1f-4bbd-a022-605ef2975d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-90878a58-67f1-4953-ae4a-1ede14ba681f,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-52459331-4a1b-4760-8c33-cd5d7362f62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891100319-172.17.0.18-1595360841891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41446,DS-bbc167f3-b2f6-4748-bfdb-7785e42fcf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-edf0d9aa-c7cb-4c40-b391-2832cfc49b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-aa7cc17f-3555-4fdf-9a5c-defe17b24fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-ac801cf9-93a0-4d73-9334-06492a0920fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-5ba1d8b4-2ced-49dc-ad3e-7d59747b030e,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-85f1666f-1e1f-4bbd-a022-605ef2975d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-90878a58-67f1-4953-ae4a-1ede14ba681f,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-52459331-4a1b-4760-8c33-cd5d7362f62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980473269-172.17.0.18-1595361204165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39557,DS-6f9e1a95-dfe5-4a20-b4f5-d6a3cf0408ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-2b6e77a2-8150-4f93-85a7-662b526b1e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-3d32ad8b-fb3f-4447-b049-cf9fa99c3498,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-8649dabf-e24c-4de2-a12c-e0acaad26b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-ee66d37c-d4a4-4095-b937-a8b51182908b,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-1849e66f-c939-46bc-8061-dded1ca3e86f,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-178e2b59-86c4-436d-84fe-3257329eb44c,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-07752efc-f855-47dc-97ec-bd22cde10d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980473269-172.17.0.18-1595361204165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39557,DS-6f9e1a95-dfe5-4a20-b4f5-d6a3cf0408ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-2b6e77a2-8150-4f93-85a7-662b526b1e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-3d32ad8b-fb3f-4447-b049-cf9fa99c3498,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-8649dabf-e24c-4de2-a12c-e0acaad26b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-ee66d37c-d4a4-4095-b937-a8b51182908b,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-1849e66f-c939-46bc-8061-dded1ca3e86f,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-178e2b59-86c4-436d-84fe-3257329eb44c,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-07752efc-f855-47dc-97ec-bd22cde10d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994741004-172.17.0.18-1595361388535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42889,DS-4ef9a53a-99de-42b6-9a6b-0078b8a13c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-199c546c-22d6-4121-be07-39c01ce5e933,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-444cbc44-1a24-4f61-853d-31bff85fcb29,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-488333e4-08d2-4b50-b12a-009a554aea80,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-37ceeb56-3bc1-4a64-81ba-8dbb16cee411,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-b60d18a1-9e96-49b4-87aa-967b6c912302,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-f00a74af-3ba5-4dea-9e5c-89c36338f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-814afdae-58ef-418d-95a1-1736c9171bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994741004-172.17.0.18-1595361388535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42889,DS-4ef9a53a-99de-42b6-9a6b-0078b8a13c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-199c546c-22d6-4121-be07-39c01ce5e933,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-444cbc44-1a24-4f61-853d-31bff85fcb29,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-488333e4-08d2-4b50-b12a-009a554aea80,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-37ceeb56-3bc1-4a64-81ba-8dbb16cee411,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-b60d18a1-9e96-49b4-87aa-967b6c912302,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-f00a74af-3ba5-4dea-9e5c-89c36338f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-814afdae-58ef-418d-95a1-1736c9171bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987786482-172.17.0.18-1595361593501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38587,DS-50994fce-fb9d-468b-832c-519ae7974d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-c527eef6-e920-4523-9009-60ce81c48134,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-95931b57-1ca7-463a-baa0-da49e864bf20,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-046c2e54-643b-45a4-bcef-dacf3aee5313,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-ccb98a19-079a-493d-a51f-586255af304f,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-a35b6c1c-4005-4b2f-94a3-677f72c3e9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-989211f8-ed91-4d12-b503-8dec9fd312e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-f95c47e3-6774-409a-ba1a-dcbbc593b9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987786482-172.17.0.18-1595361593501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38587,DS-50994fce-fb9d-468b-832c-519ae7974d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-c527eef6-e920-4523-9009-60ce81c48134,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-95931b57-1ca7-463a-baa0-da49e864bf20,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-046c2e54-643b-45a4-bcef-dacf3aee5313,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-ccb98a19-079a-493d-a51f-586255af304f,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-a35b6c1c-4005-4b2f-94a3-677f72c3e9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-989211f8-ed91-4d12-b503-8dec9fd312e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-f95c47e3-6774-409a-ba1a-dcbbc593b9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237615241-172.17.0.18-1595361697107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46631,DS-f333d422-a3b8-47c3-a06c-5d56345cbf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-b823863a-2c91-40c3-8ec0-61485b71d9db,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-1a451c1f-f1ac-4d08-b238-21cc7dd1764e,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-f764cceb-e2f2-4f45-9298-106b98c5b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-6fcd7679-5fcf-4bb6-96c2-e12d0616f054,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-197a3165-c553-4a2d-a867-8b20049fd17f,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-1777fdec-7155-4eaa-b032-d86a3ff2b197,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-892d0be5-8034-455c-8235-f074b63eb9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237615241-172.17.0.18-1595361697107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46631,DS-f333d422-a3b8-47c3-a06c-5d56345cbf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-b823863a-2c91-40c3-8ec0-61485b71d9db,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-1a451c1f-f1ac-4d08-b238-21cc7dd1764e,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-f764cceb-e2f2-4f45-9298-106b98c5b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-6fcd7679-5fcf-4bb6-96c2-e12d0616f054,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-197a3165-c553-4a2d-a867-8b20049fd17f,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-1777fdec-7155-4eaa-b032-d86a3ff2b197,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-892d0be5-8034-455c-8235-f074b63eb9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132244394-172.17.0.18-1595362343346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37571,DS-c74d1e53-c9f1-407e-aac9-2ac4043e647c,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-76fb5963-b915-4870-999a-c16908cc8e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-abfb52dd-6419-4f89-91d6-5edddf0c563f,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-d7673e6e-28f2-4ae6-a07d-3996a52f0a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-3b353de7-f39e-40fd-b06c-543e3dd22b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-7eaec533-ff41-41c5-8949-aa6f7894b633,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-dc7fdddd-2b24-4ef6-91f3-288d3736cc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-0d85c1e9-d954-4519-b145-75c5ced0b5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132244394-172.17.0.18-1595362343346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37571,DS-c74d1e53-c9f1-407e-aac9-2ac4043e647c,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-76fb5963-b915-4870-999a-c16908cc8e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-abfb52dd-6419-4f89-91d6-5edddf0c563f,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-d7673e6e-28f2-4ae6-a07d-3996a52f0a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-3b353de7-f39e-40fd-b06c-543e3dd22b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-7eaec533-ff41-41c5-8949-aa6f7894b633,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-dc7fdddd-2b24-4ef6-91f3-288d3736cc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-0d85c1e9-d954-4519-b145-75c5ced0b5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498402525-172.17.0.18-1595362499695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39622,DS-5a42d828-1fde-4e60-8ee0-727dceb099fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-bdc4f4b8-91ef-452f-953f-ee06dadabc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-0f9df673-2939-41a9-92aa-aa6c2b2180bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-2e75ac1d-ae6c-47b1-8760-c763b7699135,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-f83fc954-5ad7-47dc-a73e-5c7a0f4b70b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-e05220cd-14ec-4ca4-b667-1bdd3089dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-ee15e8b2-08d4-4cc9-9fab-efecd6d5fdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-2fab0d30-68da-4d3c-a31a-1a840e84bef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498402525-172.17.0.18-1595362499695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39622,DS-5a42d828-1fde-4e60-8ee0-727dceb099fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-bdc4f4b8-91ef-452f-953f-ee06dadabc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-0f9df673-2939-41a9-92aa-aa6c2b2180bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-2e75ac1d-ae6c-47b1-8760-c763b7699135,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-f83fc954-5ad7-47dc-a73e-5c7a0f4b70b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-e05220cd-14ec-4ca4-b667-1bdd3089dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-ee15e8b2-08d4-4cc9-9fab-efecd6d5fdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-2fab0d30-68da-4d3c-a31a-1a840e84bef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031649111-172.17.0.18-1595362659483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39265,DS-ec8a5bc7-24a1-476e-a8ec-0db876decd58,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-860eb2a0-371f-4791-92a7-c8de159350fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-e4614f35-2b07-4275-b565-06c29e32835f,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-4b61edd5-738f-4e4e-bef1-d1c4c730dd26,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-e466d467-4104-4abc-abf5-59962c34f070,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-174833a3-cff0-44e1-8609-73018ad9fd18,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-0b520388-d5be-48e8-9018-7248a2943a28,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-e55c62c6-50ed-4cde-9555-679178551a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031649111-172.17.0.18-1595362659483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39265,DS-ec8a5bc7-24a1-476e-a8ec-0db876decd58,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-860eb2a0-371f-4791-92a7-c8de159350fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-e4614f35-2b07-4275-b565-06c29e32835f,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-4b61edd5-738f-4e4e-bef1-d1c4c730dd26,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-e466d467-4104-4abc-abf5-59962c34f070,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-174833a3-cff0-44e1-8609-73018ad9fd18,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-0b520388-d5be-48e8-9018-7248a2943a28,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-e55c62c6-50ed-4cde-9555-679178551a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1820682206-172.17.0.18-1595363192616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40853,DS-05d948c7-e262-46a4-81c6-ed449800f920,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-da9b4667-2fa3-40f7-b563-9e6ac17f9e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-2a5400e0-bed7-46a7-8d07-d532277169f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-15d1ff82-7e94-4777-99c1-7d10f9827723,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-74bf7339-77b7-4b07-b906-a36178ccd44d,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-f4b7c6c1-10e0-41c1-97d3-40c800463708,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-a777ab61-f775-4bbf-b4ce-c2e5738adeae,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-c99dd8ef-a928-42f6-baa6-634803cdf8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1820682206-172.17.0.18-1595363192616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40853,DS-05d948c7-e262-46a4-81c6-ed449800f920,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-da9b4667-2fa3-40f7-b563-9e6ac17f9e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-2a5400e0-bed7-46a7-8d07-d532277169f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-15d1ff82-7e94-4777-99c1-7d10f9827723,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-74bf7339-77b7-4b07-b906-a36178ccd44d,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-f4b7c6c1-10e0-41c1-97d3-40c800463708,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-a777ab61-f775-4bbf-b4ce-c2e5738adeae,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-c99dd8ef-a928-42f6-baa6-634803cdf8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-34665784-172.17.0.18-1595363467358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-06819660-c8ac-49ec-b590-b3c361c18157,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-b331761c-6673-4c3f-a0c6-0b0f61491787,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-2fd5c31d-4b13-4d1e-9d10-3bc9684a6707,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-81757e20-3872-4d92-8f98-ecd6f85d1207,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-69fb822a-1503-4d20-b9d0-c92f21c9d9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-24c6531d-ab55-4fb5-82a9-9e15feef6ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-aa958497-5656-426c-9b7b-1bc75bab4384,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-c6fc6440-509b-4898-a398-b6ae13bc2d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-34665784-172.17.0.18-1595363467358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-06819660-c8ac-49ec-b590-b3c361c18157,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-b331761c-6673-4c3f-a0c6-0b0f61491787,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-2fd5c31d-4b13-4d1e-9d10-3bc9684a6707,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-81757e20-3872-4d92-8f98-ecd6f85d1207,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-69fb822a-1503-4d20-b9d0-c92f21c9d9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-24c6531d-ab55-4fb5-82a9-9e15feef6ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-aa958497-5656-426c-9b7b-1bc75bab4384,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-c6fc6440-509b-4898-a398-b6ae13bc2d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960952533-172.17.0.18-1595363546682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44726,DS-e9471ea3-3296-4795-b0cb-4ebb21baa696,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-c262f543-26b8-4b25-a6f1-ff9d7c12c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-17bbb250-e7a9-405f-87af-77970f9d8550,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-6cec5fee-5e13-45f7-bd4f-8bf5ba84d188,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-b8f347fe-070d-45f0-a7e6-19317eabe942,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-4996e4f5-7eb0-4bb2-947b-0af872d9a540,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-3507eaaa-8edb-4c68-b640-72db3161ebc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-977acb0c-d4ab-43a6-8bb6-15339c6f9264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960952533-172.17.0.18-1595363546682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44726,DS-e9471ea3-3296-4795-b0cb-4ebb21baa696,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-c262f543-26b8-4b25-a6f1-ff9d7c12c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-17bbb250-e7a9-405f-87af-77970f9d8550,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-6cec5fee-5e13-45f7-bd4f-8bf5ba84d188,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-b8f347fe-070d-45f0-a7e6-19317eabe942,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-4996e4f5-7eb0-4bb2-947b-0af872d9a540,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-3507eaaa-8edb-4c68-b640-72db3161ebc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-977acb0c-d4ab-43a6-8bb6-15339c6f9264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010731332-172.17.0.18-1595363920533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-378e0553-1308-4e97-8ebd-dad1c72469d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-239f278c-e3bb-4340-9dad-dbc65b6cbfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-a0aea9cb-6268-4782-854d-5cfdfc515bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-c8f4ab4e-bd8a-4f7d-b6bb-afaceee55160,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-824a2928-7c62-4a50-9ac0-72a85b062a99,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-00871686-916f-47b7-b447-9c579b182475,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-acf1a2c7-b563-4e98-9339-91ec9adef9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-3499bc35-2759-4168-b78c-cdd7e078eebb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010731332-172.17.0.18-1595363920533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-378e0553-1308-4e97-8ebd-dad1c72469d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-239f278c-e3bb-4340-9dad-dbc65b6cbfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-a0aea9cb-6268-4782-854d-5cfdfc515bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-c8f4ab4e-bd8a-4f7d-b6bb-afaceee55160,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-824a2928-7c62-4a50-9ac0-72a85b062a99,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-00871686-916f-47b7-b447-9c579b182475,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-acf1a2c7-b563-4e98-9339-91ec9adef9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-3499bc35-2759-4168-b78c-cdd7e078eebb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743201466-172.17.0.18-1595364123999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-43cfcf41-5406-4fe0-87b3-576f58502aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-0dee67eb-a6f3-4920-b346-51ecda6a5d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-2577c37c-a394-40a2-b36b-b89dd03165e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-6f9ffc65-223e-40f0-8838-310d4c68c38c,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-a1b5175e-a40f-4d68-b596-d219d3548baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-b314af4f-2f3c-46f0-8efd-34a7bae6c9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-ce3a7e4d-0e25-4914-88a8-abc183d83544,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-16d343be-a231-47c2-9ddd-e6776895b7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743201466-172.17.0.18-1595364123999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-43cfcf41-5406-4fe0-87b3-576f58502aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-0dee67eb-a6f3-4920-b346-51ecda6a5d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-2577c37c-a394-40a2-b36b-b89dd03165e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-6f9ffc65-223e-40f0-8838-310d4c68c38c,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-a1b5175e-a40f-4d68-b596-d219d3548baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-b314af4f-2f3c-46f0-8efd-34a7bae6c9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-ce3a7e4d-0e25-4914-88a8-abc183d83544,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-16d343be-a231-47c2-9ddd-e6776895b7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5079
