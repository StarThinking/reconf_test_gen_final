reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584132149-172.17.0.12-1595342195248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37578,DS-3d621da2-bb23-46c8-9446-88299cf511e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-448f4b8f-3846-4e91-887c-3c413ab62ced,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-851033ad-2bc2-40ee-8e84-740cac1fae45,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-5f9195a4-9196-410f-9ab3-4ed43c275028,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-fa401d7f-db19-48dd-94ce-09f5e59b7fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-b40d4dce-531b-4597-87cd-d5cd82dfc5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-1402e0d7-bd49-4338-8c72-a1f1bf6e41be,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-9d8bb2c7-4929-45c8-9c46-b6ffc4e2d231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584132149-172.17.0.12-1595342195248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37578,DS-3d621da2-bb23-46c8-9446-88299cf511e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-448f4b8f-3846-4e91-887c-3c413ab62ced,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-851033ad-2bc2-40ee-8e84-740cac1fae45,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-5f9195a4-9196-410f-9ab3-4ed43c275028,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-fa401d7f-db19-48dd-94ce-09f5e59b7fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-b40d4dce-531b-4597-87cd-d5cd82dfc5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-1402e0d7-bd49-4338-8c72-a1f1bf6e41be,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-9d8bb2c7-4929-45c8-9c46-b6ffc4e2d231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57365788-172.17.0.12-1595342379429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-e8e054aa-ef73-4a30-b93f-8d9bca5d42af,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-a34310bd-1d00-4fe9-b7b1-ef002596efab,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-9ed080d6-aef3-45cb-a1e9-4b08540e39ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-c7be8acd-ca44-4c0c-929a-95504d66a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-20cc5f33-74d9-4fe4-b5a1-38355b466dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-2cd9e297-3d57-4ce7-90f5-6141bdd0fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-130a024b-8c41-4bd4-bcdb-0fa0913fc4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-205eb9e2-5d91-4452-9d2a-b50456baad8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57365788-172.17.0.12-1595342379429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-e8e054aa-ef73-4a30-b93f-8d9bca5d42af,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-a34310bd-1d00-4fe9-b7b1-ef002596efab,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-9ed080d6-aef3-45cb-a1e9-4b08540e39ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-c7be8acd-ca44-4c0c-929a-95504d66a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-20cc5f33-74d9-4fe4-b5a1-38355b466dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-2cd9e297-3d57-4ce7-90f5-6141bdd0fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-130a024b-8c41-4bd4-bcdb-0fa0913fc4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-205eb9e2-5d91-4452-9d2a-b50456baad8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308125066-172.17.0.12-1595342802371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36870,DS-11b72bb6-b355-4f12-bcec-fdfbd948a4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-d439eee5-6c60-4815-b79c-f2fbb2e46083,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-c7fb143a-d153-477a-9dbb-c4efa77ebdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-4cb411a6-ed21-4738-b1fe-7361ce78bb58,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-d172e3e9-ebd9-4c13-b13a-d72dcb4a0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-44a73c2e-ac7d-431b-b273-b2b25b9fd1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-f65d52d7-48b1-4bdf-bc05-936054a8c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-bc5f0fef-09f8-429e-8920-c554a3ca402d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308125066-172.17.0.12-1595342802371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36870,DS-11b72bb6-b355-4f12-bcec-fdfbd948a4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-d439eee5-6c60-4815-b79c-f2fbb2e46083,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-c7fb143a-d153-477a-9dbb-c4efa77ebdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-4cb411a6-ed21-4738-b1fe-7361ce78bb58,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-d172e3e9-ebd9-4c13-b13a-d72dcb4a0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-44a73c2e-ac7d-431b-b273-b2b25b9fd1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-f65d52d7-48b1-4bdf-bc05-936054a8c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-bc5f0fef-09f8-429e-8920-c554a3ca402d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813140460-172.17.0.12-1595343027666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40258,DS-43980359-0c59-4f01-8202-2d7165924794,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-c0ea22db-e4b5-4682-822d-03c61e72f92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-bc99fbdc-1e49-4e5b-aca6-55dc57045353,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-bd8c9c10-3dc7-412a-ad0c-6f2f1ec9cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-a4d1d1c3-69fd-4733-8be1-7c0e6e111578,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-34fe639b-756a-40a9-9338-e0c3c0668a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-1c7d1dd7-f178-4c1b-aa0e-90528cadd1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-9be631ce-2661-4879-8d7c-fb21ec403e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813140460-172.17.0.12-1595343027666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40258,DS-43980359-0c59-4f01-8202-2d7165924794,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-c0ea22db-e4b5-4682-822d-03c61e72f92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-bc99fbdc-1e49-4e5b-aca6-55dc57045353,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-bd8c9c10-3dc7-412a-ad0c-6f2f1ec9cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-a4d1d1c3-69fd-4733-8be1-7c0e6e111578,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-34fe639b-756a-40a9-9338-e0c3c0668a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-1c7d1dd7-f178-4c1b-aa0e-90528cadd1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-9be631ce-2661-4879-8d7c-fb21ec403e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953122011-172.17.0.12-1595343327376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-587a1c55-2799-47e3-9eb1-2ac1b360222e,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-ff84c2ca-648e-4516-9413-e1cd24953897,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-6495254c-9bfc-48b8-a7aa-e41871eef39e,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-2c936af3-3d88-4395-bef3-4fdc1dd0572e,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-168e66b5-1dee-455e-a645-1d366bd2a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-8f29b187-d2e2-4c6b-910f-e1d534f7edea,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-d5250866-efc5-4f5c-848a-65423a524ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-748c722f-7387-4147-8c89-109161c44480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953122011-172.17.0.12-1595343327376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-587a1c55-2799-47e3-9eb1-2ac1b360222e,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-ff84c2ca-648e-4516-9413-e1cd24953897,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-6495254c-9bfc-48b8-a7aa-e41871eef39e,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-2c936af3-3d88-4395-bef3-4fdc1dd0572e,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-168e66b5-1dee-455e-a645-1d366bd2a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-8f29b187-d2e2-4c6b-910f-e1d534f7edea,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-d5250866-efc5-4f5c-848a-65423a524ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-748c722f-7387-4147-8c89-109161c44480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79272049-172.17.0.12-1595343503304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-e9395336-67dd-46d6-aca3-e03e95f34dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-1ed31490-3990-420b-9222-44a27382e834,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-a9c01f4d-0cfd-4e3a-bacf-5d93ecb24b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-f7f1a7d5-4d93-416c-8d0f-b69b0a828334,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-03c93863-a81f-454d-9a2b-871fe5ab9065,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-5099e614-ab87-4bc2-bf88-e5e92cd666b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-5e02b586-a350-4391-93ae-0678f017d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-1bef2e3f-0899-4215-999c-e847eeaa1e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79272049-172.17.0.12-1595343503304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-e9395336-67dd-46d6-aca3-e03e95f34dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-1ed31490-3990-420b-9222-44a27382e834,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-a9c01f4d-0cfd-4e3a-bacf-5d93ecb24b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-f7f1a7d5-4d93-416c-8d0f-b69b0a828334,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-03c93863-a81f-454d-9a2b-871fe5ab9065,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-5099e614-ab87-4bc2-bf88-e5e92cd666b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-5e02b586-a350-4391-93ae-0678f017d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-1bef2e3f-0899-4215-999c-e847eeaa1e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354799246-172.17.0.12-1595343612141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-1e024a7a-7fa5-4a4e-a015-a2b82bcd6ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-201a6bda-2484-4f53-a156-f1828a4cb08a,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-0fdd52df-7459-4ae0-b5d7-ec65f368b318,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-2bd0cf27-a10d-46ba-83a2-aae8f96ce784,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-f982ad62-834b-414f-861e-ca15eddff580,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-40e18b1f-820b-4ef3-97b0-c8e942a3aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-b21af3f9-2c99-4733-a6fb-ad777288a31c,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-652a8dcd-c121-4ba5-9cb7-a08b75627e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354799246-172.17.0.12-1595343612141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-1e024a7a-7fa5-4a4e-a015-a2b82bcd6ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-201a6bda-2484-4f53-a156-f1828a4cb08a,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-0fdd52df-7459-4ae0-b5d7-ec65f368b318,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-2bd0cf27-a10d-46ba-83a2-aae8f96ce784,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-f982ad62-834b-414f-861e-ca15eddff580,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-40e18b1f-820b-4ef3-97b0-c8e942a3aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-b21af3f9-2c99-4733-a6fb-ad777288a31c,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-652a8dcd-c121-4ba5-9cb7-a08b75627e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783742587-172.17.0.12-1595343827425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33825,DS-bb528a49-4fcd-41d5-8633-7e6a370088c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-388c746d-0035-4fb4-9c36-ed9b9e529e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-35a7ea75-682f-48a0-8cb4-d572fe570b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-d02997c7-9f4d-4176-8518-c116a15150b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-efe474ca-654b-4dcc-98f6-4496ec601d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-43cf2761-a0d3-440b-9cb4-f53f428b4bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-cbb5629e-8351-43eb-b505-7021accae1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-6427d456-ffb7-4867-a0d1-ddb4e755b5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783742587-172.17.0.12-1595343827425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33825,DS-bb528a49-4fcd-41d5-8633-7e6a370088c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-388c746d-0035-4fb4-9c36-ed9b9e529e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-35a7ea75-682f-48a0-8cb4-d572fe570b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-d02997c7-9f4d-4176-8518-c116a15150b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-efe474ca-654b-4dcc-98f6-4496ec601d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-43cf2761-a0d3-440b-9cb4-f53f428b4bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-cbb5629e-8351-43eb-b505-7021accae1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-6427d456-ffb7-4867-a0d1-ddb4e755b5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976672018-172.17.0.12-1595343865196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-ced882bd-e4e9-4231-b0d8-c42aab4fb015,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-408d2ce5-2ca4-40a0-95b3-6cd8dcdc74b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-b79b4f09-f67a-45fa-9782-5e1b51acd72a,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-6f817500-b298-4dfa-a113-363e24de02d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-7790e07b-5166-455f-9388-b6d2a014253d,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-93458cb8-9c72-4338-9604-1b6831d87083,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-ba46ddc8-e083-4d43-ac5c-5c97920cce89,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-970fce8f-827a-49c0-8bea-b0ac9ba7e403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976672018-172.17.0.12-1595343865196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-ced882bd-e4e9-4231-b0d8-c42aab4fb015,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-408d2ce5-2ca4-40a0-95b3-6cd8dcdc74b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-b79b4f09-f67a-45fa-9782-5e1b51acd72a,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-6f817500-b298-4dfa-a113-363e24de02d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-7790e07b-5166-455f-9388-b6d2a014253d,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-93458cb8-9c72-4338-9604-1b6831d87083,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-ba46ddc8-e083-4d43-ac5c-5c97920cce89,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-970fce8f-827a-49c0-8bea-b0ac9ba7e403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202661233-172.17.0.12-1595344205050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34474,DS-ed5df5c0-1951-4314-b316-dc4fc51c5c54,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-24ef5891-dcbc-4570-a33d-f8d934b7e1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-1d403aeb-9ae2-46fc-9f42-b61ca517b014,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-60a7fb19-057f-4db2-90ef-bd9c998a9d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-b128d460-9eaf-4176-af82-ed43ebe56079,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-40199122-85d6-487d-bec2-beffd2b6cad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-644c5a51-1713-4730-8724-172b853fe4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-fd61f298-777a-4ead-a2bc-e0aee732a190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202661233-172.17.0.12-1595344205050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34474,DS-ed5df5c0-1951-4314-b316-dc4fc51c5c54,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-24ef5891-dcbc-4570-a33d-f8d934b7e1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-1d403aeb-9ae2-46fc-9f42-b61ca517b014,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-60a7fb19-057f-4db2-90ef-bd9c998a9d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-b128d460-9eaf-4176-af82-ed43ebe56079,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-40199122-85d6-487d-bec2-beffd2b6cad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-644c5a51-1713-4730-8724-172b853fe4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-fd61f298-777a-4ead-a2bc-e0aee732a190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426960692-172.17.0.12-1595344393188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45933,DS-a9817488-834e-4644-80e6-2c88f8be6a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-805e8bdc-bbab-4c99-a6c6-74822a0ef7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-3ec8977e-5cfd-49bc-a7a3-a373a4ba496e,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-7272cfad-17c1-40e3-a263-22d47243d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-a967d0d2-9665-4b9d-8119-9b8160bd6daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-cba85a3d-56ac-4b6a-8b9b-1a832fe6f36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-e21000cd-fcc6-4037-9e6b-c754e442c517,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-b0c5ff7b-f05f-4eb2-a8c0-5ea918fae2a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426960692-172.17.0.12-1595344393188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45933,DS-a9817488-834e-4644-80e6-2c88f8be6a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-805e8bdc-bbab-4c99-a6c6-74822a0ef7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-3ec8977e-5cfd-49bc-a7a3-a373a4ba496e,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-7272cfad-17c1-40e3-a263-22d47243d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-a967d0d2-9665-4b9d-8119-9b8160bd6daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-cba85a3d-56ac-4b6a-8b9b-1a832fe6f36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-e21000cd-fcc6-4037-9e6b-c754e442c517,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-b0c5ff7b-f05f-4eb2-a8c0-5ea918fae2a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118298738-172.17.0.12-1595344958453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43749,DS-500c7804-c0ba-46aa-84ad-ba58cc8b234e,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-8baa9609-80c3-4c08-b2aa-6ca83c3709dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-a6abc19d-86d0-4c27-91bf-ea5718dd59ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-df989492-2579-4800-9971-4d2f011b98bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-b7d2092d-955d-4d40-843f-31ab11b938fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-652233d6-d134-4bc8-b580-de9de51a535b,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-870a2c13-49fe-409b-82a0-9fb9bae24c69,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-62f9e81e-dffe-48aa-8e68-8d7c0c1d5e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118298738-172.17.0.12-1595344958453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43749,DS-500c7804-c0ba-46aa-84ad-ba58cc8b234e,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-8baa9609-80c3-4c08-b2aa-6ca83c3709dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-a6abc19d-86d0-4c27-91bf-ea5718dd59ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-df989492-2579-4800-9971-4d2f011b98bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-b7d2092d-955d-4d40-843f-31ab11b938fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-652233d6-d134-4bc8-b580-de9de51a535b,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-870a2c13-49fe-409b-82a0-9fb9bae24c69,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-62f9e81e-dffe-48aa-8e68-8d7c0c1d5e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457108522-172.17.0.12-1595345058496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-8b415c23-f6d4-4e60-b6d1-da2566a47b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-b58fe15a-2141-4d6a-a299-8ebb2a9c4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-d31063ee-a9b9-4c8c-8a07-8cd81a555eea,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-a1c413b4-87f2-4e22-adbd-9325b58636a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-7c8d95bb-674e-4f58-8010-9b53cc60c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-fe4c4e83-bb60-4860-9506-aafce5b75153,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-35d499b4-a615-4ad6-9a5a-4d0a29c0cb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-d0eba7d4-0105-4837-8334-8f998f5830f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457108522-172.17.0.12-1595345058496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-8b415c23-f6d4-4e60-b6d1-da2566a47b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-b58fe15a-2141-4d6a-a299-8ebb2a9c4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-d31063ee-a9b9-4c8c-8a07-8cd81a555eea,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-a1c413b4-87f2-4e22-adbd-9325b58636a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-7c8d95bb-674e-4f58-8010-9b53cc60c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-fe4c4e83-bb60-4860-9506-aafce5b75153,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-35d499b4-a615-4ad6-9a5a-4d0a29c0cb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-d0eba7d4-0105-4837-8334-8f998f5830f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750372372-172.17.0.12-1595345915807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36253,DS-343c219e-e9df-4310-9da2-fa65b060bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-94a9ffdf-e8e9-40ce-b87d-5ffd73d65598,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-866e688d-9a0a-4854-96dd-0bae51fb12d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-5e741266-a2c1-4fc5-96cc-2ea765fff97d,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-d67ac529-36be-4a28-b2a8-b8649604a28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-2b23d26a-da28-4fed-8b99-7c1f14f270ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-112d4bf6-cb7f-47e7-b82d-58c748c4fff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-454d6a2c-7421-43f1-8810-aaa61ede2c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750372372-172.17.0.12-1595345915807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36253,DS-343c219e-e9df-4310-9da2-fa65b060bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-94a9ffdf-e8e9-40ce-b87d-5ffd73d65598,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-866e688d-9a0a-4854-96dd-0bae51fb12d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-5e741266-a2c1-4fc5-96cc-2ea765fff97d,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-d67ac529-36be-4a28-b2a8-b8649604a28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-2b23d26a-da28-4fed-8b99-7c1f14f270ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-112d4bf6-cb7f-47e7-b82d-58c748c4fff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-454d6a2c-7421-43f1-8810-aaa61ede2c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31348541-172.17.0.12-1595346576206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-58ef6f25-e4ad-4199-b333-5873319e80d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-4703ae59-4508-4681-ab2a-93b208cb9511,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-90a3d78d-52db-4c0f-8b44-44bb4ce22b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-ac27f7db-644a-482a-b15b-12866a74d202,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-987b3b90-1de2-4294-ad90-16b07fd925fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-66f2b0b2-851c-47f2-87d2-d9977eca80f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-b2a4ce5e-8a9c-4269-a961-ee386b1b6737,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-2e78c9c9-08c6-464e-8fcb-255cdae12ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31348541-172.17.0.12-1595346576206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-58ef6f25-e4ad-4199-b333-5873319e80d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-4703ae59-4508-4681-ab2a-93b208cb9511,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-90a3d78d-52db-4c0f-8b44-44bb4ce22b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-ac27f7db-644a-482a-b15b-12866a74d202,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-987b3b90-1de2-4294-ad90-16b07fd925fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-66f2b0b2-851c-47f2-87d2-d9977eca80f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-b2a4ce5e-8a9c-4269-a961-ee386b1b6737,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-2e78c9c9-08c6-464e-8fcb-255cdae12ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769331334-172.17.0.12-1595346739548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46230,DS-e409bb73-eb18-4d76-bfd5-268300ef3209,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-d0fe962d-f066-4be2-ac7f-8d5486326179,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-96f504ee-2f82-43f1-84ff-9bbc50369b88,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-d0a8d66a-ea56-4965-9118-94cf5f144eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-1d111a75-9d9f-429f-a83c-886c89733713,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-87c9d7e0-abf8-4cec-93f2-981c4e1808f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-19a21204-fb39-491c-95b7-b4d64bd0b0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-77a4c263-cadd-48a6-9a91-7db5f3915f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769331334-172.17.0.12-1595346739548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46230,DS-e409bb73-eb18-4d76-bfd5-268300ef3209,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-d0fe962d-f066-4be2-ac7f-8d5486326179,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-96f504ee-2f82-43f1-84ff-9bbc50369b88,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-d0a8d66a-ea56-4965-9118-94cf5f144eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-1d111a75-9d9f-429f-a83c-886c89733713,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-87c9d7e0-abf8-4cec-93f2-981c4e1808f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-19a21204-fb39-491c-95b7-b4d64bd0b0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-77a4c263-cadd-48a6-9a91-7db5f3915f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483617169-172.17.0.12-1595347355310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-5431feca-ad44-46fe-abf5-9de6f639b233,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-30694679-c9fb-4224-8033-5422d1e523fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-da37c8c1-fad2-4505-a81f-4882fc56504d,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-0f3d7c79-7c2d-4fbe-b44b-eeea80a5d654,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-7375f779-b5a3-48e5-a1d8-dc9aa666a26f,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-6899d2a8-7da8-4a44-a9b8-7d34af7432ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-a262765b-c1d8-45e5-ae58-0ca1d79e25af,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-ce4d175c-f835-4938-b6dc-024cbf99235d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483617169-172.17.0.12-1595347355310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-5431feca-ad44-46fe-abf5-9de6f639b233,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-30694679-c9fb-4224-8033-5422d1e523fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-da37c8c1-fad2-4505-a81f-4882fc56504d,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-0f3d7c79-7c2d-4fbe-b44b-eeea80a5d654,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-7375f779-b5a3-48e5-a1d8-dc9aa666a26f,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-6899d2a8-7da8-4a44-a9b8-7d34af7432ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-a262765b-c1d8-45e5-ae58-0ca1d79e25af,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-ce4d175c-f835-4938-b6dc-024cbf99235d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5565
