reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166592226-172.17.0.18-1595355312796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35013,DS-abe0b736-ee6c-4ad0-84e6-94aa4e312254,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-e813a8eb-9567-4033-bb1f-42850d804b19,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-3df592b0-2964-43a2-98a4-99affd797071,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-ccd107ac-fb6b-4c89-930a-acdc64314809,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-61b4d603-04f2-490d-a2f7-f73562f615ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-b856b672-4e97-448b-9f7b-f8a52f7a5db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-94691340-f0c2-4ceb-b708-35cd49e6a45c,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-b88fae1b-a8e0-4670-b33e-23102de7a47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166592226-172.17.0.18-1595355312796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35013,DS-abe0b736-ee6c-4ad0-84e6-94aa4e312254,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-e813a8eb-9567-4033-bb1f-42850d804b19,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-3df592b0-2964-43a2-98a4-99affd797071,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-ccd107ac-fb6b-4c89-930a-acdc64314809,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-61b4d603-04f2-490d-a2f7-f73562f615ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-b856b672-4e97-448b-9f7b-f8a52f7a5db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-94691340-f0c2-4ceb-b708-35cd49e6a45c,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-b88fae1b-a8e0-4670-b33e-23102de7a47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371368840-172.17.0.18-1595355598023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-9331ccba-3cb2-4084-9e7d-e552e7cea48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-83d377e2-6d71-4103-88bf-75594fec9311,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-81e682e5-bcd3-439d-bf2d-65112f32da61,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-1d03c5b2-4018-480d-b17f-2eb9934b81b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-958953b2-ff67-4de5-b72b-f524180665a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-f7304baf-2012-45c8-b013-0ee5900245ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-44264ac9-6a76-47bc-a32d-6e24f9757aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-852c339e-8bf2-405c-b07c-26342d4a7600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371368840-172.17.0.18-1595355598023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-9331ccba-3cb2-4084-9e7d-e552e7cea48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-83d377e2-6d71-4103-88bf-75594fec9311,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-81e682e5-bcd3-439d-bf2d-65112f32da61,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-1d03c5b2-4018-480d-b17f-2eb9934b81b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-958953b2-ff67-4de5-b72b-f524180665a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-f7304baf-2012-45c8-b013-0ee5900245ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-44264ac9-6a76-47bc-a32d-6e24f9757aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-852c339e-8bf2-405c-b07c-26342d4a7600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282652006-172.17.0.18-1595355927915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43244,DS-a7552049-98d3-48be-a463-55675eb38415,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f7f4d7f6-efe5-42b0-94b7-849595d2a725,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-cc6c4ed1-5371-4914-8fbd-7dcd34d041e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-4982686a-724a-40c9-a392-7f223c5e6466,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-43ce393b-3fa9-41c8-9729-d8520edf6df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-aa1a7bdf-a36e-498f-81df-7da4f2093c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-be8eca87-a548-4a77-bf6c-3e14ac6ff50c,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-66c4bc76-99df-4778-855d-216ee71c5398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282652006-172.17.0.18-1595355927915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43244,DS-a7552049-98d3-48be-a463-55675eb38415,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f7f4d7f6-efe5-42b0-94b7-849595d2a725,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-cc6c4ed1-5371-4914-8fbd-7dcd34d041e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-4982686a-724a-40c9-a392-7f223c5e6466,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-43ce393b-3fa9-41c8-9729-d8520edf6df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-aa1a7bdf-a36e-498f-81df-7da4f2093c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-be8eca87-a548-4a77-bf6c-3e14ac6ff50c,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-66c4bc76-99df-4778-855d-216ee71c5398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011729705-172.17.0.18-1595355959628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-ef36b09f-e1ff-4cea-a36f-a3e8c822d7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-bc880465-c505-455e-8dbf-361372618050,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-7fa427bc-1f2f-4519-8713-7aecf3a9945b,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-6c6d760e-2af7-4e1a-a9f3-e411780f3f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-5971a07f-f364-4448-be4b-b8ab5b060a85,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-8faa99f2-3860-45fc-8876-cd6cd499a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-788e544c-c4a8-48da-8c4e-b2f339364f35,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-a78d02c3-d511-4d15-9924-ba97684cfeb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011729705-172.17.0.18-1595355959628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-ef36b09f-e1ff-4cea-a36f-a3e8c822d7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-bc880465-c505-455e-8dbf-361372618050,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-7fa427bc-1f2f-4519-8713-7aecf3a9945b,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-6c6d760e-2af7-4e1a-a9f3-e411780f3f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-5971a07f-f364-4448-be4b-b8ab5b060a85,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-8faa99f2-3860-45fc-8876-cd6cd499a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-788e544c-c4a8-48da-8c4e-b2f339364f35,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-a78d02c3-d511-4d15-9924-ba97684cfeb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913872591-172.17.0.18-1595356839275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35155,DS-59f193f0-25b6-43b9-be2d-17ba4fd0e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-be00ef2e-42db-441e-9020-3ce1d074f479,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-8ec65bca-4266-4c7c-afc6-6a5dc773f5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-51e47fa4-ff14-4303-9834-1ce1520fe073,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-37418239-94b0-4ad5-970b-f69c0fac290b,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-453fd701-4b33-48cb-aca1-bb94e146cb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-33a9687f-d8dd-4840-864e-95245152c940,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-0c5b84b4-655c-42e1-a63a-e39575241c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913872591-172.17.0.18-1595356839275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35155,DS-59f193f0-25b6-43b9-be2d-17ba4fd0e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-be00ef2e-42db-441e-9020-3ce1d074f479,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-8ec65bca-4266-4c7c-afc6-6a5dc773f5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-51e47fa4-ff14-4303-9834-1ce1520fe073,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-37418239-94b0-4ad5-970b-f69c0fac290b,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-453fd701-4b33-48cb-aca1-bb94e146cb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-33a9687f-d8dd-4840-864e-95245152c940,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-0c5b84b4-655c-42e1-a63a-e39575241c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164097725-172.17.0.18-1595358653190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36623,DS-d9dfaf2a-5ebb-4be4-8ff1-dc8f3cfc6aca,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-1a6d4cc7-d4fa-4a31-9084-52c9cdd7037c,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-f927f173-0f73-41d6-94ac-bb2f90b8a588,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-89e9824d-8c75-455d-bbf8-aa94340f7ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-138c3f15-8f08-486d-89a8-67ab57457a32,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-fd260a9d-85b5-4f80-b60a-30104d307841,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-4db47d98-caa1-4d89-a0c1-e2ccb3580fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-c4c5ac2e-11dc-4789-8e65-d0f3074711d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164097725-172.17.0.18-1595358653190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36623,DS-d9dfaf2a-5ebb-4be4-8ff1-dc8f3cfc6aca,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-1a6d4cc7-d4fa-4a31-9084-52c9cdd7037c,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-f927f173-0f73-41d6-94ac-bb2f90b8a588,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-89e9824d-8c75-455d-bbf8-aa94340f7ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-138c3f15-8f08-486d-89a8-67ab57457a32,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-fd260a9d-85b5-4f80-b60a-30104d307841,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-4db47d98-caa1-4d89-a0c1-e2ccb3580fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-c4c5ac2e-11dc-4789-8e65-d0f3074711d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841833709-172.17.0.18-1595358796285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39118,DS-739332c5-5ee6-44d8-a68b-6fc016716c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-afb5e3fe-77f0-4d25-92f9-2171988a994b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-814eb557-0ef6-4980-965e-9ef03f6e83b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-b99c86d2-cb6a-4e25-9530-8a9598ca3caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-aea07397-b429-4fce-a973-6ed97555f128,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-618b8e96-e4b3-4b74-a8f3-a442b174061d,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-1bc1ba4f-f90e-4192-80b3-eef8f3d83ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-4fd1b09d-f5ab-49b2-83a2-8d44ccc212dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841833709-172.17.0.18-1595358796285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39118,DS-739332c5-5ee6-44d8-a68b-6fc016716c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-afb5e3fe-77f0-4d25-92f9-2171988a994b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-814eb557-0ef6-4980-965e-9ef03f6e83b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-b99c86d2-cb6a-4e25-9530-8a9598ca3caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-aea07397-b429-4fce-a973-6ed97555f128,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-618b8e96-e4b3-4b74-a8f3-a442b174061d,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-1bc1ba4f-f90e-4192-80b3-eef8f3d83ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-4fd1b09d-f5ab-49b2-83a2-8d44ccc212dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907292542-172.17.0.18-1595359461699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35985,DS-84c2a98b-f00a-41ad-8f6a-028c0ab1ca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-3765ea69-a493-49d2-bf09-b89ff24ebc63,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-76203d8f-d2a3-4cff-b5a6-284c27527829,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-3f72208e-b8b0-4085-b2cc-c4b629bd7b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-09d58867-cceb-4c41-ac4b-ee63272c7f54,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-d140f16c-7ee1-40b0-8c02-ed6eaf9af3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-42c63785-f76d-4c85-b4b0-f1d1b4398579,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-2b672d2d-f3f3-4eac-b792-918ec0af901c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907292542-172.17.0.18-1595359461699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35985,DS-84c2a98b-f00a-41ad-8f6a-028c0ab1ca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-3765ea69-a493-49d2-bf09-b89ff24ebc63,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-76203d8f-d2a3-4cff-b5a6-284c27527829,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-3f72208e-b8b0-4085-b2cc-c4b629bd7b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-09d58867-cceb-4c41-ac4b-ee63272c7f54,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-d140f16c-7ee1-40b0-8c02-ed6eaf9af3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-42c63785-f76d-4c85-b4b0-f1d1b4398579,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-2b672d2d-f3f3-4eac-b792-918ec0af901c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997375427-172.17.0.18-1595359964424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-16a2651e-d9b7-47ba-b448-e66a9751c214,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-42c2c419-8478-476f-be67-950ef82c2220,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-4e8ca76b-3c52-4442-8fcd-e18ca5726377,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-bc9c4c7f-fc87-48e1-9d6d-0ad3ffc0912e,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-afbdb23f-9b0d-4aaa-bd1c-96681234e1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-847b8259-c353-493e-ac35-21834bdb43ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-19aa7c25-91c1-4ead-88a5-e734aaa2429a,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-720ffa3f-7aff-4433-8fa3-0434c304c32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997375427-172.17.0.18-1595359964424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-16a2651e-d9b7-47ba-b448-e66a9751c214,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-42c2c419-8478-476f-be67-950ef82c2220,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-4e8ca76b-3c52-4442-8fcd-e18ca5726377,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-bc9c4c7f-fc87-48e1-9d6d-0ad3ffc0912e,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-afbdb23f-9b0d-4aaa-bd1c-96681234e1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-847b8259-c353-493e-ac35-21834bdb43ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-19aa7c25-91c1-4ead-88a5-e734aaa2429a,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-720ffa3f-7aff-4433-8fa3-0434c304c32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519306077-172.17.0.18-1595360296584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39603,DS-89109327-e77d-43f9-b298-7785bf789d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-7aad6d62-87c6-43b3-8704-52d4cf34c5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-ccf35b6c-8ef9-4234-8f62-c08336b4a39a,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-cb878828-4a04-4cdc-991b-610ea6d1419c,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-7a738f9c-0934-45dd-96fc-bbb32512c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-22512c05-19ea-4926-bd82-4e313ba6122f,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-7d78b0c5-0b4c-4043-9c50-4414939e3cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-03781949-d0d7-4cda-b6e1-f6c0d64b7592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519306077-172.17.0.18-1595360296584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39603,DS-89109327-e77d-43f9-b298-7785bf789d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-7aad6d62-87c6-43b3-8704-52d4cf34c5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-ccf35b6c-8ef9-4234-8f62-c08336b4a39a,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-cb878828-4a04-4cdc-991b-610ea6d1419c,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-7a738f9c-0934-45dd-96fc-bbb32512c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-22512c05-19ea-4926-bd82-4e313ba6122f,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-7d78b0c5-0b4c-4043-9c50-4414939e3cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-03781949-d0d7-4cda-b6e1-f6c0d64b7592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5416
