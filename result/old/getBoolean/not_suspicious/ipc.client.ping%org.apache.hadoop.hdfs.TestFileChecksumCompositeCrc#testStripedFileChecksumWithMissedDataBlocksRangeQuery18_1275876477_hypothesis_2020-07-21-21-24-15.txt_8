reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995193078-172.17.0.16-1595367050725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44410,DS-7b891e97-55fa-47cf-b79a-87ea679ccc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-8eb41ba4-b126-4870-bed1-1396d43d2eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-91482c9c-6a2b-49ac-884e-28fe0b266417,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-950762ca-920c-42ae-841c-2c236ac959ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-ab1300fa-b914-4a68-943f-6edef4fd820f,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-0713d367-4137-4286-989e-7b45febd6052,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-3f217aa0-23e1-4e8e-92b3-8d5423377383,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-08b5fa7b-8ba5-4ef4-aa6f-0613bb25caf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995193078-172.17.0.16-1595367050725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44410,DS-7b891e97-55fa-47cf-b79a-87ea679ccc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-8eb41ba4-b126-4870-bed1-1396d43d2eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-91482c9c-6a2b-49ac-884e-28fe0b266417,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-950762ca-920c-42ae-841c-2c236ac959ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-ab1300fa-b914-4a68-943f-6edef4fd820f,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-0713d367-4137-4286-989e-7b45febd6052,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-3f217aa0-23e1-4e8e-92b3-8d5423377383,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-08b5fa7b-8ba5-4ef4-aa6f-0613bb25caf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225597297-172.17.0.16-1595367283627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-dd4bcb4e-6c21-4b6f-9cfb-1ae8de328fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-8751fdf6-c112-415d-baa1-9dfffd384c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-9ff4094e-c6f3-423c-a872-89090e0b9cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-fb5c7cd4-2581-4a78-bb67-c490916ea46e,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-532976bd-2252-498a-a78a-846e29a4313a,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-ba17a5f4-dae6-47e7-92b5-6676e02e6c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-9933dac6-f40a-4ae2-b9f3-7bf657e2b622,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-9a0d1bc9-fbe5-49e9-b3ec-8c7d273a2cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225597297-172.17.0.16-1595367283627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-dd4bcb4e-6c21-4b6f-9cfb-1ae8de328fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-8751fdf6-c112-415d-baa1-9dfffd384c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-9ff4094e-c6f3-423c-a872-89090e0b9cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-fb5c7cd4-2581-4a78-bb67-c490916ea46e,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-532976bd-2252-498a-a78a-846e29a4313a,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-ba17a5f4-dae6-47e7-92b5-6676e02e6c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-9933dac6-f40a-4ae2-b9f3-7bf657e2b622,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-9a0d1bc9-fbe5-49e9-b3ec-8c7d273a2cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804397693-172.17.0.16-1595368305106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-6a5b5236-acc2-42ae-af53-4c1e78950488,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-fcb733fc-f393-45a5-9f1c-c67eed6ac792,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-2f381e22-da05-45ef-9a45-aff2bcd7429e,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-9e3eee79-e45a-406d-b8d7-b602b2107cac,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-8477b2cc-5f58-4344-abef-90ccf43d919b,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-e2a6aeaa-b6a3-4f1c-bf88-cf32c42e360c,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-0edeb481-b283-47b8-8f81-3721af1be461,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-8af32eb3-2381-47f1-87d5-5c06722b4758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804397693-172.17.0.16-1595368305106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-6a5b5236-acc2-42ae-af53-4c1e78950488,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-fcb733fc-f393-45a5-9f1c-c67eed6ac792,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-2f381e22-da05-45ef-9a45-aff2bcd7429e,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-9e3eee79-e45a-406d-b8d7-b602b2107cac,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-8477b2cc-5f58-4344-abef-90ccf43d919b,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-e2a6aeaa-b6a3-4f1c-bf88-cf32c42e360c,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-0edeb481-b283-47b8-8f81-3721af1be461,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-8af32eb3-2381-47f1-87d5-5c06722b4758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810484317-172.17.0.16-1595368873747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33316,DS-65e28918-e837-4e4e-9c47-6404cd9d3a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-3f26ec00-e3ec-4298-962b-f8800c43201d,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-0883b215-97f1-45ab-9e7b-ccdd5a782020,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-b682e490-4e03-4d18-ae2b-9062d2c19fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-46b8fb10-cb38-438b-87d1-9ef299a30215,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-5e1e122d-dfa0-40dc-8504-42d3eda72bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-83c963e8-d889-41d4-b43b-2b94804c0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-bf0779a8-ddd7-4542-82a3-8bdc7165d9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810484317-172.17.0.16-1595368873747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33316,DS-65e28918-e837-4e4e-9c47-6404cd9d3a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-3f26ec00-e3ec-4298-962b-f8800c43201d,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-0883b215-97f1-45ab-9e7b-ccdd5a782020,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-b682e490-4e03-4d18-ae2b-9062d2c19fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-46b8fb10-cb38-438b-87d1-9ef299a30215,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-5e1e122d-dfa0-40dc-8504-42d3eda72bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-83c963e8-d889-41d4-b43b-2b94804c0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-bf0779a8-ddd7-4542-82a3-8bdc7165d9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763419310-172.17.0.16-1595369150089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34872,DS-d198f236-f49f-40c7-b7ea-74e68c6f8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-45f9f00c-d249-49b5-add5-9c6bd1e4cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-7dfcfce3-f3a2-4bf9-9c18-06509aae1229,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-0df89acc-a214-4c14-a366-91a673bb06b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-d1a2d077-2826-46d5-b951-881c6affe186,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-536d78b1-167b-46f0-8761-79e7f386def7,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-a416a715-b251-42a8-b799-11a844dfa140,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-8a6cdbdc-35f9-4aad-81ee-f616a7a511bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763419310-172.17.0.16-1595369150089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34872,DS-d198f236-f49f-40c7-b7ea-74e68c6f8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-45f9f00c-d249-49b5-add5-9c6bd1e4cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-7dfcfce3-f3a2-4bf9-9c18-06509aae1229,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-0df89acc-a214-4c14-a366-91a673bb06b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-d1a2d077-2826-46d5-b951-881c6affe186,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-536d78b1-167b-46f0-8761-79e7f386def7,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-a416a715-b251-42a8-b799-11a844dfa140,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-8a6cdbdc-35f9-4aad-81ee-f616a7a511bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528025173-172.17.0.16-1595369291671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35866,DS-5dc8f1ea-184e-49d8-ac5b-c1ded0ff5ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-18b469ba-b6e7-442e-a4cb-b80476ccb83f,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-7601d518-8ee2-45f2-b68b-22ddd686a5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-963fe387-33fb-4244-b6be-79dade5b7c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-b7866dc3-05e3-494a-b99d-cf6494afb117,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-5cd456c2-9fb1-427f-bc95-0949bb26ce6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-751b4253-faec-4e4b-afb9-0f2c3eca9e68,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-fd78abbd-f3f2-4971-9aff-68f2ce819e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528025173-172.17.0.16-1595369291671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35866,DS-5dc8f1ea-184e-49d8-ac5b-c1ded0ff5ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-18b469ba-b6e7-442e-a4cb-b80476ccb83f,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-7601d518-8ee2-45f2-b68b-22ddd686a5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-963fe387-33fb-4244-b6be-79dade5b7c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-b7866dc3-05e3-494a-b99d-cf6494afb117,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-5cd456c2-9fb1-427f-bc95-0949bb26ce6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-751b4253-faec-4e4b-afb9-0f2c3eca9e68,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-fd78abbd-f3f2-4971-9aff-68f2ce819e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753130151-172.17.0.16-1595369497626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-8fd04232-591e-4616-aa24-81258973f336,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-07f8bf0d-8cc5-4a11-8087-4f1eb6a9ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-b62429fd-61ae-41cc-afde-db6c0185c195,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-904276c6-e518-4329-b9d4-6fe64d708e74,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-d6f48035-f42a-4b5a-9600-330d0c6e3add,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-7caad703-ce26-4d0b-910b-951c773f5c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-e87afbfa-8537-4dbc-b3f9-164213763708,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-ba55d91d-0842-4106-8ebb-e011d304321b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753130151-172.17.0.16-1595369497626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-8fd04232-591e-4616-aa24-81258973f336,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-07f8bf0d-8cc5-4a11-8087-4f1eb6a9ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-b62429fd-61ae-41cc-afde-db6c0185c195,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-904276c6-e518-4329-b9d4-6fe64d708e74,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-d6f48035-f42a-4b5a-9600-330d0c6e3add,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-7caad703-ce26-4d0b-910b-951c773f5c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-e87afbfa-8537-4dbc-b3f9-164213763708,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-ba55d91d-0842-4106-8ebb-e011d304321b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956840225-172.17.0.16-1595369772593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-96282c3b-c948-4cb5-ac97-4fa0f04634d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-b9290194-a09e-4c2b-9f7b-d13cbb1c6c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-a0507a93-4659-46c2-9404-125d001d2253,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-955c3729-627b-4300-9c65-3980746cbda6,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-31223a1b-6509-44d8-a9db-693d436a62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-7bd68529-89fc-48d0-8513-fcbbf954122b,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-88e2cdc7-f7d7-4cf9-bf09-1e02c157077c,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-933661a2-3700-481f-b414-5f29bb5e4551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956840225-172.17.0.16-1595369772593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-96282c3b-c948-4cb5-ac97-4fa0f04634d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-b9290194-a09e-4c2b-9f7b-d13cbb1c6c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-a0507a93-4659-46c2-9404-125d001d2253,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-955c3729-627b-4300-9c65-3980746cbda6,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-31223a1b-6509-44d8-a9db-693d436a62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-7bd68529-89fc-48d0-8513-fcbbf954122b,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-88e2cdc7-f7d7-4cf9-bf09-1e02c157077c,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-933661a2-3700-481f-b414-5f29bb5e4551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610560353-172.17.0.16-1595369842172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40324,DS-e38afa55-80ed-4eda-b48e-7fe70af66ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-957fb4d9-0ba1-4fb3-9ea3-4ea1d2d2cfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-a9e857a8-2326-4ef1-ba42-d6a7e0ece60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-c6e9bf4d-ef99-4a22-8bdf-3015caea516d,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-1691eefa-43e1-4864-b40d-0d874778dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-aeb45476-7967-426e-9713-54b3998a468c,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-8710d0f6-6b2f-4da6-82f4-98efa7ee0bee,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-4d714258-5c34-4137-a14a-f5c376f7bf6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610560353-172.17.0.16-1595369842172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40324,DS-e38afa55-80ed-4eda-b48e-7fe70af66ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-957fb4d9-0ba1-4fb3-9ea3-4ea1d2d2cfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-a9e857a8-2326-4ef1-ba42-d6a7e0ece60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-c6e9bf4d-ef99-4a22-8bdf-3015caea516d,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-1691eefa-43e1-4864-b40d-0d874778dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-aeb45476-7967-426e-9713-54b3998a468c,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-8710d0f6-6b2f-4da6-82f4-98efa7ee0bee,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-4d714258-5c34-4137-a14a-f5c376f7bf6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558465447-172.17.0.16-1595370109081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-bb81c520-4cb0-469c-b1b0-9eb2bd2a2945,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-a7b4fc1d-2525-4e64-a3cd-de5eac31e2df,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-fa401871-22b2-4964-9d9c-c17333c0501e,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-f692bcbc-e172-44ba-b948-32440009f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-71bafda2-ccb5-4f5e-a67a-e7655c6e3efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-3fc6552e-c71e-4521-9fb7-aaa71262cc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-87066b3e-34cf-430b-b0ac-a38fd256a758,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-dd27f7a8-2c0f-4501-9351-4d6ffdda87ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558465447-172.17.0.16-1595370109081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-bb81c520-4cb0-469c-b1b0-9eb2bd2a2945,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-a7b4fc1d-2525-4e64-a3cd-de5eac31e2df,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-fa401871-22b2-4964-9d9c-c17333c0501e,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-f692bcbc-e172-44ba-b948-32440009f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-71bafda2-ccb5-4f5e-a67a-e7655c6e3efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-3fc6552e-c71e-4521-9fb7-aaa71262cc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-87066b3e-34cf-430b-b0ac-a38fd256a758,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-dd27f7a8-2c0f-4501-9351-4d6ffdda87ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140331453-172.17.0.16-1595370181019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-1a690c75-25dc-4650-957f-a82e48682495,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-33c8f831-294c-468d-aa03-4cdf7107d958,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-169e8684-c2a3-4be9-9cf6-46cfbd5fc94c,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-ed7a03c6-f134-49dc-9522-0b5b43f8238d,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-134a96d4-e1d3-4333-bc0c-2d241a11b218,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-c90556c0-a5ef-443c-a169-38dfaa9ded69,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-99bdd066-293b-46ea-8726-10f8c6643728,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-a6b3dcb4-a5c7-4f70-87ce-a660532665cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140331453-172.17.0.16-1595370181019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-1a690c75-25dc-4650-957f-a82e48682495,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-33c8f831-294c-468d-aa03-4cdf7107d958,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-169e8684-c2a3-4be9-9cf6-46cfbd5fc94c,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-ed7a03c6-f134-49dc-9522-0b5b43f8238d,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-134a96d4-e1d3-4333-bc0c-2d241a11b218,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-c90556c0-a5ef-443c-a169-38dfaa9ded69,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-99bdd066-293b-46ea-8726-10f8c6643728,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-a6b3dcb4-a5c7-4f70-87ce-a660532665cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773790467-172.17.0.16-1595370288487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44051,DS-f631d1cd-bbe3-417c-9762-4af8caf36da6,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-d21ee01f-c457-4ac4-8a60-597578cfe250,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-e0c73862-16ed-4470-9a56-be9239d8c207,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-51f6e700-4431-4481-aeba-fab2fe915827,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-94ee9dc1-4963-42f7-b93a-844cb11a6115,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-c34219b6-b98f-4828-8b4f-acd14bcf248c,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8594e5d9-3654-4aa9-9bb0-e7d7beabc3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-47b3de51-946a-4c1a-b7c7-e862cb7ee407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773790467-172.17.0.16-1595370288487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44051,DS-f631d1cd-bbe3-417c-9762-4af8caf36da6,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-d21ee01f-c457-4ac4-8a60-597578cfe250,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-e0c73862-16ed-4470-9a56-be9239d8c207,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-51f6e700-4431-4481-aeba-fab2fe915827,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-94ee9dc1-4963-42f7-b93a-844cb11a6115,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-c34219b6-b98f-4828-8b4f-acd14bcf248c,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8594e5d9-3654-4aa9-9bb0-e7d7beabc3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-47b3de51-946a-4c1a-b7c7-e862cb7ee407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509775024-172.17.0.16-1595370424984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-5feece0c-896d-49d4-a998-9a74f58c1fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-c4537511-a293-4b0c-9014-818ea64954e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-3fcfbfb6-c20f-4484-8853-04b652e2da08,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-f14fb9a6-8b8a-487e-9845-f423bdacb456,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-5cb82913-4369-44d4-84ef-c2c660daf889,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-575e852c-4315-4f9d-9de2-a46d35009b38,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-252cf9b1-4533-408d-9945-6350d1942830,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-8c2918a1-5740-42ed-96e7-746932095c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509775024-172.17.0.16-1595370424984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-5feece0c-896d-49d4-a998-9a74f58c1fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-c4537511-a293-4b0c-9014-818ea64954e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-3fcfbfb6-c20f-4484-8853-04b652e2da08,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-f14fb9a6-8b8a-487e-9845-f423bdacb456,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-5cb82913-4369-44d4-84ef-c2c660daf889,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-575e852c-4315-4f9d-9de2-a46d35009b38,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-252cf9b1-4533-408d-9945-6350d1942830,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-8c2918a1-5740-42ed-96e7-746932095c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919911240-172.17.0.16-1595370461616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-d3ec4a10-dd3f-47f2-a37c-a115d91bbacf,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-92b2a3db-fc56-479d-96dc-dc9699d1fbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-1f44897b-1ed2-4b9e-8d3a-bcae24437a28,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-5350ddc5-8bfc-4947-80c9-74cae867f870,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-a0446d40-a7cf-47a5-bd36-115a5854d7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-f0d7c3f9-6f13-4b6b-8cd3-6664a91965f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-c4d111fa-23fb-48d4-8249-bd7989ebc521,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-5ca31a23-57ae-41f7-824d-dd4f4fb93ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919911240-172.17.0.16-1595370461616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-d3ec4a10-dd3f-47f2-a37c-a115d91bbacf,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-92b2a3db-fc56-479d-96dc-dc9699d1fbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-1f44897b-1ed2-4b9e-8d3a-bcae24437a28,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-5350ddc5-8bfc-4947-80c9-74cae867f870,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-a0446d40-a7cf-47a5-bd36-115a5854d7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-f0d7c3f9-6f13-4b6b-8cd3-6664a91965f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-c4d111fa-23fb-48d4-8249-bd7989ebc521,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-5ca31a23-57ae-41f7-824d-dd4f4fb93ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839843359-172.17.0.16-1595370682786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41992,DS-fd0ec81c-a8b1-421f-8db4-a4f65df7a862,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-247eb5b0-93c0-46fe-9bfc-1941aaafeefe,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-7d1f6e13-29d1-471a-8cbd-094bfb9b30da,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-380412cf-06c8-4fdf-952a-59ee04501aba,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-6eb0bd9d-eb22-4f71-8ad2-af002aba5f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-9972b9ed-3bf3-4615-b78d-b1d3b39fe14b,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-adfcc6eb-58f1-44f0-b42f-81fbdac68f94,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-b59cb83b-ae65-468d-81bd-24dba6767adc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839843359-172.17.0.16-1595370682786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41992,DS-fd0ec81c-a8b1-421f-8db4-a4f65df7a862,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-247eb5b0-93c0-46fe-9bfc-1941aaafeefe,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-7d1f6e13-29d1-471a-8cbd-094bfb9b30da,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-380412cf-06c8-4fdf-952a-59ee04501aba,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-6eb0bd9d-eb22-4f71-8ad2-af002aba5f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-9972b9ed-3bf3-4615-b78d-b1d3b39fe14b,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-adfcc6eb-58f1-44f0-b42f-81fbdac68f94,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-b59cb83b-ae65-468d-81bd-24dba6767adc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285806403-172.17.0.16-1595370717871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-951c809c-3e3d-4c8c-8768-d4616e0e081b,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-989a264d-1fc4-4683-be46-3ec642282d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-a3867ae7-26b9-4b69-af01-69e57e3de25f,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-2a1f6baf-e85b-4a45-b7d1-07e0a163e778,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-74ca7d14-b522-4b45-9f7c-71fcf1d11d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-c9fbe5ea-d422-40d5-a2cb-ca0fe0491814,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-eea9cc86-2552-437d-9e51-fd30367a3500,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-fb9ae9f5-42f1-4ab8-a496-163348fd35fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285806403-172.17.0.16-1595370717871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-951c809c-3e3d-4c8c-8768-d4616e0e081b,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-989a264d-1fc4-4683-be46-3ec642282d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-a3867ae7-26b9-4b69-af01-69e57e3de25f,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-2a1f6baf-e85b-4a45-b7d1-07e0a163e778,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-74ca7d14-b522-4b45-9f7c-71fcf1d11d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-c9fbe5ea-d422-40d5-a2cb-ca0fe0491814,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-eea9cc86-2552-437d-9e51-fd30367a3500,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-fb9ae9f5-42f1-4ab8-a496-163348fd35fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719585215-172.17.0.16-1595370821328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-136051e7-aaf3-458d-b43d-6d753bc8c2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-6f9ae295-105a-401f-8af6-a1273455ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-a2a1e9ce-ea07-4883-a4ac-6b3a912b0160,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-a4a7bbb9-32ba-4d6e-8984-34747786cd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-540a7cf0-cb59-4d81-866f-48fc6fd75b26,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-df2e517a-737a-4fb4-8637-a64f48bd9c22,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-061527f1-2bbf-4fa9-8ac6-b939acc82017,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-35cf1d93-b8d4-4f14-87a6-a80835305613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719585215-172.17.0.16-1595370821328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-136051e7-aaf3-458d-b43d-6d753bc8c2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-6f9ae295-105a-401f-8af6-a1273455ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-a2a1e9ce-ea07-4883-a4ac-6b3a912b0160,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-a4a7bbb9-32ba-4d6e-8984-34747786cd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-540a7cf0-cb59-4d81-866f-48fc6fd75b26,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-df2e517a-737a-4fb4-8637-a64f48bd9c22,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-061527f1-2bbf-4fa9-8ac6-b939acc82017,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-35cf1d93-b8d4-4f14-87a6-a80835305613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697439616-172.17.0.16-1595370896055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-21bae833-b014-4be5-9929-3027862703a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-6e517046-113d-4d34-a0b0-5e43924d63a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-c87471b6-75ee-4224-9594-a8e366a70660,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-bb2d9d33-89a4-4376-a281-6efece72a29c,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-ecbce6b7-9052-43b7-a2d3-fe4e050763f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-450b9ad4-a299-4e4e-beac-edc5bb32c57b,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-6866e07a-877e-4020-94c2-b73dfe3b879e,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-efab284d-3871-4ff3-b55e-7f14085feae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697439616-172.17.0.16-1595370896055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-21bae833-b014-4be5-9929-3027862703a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-6e517046-113d-4d34-a0b0-5e43924d63a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-c87471b6-75ee-4224-9594-a8e366a70660,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-bb2d9d33-89a4-4376-a281-6efece72a29c,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-ecbce6b7-9052-43b7-a2d3-fe4e050763f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-450b9ad4-a299-4e4e-beac-edc5bb32c57b,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-6866e07a-877e-4020-94c2-b73dfe3b879e,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-efab284d-3871-4ff3-b55e-7f14085feae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618474112-172.17.0.16-1595371127265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46738,DS-c5e1c985-0b82-491a-9867-de2c43df0d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-052f9afb-5ce5-4b8e-8922-a5c226024003,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-f0d0cb16-ae6c-4da1-beb1-8f8ec5835e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-7523bc93-b9fb-498a-b0d0-3f6c7f72dbde,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-7707eb9a-bf98-4760-9516-435a668c17f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-ba559610-e5dc-4868-b6ed-d215adf31a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-901f4f5c-3cbe-4479-bf2f-4cf78d65fa11,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-72716f8c-6608-43e4-8194-7a1f8ea34267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618474112-172.17.0.16-1595371127265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46738,DS-c5e1c985-0b82-491a-9867-de2c43df0d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-052f9afb-5ce5-4b8e-8922-a5c226024003,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-f0d0cb16-ae6c-4da1-beb1-8f8ec5835e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-7523bc93-b9fb-498a-b0d0-3f6c7f72dbde,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-7707eb9a-bf98-4760-9516-435a668c17f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-ba559610-e5dc-4868-b6ed-d215adf31a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-901f4f5c-3cbe-4479-bf2f-4cf78d65fa11,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-72716f8c-6608-43e4-8194-7a1f8ea34267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576561700-172.17.0.16-1595371464307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-ceb571c5-cc46-43b9-b76e-b31e21d2e742,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-bbc69e12-b2e4-4b85-97f5-e21c1007214c,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-0d112806-e9d8-4892-af17-80dbe4bdb914,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-a6faa68f-e64e-4805-9c90-aa11c9856763,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-a4fb4797-ec07-4ca5-baa2-530ad0053a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-a4040318-43b9-41ae-9ef3-60b31caaaac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-d490c082-2903-41b5-a7d5-726d60adc7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-26b8a5eb-abef-415f-a27d-1fa339c413ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576561700-172.17.0.16-1595371464307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-ceb571c5-cc46-43b9-b76e-b31e21d2e742,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-bbc69e12-b2e4-4b85-97f5-e21c1007214c,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-0d112806-e9d8-4892-af17-80dbe4bdb914,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-a6faa68f-e64e-4805-9c90-aa11c9856763,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-a4fb4797-ec07-4ca5-baa2-530ad0053a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-a4040318-43b9-41ae-9ef3-60b31caaaac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-d490c082-2903-41b5-a7d5-726d60adc7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-26b8a5eb-abef-415f-a27d-1fa339c413ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612477299-172.17.0.16-1595371819247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42186,DS-39b95a8f-fae8-49f2-9263-0783067211f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-c652ffc9-f4a7-47b5-bc1d-e3582b9eb4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-d831aa14-6d9d-4908-a71a-73644424850f,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-6596dda8-b0d5-4032-b831-fe952b78cbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-8d21bbb7-fe5a-4480-be39-cef12305dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-9dd3a4d5-239e-485a-94be-b55fa17844b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-f33282b9-a408-47b0-a100-e257da647e31,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-9b0c1646-8ace-4eac-9ca0-f353d74ddd2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612477299-172.17.0.16-1595371819247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42186,DS-39b95a8f-fae8-49f2-9263-0783067211f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-c652ffc9-f4a7-47b5-bc1d-e3582b9eb4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-d831aa14-6d9d-4908-a71a-73644424850f,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-6596dda8-b0d5-4032-b831-fe952b78cbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-8d21bbb7-fe5a-4480-be39-cef12305dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-9dd3a4d5-239e-485a-94be-b55fa17844b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-f33282b9-a408-47b0-a100-e257da647e31,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-9b0c1646-8ace-4eac-9ca0-f353d74ddd2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5332
