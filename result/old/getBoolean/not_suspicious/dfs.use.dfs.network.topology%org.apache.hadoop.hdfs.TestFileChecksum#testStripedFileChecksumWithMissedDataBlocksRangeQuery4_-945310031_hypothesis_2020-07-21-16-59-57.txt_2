reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622785952-172.17.0.14-1595350931074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-639df15c-586d-4b01-b1ed-e6094a040fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-655a2811-6710-41d7-90d7-669b341d16ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-56e950a9-2de4-44f7-9562-dd97809a8154,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-8422b797-a5c2-4802-beb5-2412ad769318,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-1fc581e6-43bb-495e-9a2e-669edb145dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-15086d2c-f8b1-4e53-860e-918b0573707f,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d46830b1-c904-4d4a-acb1-ed85ef346551,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-a2babb0b-7278-4e58-85a7-f7e8d44d74ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622785952-172.17.0.14-1595350931074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-639df15c-586d-4b01-b1ed-e6094a040fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-655a2811-6710-41d7-90d7-669b341d16ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-56e950a9-2de4-44f7-9562-dd97809a8154,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-8422b797-a5c2-4802-beb5-2412ad769318,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-1fc581e6-43bb-495e-9a2e-669edb145dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-15086d2c-f8b1-4e53-860e-918b0573707f,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d46830b1-c904-4d4a-acb1-ed85ef346551,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-a2babb0b-7278-4e58-85a7-f7e8d44d74ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484723595-172.17.0.14-1595351431400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-106a50ff-67a7-493a-9977-49cd68342629,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-4e3aa33d-d0f7-4fe4-837f-38376e4e21a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-922181c2-ba3b-4443-9997-8caa5f9d0b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-f28e1af9-27e6-4275-8070-73a910d84110,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-f0352ccd-4d03-46f2-b1cb-b06107653527,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-fd7103b6-aea7-4dbd-931f-e2a301d232df,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-5117b4ec-af36-48ca-9852-4513eaf83359,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-e2ef18a6-3535-4baa-8c6b-86b67adaf0c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484723595-172.17.0.14-1595351431400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-106a50ff-67a7-493a-9977-49cd68342629,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-4e3aa33d-d0f7-4fe4-837f-38376e4e21a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-922181c2-ba3b-4443-9997-8caa5f9d0b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-f28e1af9-27e6-4275-8070-73a910d84110,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-f0352ccd-4d03-46f2-b1cb-b06107653527,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-fd7103b6-aea7-4dbd-931f-e2a301d232df,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-5117b4ec-af36-48ca-9852-4513eaf83359,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-e2ef18a6-3535-4baa-8c6b-86b67adaf0c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389764662-172.17.0.14-1595351635965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40492,DS-2b2a3b63-0d35-47bb-a4f5-e1e1283b59dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-c505d331-9004-4c87-a878-a2efe9f762cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-b86ae08f-2216-44b0-a24d-80fd41428a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-8d9d5ce3-1312-48a8-9bd8-1fc87355b3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-405e8efb-723c-44ee-b99c-b0a38bf680d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-f6db6329-a69a-4342-abec-0b80b22a9c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-3d5876ad-2515-4e71-b667-addf35d23649,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-f014476b-99c7-40a1-adb4-bd33ffc43c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389764662-172.17.0.14-1595351635965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40492,DS-2b2a3b63-0d35-47bb-a4f5-e1e1283b59dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-c505d331-9004-4c87-a878-a2efe9f762cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-b86ae08f-2216-44b0-a24d-80fd41428a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-8d9d5ce3-1312-48a8-9bd8-1fc87355b3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-405e8efb-723c-44ee-b99c-b0a38bf680d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-f6db6329-a69a-4342-abec-0b80b22a9c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-3d5876ad-2515-4e71-b667-addf35d23649,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-f014476b-99c7-40a1-adb4-bd33ffc43c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227246069-172.17.0.14-1595352159078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45516,DS-9c2bc3e6-1429-435d-91c5-7e3f1b2920ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f1369a4e-35dd-480d-a9f2-1417a7584fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-28b35efb-b80f-494f-9774-e67a0d6c1e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-b653e8ff-1d94-43c7-a101-b266c702a878,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-a37f2903-0243-40c2-b7fc-28c56ae1fcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-5b3fe3b5-3d40-47b1-872f-5ff276434d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-d34e9dcf-9d34-4fea-8983-481625d333be,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-c109abaa-b2a1-410b-9df0-308f024bb8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227246069-172.17.0.14-1595352159078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45516,DS-9c2bc3e6-1429-435d-91c5-7e3f1b2920ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f1369a4e-35dd-480d-a9f2-1417a7584fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-28b35efb-b80f-494f-9774-e67a0d6c1e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-b653e8ff-1d94-43c7-a101-b266c702a878,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-a37f2903-0243-40c2-b7fc-28c56ae1fcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-5b3fe3b5-3d40-47b1-872f-5ff276434d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-d34e9dcf-9d34-4fea-8983-481625d333be,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-c109abaa-b2a1-410b-9df0-308f024bb8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438302268-172.17.0.14-1595352879317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32958,DS-ba835f9e-d590-4f67-b43e-68c87b156733,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-9cce4f2e-8fa9-498c-a37e-0a9cc9bf6261,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-23503133-38bb-4156-96fb-5892bd81de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-d4c9966f-6784-4273-ae95-f34496381f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-a84a03cc-14ee-489b-9b52-5b21d1a09fce,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-2568af22-d953-4135-b3d2-bbb80b11e569,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-3ca37c1b-5687-405e-b151-08c3ebc8bfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-2cb91434-bdd7-4906-b009-d8d4c626f2e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438302268-172.17.0.14-1595352879317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32958,DS-ba835f9e-d590-4f67-b43e-68c87b156733,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-9cce4f2e-8fa9-498c-a37e-0a9cc9bf6261,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-23503133-38bb-4156-96fb-5892bd81de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-d4c9966f-6784-4273-ae95-f34496381f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-a84a03cc-14ee-489b-9b52-5b21d1a09fce,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-2568af22-d953-4135-b3d2-bbb80b11e569,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-3ca37c1b-5687-405e-b151-08c3ebc8bfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-2cb91434-bdd7-4906-b009-d8d4c626f2e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613422818-172.17.0.14-1595353574465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35511,DS-929cda81-7ff2-4e39-9e5c-d31631213017,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-0191cf03-8a62-44e4-8369-c06fe4f45a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-2d592eb8-eeec-4379-8f2b-9ad595339ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-942b5d73-9347-409b-81f4-6a5647aebdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-4359c9eb-fe6d-46ec-88e1-a8702063e527,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-f673b930-63f9-4405-99e7-06f98f8ce98b,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-19099d5d-ed53-4796-80d0-91d51090a02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-ed69e70b-1316-4480-bead-0d78a27332c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613422818-172.17.0.14-1595353574465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35511,DS-929cda81-7ff2-4e39-9e5c-d31631213017,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-0191cf03-8a62-44e4-8369-c06fe4f45a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-2d592eb8-eeec-4379-8f2b-9ad595339ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-942b5d73-9347-409b-81f4-6a5647aebdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-4359c9eb-fe6d-46ec-88e1-a8702063e527,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-f673b930-63f9-4405-99e7-06f98f8ce98b,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-19099d5d-ed53-4796-80d0-91d51090a02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-ed69e70b-1316-4480-bead-0d78a27332c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808579913-172.17.0.14-1595353928631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41129,DS-5abdc117-145f-4479-ba36-d3af4b39b580,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-38d205cd-74ff-487a-8c2d-00a8705b7b13,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-1eea82b6-a73f-4625-86c1-59206f956840,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-e69d60b5-a67c-494e-92f4-89f0e0d6443d,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-6542dc0c-77a0-4980-aa25-b90def2f15f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-c5f6cd5c-cfef-465d-a6ca-6f497447d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-3d538431-9d37-4878-9380-11ab432a16b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-b478b016-bfe0-403a-8af0-defaa92a0192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808579913-172.17.0.14-1595353928631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41129,DS-5abdc117-145f-4479-ba36-d3af4b39b580,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-38d205cd-74ff-487a-8c2d-00a8705b7b13,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-1eea82b6-a73f-4625-86c1-59206f956840,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-e69d60b5-a67c-494e-92f4-89f0e0d6443d,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-6542dc0c-77a0-4980-aa25-b90def2f15f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-c5f6cd5c-cfef-465d-a6ca-6f497447d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-3d538431-9d37-4878-9380-11ab432a16b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-b478b016-bfe0-403a-8af0-defaa92a0192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86130061-172.17.0.14-1595354596914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-2af38c7d-10a9-4798-b721-fef069b5e274,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-02cba9a4-5ef1-4a77-84ca-269f7f1b16a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-0dfebeba-8fa0-4d7d-9873-f68447fb1885,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-c6dbd1f5-fda6-47f5-aa10-6230bb41d537,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-a59754c0-2b49-4cd0-a1e1-34bc8cd48c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-436a381b-a556-4524-9422-6a380d195ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-660efc6b-9e22-4676-ab61-9a8a540992f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-ef7e7c1e-9e89-4fcf-a730-16957b757f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86130061-172.17.0.14-1595354596914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-2af38c7d-10a9-4798-b721-fef069b5e274,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-02cba9a4-5ef1-4a77-84ca-269f7f1b16a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-0dfebeba-8fa0-4d7d-9873-f68447fb1885,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-c6dbd1f5-fda6-47f5-aa10-6230bb41d537,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-a59754c0-2b49-4cd0-a1e1-34bc8cd48c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-436a381b-a556-4524-9422-6a380d195ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-660efc6b-9e22-4676-ab61-9a8a540992f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-ef7e7c1e-9e89-4fcf-a730-16957b757f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391779772-172.17.0.14-1595354829860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-4302599d-a602-4ae1-b026-44950375d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-dc61404c-70ff-4845-bc29-24c0d12de0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-ff570368-07e9-4475-bb9d-0db7f766e885,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-9caab9f5-ea7f-4b67-9df3-b32673c1a034,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-81fb3df4-1fb6-44ee-bd91-4fb7cffa0b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-fb8f0b0f-b574-4f72-9442-b1979e2dfe66,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-0159d0f5-c996-4ee5-9231-acffef51fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-46f15398-8a6e-4dbb-977f-a00f6a57276e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391779772-172.17.0.14-1595354829860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-4302599d-a602-4ae1-b026-44950375d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-dc61404c-70ff-4845-bc29-24c0d12de0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-ff570368-07e9-4475-bb9d-0db7f766e885,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-9caab9f5-ea7f-4b67-9df3-b32673c1a034,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-81fb3df4-1fb6-44ee-bd91-4fb7cffa0b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-fb8f0b0f-b574-4f72-9442-b1979e2dfe66,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-0159d0f5-c996-4ee5-9231-acffef51fb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-46f15398-8a6e-4dbb-977f-a00f6a57276e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840119921-172.17.0.14-1595355019528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43013,DS-c17a5a65-7035-481b-922e-f593fab1c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-3fc2970f-2cef-4dab-a31e-9084bd316315,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-d784dc51-3761-4ec6-aa56-f7f62f6f92fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-ecb44632-0ab1-4fca-aaff-0a800b7f0696,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-0bae59b8-f69a-4564-99bb-a7ffa88a74f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-3a25bb19-2b36-4bf1-aa13-cc57bdfcfa73,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-0e1618f9-ceba-4d0d-8dd1-837d2d8f564e,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-58c934bb-a7a6-4bd9-9975-1121460b8b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840119921-172.17.0.14-1595355019528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43013,DS-c17a5a65-7035-481b-922e-f593fab1c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-3fc2970f-2cef-4dab-a31e-9084bd316315,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-d784dc51-3761-4ec6-aa56-f7f62f6f92fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-ecb44632-0ab1-4fca-aaff-0a800b7f0696,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-0bae59b8-f69a-4564-99bb-a7ffa88a74f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-3a25bb19-2b36-4bf1-aa13-cc57bdfcfa73,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-0e1618f9-ceba-4d0d-8dd1-837d2d8f564e,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-58c934bb-a7a6-4bd9-9975-1121460b8b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086439599-172.17.0.14-1595355299559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44255,DS-b2b9f167-6045-4504-85e7-c2b22567c3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-a2204f8e-56fa-41cb-9962-43ad7c75ebb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-de2948d8-9488-4394-bdd7-360ded9503d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-ea217907-891d-46ab-bc4f-d78812df2b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-1a17475b-02b5-4ef4-a80b-fa90995fb402,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-7af4fa77-53a7-4bec-91ef-fb1d02ec3ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-5b99776a-0d56-4e9a-a18e-7116077951a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-e9f66113-a7e0-42cd-b93e-bc839b9adf77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086439599-172.17.0.14-1595355299559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44255,DS-b2b9f167-6045-4504-85e7-c2b22567c3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-a2204f8e-56fa-41cb-9962-43ad7c75ebb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-de2948d8-9488-4394-bdd7-360ded9503d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-ea217907-891d-46ab-bc4f-d78812df2b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-1a17475b-02b5-4ef4-a80b-fa90995fb402,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-7af4fa77-53a7-4bec-91ef-fb1d02ec3ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-5b99776a-0d56-4e9a-a18e-7116077951a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-e9f66113-a7e0-42cd-b93e-bc839b9adf77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615657624-172.17.0.14-1595355476877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45194,DS-65c83e95-d9b5-4681-9696-5f941714b023,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-c0f459ab-8ec6-4471-9353-abe890712726,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-3e83cae4-b84a-40c5-9d0f-20068b882f12,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-a130ded7-ff5d-4f30-ade9-e698acf96390,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-7d093f6e-6b7f-4211-90a1-d47b1e0f724f,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-3373c049-bc10-49d8-aa54-db225726b40b,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-46ab81d9-986c-4445-8325-f20a7269de43,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-6f6b3e3b-ab92-4e7f-b84d-819738451389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615657624-172.17.0.14-1595355476877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45194,DS-65c83e95-d9b5-4681-9696-5f941714b023,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-c0f459ab-8ec6-4471-9353-abe890712726,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-3e83cae4-b84a-40c5-9d0f-20068b882f12,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-a130ded7-ff5d-4f30-ade9-e698acf96390,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-7d093f6e-6b7f-4211-90a1-d47b1e0f724f,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-3373c049-bc10-49d8-aa54-db225726b40b,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-46ab81d9-986c-4445-8325-f20a7269de43,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-6f6b3e3b-ab92-4e7f-b84d-819738451389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887265701-172.17.0.14-1595355528222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-b529719f-0db5-4fed-aef8-6fcf310f1534,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-7fed470f-2cde-447a-8903-93dc5856f577,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-c92aa346-d1a6-4ee0-af70-bc1661f7b395,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-7acfdf20-2bff-45b2-96cb-99596d347c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-5c66dda4-c0df-425c-86d2-92831d8bb1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-995e951e-bd03-4541-b057-f34e524fbe56,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-643bcb88-8a14-4612-a7bd-cd56d969239d,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-b954a568-e225-4180-8bcb-fa7dce251bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887265701-172.17.0.14-1595355528222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-b529719f-0db5-4fed-aef8-6fcf310f1534,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-7fed470f-2cde-447a-8903-93dc5856f577,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-c92aa346-d1a6-4ee0-af70-bc1661f7b395,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-7acfdf20-2bff-45b2-96cb-99596d347c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-5c66dda4-c0df-425c-86d2-92831d8bb1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-995e951e-bd03-4541-b057-f34e524fbe56,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-643bcb88-8a14-4612-a7bd-cd56d969239d,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-b954a568-e225-4180-8bcb-fa7dce251bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396203033-172.17.0.14-1595356492638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-db6a6a77-2c8c-40c8-9b54-44d8a51d8352,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-e8405501-ec01-4926-9e97-466040694d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-2238ff6d-e713-4cd1-be72-98efecabb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-6868bfc1-f04a-4826-8cfc-a933fba4b006,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-ceb9869a-34ec-463a-9bda-dafe8fb33ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-f9a96e5c-77e3-4399-aa32-be183abc03f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-a4ea9ba4-b129-4b2b-b1fd-e6bc123530ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-4cbe1318-83af-4f87-aafc-f10b314c9064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396203033-172.17.0.14-1595356492638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-db6a6a77-2c8c-40c8-9b54-44d8a51d8352,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-e8405501-ec01-4926-9e97-466040694d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-2238ff6d-e713-4cd1-be72-98efecabb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-6868bfc1-f04a-4826-8cfc-a933fba4b006,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-ceb9869a-34ec-463a-9bda-dafe8fb33ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-f9a96e5c-77e3-4399-aa32-be183abc03f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-a4ea9ba4-b129-4b2b-b1fd-e6bc123530ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-4cbe1318-83af-4f87-aafc-f10b314c9064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23614871-172.17.0.14-1595356834068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-b394dae1-5122-4836-b1a4-c644b89a8cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-e3aa1ab9-2e92-4c19-8fcd-6fb89e73f581,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-1b216e9a-191a-4b26-8eec-0a381511cfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4431f4d1-51fc-4f49-82dd-e55d456a8015,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-a9d2a433-4fd9-4a7a-ab83-5bc30dacf26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d82338dd-a4d9-403d-abfc-9c3ca0b1cbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-0ff88dde-7100-4b6a-ab61-46acaf08afd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-34675726-14c5-49d3-a17f-7b4467fe36d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23614871-172.17.0.14-1595356834068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-b394dae1-5122-4836-b1a4-c644b89a8cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-e3aa1ab9-2e92-4c19-8fcd-6fb89e73f581,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-1b216e9a-191a-4b26-8eec-0a381511cfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4431f4d1-51fc-4f49-82dd-e55d456a8015,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-a9d2a433-4fd9-4a7a-ab83-5bc30dacf26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d82338dd-a4d9-403d-abfc-9c3ca0b1cbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-0ff88dde-7100-4b6a-ab61-46acaf08afd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-34675726-14c5-49d3-a17f-7b4467fe36d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474172700-172.17.0.14-1595357084920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-de8f12cc-49f9-4e48-ab6c-9f57dc4d5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-f612c417-b543-49d1-946d-c89a8f5895fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-e2ecdf6f-8352-4d6d-8248-60251c49cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-1a0df499-e905-4afc-8a9c-9ba77c69124c,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-ddb7f15e-d7f7-471e-a42c-de6f0ee9eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-9defdf67-e0d6-4ebf-9d57-fb8f19ca0530,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-04d149df-ebdc-40d7-8bfb-04703cec3d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-4911a513-fe93-43f5-a961-bd23e41dc7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474172700-172.17.0.14-1595357084920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-de8f12cc-49f9-4e48-ab6c-9f57dc4d5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-f612c417-b543-49d1-946d-c89a8f5895fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-e2ecdf6f-8352-4d6d-8248-60251c49cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-1a0df499-e905-4afc-8a9c-9ba77c69124c,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-ddb7f15e-d7f7-471e-a42c-de6f0ee9eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-9defdf67-e0d6-4ebf-9d57-fb8f19ca0530,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-04d149df-ebdc-40d7-8bfb-04703cec3d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-4911a513-fe93-43f5-a961-bd23e41dc7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6599
