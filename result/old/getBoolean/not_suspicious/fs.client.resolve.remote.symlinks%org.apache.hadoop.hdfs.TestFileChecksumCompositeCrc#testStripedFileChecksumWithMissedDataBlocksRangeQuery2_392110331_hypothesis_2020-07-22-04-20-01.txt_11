reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726084413-172.17.0.12-1595391833279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-427d6756-ce15-403a-a688-ea3fc87318e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-12244cc0-03c9-4225-b8b4-c7f80636c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-f43ac68b-5476-4637-b3a3-a6b91297ef96,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-4e47d0df-0bae-44e5-b5e5-ae77caa674f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-0a7f0289-b993-43d8-9fdc-bcc5cc9d8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-91e6504c-db93-4ce9-9fcc-e74acc11431e,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-188c1474-6644-48ee-9dd2-d16a821a8093,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-1f43b62d-4a99-46b1-a6b6-9c11c9c6710d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726084413-172.17.0.12-1595391833279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-427d6756-ce15-403a-a688-ea3fc87318e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-12244cc0-03c9-4225-b8b4-c7f80636c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-f43ac68b-5476-4637-b3a3-a6b91297ef96,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-4e47d0df-0bae-44e5-b5e5-ae77caa674f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-0a7f0289-b993-43d8-9fdc-bcc5cc9d8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-91e6504c-db93-4ce9-9fcc-e74acc11431e,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-188c1474-6644-48ee-9dd2-d16a821a8093,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-1f43b62d-4a99-46b1-a6b6-9c11c9c6710d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875997857-172.17.0.12-1595391921037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46600,DS-a3fac655-576c-423a-8b93-690dc6bc1cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-43025e2e-9030-4e56-94d0-f4beb4976a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-1b7db75b-358f-4dfd-ad5c-ff9e29052138,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-263488d6-9b09-4419-a4db-de12d2553d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-5f4c76e3-dd15-4b1c-b7ca-c6acfc773779,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-180e6b0b-fb2e-458a-b5bd-4c987258154d,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-b2d6ec1c-5cf1-4147-a398-152d9c52ac61,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-9e86060a-f79c-45a4-9465-491b5b2b6c73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875997857-172.17.0.12-1595391921037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46600,DS-a3fac655-576c-423a-8b93-690dc6bc1cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-43025e2e-9030-4e56-94d0-f4beb4976a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-1b7db75b-358f-4dfd-ad5c-ff9e29052138,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-263488d6-9b09-4419-a4db-de12d2553d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-5f4c76e3-dd15-4b1c-b7ca-c6acfc773779,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-180e6b0b-fb2e-458a-b5bd-4c987258154d,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-b2d6ec1c-5cf1-4147-a398-152d9c52ac61,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-9e86060a-f79c-45a4-9465-491b5b2b6c73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491543730-172.17.0.12-1595392054913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42325,DS-bb970674-f6fc-4f45-aa36-fc712c8e0a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-fbc8454d-aac1-4b23-9eeb-643847f75e16,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-6213fa5c-379f-4d0c-88f1-42bde42dd16e,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-0a174154-9088-4c36-9084-a21dd1f2ec83,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-84cb40dc-2252-4ea2-9e04-6955ea2bece2,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-8d6e5d2b-bd81-4a36-a988-17117d83ea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-923c2cc4-71b7-490d-9f99-03b6b684d8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-2fb6eb7a-386f-4115-8364-01bc2ca84161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491543730-172.17.0.12-1595392054913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42325,DS-bb970674-f6fc-4f45-aa36-fc712c8e0a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-fbc8454d-aac1-4b23-9eeb-643847f75e16,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-6213fa5c-379f-4d0c-88f1-42bde42dd16e,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-0a174154-9088-4c36-9084-a21dd1f2ec83,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-84cb40dc-2252-4ea2-9e04-6955ea2bece2,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-8d6e5d2b-bd81-4a36-a988-17117d83ea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-923c2cc4-71b7-490d-9f99-03b6b684d8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-2fb6eb7a-386f-4115-8364-01bc2ca84161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223642479-172.17.0.12-1595392533661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-0ea40838-4c25-4f64-a510-9f5ee1340de3,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-84332ab9-c7e1-4729-854c-47fc499d4106,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-b2035cc0-b909-46ab-927a-ac1d1cbb6fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-fa7d27e0-c2f3-462e-96aa-fe31df977015,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-14cd2855-a6b0-410b-864d-42d8ff6fd75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-db4f6e02-8fbb-4fe5-bdcb-e3e64ce2170b,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-8ed77e43-1864-42e0-baea-da340a12a466,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-d6e3401f-2da1-443b-9349-c889d488ab32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223642479-172.17.0.12-1595392533661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-0ea40838-4c25-4f64-a510-9f5ee1340de3,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-84332ab9-c7e1-4729-854c-47fc499d4106,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-b2035cc0-b909-46ab-927a-ac1d1cbb6fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-fa7d27e0-c2f3-462e-96aa-fe31df977015,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-14cd2855-a6b0-410b-864d-42d8ff6fd75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-db4f6e02-8fbb-4fe5-bdcb-e3e64ce2170b,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-8ed77e43-1864-42e0-baea-da340a12a466,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-d6e3401f-2da1-443b-9349-c889d488ab32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636222560-172.17.0.12-1595393725130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-8687daea-ef61-4cd1-98b2-4748cebc621d,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-0e806584-4368-4b28-937c-ccfbd90ac2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-9e4d5abd-828c-4e08-ade9-14a7bcbba417,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-4aae5c96-5896-4a37-ab6b-32938ca4c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-c2045bd8-fde6-471c-ba04-15462480392e,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-deb0f1d9-aedd-42c9-bff6-7178c1391156,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-28555ea2-a65e-4d36-8fed-2c6a536fe931,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-aefcc390-0faf-49b0-8692-bdf3b829b1a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636222560-172.17.0.12-1595393725130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-8687daea-ef61-4cd1-98b2-4748cebc621d,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-0e806584-4368-4b28-937c-ccfbd90ac2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-9e4d5abd-828c-4e08-ade9-14a7bcbba417,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-4aae5c96-5896-4a37-ab6b-32938ca4c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-c2045bd8-fde6-471c-ba04-15462480392e,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-deb0f1d9-aedd-42c9-bff6-7178c1391156,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-28555ea2-a65e-4d36-8fed-2c6a536fe931,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-aefcc390-0faf-49b0-8692-bdf3b829b1a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507337076-172.17.0.12-1595393860097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-072d965d-7a30-48be-ac14-956b74610e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-4d01de45-e8fe-4a23-b6a4-dcad33515c22,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-a816890d-f32f-4af5-b06c-c6e4203a7d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-dbfeda92-6868-4551-a5d2-4c08772d4948,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-b8928108-df3e-4a97-8a66-17283c5ac3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-b168f54e-73a5-4eb2-a5dc-f45a3ae1935e,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-a9c84409-f632-46c2-a2bd-accb3578203a,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-6e7681db-8097-4060-b19a-5e942fe74dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507337076-172.17.0.12-1595393860097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-072d965d-7a30-48be-ac14-956b74610e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-4d01de45-e8fe-4a23-b6a4-dcad33515c22,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-a816890d-f32f-4af5-b06c-c6e4203a7d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-dbfeda92-6868-4551-a5d2-4c08772d4948,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-b8928108-df3e-4a97-8a66-17283c5ac3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-b168f54e-73a5-4eb2-a5dc-f45a3ae1935e,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-a9c84409-f632-46c2-a2bd-accb3578203a,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-6e7681db-8097-4060-b19a-5e942fe74dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413839204-172.17.0.12-1595393898826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46022,DS-8d3bde52-435b-4259-b18b-e5cdaa4b43da,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-c867a16c-8597-446d-b54a-f1994f1a909e,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-3f164882-5007-46f3-b76d-efe3b94f7346,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-df739f8d-42f9-4e0e-93d7-d31c78c08b24,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-c0a7b36f-3628-4a67-9fd0-474f74416a31,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-6b7d4c1b-6354-4d86-8579-5d0fe041a745,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-64cbe666-bcc5-4605-8857-1387bf38f206,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-c09a164d-4bc6-4540-915b-c55d9d429c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413839204-172.17.0.12-1595393898826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46022,DS-8d3bde52-435b-4259-b18b-e5cdaa4b43da,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-c867a16c-8597-446d-b54a-f1994f1a909e,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-3f164882-5007-46f3-b76d-efe3b94f7346,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-df739f8d-42f9-4e0e-93d7-d31c78c08b24,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-c0a7b36f-3628-4a67-9fd0-474f74416a31,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-6b7d4c1b-6354-4d86-8579-5d0fe041a745,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-64cbe666-bcc5-4605-8857-1387bf38f206,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-c09a164d-4bc6-4540-915b-c55d9d429c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135433505-172.17.0.12-1595393933431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-b61c819f-4760-46dd-a5fd-886f8ff9245a,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-65536313-cff1-4128-972e-071664560f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-ea320543-c79c-4b77-8e93-9a2c625a49d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e1ec754c-57b3-461c-b1f0-4888906a8172,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-37c21d33-704f-48fa-b88a-9de12b19b3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-4e356567-5c1a-41fb-bec1-b1af3974d6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-3239dab5-3de0-4c5e-944e-5043f0caa575,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-d8a31ab0-c40c-4975-bc8b-ab92f7bcc668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135433505-172.17.0.12-1595393933431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-b61c819f-4760-46dd-a5fd-886f8ff9245a,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-65536313-cff1-4128-972e-071664560f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-ea320543-c79c-4b77-8e93-9a2c625a49d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e1ec754c-57b3-461c-b1f0-4888906a8172,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-37c21d33-704f-48fa-b88a-9de12b19b3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-4e356567-5c1a-41fb-bec1-b1af3974d6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-3239dab5-3de0-4c5e-944e-5043f0caa575,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-d8a31ab0-c40c-4975-bc8b-ab92f7bcc668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151723959-172.17.0.12-1595393964889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-bf6ee7cd-7602-48bb-9c44-59e8d3a1aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-86a77329-11de-4f10-a52d-6f8db74e269d,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-e34d264e-ed42-47d0-bb68-62a8edc532f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-98b08cdf-051c-4f5b-8a32-831f5c73ebed,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-9eb33b1e-398d-43dc-8299-df4166c15418,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-4465436b-d53f-42d1-906b-91a7190275d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-838b00a1-5c79-43ab-8486-b46f56742eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-25570b15-514f-40ce-880b-fb63eacac23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151723959-172.17.0.12-1595393964889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-bf6ee7cd-7602-48bb-9c44-59e8d3a1aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-86a77329-11de-4f10-a52d-6f8db74e269d,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-e34d264e-ed42-47d0-bb68-62a8edc532f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-98b08cdf-051c-4f5b-8a32-831f5c73ebed,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-9eb33b1e-398d-43dc-8299-df4166c15418,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-4465436b-d53f-42d1-906b-91a7190275d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-838b00a1-5c79-43ab-8486-b46f56742eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-25570b15-514f-40ce-880b-fb63eacac23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467091691-172.17.0.12-1595394539053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-6f835182-c98b-4ab1-81aa-9b25a40cf039,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-3adb22bf-5595-4ad6-900f-cf29369a3dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-eb778b96-73ea-47a8-a749-b722b4db92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-49a8fa60-bf81-4571-8e8f-a5c2fb9bf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-4f353ac1-4a94-43a3-ab97-6e623e2daa04,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-09f558e2-412c-46bc-b77a-f2a8f53f4102,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-7127c832-cca9-4b82-b016-afb25f4db7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-b3d21a5f-96e5-44fa-b072-0a24796a1f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467091691-172.17.0.12-1595394539053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-6f835182-c98b-4ab1-81aa-9b25a40cf039,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-3adb22bf-5595-4ad6-900f-cf29369a3dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-eb778b96-73ea-47a8-a749-b722b4db92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-49a8fa60-bf81-4571-8e8f-a5c2fb9bf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-4f353ac1-4a94-43a3-ab97-6e623e2daa04,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-09f558e2-412c-46bc-b77a-f2a8f53f4102,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-7127c832-cca9-4b82-b016-afb25f4db7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-b3d21a5f-96e5-44fa-b072-0a24796a1f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005447778-172.17.0.12-1595394917612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46643,DS-e80ccbb2-4d0b-4f4a-9235-f0cdca0ff6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-d056f29f-77b9-4947-a23a-f91523a5e03d,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-2769395f-f3ae-4903-a104-0c5119d61287,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-14132e73-5127-4a39-aeac-57ef726f8695,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-8c1d9e32-75ef-4652-ad91-dce05fe90847,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-32d7758d-40a4-47f2-bd33-984e1c4731e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-88a9d825-47c8-41e2-9c8d-a3f260ae56b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-4fb7d0b5-4344-4fde-a551-0b2edc02e972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005447778-172.17.0.12-1595394917612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46643,DS-e80ccbb2-4d0b-4f4a-9235-f0cdca0ff6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-d056f29f-77b9-4947-a23a-f91523a5e03d,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-2769395f-f3ae-4903-a104-0c5119d61287,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-14132e73-5127-4a39-aeac-57ef726f8695,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-8c1d9e32-75ef-4652-ad91-dce05fe90847,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-32d7758d-40a4-47f2-bd33-984e1c4731e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-88a9d825-47c8-41e2-9c8d-a3f260ae56b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-4fb7d0b5-4344-4fde-a551-0b2edc02e972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841363497-172.17.0.12-1595395065832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44870,DS-4cadd46e-937e-4b5d-a0bb-2166ef062bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-81a6fe21-7ead-4ace-bb06-6cf5b7ac4698,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-35f93e02-52b9-4e22-99e6-8827bbb04eac,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-dac550dd-a08b-4e80-8af1-0c4f3a2c30aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-a4e2a789-7553-4abd-9925-f4f39302eb91,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-197b9296-4560-4b46-ba25-59f1e37ec49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-aa93f50c-2c9c-497e-86ae-758365d09c33,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-c583bca2-c755-4ad1-8826-938740bd64fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841363497-172.17.0.12-1595395065832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44870,DS-4cadd46e-937e-4b5d-a0bb-2166ef062bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-81a6fe21-7ead-4ace-bb06-6cf5b7ac4698,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-35f93e02-52b9-4e22-99e6-8827bbb04eac,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-dac550dd-a08b-4e80-8af1-0c4f3a2c30aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-a4e2a789-7553-4abd-9925-f4f39302eb91,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-197b9296-4560-4b46-ba25-59f1e37ec49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-aa93f50c-2c9c-497e-86ae-758365d09c33,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-c583bca2-c755-4ad1-8826-938740bd64fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609077112-172.17.0.12-1595395102710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-24b850fd-3022-4a92-9a03-2e1605f5d7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-310587cb-1a5b-4288-9f87-8acff71ae369,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-a51b38cb-5f40-42fb-b4a6-939db0998152,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-e3f2886a-68b8-464d-a9b3-88ec439450cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-bfd0e636-d403-43f2-9fe8-a481a177e5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-7e09242a-3afb-4f47-a4f0-6969b61a78f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-cc1fe5df-73dc-45f8-8e56-dcf8c81d0352,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-05b315fb-34eb-41a8-b634-361b95d731fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609077112-172.17.0.12-1595395102710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-24b850fd-3022-4a92-9a03-2e1605f5d7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-310587cb-1a5b-4288-9f87-8acff71ae369,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-a51b38cb-5f40-42fb-b4a6-939db0998152,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-e3f2886a-68b8-464d-a9b3-88ec439450cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-bfd0e636-d403-43f2-9fe8-a481a177e5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-7e09242a-3afb-4f47-a4f0-6969b61a78f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-cc1fe5df-73dc-45f8-8e56-dcf8c81d0352,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-05b315fb-34eb-41a8-b634-361b95d731fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578591637-172.17.0.12-1595395485334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33017,DS-22e38938-e041-4d57-baed-9c3089951949,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-f9a1cd2b-ff2f-40db-99be-8545bb7d7665,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-55ce26f7-4c0f-477f-b60b-136f8a8387b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-88594866-05c7-44b6-b715-163fcc4fe63d,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-21c6bdff-b197-40ef-a5e8-b0d7ca95b0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-9bb92512-f85e-4fd4-91a0-140b79938af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-87fc7fa9-6a58-413b-abb2-3b23b59148df,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-c7c8bd45-241d-402e-9f66-222f2fdde026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578591637-172.17.0.12-1595395485334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33017,DS-22e38938-e041-4d57-baed-9c3089951949,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-f9a1cd2b-ff2f-40db-99be-8545bb7d7665,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-55ce26f7-4c0f-477f-b60b-136f8a8387b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-88594866-05c7-44b6-b715-163fcc4fe63d,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-21c6bdff-b197-40ef-a5e8-b0d7ca95b0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-9bb92512-f85e-4fd4-91a0-140b79938af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-87fc7fa9-6a58-413b-abb2-3b23b59148df,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-c7c8bd45-241d-402e-9f66-222f2fdde026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269116752-172.17.0.12-1595396462254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-a8832a01-dc04-4266-9dc0-3ad7b98b5944,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-32f21dad-6e5a-4e25-815d-5cb0b80725d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-024c9f30-4ed6-41e5-863b-58bb195e99be,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-62a0eb5b-1680-4514-8483-a631501c7bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-2345ae22-4c90-41a2-8f8f-928025cbc53c,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-798c3c8c-78a9-4ed4-b2e0-ebefb33e0140,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-3545c73e-738a-4353-8c9e-2d0b1579dfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-2d9f2f75-40f0-4260-9efd-7e7a05570230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269116752-172.17.0.12-1595396462254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-a8832a01-dc04-4266-9dc0-3ad7b98b5944,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-32f21dad-6e5a-4e25-815d-5cb0b80725d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-024c9f30-4ed6-41e5-863b-58bb195e99be,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-62a0eb5b-1680-4514-8483-a631501c7bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-2345ae22-4c90-41a2-8f8f-928025cbc53c,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-798c3c8c-78a9-4ed4-b2e0-ebefb33e0140,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-3545c73e-738a-4353-8c9e-2d0b1579dfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-2d9f2f75-40f0-4260-9efd-7e7a05570230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241764223-172.17.0.12-1595396681337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33539,DS-ee1f80be-d42c-4b34-bdf0-7f7ebcb8661b,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-90c94197-0cf2-4177-9264-bebcda459686,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-ab0970e1-4596-4697-b6b2-7aa3db4a147c,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-6ec7abbf-59e9-4c97-882e-349b927b4870,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-b6ff547f-19f5-4af6-a1c5-f3eb36065771,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-ba49ab65-8a6a-472d-a516-e01e0853d134,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-9987717b-41ad-4bff-b0be-91d10d452950,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-e0ef9fd8-edb5-424f-8342-4d9ee96b128e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241764223-172.17.0.12-1595396681337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33539,DS-ee1f80be-d42c-4b34-bdf0-7f7ebcb8661b,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-90c94197-0cf2-4177-9264-bebcda459686,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-ab0970e1-4596-4697-b6b2-7aa3db4a147c,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-6ec7abbf-59e9-4c97-882e-349b927b4870,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-b6ff547f-19f5-4af6-a1c5-f3eb36065771,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-ba49ab65-8a6a-472d-a516-e01e0853d134,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-9987717b-41ad-4bff-b0be-91d10d452950,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-e0ef9fd8-edb5-424f-8342-4d9ee96b128e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94328283-172.17.0.12-1595396789658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-cfd64600-93c8-4bc1-866d-5ac3e1d0afc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-cba5ed56-360e-4e0f-b942-a2a94a0dd383,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-83264b00-1c02-40b4-8e82-76ea1c63f715,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-c037f74f-2cf0-43a9-9151-b79e3e832efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-dbf996a5-b88d-47f9-9361-d6e7a268e723,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-0d2d226a-10e2-4972-ac02-f26f117c0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-0ab7a946-3ce0-4125-89c4-7fe3f0e3c536,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-1d4c4792-f070-4524-bfab-4992de53e55b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94328283-172.17.0.12-1595396789658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-cfd64600-93c8-4bc1-866d-5ac3e1d0afc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-cba5ed56-360e-4e0f-b942-a2a94a0dd383,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-83264b00-1c02-40b4-8e82-76ea1c63f715,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-c037f74f-2cf0-43a9-9151-b79e3e832efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-dbf996a5-b88d-47f9-9361-d6e7a268e723,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-0d2d226a-10e2-4972-ac02-f26f117c0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-0ab7a946-3ce0-4125-89c4-7fe3f0e3c536,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-1d4c4792-f070-4524-bfab-4992de53e55b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873847582-172.17.0.12-1595396858740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-a0a6cb50-4c91-4616-a0a1-f41c355c1232,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-45a0e7f5-dea7-47c3-9047-ddec5aba9f04,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-58efd611-d169-4d94-8071-722697c1daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-2a94ee8a-fdd3-4ff1-af2a-a2c31e321c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-3ff2c13f-3ffc-4a3f-9cf7-fa06e3f4becd,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-03286124-f276-4e28-b3d2-adefa52b5408,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-23851aab-fb4d-45e2-885e-c632aa556c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-fdce0385-ceea-4c2a-b3b8-d03c92e1e946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873847582-172.17.0.12-1595396858740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-a0a6cb50-4c91-4616-a0a1-f41c355c1232,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-45a0e7f5-dea7-47c3-9047-ddec5aba9f04,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-58efd611-d169-4d94-8071-722697c1daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-2a94ee8a-fdd3-4ff1-af2a-a2c31e321c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-3ff2c13f-3ffc-4a3f-9cf7-fa06e3f4becd,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-03286124-f276-4e28-b3d2-adefa52b5408,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-23851aab-fb4d-45e2-885e-c632aa556c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-fdce0385-ceea-4c2a-b3b8-d03c92e1e946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5317
