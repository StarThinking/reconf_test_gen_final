reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619718192-172.17.0.11-1595361804876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-29f50706-f7f0-494f-9863-9cc359ae0ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-150a7ddf-a2a9-485b-a6fc-9cbef8e726b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-4cf7b001-e369-499b-a952-9007e21a77b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-82319e08-7bef-4d01-bdee-c2f9da57ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-9398af6f-0a55-4a3d-8a14-8a753a4240b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-08b40adb-dbf8-4bf9-a4b4-8a309f3bb8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-04df8294-8975-4964-99c6-116de384a141,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-a3a3f85c-7071-411d-85d4-ff2e6068c886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619718192-172.17.0.11-1595361804876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-29f50706-f7f0-494f-9863-9cc359ae0ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-150a7ddf-a2a9-485b-a6fc-9cbef8e726b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-4cf7b001-e369-499b-a952-9007e21a77b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-82319e08-7bef-4d01-bdee-c2f9da57ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-9398af6f-0a55-4a3d-8a14-8a753a4240b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-08b40adb-dbf8-4bf9-a4b4-8a309f3bb8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-04df8294-8975-4964-99c6-116de384a141,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-a3a3f85c-7071-411d-85d4-ff2e6068c886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273932261-172.17.0.11-1595361939179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-ade36e73-fa58-41c7-a9e4-4746a5218f30,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-821a3b23-6115-4808-96ef-602e1ebd2a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-b4d2697e-c850-4b52-88e1-f0b7e468ae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-4ea7eed3-c616-40a9-863e-d10bddc00cff,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-fd5e2227-17e6-4fc4-8f47-bf588a65df9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-021a21d7-e358-4cca-8c24-1793101c3491,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-fdc22566-6868-4c45-b1f2-fd7a87673b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d6095f61-901c-4fb0-9c4d-aa5798263707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273932261-172.17.0.11-1595361939179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-ade36e73-fa58-41c7-a9e4-4746a5218f30,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-821a3b23-6115-4808-96ef-602e1ebd2a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-b4d2697e-c850-4b52-88e1-f0b7e468ae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-4ea7eed3-c616-40a9-863e-d10bddc00cff,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-fd5e2227-17e6-4fc4-8f47-bf588a65df9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-021a21d7-e358-4cca-8c24-1793101c3491,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-fdc22566-6868-4c45-b1f2-fd7a87673b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d6095f61-901c-4fb0-9c4d-aa5798263707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709929239-172.17.0.11-1595363000003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-3f346a06-2866-455d-969b-9fecdc6f29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-a5382862-f0f5-4ff7-b0ed-daf4706a822e,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-912c9e5a-d44d-4b11-a152-ae94e6377dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-bcc94259-72f0-485c-9fae-01f3d3d5ba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-7eaf0b05-0f9c-4090-b516-51ee0745f470,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-f794a3b7-9aca-40d9-864f-353fb754d848,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-95ade542-f449-43ba-a506-1a96f94630c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-9a54db36-0b5a-45f4-bd82-c477f3ba0aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709929239-172.17.0.11-1595363000003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-3f346a06-2866-455d-969b-9fecdc6f29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-a5382862-f0f5-4ff7-b0ed-daf4706a822e,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-912c9e5a-d44d-4b11-a152-ae94e6377dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-bcc94259-72f0-485c-9fae-01f3d3d5ba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-7eaf0b05-0f9c-4090-b516-51ee0745f470,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-f794a3b7-9aca-40d9-864f-353fb754d848,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-95ade542-f449-43ba-a506-1a96f94630c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-9a54db36-0b5a-45f4-bd82-c477f3ba0aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527007758-172.17.0.11-1595363039593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40591,DS-994dc1fa-cb49-4763-9f94-b6f520d64b06,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-50a98849-a9f3-4a46-9b12-23a76f00a324,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-9edc9b53-5673-44fc-ade5-4ca1cabaf7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-f349f98b-b091-4494-908d-bd997a07bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-49810802-3b47-4cbe-b2d7-9c4ac3fcfb64,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-75719326-b3bd-42c0-9303-c536ce370eba,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-1dee91db-b1eb-4673-ba99-3284f7a64531,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-fa51080f-77b6-43dd-8376-c00758fc65fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527007758-172.17.0.11-1595363039593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40591,DS-994dc1fa-cb49-4763-9f94-b6f520d64b06,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-50a98849-a9f3-4a46-9b12-23a76f00a324,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-9edc9b53-5673-44fc-ade5-4ca1cabaf7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-f349f98b-b091-4494-908d-bd997a07bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-49810802-3b47-4cbe-b2d7-9c4ac3fcfb64,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-75719326-b3bd-42c0-9303-c536ce370eba,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-1dee91db-b1eb-4673-ba99-3284f7a64531,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-fa51080f-77b6-43dd-8376-c00758fc65fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989436214-172.17.0.11-1595363139917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-74475d39-b6be-4e33-a5b9-9f9445317d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-315453f1-45fd-4a91-b73d-45fbf094ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-9589b8a5-5630-4d29-884a-7cad223ed22e,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-28a3e906-cb0a-431b-ad6f-86467dde6364,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-dda7b387-cb26-4db7-ad74-5e365d2a3fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-3b8e3d7b-1930-426d-aa1b-22332b01edbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-edc29226-4344-4b9d-9776-bd35bcd5fdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-c8f2e58c-3e20-4297-b3fa-ddf2d33ede8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989436214-172.17.0.11-1595363139917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-74475d39-b6be-4e33-a5b9-9f9445317d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-315453f1-45fd-4a91-b73d-45fbf094ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-9589b8a5-5630-4d29-884a-7cad223ed22e,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-28a3e906-cb0a-431b-ad6f-86467dde6364,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-dda7b387-cb26-4db7-ad74-5e365d2a3fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-3b8e3d7b-1930-426d-aa1b-22332b01edbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-edc29226-4344-4b9d-9776-bd35bcd5fdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-c8f2e58c-3e20-4297-b3fa-ddf2d33ede8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911626227-172.17.0.11-1595363206165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43875,DS-b876e294-d5a9-49b8-841a-9e7703c6509c,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-3ba85855-97d2-4983-8048-e070ce42065f,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-224f4820-9057-4931-9ed5-504e924b7035,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-8759e503-2353-419f-9928-8ff78512f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-7d1f3536-f5c0-442b-a110-2984ab018df4,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-5bb85c65-b92e-4524-8451-859efff5dbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-899f7ff6-9f25-4bdb-802f-f486471aa6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-b0c3265a-e80e-4f46-9630-d2e6672b56e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911626227-172.17.0.11-1595363206165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43875,DS-b876e294-d5a9-49b8-841a-9e7703c6509c,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-3ba85855-97d2-4983-8048-e070ce42065f,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-224f4820-9057-4931-9ed5-504e924b7035,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-8759e503-2353-419f-9928-8ff78512f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-7d1f3536-f5c0-442b-a110-2984ab018df4,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-5bb85c65-b92e-4524-8451-859efff5dbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-899f7ff6-9f25-4bdb-802f-f486471aa6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-b0c3265a-e80e-4f46-9630-d2e6672b56e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093527442-172.17.0.11-1595363271617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-eb9468b7-2043-4892-a2a7-ebf3a99a15fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-627bd815-ec0c-4079-a6f8-3db41b127dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-12c73279-a81a-4e97-969c-88274dc78b74,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-5104fdf7-6a28-4c91-bffb-76159eb54db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-89babdaf-abd8-4b20-b8c8-9601cfac9628,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-c637f144-913e-4450-a775-7eb6589765b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-b0b0bcf9-e268-410a-91d5-fc12fe1f5f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-cb2fb305-65aa-42c2-a69f-e3f0a69779c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093527442-172.17.0.11-1595363271617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-eb9468b7-2043-4892-a2a7-ebf3a99a15fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-627bd815-ec0c-4079-a6f8-3db41b127dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-12c73279-a81a-4e97-969c-88274dc78b74,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-5104fdf7-6a28-4c91-bffb-76159eb54db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-89babdaf-abd8-4b20-b8c8-9601cfac9628,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-c637f144-913e-4450-a775-7eb6589765b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-b0b0bcf9-e268-410a-91d5-fc12fe1f5f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-cb2fb305-65aa-42c2-a69f-e3f0a69779c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758238250-172.17.0.11-1595363513822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-ef156139-b627-4109-af7a-7df4262fed10,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-4ce69b1a-447a-4a5c-9fec-5a5a3f160eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-a15b94e8-473c-4122-bab7-a02278d5b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-df7058ec-373b-411d-a7b0-72d460cf470d,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-1a22568f-4548-4f5d-839b-a81c26b5daba,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-a2cdea9b-540e-459a-bca3-ffc96d6efde6,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-c3d6ea3e-9805-4768-8da4-f4d5339250d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-e9e9e6d4-964e-49de-b1ab-c503f7e1251a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758238250-172.17.0.11-1595363513822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-ef156139-b627-4109-af7a-7df4262fed10,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-4ce69b1a-447a-4a5c-9fec-5a5a3f160eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-a15b94e8-473c-4122-bab7-a02278d5b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-df7058ec-373b-411d-a7b0-72d460cf470d,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-1a22568f-4548-4f5d-839b-a81c26b5daba,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-a2cdea9b-540e-459a-bca3-ffc96d6efde6,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-c3d6ea3e-9805-4768-8da4-f4d5339250d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-e9e9e6d4-964e-49de-b1ab-c503f7e1251a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990981104-172.17.0.11-1595364252370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33673,DS-dd8687f4-05ff-4dd3-92a9-a7e3cca0e902,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-888cd714-d44e-410e-9ad2-5ba05e00e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-1050e4b8-cbcc-4f88-bdde-07852e6d9bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-c8904ca8-cdc6-442c-b915-615cdcde4800,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-559a5b48-3949-4b52-913e-4928f6295725,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-7edc8b6d-35a0-4987-9edd-08e26feb70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-e005b9f0-c28c-4ad5-ba4a-72d7baf6a7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-ead47165-9f33-4048-83eb-a4d2d437553c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990981104-172.17.0.11-1595364252370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33673,DS-dd8687f4-05ff-4dd3-92a9-a7e3cca0e902,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-888cd714-d44e-410e-9ad2-5ba05e00e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-1050e4b8-cbcc-4f88-bdde-07852e6d9bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-c8904ca8-cdc6-442c-b915-615cdcde4800,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-559a5b48-3949-4b52-913e-4928f6295725,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-7edc8b6d-35a0-4987-9edd-08e26feb70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-e005b9f0-c28c-4ad5-ba4a-72d7baf6a7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-ead47165-9f33-4048-83eb-a4d2d437553c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391535645-172.17.0.11-1595364614154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-1d3ecfba-15c7-47f3-b5d0-a1c46d799cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-f12b3083-945b-401e-b4c2-108f9e897167,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-c600e4b3-76c2-47f5-a36b-e9dddf38214f,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-579cb56b-4eb9-4f0f-af10-bdd59332b92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-b9466762-be75-48b1-8210-96074db0a0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-6d394ab6-5a58-4cc3-ba0f-d22e2e9591b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-774585d1-16a7-43d6-aa39-9c2d466bc875,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-15f43dc2-6098-4cb8-9214-39e4b95b45c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391535645-172.17.0.11-1595364614154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-1d3ecfba-15c7-47f3-b5d0-a1c46d799cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-f12b3083-945b-401e-b4c2-108f9e897167,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-c600e4b3-76c2-47f5-a36b-e9dddf38214f,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-579cb56b-4eb9-4f0f-af10-bdd59332b92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-b9466762-be75-48b1-8210-96074db0a0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-6d394ab6-5a58-4cc3-ba0f-d22e2e9591b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-774585d1-16a7-43d6-aa39-9c2d466bc875,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-15f43dc2-6098-4cb8-9214-39e4b95b45c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400664441-172.17.0.11-1595364843389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-5e0bf8d0-9ef9-4f28-bafb-7d06a92cd2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-ba3a7116-cf52-4aea-b851-cac47886c631,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-34f55f60-6a1d-4000-9038-9b2c646368f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-33fd2f92-d92e-4e0c-aef8-98fb4482d442,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-ae035f18-cdf4-4bd0-b35b-2da2ea801aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-ea90aae2-5147-49df-bfe7-e8891fc45711,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-5afadb5f-fd05-4ade-913b-2fe4692688de,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-78c21d1a-4a27-447c-9d2e-f7483acb898e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400664441-172.17.0.11-1595364843389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-5e0bf8d0-9ef9-4f28-bafb-7d06a92cd2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-ba3a7116-cf52-4aea-b851-cac47886c631,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-34f55f60-6a1d-4000-9038-9b2c646368f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-33fd2f92-d92e-4e0c-aef8-98fb4482d442,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-ae035f18-cdf4-4bd0-b35b-2da2ea801aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-ea90aae2-5147-49df-bfe7-e8891fc45711,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-5afadb5f-fd05-4ade-913b-2fe4692688de,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-78c21d1a-4a27-447c-9d2e-f7483acb898e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88066319-172.17.0.11-1595365042487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-c30a7395-2752-44f2-ae1c-d5b6aa210680,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-4edd6a11-2872-4d6f-8525-b4439af84c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-44955f14-eddd-4d91-8f0e-c3e6d4e02ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-31d29f64-b382-4e30-87d1-e8693f1767e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-659b31bd-5923-4853-90ce-9b1b291dcd12,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-c982781a-5f49-4c91-b1bc-913f4e9f7575,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-050acb5e-9ecf-4b7a-9817-5f36763de87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-d931663f-3f39-4eae-806e-f9109f346ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88066319-172.17.0.11-1595365042487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-c30a7395-2752-44f2-ae1c-d5b6aa210680,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-4edd6a11-2872-4d6f-8525-b4439af84c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-44955f14-eddd-4d91-8f0e-c3e6d4e02ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-31d29f64-b382-4e30-87d1-e8693f1767e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-659b31bd-5923-4853-90ce-9b1b291dcd12,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-c982781a-5f49-4c91-b1bc-913f4e9f7575,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-050acb5e-9ecf-4b7a-9817-5f36763de87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-d931663f-3f39-4eae-806e-f9109f346ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934792456-172.17.0.11-1595365397622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41117,DS-8b1c7956-50e8-49b2-be12-c63ac9d1469d,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-a986060e-7c96-4171-a277-ec5eb152fbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-0e3a5f71-5f04-4dba-ab8b-5f7bd1ae6b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-d291ebbd-ffe5-4323-96b7-82d8f7df819e,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-301cb039-4116-46a9-9c22-d0e86d4daa24,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-526136f2-a3e9-4eb0-a13f-bac571975a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-98850438-577b-442c-8aaf-1f332887f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-b1e0b2d2-a282-4b03-9517-8edb6b3e1e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934792456-172.17.0.11-1595365397622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41117,DS-8b1c7956-50e8-49b2-be12-c63ac9d1469d,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-a986060e-7c96-4171-a277-ec5eb152fbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-0e3a5f71-5f04-4dba-ab8b-5f7bd1ae6b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-d291ebbd-ffe5-4323-96b7-82d8f7df819e,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-301cb039-4116-46a9-9c22-d0e86d4daa24,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-526136f2-a3e9-4eb0-a13f-bac571975a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-98850438-577b-442c-8aaf-1f332887f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-b1e0b2d2-a282-4b03-9517-8edb6b3e1e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183470163-172.17.0.11-1595365628862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-bed8e97e-bea0-497d-929e-5b1955dd3373,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-99471066-21fd-41fe-b712-454193c866ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-71ec7c98-c503-4802-a359-6ff22a5a9bda,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-e4572403-aa49-45be-9094-0da50996f4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-102eef04-b9a5-4cdf-88e5-2405e3f77b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-9e7b2e23-a759-40fe-bf84-07454cdff0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-48387c95-67e6-456d-a97c-0110ac5189d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-c3c16f99-e86c-407e-922c-4dc05106000a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183470163-172.17.0.11-1595365628862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-bed8e97e-bea0-497d-929e-5b1955dd3373,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-99471066-21fd-41fe-b712-454193c866ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-71ec7c98-c503-4802-a359-6ff22a5a9bda,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-e4572403-aa49-45be-9094-0da50996f4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-102eef04-b9a5-4cdf-88e5-2405e3f77b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-9e7b2e23-a759-40fe-bf84-07454cdff0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-48387c95-67e6-456d-a97c-0110ac5189d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-c3c16f99-e86c-407e-922c-4dc05106000a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563643135-172.17.0.11-1595366259287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-f07fd91e-1257-4c49-9e32-758fa9904db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-07168dd1-0306-4d4e-8026-7e21b08e35d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-d6054379-4127-458d-aaef-a6a0e184a971,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-1a053ad5-620c-405a-92c5-03c61c0ec2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-ac1ce49d-664f-43f3-9828-d117ec03d171,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-ad8e34e5-a500-4db2-beda-67379cb03735,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-8c004680-ccf6-4a1f-9828-79a697f06157,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-d101b41e-8382-486e-9505-d25331c23b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563643135-172.17.0.11-1595366259287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-f07fd91e-1257-4c49-9e32-758fa9904db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-07168dd1-0306-4d4e-8026-7e21b08e35d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-d6054379-4127-458d-aaef-a6a0e184a971,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-1a053ad5-620c-405a-92c5-03c61c0ec2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-ac1ce49d-664f-43f3-9828-d117ec03d171,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-ad8e34e5-a500-4db2-beda-67379cb03735,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-8c004680-ccf6-4a1f-9828-79a697f06157,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-d101b41e-8382-486e-9505-d25331c23b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116632417-172.17.0.11-1595366297672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37364,DS-f78bbf9c-7762-449b-bb2a-33d37b9c5512,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-8a89817f-6308-43c2-9d01-a33dc57d020c,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-a570c83f-ecef-464f-961e-f607ad6d9f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-1f740fef-e42a-41ce-8d25-075834494faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-06ece8e6-f6bd-4352-8864-67a2fcd8a3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-bc1ec08b-46b7-484e-a4f6-c21b5fb9dfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-c95934d8-b955-4211-b681-995a174beb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-acbb055a-9d13-48cc-940c-23fdccc14ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116632417-172.17.0.11-1595366297672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37364,DS-f78bbf9c-7762-449b-bb2a-33d37b9c5512,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-8a89817f-6308-43c2-9d01-a33dc57d020c,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-a570c83f-ecef-464f-961e-f607ad6d9f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-1f740fef-e42a-41ce-8d25-075834494faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-06ece8e6-f6bd-4352-8864-67a2fcd8a3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-bc1ec08b-46b7-484e-a4f6-c21b5fb9dfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-c95934d8-b955-4211-b681-995a174beb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-acbb055a-9d13-48cc-940c-23fdccc14ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320691931-172.17.0.11-1595366374645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-e2032c11-9328-495b-b154-c47133bdf608,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-46be59a2-5249-4cb6-9a68-626f704c5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-48861fcf-f9c8-4a91-9fd7-c7099bb54294,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-bb4db82b-e99d-487a-9203-ec47d0e3879c,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-22d4db2a-0c85-413d-bcdd-11ad14c4549e,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-a1533727-255b-4a73-b23c-f98dc32d0802,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-a5c75eca-d495-459b-a51f-7545d43dae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-6e4653b2-e3cc-4479-aabd-9cc74769d593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320691931-172.17.0.11-1595366374645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-e2032c11-9328-495b-b154-c47133bdf608,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-46be59a2-5249-4cb6-9a68-626f704c5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-48861fcf-f9c8-4a91-9fd7-c7099bb54294,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-bb4db82b-e99d-487a-9203-ec47d0e3879c,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-22d4db2a-0c85-413d-bcdd-11ad14c4549e,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-a1533727-255b-4a73-b23c-f98dc32d0802,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-a5c75eca-d495-459b-a51f-7545d43dae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-6e4653b2-e3cc-4479-aabd-9cc74769d593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266022178-172.17.0.11-1595366480678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34658,DS-3485f253-710e-47b0-917e-c9741dc42189,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-7d0560e2-9947-4f33-993b-3166bd5a9608,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-daea486b-89ce-4c40-aad9-0ec7e01ac1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-8893c4df-67e2-46cc-a8ce-da89498926b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-e37e2c05-5a7a-41af-8f86-b5d1132323d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-995e846f-75fd-4a7b-a9d8-39ba7bd9a701,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-843e6731-67e9-4163-ab5f-df509a701ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-0f25f1ee-1b3e-457f-8a22-985a66c8c759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266022178-172.17.0.11-1595366480678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34658,DS-3485f253-710e-47b0-917e-c9741dc42189,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-7d0560e2-9947-4f33-993b-3166bd5a9608,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-daea486b-89ce-4c40-aad9-0ec7e01ac1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-8893c4df-67e2-46cc-a8ce-da89498926b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-e37e2c05-5a7a-41af-8f86-b5d1132323d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-995e846f-75fd-4a7b-a9d8-39ba7bd9a701,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-843e6731-67e9-4163-ab5f-df509a701ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-0f25f1ee-1b3e-457f-8a22-985a66c8c759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705321607-172.17.0.11-1595366807993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43380,DS-92099885-17e8-4dd9-ad51-50f78252ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-18128f2f-d58c-42bd-b175-f55d9906a8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-c65313fd-0142-4e43-9fe1-1ef46353cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-17f2058f-aa72-4f89-a06d-0aea7f670334,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-8d339f2d-12a1-4b01-8e25-943ba9cbea61,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-b0e4576a-e254-4381-a5bf-0c7853d4ef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-6e1a947a-357d-48f5-864f-0e0789fad30d,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-b1a89876-7112-47c5-b12b-1b37597b6dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705321607-172.17.0.11-1595366807993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43380,DS-92099885-17e8-4dd9-ad51-50f78252ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-18128f2f-d58c-42bd-b175-f55d9906a8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-c65313fd-0142-4e43-9fe1-1ef46353cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-17f2058f-aa72-4f89-a06d-0aea7f670334,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-8d339f2d-12a1-4b01-8e25-943ba9cbea61,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-b0e4576a-e254-4381-a5bf-0c7853d4ef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-6e1a947a-357d-48f5-864f-0e0789fad30d,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-b1a89876-7112-47c5-b12b-1b37597b6dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5076
