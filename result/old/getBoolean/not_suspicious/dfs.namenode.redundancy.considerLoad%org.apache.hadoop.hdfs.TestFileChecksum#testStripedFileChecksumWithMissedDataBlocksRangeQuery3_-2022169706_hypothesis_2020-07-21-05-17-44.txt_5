reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710818027-172.17.0.20-1595308910789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35877,DS-9ee598cf-ac9b-43f1-828a-aff0bb9df28c,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-d89a6f86-51c1-4163-9957-5dbe82dbef84,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-84ec1f19-68e6-436a-9eb6-4e39a708f3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-55498869-c8ae-4fc0-b989-a1b400371017,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-a237a44a-1f55-4749-a88c-53aeed1824e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-2b9a2438-973f-4cdf-b02e-eb08c49c7e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-093cdbbf-6974-4bc1-b15a-015cb5623177,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-5161fe18-e4c9-453f-b61e-15ec2b3f1fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710818027-172.17.0.20-1595308910789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35877,DS-9ee598cf-ac9b-43f1-828a-aff0bb9df28c,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-d89a6f86-51c1-4163-9957-5dbe82dbef84,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-84ec1f19-68e6-436a-9eb6-4e39a708f3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-55498869-c8ae-4fc0-b989-a1b400371017,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-a237a44a-1f55-4749-a88c-53aeed1824e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-2b9a2438-973f-4cdf-b02e-eb08c49c7e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-093cdbbf-6974-4bc1-b15a-015cb5623177,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-5161fe18-e4c9-453f-b61e-15ec2b3f1fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421656323-172.17.0.20-1595308946072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-fad83fe4-7319-40a3-ae95-4e4d9ff5e195,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-003bb0ae-cefe-430c-ab24-411892551932,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-bb621386-8776-4eeb-b279-c6db6a656196,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-67f38a3d-915c-4ce6-b4b2-3a8024e2166c,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1877f6d9-cbf9-4c96-aede-46b54cacd323,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-2346375f-4a88-4f1b-94c9-3b810ee6f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-3742e563-a992-4ac7-8ff9-c3fb8ef1e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-21bb8fdb-c710-47b9-8fc1-0031e4170bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421656323-172.17.0.20-1595308946072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-fad83fe4-7319-40a3-ae95-4e4d9ff5e195,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-003bb0ae-cefe-430c-ab24-411892551932,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-bb621386-8776-4eeb-b279-c6db6a656196,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-67f38a3d-915c-4ce6-b4b2-3a8024e2166c,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1877f6d9-cbf9-4c96-aede-46b54cacd323,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-2346375f-4a88-4f1b-94c9-3b810ee6f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-3742e563-a992-4ac7-8ff9-c3fb8ef1e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-21bb8fdb-c710-47b9-8fc1-0031e4170bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131480125-172.17.0.20-1595308976007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-038c8729-ef08-4d6b-9bd7-8cf37f8140a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-7c1779a4-d17c-464b-9927-f650f8d4ee91,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-a82266ca-0c83-4fcf-9bb2-fd52e36c17be,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-44b5fa01-1dd1-422a-ae6f-458d16a622e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-57e3523d-1cfb-4385-84d2-36ed468a40ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-0eedb735-352c-4dec-80cd-1607f6d935ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-f8c3c607-de92-40e7-80c5-98a4cf78a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-e199ca5f-dbac-4fb6-af9d-da321fb886c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131480125-172.17.0.20-1595308976007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-038c8729-ef08-4d6b-9bd7-8cf37f8140a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-7c1779a4-d17c-464b-9927-f650f8d4ee91,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-a82266ca-0c83-4fcf-9bb2-fd52e36c17be,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-44b5fa01-1dd1-422a-ae6f-458d16a622e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-57e3523d-1cfb-4385-84d2-36ed468a40ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-0eedb735-352c-4dec-80cd-1607f6d935ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-f8c3c607-de92-40e7-80c5-98a4cf78a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-e199ca5f-dbac-4fb6-af9d-da321fb886c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745458400-172.17.0.20-1595309172304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39784,DS-8118a16e-314e-49df-9301-f106041f043b,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-17556be0-e481-4eac-ad38-5f40519cd121,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-84bdd283-f560-4e99-b673-47075c207ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-8fad141d-665c-451d-aa30-b095a388f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-4a4208df-82c2-481d-91c4-bc601a32198b,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-49f7adab-f644-4774-b2d6-e2034fc31567,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-3012b02e-097e-460d-af5d-5011ca2d33bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-c8bc9673-e172-4fdc-b711-43fed471e428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745458400-172.17.0.20-1595309172304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39784,DS-8118a16e-314e-49df-9301-f106041f043b,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-17556be0-e481-4eac-ad38-5f40519cd121,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-84bdd283-f560-4e99-b673-47075c207ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-8fad141d-665c-451d-aa30-b095a388f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-4a4208df-82c2-481d-91c4-bc601a32198b,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-49f7adab-f644-4774-b2d6-e2034fc31567,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-3012b02e-097e-460d-af5d-5011ca2d33bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-c8bc9673-e172-4fdc-b711-43fed471e428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603910775-172.17.0.20-1595309341140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35739,DS-ddca79aa-fadd-4e5e-9560-8a2c9358d722,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-63514012-3d0f-4578-a683-3f0fa7e6981d,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-f80f55a5-7e04-4657-9454-bcb8a6c6dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-3eefeeb7-ec2c-45a0-a42d-e8df145db796,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-b6adfd28-4f4e-4d95-a8e2-b4c4695c5404,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-7394d044-4d6f-4627-bf64-331e21fbedf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-d470dbd8-2412-4693-b224-7eecc6f13f10,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-cf1990ce-1487-4177-bbf1-4420ef32bb0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603910775-172.17.0.20-1595309341140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35739,DS-ddca79aa-fadd-4e5e-9560-8a2c9358d722,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-63514012-3d0f-4578-a683-3f0fa7e6981d,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-f80f55a5-7e04-4657-9454-bcb8a6c6dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-3eefeeb7-ec2c-45a0-a42d-e8df145db796,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-b6adfd28-4f4e-4d95-a8e2-b4c4695c5404,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-7394d044-4d6f-4627-bf64-331e21fbedf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-d470dbd8-2412-4693-b224-7eecc6f13f10,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-cf1990ce-1487-4177-bbf1-4420ef32bb0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518482750-172.17.0.20-1595309467654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42921,DS-cfa2299e-0bdf-41f7-92e6-f2c84697a483,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-8cd9cba6-5d9c-493f-a897-c650b8d1aa12,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-7964bef9-fe21-4aa8-b4b0-65d02fe26860,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-1c47ccd9-b8ff-4a19-86e0-65f7c0356927,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-5afd1155-df6a-4972-893b-67d86797b22d,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-20e824fc-0061-48dd-9b13-113a5f480c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-c85f9250-2b38-4512-ab33-f4e2e7e4a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-aba089a3-e7d6-40f7-9002-d2fc6e2755cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518482750-172.17.0.20-1595309467654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42921,DS-cfa2299e-0bdf-41f7-92e6-f2c84697a483,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-8cd9cba6-5d9c-493f-a897-c650b8d1aa12,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-7964bef9-fe21-4aa8-b4b0-65d02fe26860,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-1c47ccd9-b8ff-4a19-86e0-65f7c0356927,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-5afd1155-df6a-4972-893b-67d86797b22d,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-20e824fc-0061-48dd-9b13-113a5f480c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-c85f9250-2b38-4512-ab33-f4e2e7e4a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-aba089a3-e7d6-40f7-9002-d2fc6e2755cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615503768-172.17.0.20-1595310086820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-1c8dbf96-64cd-475d-8ff6-e34b3d3fcb80,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-ad35818e-de5c-4753-92d2-cc62912e9ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-8506571d-7336-43c4-a41a-0822a5277c86,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-db9d87cd-0b44-4fcd-a520-2006150f5794,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-62289daf-c42e-47ed-b19b-3d8ff90efcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-f86892da-5dbc-430b-97ea-8a36d01ecf12,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-fe748bed-bd34-430e-90f4-36cd52f61069,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-8ec97ab4-5ce6-4080-8b79-f4a4fb94aa95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615503768-172.17.0.20-1595310086820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-1c8dbf96-64cd-475d-8ff6-e34b3d3fcb80,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-ad35818e-de5c-4753-92d2-cc62912e9ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-8506571d-7336-43c4-a41a-0822a5277c86,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-db9d87cd-0b44-4fcd-a520-2006150f5794,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-62289daf-c42e-47ed-b19b-3d8ff90efcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-f86892da-5dbc-430b-97ea-8a36d01ecf12,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-fe748bed-bd34-430e-90f4-36cd52f61069,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-8ec97ab4-5ce6-4080-8b79-f4a4fb94aa95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959482381-172.17.0.20-1595310185061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37563,DS-65efc21e-129d-4c4a-8e36-b4b920fb7e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-eed44d6c-482e-42f4-802b-e9407d74a2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-2f8bb9b1-965b-4a73-9f86-8cd5400e9dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-ba05141d-e06b-4c8a-b342-1b2c5a29b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-fc6fd063-ccda-4dd5-96d8-b9e17ed1d68c,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-a8cda094-d010-4e77-b423-9163fb873c71,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-4ce15590-1186-47f7-984f-1abda7afc2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-3a3e6809-8887-48bd-846c-59ae0c223ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959482381-172.17.0.20-1595310185061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37563,DS-65efc21e-129d-4c4a-8e36-b4b920fb7e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-eed44d6c-482e-42f4-802b-e9407d74a2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-2f8bb9b1-965b-4a73-9f86-8cd5400e9dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-ba05141d-e06b-4c8a-b342-1b2c5a29b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-fc6fd063-ccda-4dd5-96d8-b9e17ed1d68c,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-a8cda094-d010-4e77-b423-9163fb873c71,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-4ce15590-1186-47f7-984f-1abda7afc2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-3a3e6809-8887-48bd-846c-59ae0c223ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054644283-172.17.0.20-1595310221309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-e34a2aaa-ad27-47dc-ae8b-e5a277c1a459,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-53b6e55e-268e-48f0-8ae1-527bf260ad08,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-5657ba23-c364-4b26-b7a0-d5ee3a7e50de,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-5789bdd0-52a1-4ae2-a597-457d68fd4ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-de3aafde-a13e-4986-be6f-178b570390cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-74f4050d-24ea-4d5e-9047-5b13e891b249,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-f91c88da-5179-441d-b2fb-c44301af88f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-d9349d82-5f2a-49f5-a0ba-63011bcfa867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054644283-172.17.0.20-1595310221309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-e34a2aaa-ad27-47dc-ae8b-e5a277c1a459,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-53b6e55e-268e-48f0-8ae1-527bf260ad08,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-5657ba23-c364-4b26-b7a0-d5ee3a7e50de,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-5789bdd0-52a1-4ae2-a597-457d68fd4ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-de3aafde-a13e-4986-be6f-178b570390cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-74f4050d-24ea-4d5e-9047-5b13e891b249,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-f91c88da-5179-441d-b2fb-c44301af88f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-d9349d82-5f2a-49f5-a0ba-63011bcfa867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853415152-172.17.0.20-1595310575705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39020,DS-395858c2-5912-4cc9-aab4-ba429a863053,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-24aa10b4-a263-4608-a840-f20b7b2ce569,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-4371a5d4-d9a1-4038-bc7b-9314b7f1967c,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-844d85f6-ce46-4f18-a082-baaf9413c569,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-32e88cfd-042e-4b12-85a9-c3cd33c816f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-b5736511-2fb8-4f21-a635-8142559d991a,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-6d3e1b55-6a55-4503-94c5-60a525bdf65a,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-9a0b9def-132f-48cc-947c-80b5544a517e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853415152-172.17.0.20-1595310575705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39020,DS-395858c2-5912-4cc9-aab4-ba429a863053,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-24aa10b4-a263-4608-a840-f20b7b2ce569,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-4371a5d4-d9a1-4038-bc7b-9314b7f1967c,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-844d85f6-ce46-4f18-a082-baaf9413c569,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-32e88cfd-042e-4b12-85a9-c3cd33c816f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-b5736511-2fb8-4f21-a635-8142559d991a,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-6d3e1b55-6a55-4503-94c5-60a525bdf65a,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-9a0b9def-132f-48cc-947c-80b5544a517e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597531281-172.17.0.20-1595310875261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-48bf3b54-e6e4-461a-968a-94c2b1b1a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-67502d9e-bcbb-49ba-a86e-cd039dd95c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-c5ed6dda-1ab0-46f7-8c46-7f852d364f37,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-68f5624e-aacd-437b-bf90-9de374aa4124,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-01ab14e4-e3a0-4d4a-8322-c7041a77cd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-d0039124-0c7c-43e2-8d1d-2ab960871049,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-ca61caf4-bf36-46b1-97d1-8635b28c9504,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-e1e80f13-ef51-4108-9870-3c55e93299ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597531281-172.17.0.20-1595310875261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-48bf3b54-e6e4-461a-968a-94c2b1b1a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-67502d9e-bcbb-49ba-a86e-cd039dd95c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-c5ed6dda-1ab0-46f7-8c46-7f852d364f37,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-68f5624e-aacd-437b-bf90-9de374aa4124,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-01ab14e4-e3a0-4d4a-8322-c7041a77cd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-d0039124-0c7c-43e2-8d1d-2ab960871049,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-ca61caf4-bf36-46b1-97d1-8635b28c9504,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-e1e80f13-ef51-4108-9870-3c55e93299ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218959783-172.17.0.20-1595312594085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-1629b08d-1e42-4581-a92a-7796d05612f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-96c597c2-d727-4123-b30e-2dc21a6ffb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-8886d7c8-1062-4c24-ba5a-60eebeaad8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-69370f3e-e30f-4d21-aef5-eeecd20d20e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-4b66e669-c3e3-4945-aeb0-f6e315fe6875,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-110391d4-bc01-41e4-b4d7-dfa01a64765a,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-1d8f3fda-f2ec-4be8-922a-77c9f42dbab0,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-dd40d65e-0ecd-4ea9-b2b4-0a0763e6dc7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218959783-172.17.0.20-1595312594085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-1629b08d-1e42-4581-a92a-7796d05612f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-96c597c2-d727-4123-b30e-2dc21a6ffb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-8886d7c8-1062-4c24-ba5a-60eebeaad8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-69370f3e-e30f-4d21-aef5-eeecd20d20e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-4b66e669-c3e3-4945-aeb0-f6e315fe6875,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-110391d4-bc01-41e4-b4d7-dfa01a64765a,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-1d8f3fda-f2ec-4be8-922a-77c9f42dbab0,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-dd40d65e-0ecd-4ea9-b2b4-0a0763e6dc7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031487587-172.17.0.20-1595312627435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-4a920306-4a13-41ab-88b5-f6d901cfc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-2d835e1f-7735-417f-970a-85426d461be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-e8ca8f09-d0ef-4454-9d5e-e4131e394b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-a5a637d0-22e1-4121-a11e-cac7661088f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-af8450dd-2850-4339-a012-bd0aa523aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-81b02771-94b0-4a0d-a758-27a1d58c8445,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-ff6a7f25-789b-4fdc-b2ab-579bee39d1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-1261dfa1-5a5f-46ae-8601-a9f67a274000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031487587-172.17.0.20-1595312627435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-4a920306-4a13-41ab-88b5-f6d901cfc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-2d835e1f-7735-417f-970a-85426d461be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-e8ca8f09-d0ef-4454-9d5e-e4131e394b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-a5a637d0-22e1-4121-a11e-cac7661088f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-af8450dd-2850-4339-a012-bd0aa523aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-81b02771-94b0-4a0d-a758-27a1d58c8445,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-ff6a7f25-789b-4fdc-b2ab-579bee39d1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-1261dfa1-5a5f-46ae-8601-a9f67a274000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79124261-172.17.0.20-1595312835278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-9cf54189-987d-4f06-9015-eb206f43b979,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-ebdd97af-0932-471b-89e9-7eec7322e4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-08189c10-d7b7-4fa2-a1b6-e3876b9ab541,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-f08ce7b6-3feb-4dbd-81e8-236bc2f086e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-d4b172ce-4ab2-423f-a400-ce99ba6e3c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-1143fc7d-2a7a-4ea6-ba8f-78eeec4ee861,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-69af8b52-198b-41b5-8a1a-02bfb66e424c,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-79a0e8a2-ec9f-4ba9-9ce2-b5ef133a927a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79124261-172.17.0.20-1595312835278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-9cf54189-987d-4f06-9015-eb206f43b979,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-ebdd97af-0932-471b-89e9-7eec7322e4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-08189c10-d7b7-4fa2-a1b6-e3876b9ab541,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-f08ce7b6-3feb-4dbd-81e8-236bc2f086e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-d4b172ce-4ab2-423f-a400-ce99ba6e3c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-1143fc7d-2a7a-4ea6-ba8f-78eeec4ee861,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-69af8b52-198b-41b5-8a1a-02bfb66e424c,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-79a0e8a2-ec9f-4ba9-9ce2-b5ef133a927a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99924968-172.17.0.20-1595313246372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33990,DS-640bbc9a-c19d-4326-baf8-0de19a2fd1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-313d4725-7871-4d63-9c5f-1380dc3f2fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-6de1802d-672e-4239-b691-8d83ca2f9c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-dc13566c-91a6-4634-b9c1-aba12df33eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-8cbb32c2-71de-41d9-ab58-e9e191c06f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-9b2d87fb-666f-4c75-89b4-e547e5551ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-7dfd087d-4f54-4942-b0e6-c6184ad79cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-540175f3-2950-4eab-bed2-fc3360dd2961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99924968-172.17.0.20-1595313246372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33990,DS-640bbc9a-c19d-4326-baf8-0de19a2fd1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-313d4725-7871-4d63-9c5f-1380dc3f2fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-6de1802d-672e-4239-b691-8d83ca2f9c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-dc13566c-91a6-4634-b9c1-aba12df33eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-8cbb32c2-71de-41d9-ab58-e9e191c06f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-9b2d87fb-666f-4c75-89b4-e547e5551ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-7dfd087d-4f54-4942-b0e6-c6184ad79cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-540175f3-2950-4eab-bed2-fc3360dd2961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689048780-172.17.0.20-1595313626548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35965,DS-e731d299-9e1b-485b-819e-e5c657ba1938,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-5a98b6fa-fd9f-4304-855b-caf19bc6f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-31e7b76b-4a66-44ce-834f-d32ec85c9447,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-07298958-75d5-4b1a-adfb-350d9800553a,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-a7446f24-6e82-4d72-8182-deaae010b0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-551b0e5c-6623-475d-bb56-cc0f5dce4448,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-541e25b2-16eb-480e-b082-ce3cca35cdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-1e04e654-e471-4593-81ba-cd86640ee56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689048780-172.17.0.20-1595313626548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35965,DS-e731d299-9e1b-485b-819e-e5c657ba1938,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-5a98b6fa-fd9f-4304-855b-caf19bc6f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-31e7b76b-4a66-44ce-834f-d32ec85c9447,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-07298958-75d5-4b1a-adfb-350d9800553a,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-a7446f24-6e82-4d72-8182-deaae010b0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-551b0e5c-6623-475d-bb56-cc0f5dce4448,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-541e25b2-16eb-480e-b082-ce3cca35cdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-1e04e654-e471-4593-81ba-cd86640ee56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339997031-172.17.0.20-1595313660304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45260,DS-c1841103-f470-4b85-acbb-dc0e9e1991bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-f2c7a272-8cf4-4093-a53a-6ddb4c68dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-886fc609-1f5f-4872-893d-88d134cae6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-8ae09482-0079-4b33-abe0-de6a53cc2458,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-14336185-a5c1-4e8f-ad7a-575d36256703,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-bfd9c14d-6dfa-4da4-9324-148066f4089f,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-4043c978-ea3f-4149-9ac4-f1bd8e783f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-52c82322-a00c-46b9-9a8c-ed2ab77af218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339997031-172.17.0.20-1595313660304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45260,DS-c1841103-f470-4b85-acbb-dc0e9e1991bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-f2c7a272-8cf4-4093-a53a-6ddb4c68dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-886fc609-1f5f-4872-893d-88d134cae6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-8ae09482-0079-4b33-abe0-de6a53cc2458,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-14336185-a5c1-4e8f-ad7a-575d36256703,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-bfd9c14d-6dfa-4da4-9324-148066f4089f,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-4043c978-ea3f-4149-9ac4-f1bd8e783f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-52c82322-a00c-46b9-9a8c-ed2ab77af218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116990637-172.17.0.20-1595313699104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33329,DS-7afe3faf-530b-4dc1-98eb-b7d3463a6581,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-2fc42063-417b-458c-b2fc-2c1c68af2f25,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-f9d1eacf-ce7a-4043-9342-8d77dc2dec77,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-adbeb2ba-e1cb-4587-a527-84004176b49a,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-7b49708b-dc44-45d3-a6fa-4a5a398ac2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-ac6caf2f-d5a8-4e95-a5b5-39e625193134,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-1f0bdd65-9a78-4ac1-8d73-8a64ee48d240,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-332e802b-9f02-4b5a-ba61-5d4c2e009f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116990637-172.17.0.20-1595313699104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33329,DS-7afe3faf-530b-4dc1-98eb-b7d3463a6581,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-2fc42063-417b-458c-b2fc-2c1c68af2f25,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-f9d1eacf-ce7a-4043-9342-8d77dc2dec77,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-adbeb2ba-e1cb-4587-a527-84004176b49a,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-7b49708b-dc44-45d3-a6fa-4a5a398ac2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-ac6caf2f-d5a8-4e95-a5b5-39e625193134,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-1f0bdd65-9a78-4ac1-8d73-8a64ee48d240,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-332e802b-9f02-4b5a-ba61-5d4c2e009f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5183
