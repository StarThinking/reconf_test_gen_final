reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558410069-172.17.0.4-1595300763865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-d75a205b-4400-4271-82f4-8f130fce7728,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-eb10cf13-e060-4d0b-b9c9-85472505f25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-94e67832-01d5-4eae-9bf8-2d99d868e64b,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-738e3aad-ec6c-4cc6-aa1e-af481e49c531,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-aff20db3-cb57-4c54-afff-79a0265a4256,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-28d1fc83-0bf4-4cbe-830e-22e03e5c288a,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-e604f5c6-cf5f-4e7e-873b-25021b3c6398,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-bef31f27-c76b-4881-acd7-2cb018fa6a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558410069-172.17.0.4-1595300763865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-d75a205b-4400-4271-82f4-8f130fce7728,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-eb10cf13-e060-4d0b-b9c9-85472505f25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-94e67832-01d5-4eae-9bf8-2d99d868e64b,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-738e3aad-ec6c-4cc6-aa1e-af481e49c531,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-aff20db3-cb57-4c54-afff-79a0265a4256,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-28d1fc83-0bf4-4cbe-830e-22e03e5c288a,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-e604f5c6-cf5f-4e7e-873b-25021b3c6398,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-bef31f27-c76b-4881-acd7-2cb018fa6a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092121158-172.17.0.4-1595301332736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-7da408c3-5931-4ddf-800b-e47624c83f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-a33c3d95-c8ab-4a05-8947-dc671d166f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-10d6f6cb-2c9a-4c79-9375-95efe51ecd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-b8f4754a-a7f0-404c-9a98-44c2557feb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-740d18af-2b48-4c8a-8f66-b76c642333f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-87c2f95c-6cb3-469c-8886-d6bd0919710b,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-44e29fc3-8f5f-4a85-bffa-11e1041ed340,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-240aea28-346a-48c1-a14a-3859bed13852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092121158-172.17.0.4-1595301332736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-7da408c3-5931-4ddf-800b-e47624c83f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-a33c3d95-c8ab-4a05-8947-dc671d166f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-10d6f6cb-2c9a-4c79-9375-95efe51ecd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-b8f4754a-a7f0-404c-9a98-44c2557feb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-740d18af-2b48-4c8a-8f66-b76c642333f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-87c2f95c-6cb3-469c-8886-d6bd0919710b,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-44e29fc3-8f5f-4a85-bffa-11e1041ed340,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-240aea28-346a-48c1-a14a-3859bed13852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921488403-172.17.0.4-1595301577531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-5b05b371-eebe-4ec6-8e4b-18323d23c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-67b9b683-dba9-4f91-a957-0f86acf5d2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-a3eff334-f4e2-4810-b7c5-829af7c4a856,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-61ec20a7-ffb4-485e-91e4-7cb2e3df1660,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-42a2ebf2-cc16-492f-b2ba-a0909eb1fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-96abd46b-2d2e-4089-8734-c52c86409ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-c5c6da7e-62e9-4423-ae74-9b5d0b422dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-7ce501b4-b055-4925-954e-c17c6d17e18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921488403-172.17.0.4-1595301577531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-5b05b371-eebe-4ec6-8e4b-18323d23c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-67b9b683-dba9-4f91-a957-0f86acf5d2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-a3eff334-f4e2-4810-b7c5-829af7c4a856,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-61ec20a7-ffb4-485e-91e4-7cb2e3df1660,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-42a2ebf2-cc16-492f-b2ba-a0909eb1fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-96abd46b-2d2e-4089-8734-c52c86409ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-c5c6da7e-62e9-4423-ae74-9b5d0b422dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-7ce501b4-b055-4925-954e-c17c6d17e18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284816056-172.17.0.4-1595301614210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34513,DS-bc319a91-de80-48a9-a2b5-3ba8b9f690ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-775d8340-60d0-41f2-9ae0-746298ecc92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-d4bdfa67-8a26-443d-9ff5-0bcdf66b7ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-4f4348a7-ba63-49e9-84a7-bcd7dad0b60c,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-4993d190-8061-44bb-b8e4-3c7a09b7eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-c362b3f3-9fd0-461e-a1c3-ad5ac69d64bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-17cc9c02-86ad-46d5-9e7c-69a5a7198cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-e45e1052-a3be-49dc-bb89-fa7dc26d660e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284816056-172.17.0.4-1595301614210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34513,DS-bc319a91-de80-48a9-a2b5-3ba8b9f690ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-775d8340-60d0-41f2-9ae0-746298ecc92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-d4bdfa67-8a26-443d-9ff5-0bcdf66b7ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-4f4348a7-ba63-49e9-84a7-bcd7dad0b60c,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-4993d190-8061-44bb-b8e4-3c7a09b7eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-c362b3f3-9fd0-461e-a1c3-ad5ac69d64bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-17cc9c02-86ad-46d5-9e7c-69a5a7198cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-e45e1052-a3be-49dc-bb89-fa7dc26d660e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706373034-172.17.0.4-1595301730374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-75b56221-b52e-489b-bde6-b3c50ab0a71d,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-1d8c33d6-5f07-4644-b0f5-f8cfd2f2e8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-793d40c7-c9ae-4e7a-bbcf-0a96d38a1f10,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-8c7ac2e3-04ab-487c-a571-3d9b4a5bb8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-56a4dd75-5ca0-46c7-aa81-6aa5655a0555,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-cf5a61cf-404c-4289-92ef-d9151e2fc5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-47383732-b642-416d-871e-347896c58ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-4e0b1fe0-a34b-42d7-81d3-52b72df0f137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706373034-172.17.0.4-1595301730374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-75b56221-b52e-489b-bde6-b3c50ab0a71d,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-1d8c33d6-5f07-4644-b0f5-f8cfd2f2e8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-793d40c7-c9ae-4e7a-bbcf-0a96d38a1f10,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-8c7ac2e3-04ab-487c-a571-3d9b4a5bb8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-56a4dd75-5ca0-46c7-aa81-6aa5655a0555,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-cf5a61cf-404c-4289-92ef-d9151e2fc5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-47383732-b642-416d-871e-347896c58ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-4e0b1fe0-a34b-42d7-81d3-52b72df0f137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352681070-172.17.0.4-1595302098804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38393,DS-ab1eeb42-6a53-4991-ace8-b0ecb86f8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-ceb95cf0-95a0-499c-bc23-f32516a92c43,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-672ae7f5-ffe7-406b-bc55-32ee503aaf71,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-6cbf1c01-03fa-4b89-863f-cee61d6749ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-504432d6-8fce-45a3-b072-0125af04ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-7b31db02-b073-47bb-97ce-d1084003b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-83302fe6-1bde-438f-97c9-eafe25dde44f,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-2c0238ae-0560-403a-9df3-930f1deb07e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352681070-172.17.0.4-1595302098804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38393,DS-ab1eeb42-6a53-4991-ace8-b0ecb86f8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-ceb95cf0-95a0-499c-bc23-f32516a92c43,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-672ae7f5-ffe7-406b-bc55-32ee503aaf71,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-6cbf1c01-03fa-4b89-863f-cee61d6749ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-504432d6-8fce-45a3-b072-0125af04ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-7b31db02-b073-47bb-97ce-d1084003b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-83302fe6-1bde-438f-97c9-eafe25dde44f,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-2c0238ae-0560-403a-9df3-930f1deb07e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184362205-172.17.0.4-1595302218113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41108,DS-b8d46777-e799-4799-880d-aabea3d85ede,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-4c1b3bd9-64d9-4776-bae4-f3e0935e2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-0bb9b9ca-b6a3-4567-9096-86654f934c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-d64ab1a0-0d43-4a61-851f-79cd000d85f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-46e7dc3d-d23a-4b7b-b2d7-2a801fad787e,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-3d48b6e1-2313-4ad2-b90e-7e5b752a4611,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-40fffaea-ff18-4a84-8e8b-1c38cedd11f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-56661d5a-cd73-49b6-9ae9-97e907ccdb0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184362205-172.17.0.4-1595302218113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41108,DS-b8d46777-e799-4799-880d-aabea3d85ede,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-4c1b3bd9-64d9-4776-bae4-f3e0935e2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-0bb9b9ca-b6a3-4567-9096-86654f934c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-d64ab1a0-0d43-4a61-851f-79cd000d85f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-46e7dc3d-d23a-4b7b-b2d7-2a801fad787e,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-3d48b6e1-2313-4ad2-b90e-7e5b752a4611,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-40fffaea-ff18-4a84-8e8b-1c38cedd11f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-56661d5a-cd73-49b6-9ae9-97e907ccdb0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113548365-172.17.0.4-1595303024234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-46b19a1b-2d3b-46b9-8a87-5353f6e6c7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-6f75179a-2a6e-46fa-92a5-fd42af743985,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-9e83c616-2a97-44c4-808b-103d8ed119c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-95a7a05f-759d-491f-8c5f-665122780133,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-f3934f16-ee51-4cf7-8d76-a3a15283228e,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-a67b3a14-ac33-47e7-9685-653b4401c64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-bdfc5b81-2e4a-4807-b746-84261fd3c466,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-98108a57-0725-4d0e-ade7-20485052ae62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113548365-172.17.0.4-1595303024234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-46b19a1b-2d3b-46b9-8a87-5353f6e6c7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-6f75179a-2a6e-46fa-92a5-fd42af743985,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-9e83c616-2a97-44c4-808b-103d8ed119c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-95a7a05f-759d-491f-8c5f-665122780133,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-f3934f16-ee51-4cf7-8d76-a3a15283228e,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-a67b3a14-ac33-47e7-9685-653b4401c64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-bdfc5b81-2e4a-4807-b746-84261fd3c466,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-98108a57-0725-4d0e-ade7-20485052ae62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317054094-172.17.0.4-1595304200683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-ee589e7a-7fde-4552-b91e-ec08cbfcd18a,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-2610a284-5624-45bd-b6c3-1f4aa34436ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-4d6c8de9-a116-445e-bcee-c9547630f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-7aa78e99-19f4-41d9-9c6a-beaf062b9ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-c3d673cd-afbb-4528-ae36-ec52cb55bc29,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-b4d608ce-65c8-4cc8-ad10-97a3e309583c,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-2dc57dc9-6bc3-4e36-bc1b-055abc54b77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-e4b08729-49e6-434b-a91f-c010672c7c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317054094-172.17.0.4-1595304200683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-ee589e7a-7fde-4552-b91e-ec08cbfcd18a,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-2610a284-5624-45bd-b6c3-1f4aa34436ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-4d6c8de9-a116-445e-bcee-c9547630f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-7aa78e99-19f4-41d9-9c6a-beaf062b9ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-c3d673cd-afbb-4528-ae36-ec52cb55bc29,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-b4d608ce-65c8-4cc8-ad10-97a3e309583c,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-2dc57dc9-6bc3-4e36-bc1b-055abc54b77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-e4b08729-49e6-434b-a91f-c010672c7c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405674637-172.17.0.4-1595304756539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-bee08792-9fed-4f3e-8889-2f7c6d34d114,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-323b057a-8a97-4078-b607-9feddd22b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-de3d070e-00fc-465b-a6ee-ae8d5aeebc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-f6b1aede-528f-4fee-92a0-195163daa997,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-d917ce80-cab7-4085-97ea-797e8fe6b271,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-58dde1f2-53f5-478d-95e3-d92199be80ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-947503d9-0081-4a49-aece-4d0c24350384,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-146a5d91-4cf5-4da2-8d8d-f2e9aa18686c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405674637-172.17.0.4-1595304756539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-bee08792-9fed-4f3e-8889-2f7c6d34d114,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-323b057a-8a97-4078-b607-9feddd22b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-de3d070e-00fc-465b-a6ee-ae8d5aeebc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-f6b1aede-528f-4fee-92a0-195163daa997,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-d917ce80-cab7-4085-97ea-797e8fe6b271,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-58dde1f2-53f5-478d-95e3-d92199be80ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-947503d9-0081-4a49-aece-4d0c24350384,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-146a5d91-4cf5-4da2-8d8d-f2e9aa18686c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437823181-172.17.0.4-1595305163995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35439,DS-381af4ab-f9d3-498e-a785-9c35f8c2cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-4d8b76c3-7226-4fdc-8817-6b90371dde58,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-2a76c047-22c6-43b0-abf6-63c266124282,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-78ac89c4-0e75-484a-a6d2-66860f621b55,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-8f19ba32-6926-4e58-9ad9-05b8c78254ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-1a0f9f1e-7ff5-4684-8159-6f82345032e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-325b64b7-afe0-4ac0-a908-f227c836ffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-59eef2fc-9de9-4d3f-8b99-760866dc4fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437823181-172.17.0.4-1595305163995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35439,DS-381af4ab-f9d3-498e-a785-9c35f8c2cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-4d8b76c3-7226-4fdc-8817-6b90371dde58,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-2a76c047-22c6-43b0-abf6-63c266124282,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-78ac89c4-0e75-484a-a6d2-66860f621b55,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-8f19ba32-6926-4e58-9ad9-05b8c78254ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-1a0f9f1e-7ff5-4684-8159-6f82345032e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-325b64b7-afe0-4ac0-a908-f227c836ffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-59eef2fc-9de9-4d3f-8b99-760866dc4fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28991191-172.17.0.4-1595306496743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34301,DS-0a3078f9-7c69-4b51-9064-61d4e9a2f792,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-1236185a-7de3-4163-a9b9-15089f7455e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-ab72d825-ffab-43c3-b732-1dee79ffa399,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-e675e9e8-396a-4085-9931-5fdf31756b49,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-a923da0d-21d1-4373-9a9f-193520ab287c,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-50703b21-f7ef-4307-b43d-ce2ea3268b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-02c68b92-2719-4590-950c-349292a333da,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-e6bf809e-0929-4aa4-a90a-af413dcc317c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28991191-172.17.0.4-1595306496743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34301,DS-0a3078f9-7c69-4b51-9064-61d4e9a2f792,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-1236185a-7de3-4163-a9b9-15089f7455e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-ab72d825-ffab-43c3-b732-1dee79ffa399,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-e675e9e8-396a-4085-9931-5fdf31756b49,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-a923da0d-21d1-4373-9a9f-193520ab287c,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-50703b21-f7ef-4307-b43d-ce2ea3268b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-02c68b92-2719-4590-950c-349292a333da,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-e6bf809e-0929-4aa4-a90a-af413dcc317c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682279122-172.17.0.4-1595306712886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33228,DS-7592c522-7d33-4c66-a34e-70f7a9117eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-e4a3169f-a00f-4997-b311-e6c0a2a0506c,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-b1bf43c1-4e62-4702-a533-fd8dbc7d3db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-3e930331-7c13-4301-a252-d4e94e8d61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-e286d300-5e6f-40b7-a300-b9753dc227d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-98355928-b22f-42e5-83c9-71a28702e4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-1dc65169-be36-44fd-af9d-91a2f35d05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-bd3f1a63-fdf5-4cb4-8379-8b8e3d46163a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682279122-172.17.0.4-1595306712886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33228,DS-7592c522-7d33-4c66-a34e-70f7a9117eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-e4a3169f-a00f-4997-b311-e6c0a2a0506c,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-b1bf43c1-4e62-4702-a533-fd8dbc7d3db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-3e930331-7c13-4301-a252-d4e94e8d61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-e286d300-5e6f-40b7-a300-b9753dc227d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-98355928-b22f-42e5-83c9-71a28702e4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-1dc65169-be36-44fd-af9d-91a2f35d05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-bd3f1a63-fdf5-4cb4-8379-8b8e3d46163a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355974894-172.17.0.4-1595306751568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-687bf24e-7348-436f-9999-158c3b97e2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-81345f9d-f689-418d-940f-2396e5331bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-0abb57e1-ee27-4aa2-a3ce-85877e073367,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-b763df96-2fa7-4966-b35e-30f55dbd22e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-1cfa8179-fec0-47da-ae7a-84bb9f2314c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-9e2a1738-6ef9-4e8b-809a-bff0ed7f9611,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-a5df1ed4-72ad-480c-9676-2df7e688df3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-5204f84e-439e-4666-ab38-cb90dcf1f23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355974894-172.17.0.4-1595306751568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-687bf24e-7348-436f-9999-158c3b97e2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-81345f9d-f689-418d-940f-2396e5331bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-0abb57e1-ee27-4aa2-a3ce-85877e073367,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-b763df96-2fa7-4966-b35e-30f55dbd22e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-1cfa8179-fec0-47da-ae7a-84bb9f2314c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-9e2a1738-6ef9-4e8b-809a-bff0ed7f9611,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-a5df1ed4-72ad-480c-9676-2df7e688df3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-5204f84e-439e-4666-ab38-cb90dcf1f23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6407
