reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014633557-172.17.0.20-1595331316365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34650,DS-b857cc8e-d1b5-4d3f-bbd0-c142cd405180,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-30fe0f5c-1ba5-4906-95c8-87a6ee0d1410,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-51a1a456-ef3d-4461-bd8a-35ee47e70704,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-a9b0acc1-0a12-424b-aada-106fbe62dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-2edde104-9f72-4703-b804-00380a8dae03,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-a8f95375-555c-47d9-be32-3981682e0b57,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-7f09c58e-f846-494f-a6f9-535ebbbc20a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-8cfb5d7a-c319-4248-8758-5ea981855dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014633557-172.17.0.20-1595331316365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34650,DS-b857cc8e-d1b5-4d3f-bbd0-c142cd405180,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-30fe0f5c-1ba5-4906-95c8-87a6ee0d1410,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-51a1a456-ef3d-4461-bd8a-35ee47e70704,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-a9b0acc1-0a12-424b-aada-106fbe62dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-2edde104-9f72-4703-b804-00380a8dae03,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-a8f95375-555c-47d9-be32-3981682e0b57,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-7f09c58e-f846-494f-a6f9-535ebbbc20a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-8cfb5d7a-c319-4248-8758-5ea981855dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186750856-172.17.0.20-1595331448907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-9ad6e684-d606-4e07-817f-e3445ac952fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-2d302be5-26bd-4bd7-9d61-b903d30e6d90,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-2c82df29-2f7e-4826-987a-00aa3dd0c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-a67c8976-87e6-4538-a91c-9e6528683261,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-75783a4f-a166-48f3-8c0f-b544b0d0345a,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-36427ec1-5d41-45c8-950a-022a192a9160,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-3b332b7f-40d2-4453-9db2-b617e5e7dd02,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-affcaebd-1940-4f78-b6ce-098ea12c00e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186750856-172.17.0.20-1595331448907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-9ad6e684-d606-4e07-817f-e3445ac952fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-2d302be5-26bd-4bd7-9d61-b903d30e6d90,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-2c82df29-2f7e-4826-987a-00aa3dd0c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-a67c8976-87e6-4538-a91c-9e6528683261,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-75783a4f-a166-48f3-8c0f-b544b0d0345a,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-36427ec1-5d41-45c8-950a-022a192a9160,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-3b332b7f-40d2-4453-9db2-b617e5e7dd02,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-affcaebd-1940-4f78-b6ce-098ea12c00e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058977337-172.17.0.20-1595331773516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-98790171-48ae-489e-9a41-3d19cae029d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-579f4fcc-d0c9-4fac-951f-55ec1cf2d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-5b9abc37-22b8-4922-887f-16c7c7b35ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-f754390e-a289-4b8d-b659-c127df3d2525,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-387bebec-bb97-46b8-9999-41f7b2101340,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-a80ecf8a-909b-469f-88b7-8c3ba828857a,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-45b673e9-8d40-4eee-ba6f-bd0d8b0bf723,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-f3f81492-d657-4428-aa07-69eeddc08238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058977337-172.17.0.20-1595331773516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-98790171-48ae-489e-9a41-3d19cae029d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-579f4fcc-d0c9-4fac-951f-55ec1cf2d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-5b9abc37-22b8-4922-887f-16c7c7b35ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-f754390e-a289-4b8d-b659-c127df3d2525,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-387bebec-bb97-46b8-9999-41f7b2101340,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-a80ecf8a-909b-469f-88b7-8c3ba828857a,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-45b673e9-8d40-4eee-ba6f-bd0d8b0bf723,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-f3f81492-d657-4428-aa07-69eeddc08238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731377059-172.17.0.20-1595332134833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-94ecf29e-9631-44e1-9374-cb1879796d11,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-51390104-0a23-459c-af0f-95cb13103913,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-e249f363-4845-4536-91d2-5bc749bb5a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-8ce3a5c9-492b-407a-bd9a-50b4c4ac2b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-a99c3fbc-c0b3-443b-8936-d6adea3ce0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-b2a59bfe-8080-494a-9711-44242c5cf57e,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-5efa4bd7-2c1a-4fc9-aa54-c2e76f0993f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-759d4d30-766e-4eeb-a7f1-6f0a9546ef66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731377059-172.17.0.20-1595332134833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-94ecf29e-9631-44e1-9374-cb1879796d11,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-51390104-0a23-459c-af0f-95cb13103913,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-e249f363-4845-4536-91d2-5bc749bb5a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-8ce3a5c9-492b-407a-bd9a-50b4c4ac2b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-a99c3fbc-c0b3-443b-8936-d6adea3ce0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-b2a59bfe-8080-494a-9711-44242c5cf57e,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-5efa4bd7-2c1a-4fc9-aa54-c2e76f0993f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-759d4d30-766e-4eeb-a7f1-6f0a9546ef66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711577368-172.17.0.20-1595333387632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41107,DS-451af95d-0d0d-4308-848f-ff2cf632f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-ca7cf3b0-ff7e-444a-b2b1-d5dc915c4b81,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-4eddff9e-6e68-4620-9c1f-c17055b3f189,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-f9be909f-8eb4-493b-955a-685476686f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-c636bf01-fa11-4ce0-a3ba-cc6b68c38e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-f1810631-c557-4177-9ed9-48274040c986,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-53825252-f967-4995-9872-90d1434c541a,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-a21cc5f0-3780-41c1-80d2-44fa6619a768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711577368-172.17.0.20-1595333387632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41107,DS-451af95d-0d0d-4308-848f-ff2cf632f6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-ca7cf3b0-ff7e-444a-b2b1-d5dc915c4b81,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-4eddff9e-6e68-4620-9c1f-c17055b3f189,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-f9be909f-8eb4-493b-955a-685476686f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-c636bf01-fa11-4ce0-a3ba-cc6b68c38e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-f1810631-c557-4177-9ed9-48274040c986,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-53825252-f967-4995-9872-90d1434c541a,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-a21cc5f0-3780-41c1-80d2-44fa6619a768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849596313-172.17.0.20-1595333813876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35183,DS-2f910be7-963c-4ec2-9260-b47783614dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-4ab74efa-1ae2-409a-8415-e74d7b169c09,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-26a478c6-32e4-4712-ab78-41f10e0e8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-139ad9a5-e5a2-4bf7-96da-50f04fe184c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-ebaa327a-19e4-43bd-9b1b-ab2ddf87bd16,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-e901e095-0b18-4df1-94f0-006dd84b9087,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-03e624fe-8651-433b-99d8-eee0eeae3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-5e285958-d5ce-4b3b-9142-69f6ec76ffb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849596313-172.17.0.20-1595333813876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35183,DS-2f910be7-963c-4ec2-9260-b47783614dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-4ab74efa-1ae2-409a-8415-e74d7b169c09,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-26a478c6-32e4-4712-ab78-41f10e0e8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-139ad9a5-e5a2-4bf7-96da-50f04fe184c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-ebaa327a-19e4-43bd-9b1b-ab2ddf87bd16,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-e901e095-0b18-4df1-94f0-006dd84b9087,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-03e624fe-8651-433b-99d8-eee0eeae3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-5e285958-d5ce-4b3b-9142-69f6ec76ffb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858239440-172.17.0.20-1595334178043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-1e5b4dd3-1c51-4ae9-a16d-5b789be2fc41,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-3681133e-f0e4-4346-8874-5715aa0b9f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-d8c91e81-f017-4fde-8f68-1243c1f0cb89,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-cb56145a-27de-41d0-991c-c785010fd909,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-99c5ff8f-e201-4682-b907-2ea44c9e41c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-bf244443-ba64-4465-a5ed-14853385c55c,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-9da73388-cb37-4378-9aa4-b041d48f4f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-02db9971-55dc-44c0-bf04-6aac9ae6b172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858239440-172.17.0.20-1595334178043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-1e5b4dd3-1c51-4ae9-a16d-5b789be2fc41,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-3681133e-f0e4-4346-8874-5715aa0b9f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-d8c91e81-f017-4fde-8f68-1243c1f0cb89,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-cb56145a-27de-41d0-991c-c785010fd909,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-99c5ff8f-e201-4682-b907-2ea44c9e41c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-bf244443-ba64-4465-a5ed-14853385c55c,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-9da73388-cb37-4378-9aa4-b041d48f4f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-02db9971-55dc-44c0-bf04-6aac9ae6b172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319210266-172.17.0.20-1595334214873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39468,DS-2a28a4bc-ba41-447a-82a2-3e2cdb666201,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-e43e7f14-4ea0-4e49-8464-f1384759bdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-654840bb-5efe-4e45-92bd-3dd133095094,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-a691ee50-8c4b-4dfc-8db5-a66cefa05cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-62ae6922-f19e-459a-ac40-dffc652e71d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-19facfb3-bab4-4e46-89ce-6d8c8f202a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-86fda3ee-73b7-4a83-a7aa-c957de2639f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-a77d78ab-e33e-4174-bead-1f92a33a12ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319210266-172.17.0.20-1595334214873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39468,DS-2a28a4bc-ba41-447a-82a2-3e2cdb666201,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-e43e7f14-4ea0-4e49-8464-f1384759bdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-654840bb-5efe-4e45-92bd-3dd133095094,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-a691ee50-8c4b-4dfc-8db5-a66cefa05cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-62ae6922-f19e-459a-ac40-dffc652e71d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-19facfb3-bab4-4e46-89ce-6d8c8f202a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-86fda3ee-73b7-4a83-a7aa-c957de2639f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-a77d78ab-e33e-4174-bead-1f92a33a12ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500154307-172.17.0.20-1595334253156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-212e3c99-4725-41ef-b338-dc2f313c954e,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-51e7763a-ffc8-46af-bfd8-8a36b570335d,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-1c92228e-5d2e-4525-b994-5e87a3358c01,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-4569b162-37c8-4464-8acd-baf380ed9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-642f5412-849f-46ef-a7f5-0e1c7462d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-9fd39f79-493a-49b6-a714-2d9ce040451b,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-907677d9-d7e0-49a8-a297-2fa08d0d256d,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-70129ffd-d927-4410-90f0-6295fa9f4f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500154307-172.17.0.20-1595334253156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-212e3c99-4725-41ef-b338-dc2f313c954e,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-51e7763a-ffc8-46af-bfd8-8a36b570335d,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-1c92228e-5d2e-4525-b994-5e87a3358c01,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-4569b162-37c8-4464-8acd-baf380ed9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-642f5412-849f-46ef-a7f5-0e1c7462d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-9fd39f79-493a-49b6-a714-2d9ce040451b,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-907677d9-d7e0-49a8-a297-2fa08d0d256d,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-70129ffd-d927-4410-90f0-6295fa9f4f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011921059-172.17.0.20-1595334455971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-98ce4267-e8e0-4613-bb29-cef7979e06fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-b2b11dfb-9fbe-4ec4-936c-e67fa900c57e,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-8db872e0-3715-488b-94c9-cf1eee752034,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-37f0a3aa-8597-4110-975a-7f59b93e4755,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-b8248888-8460-455d-8683-1e0a65238935,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-9ced741f-29e1-4425-b20a-8a3b65df471f,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-e94cfe66-9f69-4c50-8fbe-2656a14ee6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-3cb58933-dc50-49df-b9db-819af3d9894e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011921059-172.17.0.20-1595334455971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-98ce4267-e8e0-4613-bb29-cef7979e06fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-b2b11dfb-9fbe-4ec4-936c-e67fa900c57e,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-8db872e0-3715-488b-94c9-cf1eee752034,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-37f0a3aa-8597-4110-975a-7f59b93e4755,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-b8248888-8460-455d-8683-1e0a65238935,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-9ced741f-29e1-4425-b20a-8a3b65df471f,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-e94cfe66-9f69-4c50-8fbe-2656a14ee6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-3cb58933-dc50-49df-b9db-819af3d9894e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205273086-172.17.0.20-1595334531644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39786,DS-35569c9e-0c6e-4f49-bc4f-2ccf42616c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-580e64c7-c9ad-444a-b87b-6f567ee71b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-cd6e0611-bc2e-4a64-94c0-56d44a2b2e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-df7e5cf3-84eb-4e92-bd9f-1e04a3ec24fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-248803ed-d0b4-49fa-bc19-2221af47834c,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-4704d795-65a4-49e2-975f-3a9dfae620cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-61ef68b2-2c58-4ee3-bc02-8ebdca337ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-68c9cd6b-b1d4-4f5a-9ed2-05bed9711e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205273086-172.17.0.20-1595334531644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39786,DS-35569c9e-0c6e-4f49-bc4f-2ccf42616c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-580e64c7-c9ad-444a-b87b-6f567ee71b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-cd6e0611-bc2e-4a64-94c0-56d44a2b2e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-df7e5cf3-84eb-4e92-bd9f-1e04a3ec24fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-248803ed-d0b4-49fa-bc19-2221af47834c,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-4704d795-65a4-49e2-975f-3a9dfae620cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-61ef68b2-2c58-4ee3-bc02-8ebdca337ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-68c9cd6b-b1d4-4f5a-9ed2-05bed9711e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039240382-172.17.0.20-1595334570227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-9b973fef-28be-4064-9e1f-c6862e4a2380,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-e76b9a94-07f8-446d-b2c7-e7ce886d37b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-e360be33-8f82-4844-b4e1-90f80a9d1cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-4807277c-1239-48d5-9494-a5a741db9f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-a2a4bc10-cd74-41ec-80f8-fcfb7e20c230,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-05124289-a7b1-4b6c-bbfd-460f24201a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-12178f2c-4b1b-474e-a69d-4a63258b8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-9a63c0df-8169-4695-b4af-5d22ac6be6d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039240382-172.17.0.20-1595334570227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-9b973fef-28be-4064-9e1f-c6862e4a2380,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-e76b9a94-07f8-446d-b2c7-e7ce886d37b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-e360be33-8f82-4844-b4e1-90f80a9d1cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-4807277c-1239-48d5-9494-a5a741db9f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-a2a4bc10-cd74-41ec-80f8-fcfb7e20c230,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-05124289-a7b1-4b6c-bbfd-460f24201a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-12178f2c-4b1b-474e-a69d-4a63258b8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-9a63c0df-8169-4695-b4af-5d22ac6be6d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924757595-172.17.0.20-1595335022030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43679,DS-285f963a-48a2-4e7d-b136-f2fe97f82730,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-b512b86c-5caa-408b-9e58-4da66eb403b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-3738b153-7010-4a1f-9355-89cc907fc6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-a8b74902-6988-485b-b929-1fddd2f12db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-4e468135-0009-4856-ac3d-4dd4ece352c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-79b86751-a99d-42a6-9c09-95c3a43efef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-7a7d864c-a6ad-4000-9b21-147ce44b1960,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-12e11ed3-eb18-408e-9734-e968cd9684a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924757595-172.17.0.20-1595335022030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43679,DS-285f963a-48a2-4e7d-b136-f2fe97f82730,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-b512b86c-5caa-408b-9e58-4da66eb403b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-3738b153-7010-4a1f-9355-89cc907fc6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-a8b74902-6988-485b-b929-1fddd2f12db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-4e468135-0009-4856-ac3d-4dd4ece352c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-79b86751-a99d-42a6-9c09-95c3a43efef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-7a7d864c-a6ad-4000-9b21-147ce44b1960,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-12e11ed3-eb18-408e-9734-e968cd9684a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014973692-172.17.0.20-1595335059606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-8b29c415-853f-4d77-9a9a-f1577afbe315,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-72207b10-597d-451d-984e-cda551038db3,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-5bb74c33-c12d-4292-a861-f2c21ba9bd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-4cfd42ad-eef9-4e79-909e-35977e902bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-9b33862f-8b07-45c2-a20f-bfe066bcd3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-52919397-9428-40f4-8e5a-ffd018095d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-0bdc38df-e8b8-4ffb-b62d-f3d64353868d,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-af7c3a20-cd3e-4b31-a84c-7239c54c25b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014973692-172.17.0.20-1595335059606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-8b29c415-853f-4d77-9a9a-f1577afbe315,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-72207b10-597d-451d-984e-cda551038db3,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-5bb74c33-c12d-4292-a861-f2c21ba9bd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-4cfd42ad-eef9-4e79-909e-35977e902bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-9b33862f-8b07-45c2-a20f-bfe066bcd3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-52919397-9428-40f4-8e5a-ffd018095d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-0bdc38df-e8b8-4ffb-b62d-f3d64353868d,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-af7c3a20-cd3e-4b31-a84c-7239c54c25b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35655545-172.17.0.20-1595335131552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45741,DS-ca9b45a8-f7a4-4e68-8118-32bc9872a2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-60678c15-2020-4916-8a1c-423ab719d9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-8c98aa49-6b13-48ad-a3f6-feff0df1ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-294fbe73-fc5b-40c2-8d97-119b91f560d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-ccb63406-4624-4d6f-8857-35702bc906b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-4386bbc8-d561-4ae2-a2fe-22bac8a88d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-3b5a716c-6209-4612-9007-511cb8cc88fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-d62c13f9-d5a6-4885-87c2-d44f9e026e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35655545-172.17.0.20-1595335131552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45741,DS-ca9b45a8-f7a4-4e68-8118-32bc9872a2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-60678c15-2020-4916-8a1c-423ab719d9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-8c98aa49-6b13-48ad-a3f6-feff0df1ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-294fbe73-fc5b-40c2-8d97-119b91f560d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-ccb63406-4624-4d6f-8857-35702bc906b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-4386bbc8-d561-4ae2-a2fe-22bac8a88d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-3b5a716c-6209-4612-9007-511cb8cc88fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-d62c13f9-d5a6-4885-87c2-d44f9e026e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699031749-172.17.0.20-1595335247775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-372a1a27-484e-4fb3-88d1-ad867b4e2b07,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-fea34dcb-402c-481e-a42a-ac17cec96c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8c3081fd-94b0-4341-8133-258d802864ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-53ba73f1-40df-4272-a27d-2d89b63b2b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-a360c5d6-82c6-4fc3-a24c-725939c2e88a,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-e2deec46-5c85-4951-ad64-34b7b45f8900,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-66911918-85d8-45e7-a217-da093d4e5091,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-32bd7e0f-3d41-47ed-bb3e-ecb20d0f076a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699031749-172.17.0.20-1595335247775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-372a1a27-484e-4fb3-88d1-ad867b4e2b07,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-fea34dcb-402c-481e-a42a-ac17cec96c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8c3081fd-94b0-4341-8133-258d802864ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-53ba73f1-40df-4272-a27d-2d89b63b2b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-a360c5d6-82c6-4fc3-a24c-725939c2e88a,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-e2deec46-5c85-4951-ad64-34b7b45f8900,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-66911918-85d8-45e7-a217-da093d4e5091,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-32bd7e0f-3d41-47ed-bb3e-ecb20d0f076a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168192053-172.17.0.20-1595335866173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-381f0ad1-0d65-42e4-8d22-f9ab011aa067,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-95dbfcc1-f55a-42ac-b1a6-7b7f2ad6eeed,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-ea53f77a-30a3-44b8-bfb9-7308fabada25,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-7ca1b92c-0022-4bd4-b654-2c29a99581b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-6212e703-f24c-4ccc-b7c9-2b05b50ee074,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-5c9e6837-087b-4ba3-bbdf-849b96f92dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-53e0cc3e-ab51-47e3-8ebb-3fab9c95a2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-f1d5f7b1-46ab-442a-b7cf-07a091f56649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168192053-172.17.0.20-1595335866173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-381f0ad1-0d65-42e4-8d22-f9ab011aa067,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-95dbfcc1-f55a-42ac-b1a6-7b7f2ad6eeed,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-ea53f77a-30a3-44b8-bfb9-7308fabada25,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-7ca1b92c-0022-4bd4-b654-2c29a99581b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-6212e703-f24c-4ccc-b7c9-2b05b50ee074,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-5c9e6837-087b-4ba3-bbdf-849b96f92dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-53e0cc3e-ab51-47e3-8ebb-3fab9c95a2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-f1d5f7b1-46ab-442a-b7cf-07a091f56649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889123834-172.17.0.20-1595336210088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37231,DS-db9f1752-d260-44bb-a00c-6da8ae2b8245,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-baae3162-2cf8-4c66-b6dc-b214549592bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-78981f87-376a-4b06-8bbf-effde5b0989c,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-c511ed40-fa26-4df0-9d6d-bdfcdf3d735e,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-c7259735-a3ad-4584-ab19-1ec84291b4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-72344a0c-2c08-4676-a74d-5600bea2cae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-aa3a6b76-913a-474d-866b-1f75655043d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-c7be6ac6-0909-4b3b-aeb7-fe5f823b730e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889123834-172.17.0.20-1595336210088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37231,DS-db9f1752-d260-44bb-a00c-6da8ae2b8245,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-baae3162-2cf8-4c66-b6dc-b214549592bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-78981f87-376a-4b06-8bbf-effde5b0989c,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-c511ed40-fa26-4df0-9d6d-bdfcdf3d735e,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-c7259735-a3ad-4584-ab19-1ec84291b4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-72344a0c-2c08-4676-a74d-5600bea2cae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-aa3a6b76-913a-474d-866b-1f75655043d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-c7be6ac6-0909-4b3b-aeb7-fe5f823b730e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29894104-172.17.0.20-1595336248201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38576,DS-dd498af9-a380-460d-9c5f-797fbf042349,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-b4e33644-df4e-4094-b91b-31c5a441a650,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-884d9a11-419f-4797-a2c4-74290d8aa6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-12221833-1ba2-47a5-8872-3e2dfa058c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-60e64949-0ebe-478d-a3e9-1619f6dde697,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-f24d73ef-c5f3-411b-94ed-65412b664238,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-729a7e68-4564-406d-befb-9fcad8dfcaad,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-032e042d-72ce-4924-81ae-644126f977ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29894104-172.17.0.20-1595336248201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38576,DS-dd498af9-a380-460d-9c5f-797fbf042349,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-b4e33644-df4e-4094-b91b-31c5a441a650,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-884d9a11-419f-4797-a2c4-74290d8aa6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-12221833-1ba2-47a5-8872-3e2dfa058c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-60e64949-0ebe-478d-a3e9-1619f6dde697,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-f24d73ef-c5f3-411b-94ed-65412b664238,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-729a7e68-4564-406d-befb-9fcad8dfcaad,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-032e042d-72ce-4924-81ae-644126f977ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234294413-172.17.0.20-1595336320948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-8838fc12-e74e-4525-8307-f2359debbd49,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-28d73290-b782-45a5-be84-d7379075a413,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-f278ac19-d144-4842-a794-b6d1c90590bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-8dde8c14-aca4-4c94-95a9-212e21be576b,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-fc9f20a7-b8a4-4df6-a2e9-bef03c379f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-2b7077a0-46e6-4935-93d5-9fd8d684cd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-2e801895-cba0-4a0c-aaf2-624c794e28a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-9a57c4ba-79fe-4591-ad75-c284ff7ef3b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234294413-172.17.0.20-1595336320948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-8838fc12-e74e-4525-8307-f2359debbd49,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-28d73290-b782-45a5-be84-d7379075a413,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-f278ac19-d144-4842-a794-b6d1c90590bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-8dde8c14-aca4-4c94-95a9-212e21be576b,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-fc9f20a7-b8a4-4df6-a2e9-bef03c379f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-2b7077a0-46e6-4935-93d5-9fd8d684cd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-2e801895-cba0-4a0c-aaf2-624c794e28a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-9a57c4ba-79fe-4591-ad75-c284ff7ef3b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5511
