reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177521121-172.17.0.2-1595296767990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41844,DS-dfd31eeb-0c2f-402d-a6c9-bca2e89458e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-48965da9-f222-476b-952f-4b36b793664e,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-8852daa5-748c-431c-bc51-18f0624fe138,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-0101d791-4819-4042-8fd7-2e0132c8dd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-2aa3545f-2d79-4679-892c-b81278730351,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-6e1d1677-576e-4ab3-97ef-e615aca00599,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-4e9703a3-f589-4b8b-98e2-875da116cbda,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-df9b5ebf-11f6-4b52-8631-81b52da1365a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177521121-172.17.0.2-1595296767990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41844,DS-dfd31eeb-0c2f-402d-a6c9-bca2e89458e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-48965da9-f222-476b-952f-4b36b793664e,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-8852daa5-748c-431c-bc51-18f0624fe138,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-0101d791-4819-4042-8fd7-2e0132c8dd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-2aa3545f-2d79-4679-892c-b81278730351,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-6e1d1677-576e-4ab3-97ef-e615aca00599,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-4e9703a3-f589-4b8b-98e2-875da116cbda,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-df9b5ebf-11f6-4b52-8631-81b52da1365a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303261014-172.17.0.2-1595296873392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46615,DS-606d0961-5c6f-4650-8ac8-388770c80ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-f9028c0b-837d-491b-8e4c-6a55d7e338d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-7b7ec9be-dc46-481f-be91-ac4132a1c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-041a114a-83c2-402e-b410-877d130abec3,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-f4f5485a-c963-4491-87f6-32147fc227e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-33387f7a-346c-4b9d-8a2a-20db6a0fba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-a1c8b04c-0362-4a67-9c3a-8862e27fae09,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-23b75bfe-0ea1-471f-a9a3-f134f22071c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303261014-172.17.0.2-1595296873392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46615,DS-606d0961-5c6f-4650-8ac8-388770c80ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-f9028c0b-837d-491b-8e4c-6a55d7e338d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-7b7ec9be-dc46-481f-be91-ac4132a1c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-041a114a-83c2-402e-b410-877d130abec3,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-f4f5485a-c963-4491-87f6-32147fc227e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-33387f7a-346c-4b9d-8a2a-20db6a0fba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-a1c8b04c-0362-4a67-9c3a-8862e27fae09,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-23b75bfe-0ea1-471f-a9a3-f134f22071c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487325271-172.17.0.2-1595297051059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40244,DS-14dc57ed-92dc-4ab6-ba1a-25b002e78a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-f492836e-8870-4372-9666-c24326076881,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-99c5148d-e3ee-4c18-9348-b2e11c7529a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-7ecf7ac3-da69-4805-a1b9-ff42b10d923b,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-5fe24736-6b41-4bed-9227-ecf9f98e63d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-1826d403-b813-4547-8ecf-f60e6de89555,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-8f40d979-e9f6-45dc-9d5f-a3a8752db4be,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-29731b05-c78f-4293-88ae-76d03d5069ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487325271-172.17.0.2-1595297051059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40244,DS-14dc57ed-92dc-4ab6-ba1a-25b002e78a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-f492836e-8870-4372-9666-c24326076881,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-99c5148d-e3ee-4c18-9348-b2e11c7529a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-7ecf7ac3-da69-4805-a1b9-ff42b10d923b,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-5fe24736-6b41-4bed-9227-ecf9f98e63d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-1826d403-b813-4547-8ecf-f60e6de89555,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-8f40d979-e9f6-45dc-9d5f-a3a8752db4be,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-29731b05-c78f-4293-88ae-76d03d5069ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19810333-172.17.0.2-1595297123574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-90c8288f-ad3f-4bf7-b9da-8f30b191e5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-cbf6a2ac-b26c-4046-8eaf-571655a1ec59,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-81ab8159-f55e-4e10-b8a6-205b6ac67edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-a7896a68-1266-4d10-b1e1-47095e9bded9,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-b5d34a12-b0d8-42b1-8557-9dc28edd2677,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-e7495e51-f5f5-4455-a63e-3f7266491bef,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-ecfd941b-6b97-48ad-972f-a1197967e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-3b4ea14d-57fa-41d4-832e-a46860a39364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19810333-172.17.0.2-1595297123574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-90c8288f-ad3f-4bf7-b9da-8f30b191e5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-cbf6a2ac-b26c-4046-8eaf-571655a1ec59,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-81ab8159-f55e-4e10-b8a6-205b6ac67edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-a7896a68-1266-4d10-b1e1-47095e9bded9,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-b5d34a12-b0d8-42b1-8557-9dc28edd2677,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-e7495e51-f5f5-4455-a63e-3f7266491bef,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-ecfd941b-6b97-48ad-972f-a1197967e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-3b4ea14d-57fa-41d4-832e-a46860a39364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464729722-172.17.0.2-1595297529127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-83e1c0c8-da19-47e8-a06d-42fd54be2b06,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-019d6999-3af1-4b07-9a46-fe2b1962a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-0c23b6d8-c73a-478f-8215-e73af55dc8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c45451c6-5d89-4d99-a663-5bfc3c18fd01,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-3eb58272-23c3-401d-846d-d58cbaa5b61a,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-572e3a6b-6f84-4df6-8ba0-8327ea2fb164,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-6d4795f2-b8d3-4bb6-8fec-a1fcf05e9048,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-de100bf8-ac1d-4279-8ef4-3359c6ae50fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464729722-172.17.0.2-1595297529127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-83e1c0c8-da19-47e8-a06d-42fd54be2b06,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-019d6999-3af1-4b07-9a46-fe2b1962a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-0c23b6d8-c73a-478f-8215-e73af55dc8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c45451c6-5d89-4d99-a663-5bfc3c18fd01,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-3eb58272-23c3-401d-846d-d58cbaa5b61a,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-572e3a6b-6f84-4df6-8ba0-8327ea2fb164,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-6d4795f2-b8d3-4bb6-8fec-a1fcf05e9048,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-de100bf8-ac1d-4279-8ef4-3359c6ae50fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53105539-172.17.0.2-1595297625456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39970,DS-3f748aee-3820-4754-91f6-cf521bb8b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-b6571d80-9bdd-400e-ae0a-151ca3f58d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-5e547791-9114-4fbc-9125-494b7c85f001,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-61ac4d6b-fcd9-4ef0-936f-0b3f27d7c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-a6a5e7f1-5c74-40d5-8a4a-e70220cd788c,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-ad3c2c9c-a9c8-4076-b7b6-8248cba55f09,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-02333de1-6865-43d2-8adf-5c7cc47f84a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-1c922daf-64c7-4894-8db0-ad6609be4d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53105539-172.17.0.2-1595297625456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39970,DS-3f748aee-3820-4754-91f6-cf521bb8b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-b6571d80-9bdd-400e-ae0a-151ca3f58d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-5e547791-9114-4fbc-9125-494b7c85f001,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-61ac4d6b-fcd9-4ef0-936f-0b3f27d7c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-a6a5e7f1-5c74-40d5-8a4a-e70220cd788c,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-ad3c2c9c-a9c8-4076-b7b6-8248cba55f09,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-02333de1-6865-43d2-8adf-5c7cc47f84a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-1c922daf-64c7-4894-8db0-ad6609be4d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574980004-172.17.0.2-1595297771278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35331,DS-7aca7444-85cd-474e-b72e-f819290413bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-371aea4f-4f2c-4963-9b09-ecef6fb336a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-90f65409-979d-4299-93a8-37d4fae91bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-91b415d3-bc2a-4162-9809-cae8e6ab0998,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-204e0a02-0c2e-40b0-a759-1eb265b5af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-50637bd6-792b-44ed-b095-fcb8f63468c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-43e89080-3156-48e8-b27c-1c23538669ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-1c61aed7-2742-4e3a-acda-a2b2ab649027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574980004-172.17.0.2-1595297771278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35331,DS-7aca7444-85cd-474e-b72e-f819290413bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-371aea4f-4f2c-4963-9b09-ecef6fb336a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-90f65409-979d-4299-93a8-37d4fae91bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-91b415d3-bc2a-4162-9809-cae8e6ab0998,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-204e0a02-0c2e-40b0-a759-1eb265b5af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-50637bd6-792b-44ed-b095-fcb8f63468c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-43e89080-3156-48e8-b27c-1c23538669ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-1c61aed7-2742-4e3a-acda-a2b2ab649027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400914824-172.17.0.2-1595298737771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43947,DS-0a443ee3-b455-4901-89e1-2c8c2153c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-eda76731-5e79-419d-b140-6caadb9eb96e,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-21a01437-86a5-4cdd-92ca-d4bb9b9c793a,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-944a1242-a9ad-4eee-9989-d8907c3989ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-58cb1c3b-0238-47b7-bd1d-dd7bac71c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-59fc9800-58a6-4cb7-8200-c6d12f065f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-ebc41e00-6b32-49e3-a5ef-48dcdac34025,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-ded72554-2d78-49cd-b83f-c6c0540f9791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400914824-172.17.0.2-1595298737771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43947,DS-0a443ee3-b455-4901-89e1-2c8c2153c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-eda76731-5e79-419d-b140-6caadb9eb96e,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-21a01437-86a5-4cdd-92ca-d4bb9b9c793a,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-944a1242-a9ad-4eee-9989-d8907c3989ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-58cb1c3b-0238-47b7-bd1d-dd7bac71c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-59fc9800-58a6-4cb7-8200-c6d12f065f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-ebc41e00-6b32-49e3-a5ef-48dcdac34025,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-ded72554-2d78-49cd-b83f-c6c0540f9791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010546023-172.17.0.2-1595299535554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43011,DS-af10c2dc-0472-4c1d-889b-40635ef66d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-e380f123-cff9-4533-8440-e2ece67587ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-6e72b3bd-ef3e-4875-80e4-690ae9752d18,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-12177cdd-78e7-463f-9110-88bb67c41d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-ff6cc5a5-7980-46ca-8ee0-c06f5bbe723f,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-daed617b-a292-4d57-9786-8e81b13dd501,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-d667a623-f514-477f-81e6-03093bf6e20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-cb4f9a04-4a3f-4ddb-ad47-a30bb8183cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010546023-172.17.0.2-1595299535554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43011,DS-af10c2dc-0472-4c1d-889b-40635ef66d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-e380f123-cff9-4533-8440-e2ece67587ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-6e72b3bd-ef3e-4875-80e4-690ae9752d18,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-12177cdd-78e7-463f-9110-88bb67c41d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-ff6cc5a5-7980-46ca-8ee0-c06f5bbe723f,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-daed617b-a292-4d57-9786-8e81b13dd501,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-d667a623-f514-477f-81e6-03093bf6e20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-cb4f9a04-4a3f-4ddb-ad47-a30bb8183cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182992368-172.17.0.2-1595300034542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-7c4e27ba-3dec-4a7e-bb2b-68f1631a9592,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-57d2de6d-37db-448b-abef-7e72a597f686,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-a6fbf4d5-82ba-435b-98fe-f7a222334c91,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-501a4ab9-dfff-4d82-9135-1a5f10b8a2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-0827ee89-8054-43f2-93dd-66adbf375136,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-848f7b02-1ccc-4304-be87-a85a61e3cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-349404a6-6b20-412c-b148-6f4845f25ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-1b4b232f-3660-4e47-85d9-0c12ce1621b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182992368-172.17.0.2-1595300034542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-7c4e27ba-3dec-4a7e-bb2b-68f1631a9592,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-57d2de6d-37db-448b-abef-7e72a597f686,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-a6fbf4d5-82ba-435b-98fe-f7a222334c91,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-501a4ab9-dfff-4d82-9135-1a5f10b8a2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-0827ee89-8054-43f2-93dd-66adbf375136,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-848f7b02-1ccc-4304-be87-a85a61e3cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-349404a6-6b20-412c-b148-6f4845f25ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-1b4b232f-3660-4e47-85d9-0c12ce1621b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297679533-172.17.0.2-1595301377670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-f8857801-24ec-49ec-be39-a8b579d471aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-aa82eed3-db21-43f7-aeee-ae9f1020a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-d9e01d7a-300b-4373-aca4-97dc8983c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-42bafee3-6fd2-4d31-a43c-5b804de55808,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-bf66d3e4-b6e4-4b7f-93b9-b8f0b051c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-b1378e80-91cf-4f7a-a58d-65d21b7e93a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-e7aef61a-8256-4383-96cd-1c5a4663852b,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-a685d31d-329b-4e1f-b6d5-4572fbddb412,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297679533-172.17.0.2-1595301377670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-f8857801-24ec-49ec-be39-a8b579d471aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-aa82eed3-db21-43f7-aeee-ae9f1020a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-d9e01d7a-300b-4373-aca4-97dc8983c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-42bafee3-6fd2-4d31-a43c-5b804de55808,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-bf66d3e4-b6e4-4b7f-93b9-b8f0b051c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-b1378e80-91cf-4f7a-a58d-65d21b7e93a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-e7aef61a-8256-4383-96cd-1c5a4663852b,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-a685d31d-329b-4e1f-b6d5-4572fbddb412,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045215125-172.17.0.2-1595301685981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39063,DS-0ec00940-43b7-4f9f-9dbc-89c34d2a8b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-0a3c0cd5-fe3b-48ff-b46e-1ee615a243d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-46b4d6cc-fa3a-489e-afef-60253d9a172f,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-a13539b5-0de0-44f4-a170-a53ef4704870,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-7611a52f-14e0-4fda-b324-3a35f0e724b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-225b9543-0123-4d4a-b644-8a75a20e53c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-e90a1205-227d-41ee-9a7d-f87ba29590b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-c7979a6a-c3d7-45aa-920b-868360cb271e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045215125-172.17.0.2-1595301685981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39063,DS-0ec00940-43b7-4f9f-9dbc-89c34d2a8b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-0a3c0cd5-fe3b-48ff-b46e-1ee615a243d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-46b4d6cc-fa3a-489e-afef-60253d9a172f,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-a13539b5-0de0-44f4-a170-a53ef4704870,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-7611a52f-14e0-4fda-b324-3a35f0e724b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-225b9543-0123-4d4a-b644-8a75a20e53c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-e90a1205-227d-41ee-9a7d-f87ba29590b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-c7979a6a-c3d7-45aa-920b-868360cb271e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5265
