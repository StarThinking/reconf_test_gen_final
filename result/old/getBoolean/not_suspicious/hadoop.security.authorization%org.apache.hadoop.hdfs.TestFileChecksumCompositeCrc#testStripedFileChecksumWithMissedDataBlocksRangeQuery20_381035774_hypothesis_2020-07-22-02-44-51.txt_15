reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527776244-172.17.0.19-1595386638460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-fe2a454c-4129-4c16-a293-349e55257557,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-14381725-2337-49e2-b8f6-73bae0c9b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-98167da4-361a-47cd-8497-b63e553031ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-e24d71af-274b-4455-a383-d86dfba2a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-63d0acb1-d547-482c-b6ea-331617e0155f,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-4ee28177-b4c6-4c16-840b-87c3e8f26109,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-afc67efa-3518-4f4e-a2f0-8d2a5182b1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-f4c3e87b-176c-440d-a875-796d369f3484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527776244-172.17.0.19-1595386638460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-fe2a454c-4129-4c16-a293-349e55257557,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-14381725-2337-49e2-b8f6-73bae0c9b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-98167da4-361a-47cd-8497-b63e553031ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-e24d71af-274b-4455-a383-d86dfba2a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-63d0acb1-d547-482c-b6ea-331617e0155f,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-4ee28177-b4c6-4c16-840b-87c3e8f26109,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-afc67efa-3518-4f4e-a2f0-8d2a5182b1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-f4c3e87b-176c-440d-a875-796d369f3484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618387551-172.17.0.19-1595386894190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-0b8b06f3-c7b4-43cb-a9ac-fb4eb254e148,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-58945253-554e-49fa-9313-140c7065aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-79c74f2a-1d24-40b0-9cb6-01001369602a,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-bd72fd7e-a2fa-4f31-8971-b5e441598618,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-43c96d21-e40c-44b1-831f-930427c64093,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-083af8b0-b6cd-4a11-b83d-034eb164031f,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-a6d1d31e-ffb3-4797-b1b1-058d380b47e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-9dd6c485-8b2b-47cb-9742-07aef9dfe487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618387551-172.17.0.19-1595386894190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-0b8b06f3-c7b4-43cb-a9ac-fb4eb254e148,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-58945253-554e-49fa-9313-140c7065aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-79c74f2a-1d24-40b0-9cb6-01001369602a,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-bd72fd7e-a2fa-4f31-8971-b5e441598618,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-43c96d21-e40c-44b1-831f-930427c64093,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-083af8b0-b6cd-4a11-b83d-034eb164031f,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-a6d1d31e-ffb3-4797-b1b1-058d380b47e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-9dd6c485-8b2b-47cb-9742-07aef9dfe487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428928200-172.17.0.19-1595387342063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46215,DS-6a7b309d-3bba-48f3-8d98-e122eb432c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-bac7e668-a1ca-4e22-a3c3-a3df97533e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-fa179333-9d34-4862-a662-003454e4c520,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-1d94867c-5dd4-4e36-946f-fff275379c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-1c6011cf-e18a-4e51-a392-f827cd439685,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-b448663e-722b-448d-86a3-84981d81d72a,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-0b073713-d87e-44c9-8b60-453c62f9da63,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-22a624c3-bcee-4a03-ab33-32e5a7ee27a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428928200-172.17.0.19-1595387342063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46215,DS-6a7b309d-3bba-48f3-8d98-e122eb432c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-bac7e668-a1ca-4e22-a3c3-a3df97533e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-fa179333-9d34-4862-a662-003454e4c520,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-1d94867c-5dd4-4e36-946f-fff275379c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-1c6011cf-e18a-4e51-a392-f827cd439685,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-b448663e-722b-448d-86a3-84981d81d72a,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-0b073713-d87e-44c9-8b60-453c62f9da63,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-22a624c3-bcee-4a03-ab33-32e5a7ee27a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168841453-172.17.0.19-1595387375352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39842,DS-9065bcf7-3175-4d86-8825-25da1398d107,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-2aba91cb-df19-4dbf-a65d-63c6aff2759d,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-81beb18c-a8dc-4449-a672-806fddd9afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a5cc1218-5c3c-4bb8-946d-a1917a2ca2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-d986d64d-bc4f-4859-b9f6-84dba1c3efc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-eba659bd-fd84-40dc-ad09-9fb68d839e95,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-87cc94ef-9936-42b5-b897-ab900625c612,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-32c43782-e16e-46c8-93d7-af6e86965c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168841453-172.17.0.19-1595387375352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39842,DS-9065bcf7-3175-4d86-8825-25da1398d107,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-2aba91cb-df19-4dbf-a65d-63c6aff2759d,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-81beb18c-a8dc-4449-a672-806fddd9afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a5cc1218-5c3c-4bb8-946d-a1917a2ca2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-d986d64d-bc4f-4859-b9f6-84dba1c3efc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-eba659bd-fd84-40dc-ad09-9fb68d839e95,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-87cc94ef-9936-42b5-b897-ab900625c612,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-32c43782-e16e-46c8-93d7-af6e86965c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151476163-172.17.0.19-1595388208358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42678,DS-3c424bd8-37d3-4bb7-b119-1e3ea15e69ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-96a88b49-dc07-47e6-a284-6543412cd684,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-39936dff-7c28-4e50-bfd4-ade7b099fe23,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-077535e1-159d-4cae-8be8-41fa51a3f001,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-2d9ccfee-ac50-4b5c-be65-9a117bd16b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-a54f3a09-af28-44cd-b327-2c2892b4cbab,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-9d81b231-4d04-4b9e-9ffb-681864cc4174,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-2348b8a0-6861-4f24-bc68-782615eb8475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151476163-172.17.0.19-1595388208358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42678,DS-3c424bd8-37d3-4bb7-b119-1e3ea15e69ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-96a88b49-dc07-47e6-a284-6543412cd684,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-39936dff-7c28-4e50-bfd4-ade7b099fe23,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-077535e1-159d-4cae-8be8-41fa51a3f001,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-2d9ccfee-ac50-4b5c-be65-9a117bd16b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-a54f3a09-af28-44cd-b327-2c2892b4cbab,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-9d81b231-4d04-4b9e-9ffb-681864cc4174,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-2348b8a0-6861-4f24-bc68-782615eb8475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480657570-172.17.0.19-1595388482522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-1eb9cf53-90f2-41d0-a961-2b73b67da948,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-3756c640-7fe8-4afd-9db6-f30f0c2a1b40,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-693527b1-73d4-4de0-a617-784ea4cfcd22,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-12c6c72f-a12d-44eb-aa82-553af75c966e,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-c3a2873f-2f88-474d-bb39-01a7c7f1438f,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-83d52710-e53e-4cf3-bcbd-62aef8b0fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-5af4e679-5753-40d7-a42a-e8f5808f6172,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-e1971ac6-dfe7-49fc-9a70-6ff6d40caf5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480657570-172.17.0.19-1595388482522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-1eb9cf53-90f2-41d0-a961-2b73b67da948,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-3756c640-7fe8-4afd-9db6-f30f0c2a1b40,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-693527b1-73d4-4de0-a617-784ea4cfcd22,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-12c6c72f-a12d-44eb-aa82-553af75c966e,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-c3a2873f-2f88-474d-bb39-01a7c7f1438f,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-83d52710-e53e-4cf3-bcbd-62aef8b0fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-5af4e679-5753-40d7-a42a-e8f5808f6172,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-e1971ac6-dfe7-49fc-9a70-6ff6d40caf5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285006336-172.17.0.19-1595388590323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42289,DS-df1b759e-981d-41b1-a00d-4d3adfa1bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-4a75933f-afb3-4acc-9d12-47b1aca56211,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-219a0a4c-bbd3-4b7c-bad2-cf9bf4fea85b,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-493e5fd2-0c50-4c83-b1c6-f9884286b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-c52ec236-904d-4f8e-bdec-581cc81a6b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-d29e1866-2e02-48f4-adac-77ed9e36976f,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-c26762e9-bded-4f20-a28e-28cde64885ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-70a89548-796c-4b66-b6b4-b02bceee3d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285006336-172.17.0.19-1595388590323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42289,DS-df1b759e-981d-41b1-a00d-4d3adfa1bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-4a75933f-afb3-4acc-9d12-47b1aca56211,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-219a0a4c-bbd3-4b7c-bad2-cf9bf4fea85b,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-493e5fd2-0c50-4c83-b1c6-f9884286b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-c52ec236-904d-4f8e-bdec-581cc81a6b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-d29e1866-2e02-48f4-adac-77ed9e36976f,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-c26762e9-bded-4f20-a28e-28cde64885ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-70a89548-796c-4b66-b6b4-b02bceee3d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701935057-172.17.0.19-1595388687692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41073,DS-5285f083-b6a8-465b-8d9f-0f95b33f7ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-ff3ad57e-3af4-4a8d-9f7e-baad7b50b0de,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-081a4d5c-b672-4916-82af-5c095ca2bcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-edddd7f3-172e-421c-bb1c-3a0e4eb79af2,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-a79b2e74-31aa-48a6-a248-ff1e32b7f3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-1840ebea-8900-48a2-b2f1-a4101e334596,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-3fbcf994-b0a9-4270-b01e-60f8b41b86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-b105bafb-55bf-4bbd-815f-d52c0f78e20b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701935057-172.17.0.19-1595388687692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41073,DS-5285f083-b6a8-465b-8d9f-0f95b33f7ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-ff3ad57e-3af4-4a8d-9f7e-baad7b50b0de,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-081a4d5c-b672-4916-82af-5c095ca2bcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-edddd7f3-172e-421c-bb1c-3a0e4eb79af2,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-a79b2e74-31aa-48a6-a248-ff1e32b7f3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-1840ebea-8900-48a2-b2f1-a4101e334596,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-3fbcf994-b0a9-4270-b01e-60f8b41b86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-b105bafb-55bf-4bbd-815f-d52c0f78e20b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638130177-172.17.0.19-1595388938062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-2da0a1e9-6af6-4c7b-9586-5787c0d7d963,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-5f9c97d0-47de-41fd-84ad-81f9715b5658,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-8f25d76d-fd63-4108-a804-0c25a860967a,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-bd02db0a-4031-47c6-8343-f1f6889d73aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-3bdcf91a-4281-426f-b8e3-10c9376dbfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-0f9f0231-05e0-4db8-acc1-7093289185bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-e9047aac-6894-4c6c-b18e-9d290363bf31,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-417b613a-92d7-467c-861e-22c7987f6836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638130177-172.17.0.19-1595388938062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-2da0a1e9-6af6-4c7b-9586-5787c0d7d963,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-5f9c97d0-47de-41fd-84ad-81f9715b5658,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-8f25d76d-fd63-4108-a804-0c25a860967a,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-bd02db0a-4031-47c6-8343-f1f6889d73aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-3bdcf91a-4281-426f-b8e3-10c9376dbfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-0f9f0231-05e0-4db8-acc1-7093289185bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-e9047aac-6894-4c6c-b18e-9d290363bf31,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-417b613a-92d7-467c-861e-22c7987f6836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571200001-172.17.0.19-1595389016327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46270,DS-0e0ec147-65c3-466d-bb9a-9569f7bbc3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-dba52e7c-2caa-4f98-917b-a37e939f3e37,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-b101ff5c-c3d7-4192-baf6-ccc08f6e8719,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-01d032e1-7a63-43ed-9dba-167543daa312,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-3313fcc2-def3-46d0-822d-a597174c70b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-7cc9420f-e0fb-45fc-b3a5-afcb98f355cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-5a0522a2-7a7e-4c33-bc3c-82863224e179,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-84fcc727-2e74-493a-a657-f35ce8083969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571200001-172.17.0.19-1595389016327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46270,DS-0e0ec147-65c3-466d-bb9a-9569f7bbc3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-dba52e7c-2caa-4f98-917b-a37e939f3e37,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-b101ff5c-c3d7-4192-baf6-ccc08f6e8719,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-01d032e1-7a63-43ed-9dba-167543daa312,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-3313fcc2-def3-46d0-822d-a597174c70b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-7cc9420f-e0fb-45fc-b3a5-afcb98f355cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-5a0522a2-7a7e-4c33-bc3c-82863224e179,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-84fcc727-2e74-493a-a657-f35ce8083969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108695960-172.17.0.19-1595389045814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35628,DS-dd920cf5-478b-4240-83a8-d2c6d1342182,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-fe3f9963-e429-400e-a029-3a7e4d94410a,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-3eef95e4-738f-433f-9884-7e99831e9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-dba9202b-ccd5-4af7-97d6-dc6f7da38f24,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-9463cead-9d35-4fd5-9e8a-bebd38c37911,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-29f63c89-880c-48c5-aeba-8421012158bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-c5ab77e9-b4f8-47ff-a45d-5040b2f3d1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-bb2b0b1b-5669-410f-83e2-99c6e05f1a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108695960-172.17.0.19-1595389045814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35628,DS-dd920cf5-478b-4240-83a8-d2c6d1342182,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-fe3f9963-e429-400e-a029-3a7e4d94410a,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-3eef95e4-738f-433f-9884-7e99831e9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-dba9202b-ccd5-4af7-97d6-dc6f7da38f24,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-9463cead-9d35-4fd5-9e8a-bebd38c37911,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-29f63c89-880c-48c5-aeba-8421012158bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-c5ab77e9-b4f8-47ff-a45d-5040b2f3d1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-bb2b0b1b-5669-410f-83e2-99c6e05f1a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077027552-172.17.0.19-1595390067038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37701,DS-ae12a02d-3e6a-47cd-b43b-172e42f8c5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-b872c024-14ff-4075-adeb-e623df023e78,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-a9d739ea-6df2-434b-aa1c-03fc19511269,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-f3e77f6e-43db-4766-9645-0dc4380e0437,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-1cd3764e-15d8-40fe-9517-3b0539f15aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-1af80233-4a3a-4606-bb07-9bdd7af91044,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-6864bbb8-93f7-4f9a-aed2-d76f50153939,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-d57d5e98-33a1-4a3b-841b-4b498f2460b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077027552-172.17.0.19-1595390067038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37701,DS-ae12a02d-3e6a-47cd-b43b-172e42f8c5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-b872c024-14ff-4075-adeb-e623df023e78,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-a9d739ea-6df2-434b-aa1c-03fc19511269,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-f3e77f6e-43db-4766-9645-0dc4380e0437,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-1cd3764e-15d8-40fe-9517-3b0539f15aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-1af80233-4a3a-4606-bb07-9bdd7af91044,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-6864bbb8-93f7-4f9a-aed2-d76f50153939,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-d57d5e98-33a1-4a3b-841b-4b498f2460b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41235549-172.17.0.19-1595390357485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39541,DS-ed29bc32-7dab-4985-b74a-148e8190ca17,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-aca6ed23-f1ff-4e7a-b960-3342d7d8af5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-76af3a91-35d5-42ec-bba5-df60468b9936,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-c79e58a3-b340-470a-8863-3e01d2791d16,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-76af82de-b684-4c56-9ba2-22cfc9bf1092,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-28ad4662-2e63-450e-93f2-e6347a9cb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-91745acc-c218-4184-8b74-3ba73a7bdc21,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-b2850bec-8893-448f-bd14-2bc11d971828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41235549-172.17.0.19-1595390357485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39541,DS-ed29bc32-7dab-4985-b74a-148e8190ca17,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-aca6ed23-f1ff-4e7a-b960-3342d7d8af5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-76af3a91-35d5-42ec-bba5-df60468b9936,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-c79e58a3-b340-470a-8863-3e01d2791d16,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-76af82de-b684-4c56-9ba2-22cfc9bf1092,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-28ad4662-2e63-450e-93f2-e6347a9cb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-91745acc-c218-4184-8b74-3ba73a7bdc21,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-b2850bec-8893-448f-bd14-2bc11d971828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846805507-172.17.0.19-1595390649049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41287,DS-f53c7d59-378a-4dac-8519-826a22acc7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-a1035877-da05-44cf-9200-33f0dc260881,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-cada54d4-f2a3-4614-85fe-b91e1b60b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-b3768ce7-33ff-4a7d-967a-54b11a7bafd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-31eb9473-6b45-4c71-aeed-498d7d25d27a,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-6e60bac9-fc77-49ba-b473-e3b006610c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-d649091a-a54e-4cdc-b595-b00052faa042,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-5f3ffc8d-f047-4a06-bffb-82a79809ab7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846805507-172.17.0.19-1595390649049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41287,DS-f53c7d59-378a-4dac-8519-826a22acc7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-a1035877-da05-44cf-9200-33f0dc260881,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-cada54d4-f2a3-4614-85fe-b91e1b60b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-b3768ce7-33ff-4a7d-967a-54b11a7bafd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-31eb9473-6b45-4c71-aeed-498d7d25d27a,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-6e60bac9-fc77-49ba-b473-e3b006610c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-d649091a-a54e-4cdc-b595-b00052faa042,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-5f3ffc8d-f047-4a06-bffb-82a79809ab7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900178926-172.17.0.19-1595390850162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-99c84adf-c4f2-462a-8eb7-c707c3757355,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-0dd95a7b-2906-4bd0-9615-dc5b37f3f400,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-4041e7de-43e3-45f6-94af-9750fc4b4aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-8ce90059-f9e8-4148-a463-56f34b46a691,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-3dcbaeaa-9e14-4df4-9565-0fa4b4f7b74c,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-bfa4b733-ecec-4892-b3f8-2e4d0b3e2cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-81e6fa3b-c800-45e4-b754-4e6a4548c387,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-0ebb0589-3a88-4704-80d1-e1abe3995d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900178926-172.17.0.19-1595390850162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-99c84adf-c4f2-462a-8eb7-c707c3757355,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-0dd95a7b-2906-4bd0-9615-dc5b37f3f400,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-4041e7de-43e3-45f6-94af-9750fc4b4aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-8ce90059-f9e8-4148-a463-56f34b46a691,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-3dcbaeaa-9e14-4df4-9565-0fa4b4f7b74c,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-bfa4b733-ecec-4892-b3f8-2e4d0b3e2cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-81e6fa3b-c800-45e4-b754-4e6a4548c387,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-0ebb0589-3a88-4704-80d1-e1abe3995d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133424987-172.17.0.19-1595390885331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-de51eb8d-f0b4-4d83-8f98-aa79e4d4e3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-3a22df0c-dc62-4d55-b658-5b265b35f352,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-1d31ca15-39a5-4b88-b1e8-8dee3fe9e981,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-7b4229fc-ba3b-4d4c-be72-c0dd495ef6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-e19df97d-48bd-4839-9f9c-67fd470ceee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-896f8fdc-b408-4971-8d70-edc23e5fe404,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-f41f7adc-3bf4-42fb-a5f7-5bc5bb240eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-ef91a86f-b2dc-469f-9ce6-d0acabebb5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133424987-172.17.0.19-1595390885331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-de51eb8d-f0b4-4d83-8f98-aa79e4d4e3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-3a22df0c-dc62-4d55-b658-5b265b35f352,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-1d31ca15-39a5-4b88-b1e8-8dee3fe9e981,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-7b4229fc-ba3b-4d4c-be72-c0dd495ef6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-e19df97d-48bd-4839-9f9c-67fd470ceee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-896f8fdc-b408-4971-8d70-edc23e5fe404,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-f41f7adc-3bf4-42fb-a5f7-5bc5bb240eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-ef91a86f-b2dc-469f-9ce6-d0acabebb5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5204
