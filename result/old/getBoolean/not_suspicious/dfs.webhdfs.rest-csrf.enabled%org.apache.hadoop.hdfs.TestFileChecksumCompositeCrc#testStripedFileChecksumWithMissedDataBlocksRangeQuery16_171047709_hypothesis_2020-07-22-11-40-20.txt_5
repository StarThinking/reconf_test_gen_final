reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353771644-172.17.0.15-1595418066969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32790,DS-ef58f6d9-cce2-48fb-b4ec-d3d64d7fb636,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-50c9116d-333e-45e9-893d-843231e1bf73,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-38b0f60c-65d7-4452-a81c-e2627e6480c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-bef9ba10-9cbf-4062-8a88-fd80f41e3fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-2b03d8a5-9152-4b14-82a2-898d7421d243,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-293d8fe2-af82-4cef-a1e3-e916ceb94bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-fe353ae4-202d-428a-956c-3b8638ad6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-b24a2936-a1f0-40c3-a159-0a663408c816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353771644-172.17.0.15-1595418066969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32790,DS-ef58f6d9-cce2-48fb-b4ec-d3d64d7fb636,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-50c9116d-333e-45e9-893d-843231e1bf73,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-38b0f60c-65d7-4452-a81c-e2627e6480c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-bef9ba10-9cbf-4062-8a88-fd80f41e3fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-2b03d8a5-9152-4b14-82a2-898d7421d243,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-293d8fe2-af82-4cef-a1e3-e916ceb94bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-fe353ae4-202d-428a-956c-3b8638ad6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-b24a2936-a1f0-40c3-a159-0a663408c816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1576922486-172.17.0.15-1595418337548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-185f039d-16f5-4dd6-86f6-812f20cfafce,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-ed944748-0802-4856-8276-eb9a0bf529f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-b63fc9ff-95c9-4cdd-88c0-f80415844120,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-6c6a9b2f-ee0a-43dd-8dac-970bd2faf79a,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-0fdd1096-af84-4414-ad9a-8a973cec9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-9f0d675f-23b7-4b74-bb2e-2b53f3a442be,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-aa1844a1-7b28-4600-99c0-53350fd88ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-eca829b1-b484-4612-9ad3-c06e06751ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1576922486-172.17.0.15-1595418337548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-185f039d-16f5-4dd6-86f6-812f20cfafce,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-ed944748-0802-4856-8276-eb9a0bf529f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-b63fc9ff-95c9-4cdd-88c0-f80415844120,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-6c6a9b2f-ee0a-43dd-8dac-970bd2faf79a,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-0fdd1096-af84-4414-ad9a-8a973cec9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-9f0d675f-23b7-4b74-bb2e-2b53f3a442be,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-aa1844a1-7b28-4600-99c0-53350fd88ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-eca829b1-b484-4612-9ad3-c06e06751ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396195696-172.17.0.15-1595418527358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-eba2bb6d-ff60-4eeb-ba54-8522a08c8365,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-4b60bbe3-1d07-41ae-8102-7ec50dc49a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-32b7cea1-5c08-42f2-a21d-b1b6a16c39d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-e83ad034-71c0-47bc-abdd-fba4cb70c70e,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-87f599cd-ce35-420f-ae84-acc2e3d8bb57,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-7922288b-d657-46a9-8056-e30c7c0973ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-2655124b-6d3d-418a-adee-e3a03b9ce823,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-d22bf3e5-c993-483b-8ed8-574ab125950e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396195696-172.17.0.15-1595418527358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-eba2bb6d-ff60-4eeb-ba54-8522a08c8365,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-4b60bbe3-1d07-41ae-8102-7ec50dc49a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-32b7cea1-5c08-42f2-a21d-b1b6a16c39d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-e83ad034-71c0-47bc-abdd-fba4cb70c70e,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-87f599cd-ce35-420f-ae84-acc2e3d8bb57,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-7922288b-d657-46a9-8056-e30c7c0973ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-2655124b-6d3d-418a-adee-e3a03b9ce823,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-d22bf3e5-c993-483b-8ed8-574ab125950e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822621666-172.17.0.15-1595418675424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36054,DS-607cda41-d0f7-4154-a29b-b9135e93240f,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-3c9f3ed8-a37d-4f02-8684-273286d608f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-b6b644ee-e91b-42a7-a9c6-550b91d82fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-46a54d4c-79fe-4fcf-ba1a-31cd55b71355,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-c9dca292-2a7e-4f1a-af03-0169f55f9daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-d828f7c9-39ab-47a5-8f7c-ca26fd2515ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-14122da6-c1e0-4716-a511-6a6ed079c60c,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-a8f54e2d-1853-40ec-98c0-c128d283e5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822621666-172.17.0.15-1595418675424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36054,DS-607cda41-d0f7-4154-a29b-b9135e93240f,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-3c9f3ed8-a37d-4f02-8684-273286d608f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-b6b644ee-e91b-42a7-a9c6-550b91d82fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-46a54d4c-79fe-4fcf-ba1a-31cd55b71355,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-c9dca292-2a7e-4f1a-af03-0169f55f9daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-d828f7c9-39ab-47a5-8f7c-ca26fd2515ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-14122da6-c1e0-4716-a511-6a6ed079c60c,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-a8f54e2d-1853-40ec-98c0-c128d283e5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762314502-172.17.0.15-1595418906046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39340,DS-860499a7-0433-42c8-97d2-9505b5e35d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-85bbf2fd-9ed0-4852-8419-77e0f54be0be,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-0b60e8d3-867f-4266-b7bc-c52280ad67e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-bfaa206b-c53c-428a-a8d0-5fb9fa069d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-6d294aa0-cd3b-440e-9a8f-c970221a5dad,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-c54f13e1-b1e9-4202-b44b-3080f514afa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-4dbc2ab2-b678-412a-820a-f254d0923e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-482c6b35-5b89-4c17-afa6-2b7490780946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762314502-172.17.0.15-1595418906046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39340,DS-860499a7-0433-42c8-97d2-9505b5e35d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-85bbf2fd-9ed0-4852-8419-77e0f54be0be,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-0b60e8d3-867f-4266-b7bc-c52280ad67e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-bfaa206b-c53c-428a-a8d0-5fb9fa069d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-6d294aa0-cd3b-440e-9a8f-c970221a5dad,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-c54f13e1-b1e9-4202-b44b-3080f514afa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-4dbc2ab2-b678-412a-820a-f254d0923e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-482c6b35-5b89-4c17-afa6-2b7490780946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032811867-172.17.0.15-1595419009950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34380,DS-fd5a3d4b-7c7d-4aee-a392-3a9cdf13a47e,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-55bf1561-c2cb-4a0e-9ad6-53250c24bfee,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-93f7817f-681e-4c11-91f0-95d6f747e5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-69788427-48e2-41ca-8973-015379fc8aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-f26a6775-9c30-402e-929d-0fa22de8952d,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-7fcc894a-5d76-45d8-954b-9fe12b20b601,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-914c8117-6875-492c-aa66-dc0dad090246,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-9ead06a2-725f-4be0-a337-ff81b483504e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032811867-172.17.0.15-1595419009950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34380,DS-fd5a3d4b-7c7d-4aee-a392-3a9cdf13a47e,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-55bf1561-c2cb-4a0e-9ad6-53250c24bfee,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-93f7817f-681e-4c11-91f0-95d6f747e5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-69788427-48e2-41ca-8973-015379fc8aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-f26a6775-9c30-402e-929d-0fa22de8952d,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-7fcc894a-5d76-45d8-954b-9fe12b20b601,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-914c8117-6875-492c-aa66-dc0dad090246,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-9ead06a2-725f-4be0-a337-ff81b483504e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395189447-172.17.0.15-1595419807584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-af7934be-d135-469a-a9e6-7846c434b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-eeaa8895-5f92-4855-8a0d-7d7937b2a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-8be6db9f-4a94-41c4-bc21-02100604c36a,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-9de1f54f-94fe-4845-9afc-5e82f818eb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-8df33c1c-0ac4-4ceb-9855-9ef58ba312dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-59bd8492-962b-4d52-ac27-60b8eaefd27c,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-230ae6de-a503-4a0d-bf92-20f489db9531,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-77d0c22a-bde8-4305-8116-d7ea7ac239ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395189447-172.17.0.15-1595419807584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-af7934be-d135-469a-a9e6-7846c434b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-eeaa8895-5f92-4855-8a0d-7d7937b2a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-8be6db9f-4a94-41c4-bc21-02100604c36a,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-9de1f54f-94fe-4845-9afc-5e82f818eb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-8df33c1c-0ac4-4ceb-9855-9ef58ba312dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-59bd8492-962b-4d52-ac27-60b8eaefd27c,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-230ae6de-a503-4a0d-bf92-20f489db9531,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-77d0c22a-bde8-4305-8116-d7ea7ac239ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450125540-172.17.0.15-1595419950120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37093,DS-02c4d4ab-01f1-45a3-9c34-e11640fb24ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-467e171b-a954-414a-b13a-2191b064e00e,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-0a386f21-4daa-44b7-a0ff-5734c2428b73,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-981cf358-6d8f-4b14-ac45-39a4e8fe3030,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-00313844-3110-4d4b-890e-1c9654a240cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-af4dd1e0-498c-44c4-872c-a4a79d4bec68,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-9bdebc68-23ac-46ef-a202-4b50721b8b88,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-cf1f808c-cdaa-4d6d-97e6-c56d630f6b88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450125540-172.17.0.15-1595419950120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37093,DS-02c4d4ab-01f1-45a3-9c34-e11640fb24ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-467e171b-a954-414a-b13a-2191b064e00e,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-0a386f21-4daa-44b7-a0ff-5734c2428b73,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-981cf358-6d8f-4b14-ac45-39a4e8fe3030,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-00313844-3110-4d4b-890e-1c9654a240cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-af4dd1e0-498c-44c4-872c-a4a79d4bec68,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-9bdebc68-23ac-46ef-a202-4b50721b8b88,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-cf1f808c-cdaa-4d6d-97e6-c56d630f6b88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643324739-172.17.0.15-1595420487524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34867,DS-fcc531fb-0345-4e2c-94e1-6a56fa270a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-51b88a62-dd20-4d8c-87b1-67f636c0c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-6c5c82a4-50b3-4a9f-bfeb-a307dc4394ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-ee4e86fd-5043-477f-bd76-3ad8e228d201,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-5a8424a2-bb76-47b5-9c9b-986de6550a35,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-fbec4fbc-796d-405e-8a41-17fa95db4832,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-7e81816b-9d32-4de7-b905-0265b8e9bb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-5ce54a3b-8009-4ffd-8654-8819ee865d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643324739-172.17.0.15-1595420487524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34867,DS-fcc531fb-0345-4e2c-94e1-6a56fa270a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-51b88a62-dd20-4d8c-87b1-67f636c0c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-6c5c82a4-50b3-4a9f-bfeb-a307dc4394ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-ee4e86fd-5043-477f-bd76-3ad8e228d201,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-5a8424a2-bb76-47b5-9c9b-986de6550a35,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-fbec4fbc-796d-405e-8a41-17fa95db4832,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-7e81816b-9d32-4de7-b905-0265b8e9bb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-5ce54a3b-8009-4ffd-8654-8819ee865d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701423784-172.17.0.15-1595421332908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-0754845c-0148-42d1-97d8-2281e5e07078,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-b4a054e1-3ffb-40e8-a210-11cbd584be36,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-c74d3713-392e-44d3-aa60-1bd83761d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-56126cb5-a990-4f93-b26f-3e7abfa134dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-cfb8e51d-dc2c-4192-bab6-5d62c559d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-90e6b6e0-ec66-42d3-873b-8583e534f1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-1ec07894-2899-4d37-9d65-7a04d6fd354f,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-bbae3c89-6494-4a6b-9d68-80d16429dc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701423784-172.17.0.15-1595421332908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-0754845c-0148-42d1-97d8-2281e5e07078,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-b4a054e1-3ffb-40e8-a210-11cbd584be36,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-c74d3713-392e-44d3-aa60-1bd83761d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-56126cb5-a990-4f93-b26f-3e7abfa134dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-cfb8e51d-dc2c-4192-bab6-5d62c559d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-90e6b6e0-ec66-42d3-873b-8583e534f1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-1ec07894-2899-4d37-9d65-7a04d6fd354f,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-bbae3c89-6494-4a6b-9d68-80d16429dc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248669097-172.17.0.15-1595421868030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46668,DS-33648e85-4e1b-4063-8795-270ec2dc42b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-59b6fb6c-b5da-4618-acf9-00f695bd92cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-768da6da-007d-4b23-8f56-b038b514c473,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-f4c9562f-90a9-4db2-a392-6064e8ec548c,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-0bda11f6-065e-4541-b5ca-ff8c642fc89c,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-5e12fef9-794d-4926-870a-0b164ff1f099,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-74ae0f22-7a11-4d34-a3e2-caf1c3f16878,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-87050953-8da3-4875-aedd-bb55059ede23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248669097-172.17.0.15-1595421868030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46668,DS-33648e85-4e1b-4063-8795-270ec2dc42b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-59b6fb6c-b5da-4618-acf9-00f695bd92cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-768da6da-007d-4b23-8f56-b038b514c473,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-f4c9562f-90a9-4db2-a392-6064e8ec548c,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-0bda11f6-065e-4541-b5ca-ff8c642fc89c,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-5e12fef9-794d-4926-870a-0b164ff1f099,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-74ae0f22-7a11-4d34-a3e2-caf1c3f16878,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-87050953-8da3-4875-aedd-bb55059ede23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916855158-172.17.0.15-1595422118937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-2db24b55-5d32-4e52-acd9-412bd90eec2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-c1d5af7c-fb4f-4ccf-bab5-72c7d5da7da2,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-837d36b7-4d57-419a-8e77-81f2b3ae4786,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-00be102a-9c14-4191-aa21-bd95b10a5004,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-c43e7804-619d-4160-8c8b-c28271509d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-e93a16fe-e7a6-4854-97c6-ce51e71d1a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-4c9e6ce8-4536-40cc-b4eb-7c6f69b17f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-f3466219-57b9-48b9-8d48-a92194eb12e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916855158-172.17.0.15-1595422118937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-2db24b55-5d32-4e52-acd9-412bd90eec2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-c1d5af7c-fb4f-4ccf-bab5-72c7d5da7da2,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-837d36b7-4d57-419a-8e77-81f2b3ae4786,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-00be102a-9c14-4191-aa21-bd95b10a5004,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-c43e7804-619d-4160-8c8b-c28271509d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-e93a16fe-e7a6-4854-97c6-ce51e71d1a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-4c9e6ce8-4536-40cc-b4eb-7c6f69b17f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-f3466219-57b9-48b9-8d48-a92194eb12e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848270302-172.17.0.15-1595422299265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-93e60d9b-4ef3-472e-a61d-a3cd40b577ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-dbc45446-f2ad-4c7c-8cf3-31b817b54861,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6da58982-f54c-4680-b452-dbc201d33bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-f042a7e3-ea20-4ac2-ab13-df9c95868836,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-7d0e3ee5-2535-47c5-b611-fe84c5c590eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-b119a127-1103-4d90-ac9e-18919bc5907b,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-43e41d20-1cf6-44fb-a2f5-01550ee40b34,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-94953d2e-6c37-4983-9445-d1c3de179792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848270302-172.17.0.15-1595422299265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-93e60d9b-4ef3-472e-a61d-a3cd40b577ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-dbc45446-f2ad-4c7c-8cf3-31b817b54861,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6da58982-f54c-4680-b452-dbc201d33bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-f042a7e3-ea20-4ac2-ab13-df9c95868836,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-7d0e3ee5-2535-47c5-b611-fe84c5c590eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-b119a127-1103-4d90-ac9e-18919bc5907b,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-43e41d20-1cf6-44fb-a2f5-01550ee40b34,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-94953d2e-6c37-4983-9445-d1c3de179792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5187
