reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340358421-172.17.0.13-1595355798615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37649,DS-55b26967-df87-4ae8-b55e-f00444c12742,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-bd0a5535-a686-485c-b762-421a9f6c41d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-4612995e-e3c1-4463-99d1-16c377365b42,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-bbe7326b-dbf8-4af5-bd2f-39ac9ac803de,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-b2615e83-8caf-4423-8128-3cae4a12006c,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-c595913a-3266-49e1-9d0a-15fc799e8833,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-8a1c490f-9f2b-4f91-a7e0-c1a294b053b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-d1e2447d-2c44-4999-93d8-5f5e42e2ca6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340358421-172.17.0.13-1595355798615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37649,DS-55b26967-df87-4ae8-b55e-f00444c12742,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-bd0a5535-a686-485c-b762-421a9f6c41d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-4612995e-e3c1-4463-99d1-16c377365b42,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-bbe7326b-dbf8-4af5-bd2f-39ac9ac803de,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-b2615e83-8caf-4423-8128-3cae4a12006c,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-c595913a-3266-49e1-9d0a-15fc799e8833,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-8a1c490f-9f2b-4f91-a7e0-c1a294b053b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-d1e2447d-2c44-4999-93d8-5f5e42e2ca6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387429397-172.17.0.13-1595355982388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45457,DS-6ee22016-df4c-4bca-8ba4-cc9bd8b482ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-ce8d157a-c41e-4f2d-a6fa-1edb506974ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-0f584a49-8905-4dc1-8bba-5d253c9a403e,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-60d5a137-ac7c-4f35-a8cd-54f5a0f6284b,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-15506ede-da95-4eef-80f3-5b25bff63b68,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-5b64aa45-7a44-44d0-8e0c-4786eb307144,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-aaf8cad9-20f4-4570-8a88-b24af164a7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-3a161a81-cb8c-4485-b3d5-68696c76ce0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387429397-172.17.0.13-1595355982388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45457,DS-6ee22016-df4c-4bca-8ba4-cc9bd8b482ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-ce8d157a-c41e-4f2d-a6fa-1edb506974ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-0f584a49-8905-4dc1-8bba-5d253c9a403e,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-60d5a137-ac7c-4f35-a8cd-54f5a0f6284b,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-15506ede-da95-4eef-80f3-5b25bff63b68,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-5b64aa45-7a44-44d0-8e0c-4786eb307144,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-aaf8cad9-20f4-4570-8a88-b24af164a7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-3a161a81-cb8c-4485-b3d5-68696c76ce0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349270179-172.17.0.13-1595356334238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33492,DS-4f80cc85-29f6-4c4b-8ae8-1a5e245931fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-f9629f9f-bb86-4c3c-9170-faf10eb1eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-37b65eaf-8c61-4ec7-97d8-8934e791a49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-b775df1f-941f-48fd-a3f1-44c6ad08d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-3b4aa6bd-5382-4134-b324-18d185e37e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-6cd74cbe-b432-4bdf-877e-d988189d4516,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-25b80ee4-8e7d-4394-a84e-86880cd01d75,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-eac53ab8-17fa-47a8-890a-3e57076417ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349270179-172.17.0.13-1595356334238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33492,DS-4f80cc85-29f6-4c4b-8ae8-1a5e245931fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-f9629f9f-bb86-4c3c-9170-faf10eb1eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-37b65eaf-8c61-4ec7-97d8-8934e791a49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-b775df1f-941f-48fd-a3f1-44c6ad08d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-3b4aa6bd-5382-4134-b324-18d185e37e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-6cd74cbe-b432-4bdf-877e-d988189d4516,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-25b80ee4-8e7d-4394-a84e-86880cd01d75,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-eac53ab8-17fa-47a8-890a-3e57076417ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165565646-172.17.0.13-1595356367035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37890,DS-18934a5f-0e77-456e-b61f-842bcad90000,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-b2a79305-651e-406c-97c0-7a5b2c752b69,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-7d299a2c-619e-4854-b31f-8c5f91f7ed89,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-dbe1a44d-b00c-4c1a-b5b5-c9e50e6de890,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-b86684b3-2b0b-4811-a1f7-e68b075a6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-4ec8568b-2568-402e-9507-54f9b52b46f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-2c83eb41-b067-4ef0-8178-a9f7d769e98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-3f69de90-3355-416d-b541-5f500048bdb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165565646-172.17.0.13-1595356367035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37890,DS-18934a5f-0e77-456e-b61f-842bcad90000,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-b2a79305-651e-406c-97c0-7a5b2c752b69,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-7d299a2c-619e-4854-b31f-8c5f91f7ed89,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-dbe1a44d-b00c-4c1a-b5b5-c9e50e6de890,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-b86684b3-2b0b-4811-a1f7-e68b075a6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-4ec8568b-2568-402e-9507-54f9b52b46f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-2c83eb41-b067-4ef0-8178-a9f7d769e98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-3f69de90-3355-416d-b541-5f500048bdb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343861769-172.17.0.13-1595356626053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-d7651030-711c-411a-b0f9-a8986af1eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-352d8f3c-2be1-4a03-b22c-5d8af9f5f69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-9067e91f-46c2-473d-9346-fdd0d224a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-a04a95e9-85a8-47ef-a4ff-cb55ef2a78c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-2525928b-ddf0-4e10-939c-e6f8e48c217d,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-75f2761a-15cc-49f7-9713-745b4e88afed,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-96d028ce-0074-43d6-acd1-40576ad46fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-e199f00e-7555-4d57-ab8d-02c13d664dce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343861769-172.17.0.13-1595356626053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-d7651030-711c-411a-b0f9-a8986af1eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-352d8f3c-2be1-4a03-b22c-5d8af9f5f69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-9067e91f-46c2-473d-9346-fdd0d224a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-a04a95e9-85a8-47ef-a4ff-cb55ef2a78c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-2525928b-ddf0-4e10-939c-e6f8e48c217d,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-75f2761a-15cc-49f7-9713-745b4e88afed,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-96d028ce-0074-43d6-acd1-40576ad46fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-e199f00e-7555-4d57-ab8d-02c13d664dce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931021819-172.17.0.13-1595356716604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-6d9538e3-1e59-439f-b89b-81d227a3d039,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-1477f355-43d0-4725-8b13-29a85031d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-6191cca1-1342-4f67-ab47-e0a3fd2e181d,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-10e1893e-5265-4b78-b3cd-1159325b8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-6b95d87e-e691-4e43-bca0-5aa383aec273,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-5c20cb9f-4d6c-48a3-b293-ff83d479a063,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-6f7771af-cfb2-4da3-9d2f-6e04f3a5b313,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-16ea8e95-5c9f-4ed4-a309-b792ee8de8af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931021819-172.17.0.13-1595356716604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-6d9538e3-1e59-439f-b89b-81d227a3d039,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-1477f355-43d0-4725-8b13-29a85031d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-6191cca1-1342-4f67-ab47-e0a3fd2e181d,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-10e1893e-5265-4b78-b3cd-1159325b8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-6b95d87e-e691-4e43-bca0-5aa383aec273,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-5c20cb9f-4d6c-48a3-b293-ff83d479a063,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-6f7771af-cfb2-4da3-9d2f-6e04f3a5b313,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-16ea8e95-5c9f-4ed4-a309-b792ee8de8af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009113924-172.17.0.13-1595356816873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45374,DS-1a62cb40-8266-4c19-a183-195c8ccb6fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-b1b7a611-0ea3-4607-81ad-2829f1596978,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-18fad319-20b2-4b64-9f6d-9cfaba3de8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-113139b9-af70-4a1d-bf19-9ba35aae5b72,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-a4547db3-d9d2-47c0-ae62-b9d3d9c8877f,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-3aee95e6-d9e2-4a2b-a324-173d9f46ae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-e8b6888f-14f1-49cd-b918-c419921523d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-a35408e3-7782-4f85-b7eb-712f26b93c1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009113924-172.17.0.13-1595356816873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45374,DS-1a62cb40-8266-4c19-a183-195c8ccb6fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-b1b7a611-0ea3-4607-81ad-2829f1596978,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-18fad319-20b2-4b64-9f6d-9cfaba3de8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-113139b9-af70-4a1d-bf19-9ba35aae5b72,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-a4547db3-d9d2-47c0-ae62-b9d3d9c8877f,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-3aee95e6-d9e2-4a2b-a324-173d9f46ae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-e8b6888f-14f1-49cd-b918-c419921523d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-a35408e3-7782-4f85-b7eb-712f26b93c1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534901674-172.17.0.13-1595356884546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45385,DS-200b26f9-6860-420e-bfa4-dab81f97f898,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-e0d27b59-b760-42ad-abbb-c2ded4780a54,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-a2b683e0-76e9-4196-8d7b-342eb6bab434,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-1c78c548-f80f-4ce4-8e06-7811aec545e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-224ad43b-7a57-4229-9ef7-6477a4e261b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-71b29488-ceda-4287-a00c-37920f4455a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-49fde0a6-3a01-4ffc-96ba-a048783faab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-5ffd2cde-bbb1-496a-86f1-e7141657bba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534901674-172.17.0.13-1595356884546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45385,DS-200b26f9-6860-420e-bfa4-dab81f97f898,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-e0d27b59-b760-42ad-abbb-c2ded4780a54,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-a2b683e0-76e9-4196-8d7b-342eb6bab434,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-1c78c548-f80f-4ce4-8e06-7811aec545e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-224ad43b-7a57-4229-9ef7-6477a4e261b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-71b29488-ceda-4287-a00c-37920f4455a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-49fde0a6-3a01-4ffc-96ba-a048783faab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-5ffd2cde-bbb1-496a-86f1-e7141657bba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380786488-172.17.0.13-1595357113094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41103,DS-d8f6c7ab-9948-42e6-af4b-a6c54ff1783c,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-3247e6fd-888f-4483-803b-4948209d8450,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-e18b65e9-f780-4687-80fc-f4c9fb42015b,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-08c6eb6f-d16d-4403-bf58-52fbfec05189,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-478454c4-e4b0-4eec-acbb-07d0913a0861,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-15c9c87b-c9ba-473a-9fb4-b30eeb87f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-2369067f-1ac1-4071-9b55-f0cd375ad012,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-fc4e6f83-4dbb-4bcf-94cf-45cc270f1e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380786488-172.17.0.13-1595357113094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41103,DS-d8f6c7ab-9948-42e6-af4b-a6c54ff1783c,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-3247e6fd-888f-4483-803b-4948209d8450,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-e18b65e9-f780-4687-80fc-f4c9fb42015b,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-08c6eb6f-d16d-4403-bf58-52fbfec05189,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-478454c4-e4b0-4eec-acbb-07d0913a0861,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-15c9c87b-c9ba-473a-9fb4-b30eeb87f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-2369067f-1ac1-4071-9b55-f0cd375ad012,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-fc4e6f83-4dbb-4bcf-94cf-45cc270f1e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908916523-172.17.0.13-1595357245238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-9356bc47-b7ae-4e46-997e-08d411a3e29c,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-416407df-ee1e-4b46-b57e-257f3ad646fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-4b57b3db-548a-4f44-8351-6b58c896f76c,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-5bed8c59-fe27-48b1-8c32-d94f97f871f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-7f8eaf69-3c88-46d9-8c73-3238c50edc51,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-b4ab33d8-53d6-4c31-8fa5-10b1d207cbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-9b5ef4bd-8079-4de3-82b8-8f5c8a4e9c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-5d14c765-5ae6-4f98-9122-e19df9b9746a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908916523-172.17.0.13-1595357245238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-9356bc47-b7ae-4e46-997e-08d411a3e29c,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-416407df-ee1e-4b46-b57e-257f3ad646fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-4b57b3db-548a-4f44-8351-6b58c896f76c,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-5bed8c59-fe27-48b1-8c32-d94f97f871f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-7f8eaf69-3c88-46d9-8c73-3238c50edc51,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-b4ab33d8-53d6-4c31-8fa5-10b1d207cbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-9b5ef4bd-8079-4de3-82b8-8f5c8a4e9c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-5d14c765-5ae6-4f98-9122-e19df9b9746a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316355829-172.17.0.13-1595357346661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43083,DS-b048833b-9c25-4f18-a129-cf3c8bd281bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-003f1278-8527-432f-8659-bf1692d4ba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-7ecfa229-580e-4744-b278-0f17317fb3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-5469d290-a97b-4af5-97c9-2b96bbe664ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-44c6ec18-6e95-47d4-b8cd-e2e5f2a945cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-e220c113-cf52-4918-be1a-7391a5088292,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-1679101d-f84c-427a-a8ee-3acaad59828e,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-391e7513-7165-4bba-9eef-adea05d5d6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316355829-172.17.0.13-1595357346661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43083,DS-b048833b-9c25-4f18-a129-cf3c8bd281bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-003f1278-8527-432f-8659-bf1692d4ba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-7ecfa229-580e-4744-b278-0f17317fb3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-5469d290-a97b-4af5-97c9-2b96bbe664ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-44c6ec18-6e95-47d4-b8cd-e2e5f2a945cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-e220c113-cf52-4918-be1a-7391a5088292,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-1679101d-f84c-427a-a8ee-3acaad59828e,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-391e7513-7165-4bba-9eef-adea05d5d6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894674106-172.17.0.13-1595357478869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-9395d3e0-18b2-45fe-8ec3-bdc95e4fc3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-7f14d62f-0e3e-40c1-8551-2df27ac69565,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-6c560305-1d51-4b00-94d7-f7ecd1cc9ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-7eaf9948-2db9-491e-adf1-8cc753a41cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-aa7b2f0e-6d3a-4d91-93e8-17da8bd20081,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-b2fa5327-2127-4354-b788-66fc344e5f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-371452a3-ca3a-4440-8d0c-933ba8fee4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-d428d6a6-d5cc-44a0-baea-5898a2574907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894674106-172.17.0.13-1595357478869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-9395d3e0-18b2-45fe-8ec3-bdc95e4fc3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-7f14d62f-0e3e-40c1-8551-2df27ac69565,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-6c560305-1d51-4b00-94d7-f7ecd1cc9ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-7eaf9948-2db9-491e-adf1-8cc753a41cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-aa7b2f0e-6d3a-4d91-93e8-17da8bd20081,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-b2fa5327-2127-4354-b788-66fc344e5f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-371452a3-ca3a-4440-8d0c-933ba8fee4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-d428d6a6-d5cc-44a0-baea-5898a2574907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926994069-172.17.0.13-1595357662328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-8145cead-032d-4d9b-be02-6d47e0b94d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-9b8541d0-e0d4-4abc-9495-73bbac4491a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-02c17ec6-e564-4289-953d-972bb5cf30c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-cef6a181-baad-41d6-aff8-864af5c5f5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-ff0859f5-2525-4fac-9389-d82a75860e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-ccd34eb0-c64a-450f-b1d6-98b71dd0aa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-d3d4b57d-40ea-4e30-adbb-7aea64ef674e,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-3e41d6f4-cd64-4406-a935-9e8001a0b659,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926994069-172.17.0.13-1595357662328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-8145cead-032d-4d9b-be02-6d47e0b94d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-9b8541d0-e0d4-4abc-9495-73bbac4491a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-02c17ec6-e564-4289-953d-972bb5cf30c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-cef6a181-baad-41d6-aff8-864af5c5f5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-ff0859f5-2525-4fac-9389-d82a75860e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-ccd34eb0-c64a-450f-b1d6-98b71dd0aa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-d3d4b57d-40ea-4e30-adbb-7aea64ef674e,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-3e41d6f4-cd64-4406-a935-9e8001a0b659,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205301555-172.17.0.13-1595357999161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-c20f8424-3d81-4a61-b61b-a89895cd3dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-057c0917-561b-4204-9033-220c28493cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-1c388547-b36e-487b-a7a0-172f0137ce43,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-06823dc8-fc33-486c-9865-6c26ade7a16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-faf15141-6070-4b03-9cff-712b442df528,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-1d0529a1-36ec-4684-9e5b-e24a42a347f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-0b5fed3a-b4a2-40f1-88dc-ee4fbfcdce80,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-95c9a27d-7384-4ee4-8851-6690818011d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205301555-172.17.0.13-1595357999161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-c20f8424-3d81-4a61-b61b-a89895cd3dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-057c0917-561b-4204-9033-220c28493cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-1c388547-b36e-487b-a7a0-172f0137ce43,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-06823dc8-fc33-486c-9865-6c26ade7a16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-faf15141-6070-4b03-9cff-712b442df528,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-1d0529a1-36ec-4684-9e5b-e24a42a347f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-0b5fed3a-b4a2-40f1-88dc-ee4fbfcdce80,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-95c9a27d-7384-4ee4-8851-6690818011d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069962723-172.17.0.13-1595358125331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-ee754fe9-11bb-43c3-ae49-9a0876e95966,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-08d18918-aa73-4d6a-a35a-cf8e8c5f4c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-fb378684-1baa-46ba-8ab8-b32e920e5d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-fb195373-549e-4a6d-b609-f6a58bffc071,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-1d96b723-6103-4c66-a7d5-c8496efea8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-d6745da3-89d0-44a9-b979-2eb675ed1389,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-a582ff59-94ee-4e4b-813b-d9dc662b9bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-e70da4dc-5a24-4aee-a69f-151587f14f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069962723-172.17.0.13-1595358125331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-ee754fe9-11bb-43c3-ae49-9a0876e95966,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-08d18918-aa73-4d6a-a35a-cf8e8c5f4c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-fb378684-1baa-46ba-8ab8-b32e920e5d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-fb195373-549e-4a6d-b609-f6a58bffc071,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-1d96b723-6103-4c66-a7d5-c8496efea8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-d6745da3-89d0-44a9-b979-2eb675ed1389,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-a582ff59-94ee-4e4b-813b-d9dc662b9bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-e70da4dc-5a24-4aee-a69f-151587f14f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554257149-172.17.0.13-1595358705150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-299da6e9-8091-485a-a2d8-7ee69d526eee,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-487be12b-f9e1-49ab-af8a-7728c91e859a,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-a8e768cf-8410-48c3-a95e-665d3c1f7d29,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-54069217-ad3d-40fc-ac72-e84912a0f213,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-f498e535-cf70-4dfe-be1a-e619d6d88419,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-5b8d85d8-0259-407c-9f4e-0c72067df9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-497a7b75-b0db-4be7-b440-6631ca595941,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-0ce1aedc-d105-49f1-a414-27dae179eb3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554257149-172.17.0.13-1595358705150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-299da6e9-8091-485a-a2d8-7ee69d526eee,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-487be12b-f9e1-49ab-af8a-7728c91e859a,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-a8e768cf-8410-48c3-a95e-665d3c1f7d29,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-54069217-ad3d-40fc-ac72-e84912a0f213,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-f498e535-cf70-4dfe-be1a-e619d6d88419,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-5b8d85d8-0259-407c-9f4e-0c72067df9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-497a7b75-b0db-4be7-b440-6631ca595941,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-0ce1aedc-d105-49f1-a414-27dae179eb3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267400823-172.17.0.13-1595358739336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-35a4a2a9-c90d-479c-b723-198d0d2f8b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-49a0d72d-9721-41a6-befb-8d99b83e3482,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-7250cf20-3715-4a9e-9388-15b2cc5ddf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-76a23153-9069-4de6-a6d0-1d04374736bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-77c43c0b-4ae4-4a42-a17c-20bcb661309b,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-a4f9b3cb-3275-4a0a-9173-bdc59e701d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-8c57a5d9-a912-4c97-85b2-b44337713707,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-1c8f5ccb-b453-4621-a874-2d8ceb814cf7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267400823-172.17.0.13-1595358739336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-35a4a2a9-c90d-479c-b723-198d0d2f8b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-49a0d72d-9721-41a6-befb-8d99b83e3482,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-7250cf20-3715-4a9e-9388-15b2cc5ddf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-76a23153-9069-4de6-a6d0-1d04374736bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-77c43c0b-4ae4-4a42-a17c-20bcb661309b,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-a4f9b3cb-3275-4a0a-9173-bdc59e701d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-8c57a5d9-a912-4c97-85b2-b44337713707,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-1c8f5ccb-b453-4621-a874-2d8ceb814cf7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770910269-172.17.0.13-1595358943847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36483,DS-efbeee9c-b759-4539-9b6f-8c4bc13d9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-b8f482d3-4764-4378-8b01-77aa0d8b7f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-16f63f54-46eb-457c-9cc7-e46a318c7acd,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-631e0b94-11af-45de-8a40-670f49ae741e,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-63b963be-0c25-438d-8e78-6228a6e79dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-2c2f3c88-4d95-4a19-a2b6-ebd9788c11d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-3a046bc2-bea6-469b-a0f3-06bdaa0fe6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-3fc8203f-a9e1-4f5e-8230-5e31333a82d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770910269-172.17.0.13-1595358943847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36483,DS-efbeee9c-b759-4539-9b6f-8c4bc13d9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-b8f482d3-4764-4378-8b01-77aa0d8b7f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-16f63f54-46eb-457c-9cc7-e46a318c7acd,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-631e0b94-11af-45de-8a40-670f49ae741e,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-63b963be-0c25-438d-8e78-6228a6e79dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-2c2f3c88-4d95-4a19-a2b6-ebd9788c11d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-3a046bc2-bea6-469b-a0f3-06bdaa0fe6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-3fc8203f-a9e1-4f5e-8230-5e31333a82d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913865690-172.17.0.13-1595358979667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43896,DS-dae67d69-5c74-4e0b-bb16-befa24020fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-8d912df7-1fdb-4af4-83d2-98ec8cef4309,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-08573a5f-b9b4-4a21-ac28-04b055f55df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-bea349fe-bde3-4132-ad84-467a0c011eee,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-20893c50-e58b-4dcb-a751-42afd8449578,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-c8b25f86-3d9a-4ca4-9741-c2c37bcff8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-728fae39-b01c-482a-9745-e949286ed8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-256666f9-186d-458e-947b-d1b757e95fef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913865690-172.17.0.13-1595358979667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43896,DS-dae67d69-5c74-4e0b-bb16-befa24020fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-8d912df7-1fdb-4af4-83d2-98ec8cef4309,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-08573a5f-b9b4-4a21-ac28-04b055f55df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-bea349fe-bde3-4132-ad84-467a0c011eee,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-20893c50-e58b-4dcb-a751-42afd8449578,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-c8b25f86-3d9a-4ca4-9741-c2c37bcff8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-728fae39-b01c-482a-9745-e949286ed8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-256666f9-186d-458e-947b-d1b757e95fef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134565291-172.17.0.13-1595359488215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42963,DS-2e077a9a-acfd-447a-a278-a32707c31c57,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-5a41e110-eb36-4e29-aa1d-d75b25614c25,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-4b18dd0e-c0e9-45c5-b5a1-0184d8bf3d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-932e6f76-154a-4741-b79b-c96bf5043a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-a9d9066d-817d-47e8-905a-9be99b17cd69,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-816e6a24-11aa-432f-8846-684e07a10c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-bcc9fe99-8a94-4f88-b66d-9207b1153223,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-08605cf2-7a2e-43dc-b3e8-f34ebedeeacc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134565291-172.17.0.13-1595359488215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42963,DS-2e077a9a-acfd-447a-a278-a32707c31c57,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-5a41e110-eb36-4e29-aa1d-d75b25614c25,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-4b18dd0e-c0e9-45c5-b5a1-0184d8bf3d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-932e6f76-154a-4741-b79b-c96bf5043a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-a9d9066d-817d-47e8-905a-9be99b17cd69,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-816e6a24-11aa-432f-8846-684e07a10c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-bcc9fe99-8a94-4f88-b66d-9207b1153223,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-08605cf2-7a2e-43dc-b3e8-f34ebedeeacc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959563576-172.17.0.13-1595359525081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45539,DS-fe514450-b129-48e8-be95-9dd6a2abdc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-b2797983-25ba-44dd-bd1b-6894e38cfdad,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-2f5de2b2-6243-4333-acfa-e98ec8fd2ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-68103b7a-272f-4456-a095-6d8a4aaaf19b,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-6f720cd5-2bde-40b7-8da8-7c53499d374d,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-8604d23d-2a3b-4b78-a34a-59665b43192a,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-9c68c6e0-572a-4abe-8b56-a04d17557b60,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-2c34eaa7-b2cf-4371-9b55-b3ffc33af38a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959563576-172.17.0.13-1595359525081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45539,DS-fe514450-b129-48e8-be95-9dd6a2abdc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-b2797983-25ba-44dd-bd1b-6894e38cfdad,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-2f5de2b2-6243-4333-acfa-e98ec8fd2ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-68103b7a-272f-4456-a095-6d8a4aaaf19b,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-6f720cd5-2bde-40b7-8da8-7c53499d374d,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-8604d23d-2a3b-4b78-a34a-59665b43192a,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-9c68c6e0-572a-4abe-8b56-a04d17557b60,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-2c34eaa7-b2cf-4371-9b55-b3ffc33af38a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914897010-172.17.0.13-1595359664612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-201dfb77-2b9a-46e3-a20d-8f1af05bc2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-506d0d37-0fbd-4071-91ca-c0d4bc0276e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-7f52214f-b9eb-450e-a07e-af59bebf0a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-4695f137-bf33-4b4c-93ee-def2dcfce7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-afc699e4-a4e8-40ed-980b-32c0fef21c93,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-acbcf0b3-7743-4b42-822f-beaf04780ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-2ba3c3bd-7c98-4e6d-8069-8bd293768e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-b160d557-054b-46d4-aca7-2704b4dc26a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914897010-172.17.0.13-1595359664612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-201dfb77-2b9a-46e3-a20d-8f1af05bc2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-506d0d37-0fbd-4071-91ca-c0d4bc0276e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-7f52214f-b9eb-450e-a07e-af59bebf0a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-4695f137-bf33-4b4c-93ee-def2dcfce7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-afc699e4-a4e8-40ed-980b-32c0fef21c93,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-acbcf0b3-7743-4b42-822f-beaf04780ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-2ba3c3bd-7c98-4e6d-8069-8bd293768e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-b160d557-054b-46d4-aca7-2704b4dc26a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571219860-172.17.0.13-1595359800814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-d44c66ce-b530-4bac-96ed-e1cf3204dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-738fe8ca-4717-449d-a05e-e4262220607b,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-70e0135e-0000-439a-8aca-1fed00705f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-d266230d-6129-4ec5-a48b-fe72bf593ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-3d36633d-fcc7-4bf7-ad3a-249536cb8fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-77642d49-4bf9-4012-9537-588fd9698021,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-ce155f6c-41d9-40ab-bf1a-b1ea058c862a,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-eb15e717-6044-4985-a1bb-98fbe5f8d67f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571219860-172.17.0.13-1595359800814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-d44c66ce-b530-4bac-96ed-e1cf3204dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-738fe8ca-4717-449d-a05e-e4262220607b,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-70e0135e-0000-439a-8aca-1fed00705f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-d266230d-6129-4ec5-a48b-fe72bf593ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-3d36633d-fcc7-4bf7-ad3a-249536cb8fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-77642d49-4bf9-4012-9537-588fd9698021,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-ce155f6c-41d9-40ab-bf1a-b1ea058c862a,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-eb15e717-6044-4985-a1bb-98fbe5f8d67f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946985358-172.17.0.13-1595359961098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-02f10fab-6fe7-49d0-b7e8-4877898b88af,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-cc511916-7c52-4f57-8990-42fed1b860c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7406f33b-de57-4524-994d-5c869e92267a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-42d7468a-6461-4e49-a129-758fbfe2dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-6beeb6f7-2c2d-4da0-90bd-03e57d74284a,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-4d8c0b89-8562-4320-9d12-54d1221bd0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-05e60b4b-52c0-4428-b59c-4ee5440ae3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-7e3ddf99-9b99-4299-98fa-90e9bc0afbdc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946985358-172.17.0.13-1595359961098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-02f10fab-6fe7-49d0-b7e8-4877898b88af,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-cc511916-7c52-4f57-8990-42fed1b860c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7406f33b-de57-4524-994d-5c869e92267a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-42d7468a-6461-4e49-a129-758fbfe2dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-6beeb6f7-2c2d-4da0-90bd-03e57d74284a,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-4d8c0b89-8562-4320-9d12-54d1221bd0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-05e60b4b-52c0-4428-b59c-4ee5440ae3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-7e3ddf99-9b99-4299-98fa-90e9bc0afbdc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409589657-172.17.0.13-1595360070236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-d002defd-b3bd-4093-bec4-68d33fe427a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-9fe0b17d-3193-403d-ba53-50b4c1dd11bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-2ba5a840-cfea-42e4-a8d9-fb3aa7c5370a,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-5a6c7e75-67a1-4bfd-92d3-a61292deed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-611f58d7-daac-4667-9cf6-83d4ee9b576d,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-00806399-a6d1-4f94-9c86-fc10b3441201,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-f81bf1e4-f001-4172-afbc-fb7c9b3bfcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-13b05a96-6c43-4188-b4bb-4f9539adef30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409589657-172.17.0.13-1595360070236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-d002defd-b3bd-4093-bec4-68d33fe427a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-9fe0b17d-3193-403d-ba53-50b4c1dd11bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-2ba5a840-cfea-42e4-a8d9-fb3aa7c5370a,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-5a6c7e75-67a1-4bfd-92d3-a61292deed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-611f58d7-daac-4667-9cf6-83d4ee9b576d,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-00806399-a6d1-4f94-9c86-fc10b3441201,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-f81bf1e4-f001-4172-afbc-fb7c9b3bfcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-13b05a96-6c43-4188-b4bb-4f9539adef30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182522367-172.17.0.13-1595360174798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36915,DS-caad9ffc-a849-4043-b781-3ea5823d3991,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-c7446533-c1d2-4a90-848e-1cfb8fb4faea,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-7f5b3ffe-ed0d-4cd7-a09b-f5edd80d2b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-25163154-313d-4619-a441-093f1cd9b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-111704c3-0da4-44c6-b24e-fa5c94e68302,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-3161ba26-c036-49ef-8225-e25e6fab2992,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-fef8a9ea-7574-4372-b778-386f8b6ba0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-c96358d5-d66e-4759-be94-97326200d082,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182522367-172.17.0.13-1595360174798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36915,DS-caad9ffc-a849-4043-b781-3ea5823d3991,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-c7446533-c1d2-4a90-848e-1cfb8fb4faea,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-7f5b3ffe-ed0d-4cd7-a09b-f5edd80d2b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-25163154-313d-4619-a441-093f1cd9b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-111704c3-0da4-44c6-b24e-fa5c94e68302,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-3161ba26-c036-49ef-8225-e25e6fab2992,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-fef8a9ea-7574-4372-b778-386f8b6ba0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-c96358d5-d66e-4759-be94-97326200d082,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708693408-172.17.0.13-1595360362498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41403,DS-27af6f81-03d1-4331-be64-0a5ecd78a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-9f2856ed-1543-4931-9bf4-45786fb97a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-30cb491a-baed-482e-8db4-93f8053d48b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-4349aa7a-ebd6-48fe-a71c-f0fe6343aead,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-f676e0e0-3e0c-4243-b4e0-d4ca2079fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-40ff5d4f-8a1b-48cf-a8aa-5e2521c5912b,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-795ef455-189a-4b51-9b73-00e56b8921eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-ba59988a-9aff-4855-bff6-b92503bd529b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708693408-172.17.0.13-1595360362498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41403,DS-27af6f81-03d1-4331-be64-0a5ecd78a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-9f2856ed-1543-4931-9bf4-45786fb97a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-30cb491a-baed-482e-8db4-93f8053d48b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-4349aa7a-ebd6-48fe-a71c-f0fe6343aead,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-f676e0e0-3e0c-4243-b4e0-d4ca2079fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-40ff5d4f-8a1b-48cf-a8aa-5e2521c5912b,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-795ef455-189a-4b51-9b73-00e56b8921eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-ba59988a-9aff-4855-bff6-b92503bd529b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107083694-172.17.0.13-1595360422188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45569,DS-533e4007-93b3-4db6-ae47-b3bf0766c184,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-61647bb4-2f3f-4582-9542-c000c17ec2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-7fe39a72-9cf1-42d3-9fe1-704057bbe441,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-fe2b9821-98e0-4c82-b803-c4bd4cb143b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-cc119adb-e67f-4019-8cb4-09ae1ef29494,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-a37b78e7-f885-4966-84c5-9956afe0a711,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-ec4ccec3-4cb7-4a19-806d-5e21ccd4cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-7ed7ac59-1f2c-494e-ab61-0dd76816cc6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107083694-172.17.0.13-1595360422188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45569,DS-533e4007-93b3-4db6-ae47-b3bf0766c184,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-61647bb4-2f3f-4582-9542-c000c17ec2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-7fe39a72-9cf1-42d3-9fe1-704057bbe441,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-fe2b9821-98e0-4c82-b803-c4bd4cb143b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-cc119adb-e67f-4019-8cb4-09ae1ef29494,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-a37b78e7-f885-4966-84c5-9956afe0a711,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-ec4ccec3-4cb7-4a19-806d-5e21ccd4cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-7ed7ac59-1f2c-494e-ab61-0dd76816cc6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80233315-172.17.0.13-1595360497332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38588,DS-0ac16ac1-ba75-4e94-92bc-2085bbe1ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-0626a90a-11d4-41ba-8eee-aa331bbb49e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-3b1b1891-325b-4ffa-83b3-dc8f5491f828,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-48206b1c-1c20-4794-a1c0-ec69a55189d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-169ebb22-49e3-40e6-ad0f-a87d47f5ecca,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-7f4f2a93-224a-4f6a-9bf9-2a2014a31bab,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-d149630e-8320-4c60-b6c2-b502ba003d28,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-f7c89999-0fa2-450a-9099-df989febec75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80233315-172.17.0.13-1595360497332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38588,DS-0ac16ac1-ba75-4e94-92bc-2085bbe1ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-0626a90a-11d4-41ba-8eee-aa331bbb49e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-3b1b1891-325b-4ffa-83b3-dc8f5491f828,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-48206b1c-1c20-4794-a1c0-ec69a55189d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-169ebb22-49e3-40e6-ad0f-a87d47f5ecca,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-7f4f2a93-224a-4f6a-9bf9-2a2014a31bab,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-d149630e-8320-4c60-b6c2-b502ba003d28,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-f7c89999-0fa2-450a-9099-df989febec75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637086467-172.17.0.13-1595360619484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-377423e4-56fd-4596-b485-ea31391845b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-6c42cbdc-03be-494c-80a8-25c5136b7e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-2c54fda7-0c3f-49b1-a60e-510242053e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-7a94c3dc-b9be-4b37-b504-2fe9e8136f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-15d743fa-54dc-4313-9117-9bb466057b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-71bdf899-8eb0-45c0-8e0c-0f3e454e72d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-6d7002af-44fd-42ac-aad2-986c1ba3cc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-06d3f3ae-d812-4855-954c-5f492f9cb8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637086467-172.17.0.13-1595360619484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-377423e4-56fd-4596-b485-ea31391845b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-6c42cbdc-03be-494c-80a8-25c5136b7e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-2c54fda7-0c3f-49b1-a60e-510242053e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-7a94c3dc-b9be-4b37-b504-2fe9e8136f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-15d743fa-54dc-4313-9117-9bb466057b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-71bdf899-8eb0-45c0-8e0c-0f3e454e72d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-6d7002af-44fd-42ac-aad2-986c1ba3cc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-06d3f3ae-d812-4855-954c-5f492f9cb8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646513718-172.17.0.13-1595360707906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38683,DS-e47de3df-b230-40a4-ae02-1c0fd464ef10,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-001543cd-810f-4659-b3b4-8b8024477245,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-f1506c63-42e8-4c70-b9c9-2c14cde0b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-39c2d21d-3fd1-45fa-96d1-ebae53ba3943,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-abcaf214-e869-452b-815c-c5132afd5435,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-6d7813ff-4bbe-46df-a4a8-fb4537af2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-8ca825cd-6b9b-43a5-ba3a-bfe1897572b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-06abea27-2d91-4f78-bc4b-208b5fea8051,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646513718-172.17.0.13-1595360707906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38683,DS-e47de3df-b230-40a4-ae02-1c0fd464ef10,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-001543cd-810f-4659-b3b4-8b8024477245,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-f1506c63-42e8-4c70-b9c9-2c14cde0b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-39c2d21d-3fd1-45fa-96d1-ebae53ba3943,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-abcaf214-e869-452b-815c-c5132afd5435,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-6d7813ff-4bbe-46df-a4a8-fb4537af2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-8ca825cd-6b9b-43a5-ba3a-bfe1897572b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-06abea27-2d91-4f78-bc4b-208b5fea8051,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70737032-172.17.0.13-1595360740623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39680,DS-7a9bdb6a-2a22-4a64-b565-cf57fc38707a,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-4632fa9b-6053-49b2-a683-4a471c03bfec,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-cf7c33d0-6fa8-4a0f-a800-dd3717b93111,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-04b795fc-1c99-4960-b346-00a1e47aab16,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-36577dd0-7c47-4872-9f30-e1fb78e62763,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-f0cc5c11-9b25-421e-af89-53444f3df147,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-bb21d3b6-4961-4cad-bd38-e2293c4a73d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-f1921237-ccd3-4b6b-ac48-297f0c48de2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70737032-172.17.0.13-1595360740623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39680,DS-7a9bdb6a-2a22-4a64-b565-cf57fc38707a,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-4632fa9b-6053-49b2-a683-4a471c03bfec,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-cf7c33d0-6fa8-4a0f-a800-dd3717b93111,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-04b795fc-1c99-4960-b346-00a1e47aab16,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-36577dd0-7c47-4872-9f30-e1fb78e62763,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-f0cc5c11-9b25-421e-af89-53444f3df147,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-bb21d3b6-4961-4cad-bd38-e2293c4a73d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-f1921237-ccd3-4b6b-ac48-297f0c48de2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 4978
