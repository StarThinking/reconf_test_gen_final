reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531975173-172.17.0.19-1595393176866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45147,DS-69acd8d4-247b-419d-9a6e-fbb83e64de87,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-391827bb-2a73-4c99-9653-62809ed95e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-78ab0859-39a2-4198-8c69-ffa7fe8afb62,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-2b81a156-c586-45fd-8f5c-138ae8d58e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-4dcb48ce-59df-4d6b-98b0-9670d4ef8e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-4f39a188-8b17-4514-ac53-59ba366ad5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-b4bf330d-0a0e-4ad9-a67c-fe3e60f4d5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-7d58840f-bec6-480c-8e6e-d0c801d7c96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531975173-172.17.0.19-1595393176866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45147,DS-69acd8d4-247b-419d-9a6e-fbb83e64de87,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-391827bb-2a73-4c99-9653-62809ed95e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-78ab0859-39a2-4198-8c69-ffa7fe8afb62,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-2b81a156-c586-45fd-8f5c-138ae8d58e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-4dcb48ce-59df-4d6b-98b0-9670d4ef8e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-4f39a188-8b17-4514-ac53-59ba366ad5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-b4bf330d-0a0e-4ad9-a67c-fe3e60f4d5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-7d58840f-bec6-480c-8e6e-d0c801d7c96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599969928-172.17.0.19-1595393684777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-2ac65be2-4be1-4845-a63b-58f0e7dc5cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-5ad5c9cc-5136-4400-985e-fda3f8120cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-4e137e1c-8a57-4573-84cc-c944ca66dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-4db01fe3-5b00-4888-8710-2a50ae48a294,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-d71fca1f-60fa-43bb-b4e5-57dc3e9cf894,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-30d54047-ea20-40b8-b85d-010fbc50cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-ee231370-55cf-4557-a2e6-61c029ce0557,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-b9037292-3add-4e58-850a-bd163a0ca53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599969928-172.17.0.19-1595393684777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-2ac65be2-4be1-4845-a63b-58f0e7dc5cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-5ad5c9cc-5136-4400-985e-fda3f8120cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-4e137e1c-8a57-4573-84cc-c944ca66dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-4db01fe3-5b00-4888-8710-2a50ae48a294,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-d71fca1f-60fa-43bb-b4e5-57dc3e9cf894,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-30d54047-ea20-40b8-b85d-010fbc50cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-ee231370-55cf-4557-a2e6-61c029ce0557,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-b9037292-3add-4e58-850a-bd163a0ca53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737693121-172.17.0.19-1595394109674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35140,DS-aee84627-ea8e-46a8-99a8-404aff54ca69,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-44885257-b12b-4532-8363-606c82716cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-afe63397-c584-4cb0-b5e9-703d145c8211,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-ef56ccba-dd45-42aa-95d4-9125c9380de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-11cad767-9912-4acc-945a-b557bd09d56b,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-12f9e86b-98de-438b-8cba-a85e7122d089,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-3a1b7654-d0ca-45bf-96ad-46b8b73df522,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-558c1350-00d5-4bca-b030-bbec6f17b93a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737693121-172.17.0.19-1595394109674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35140,DS-aee84627-ea8e-46a8-99a8-404aff54ca69,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-44885257-b12b-4532-8363-606c82716cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-afe63397-c584-4cb0-b5e9-703d145c8211,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-ef56ccba-dd45-42aa-95d4-9125c9380de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-11cad767-9912-4acc-945a-b557bd09d56b,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-12f9e86b-98de-438b-8cba-a85e7122d089,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-3a1b7654-d0ca-45bf-96ad-46b8b73df522,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-558c1350-00d5-4bca-b030-bbec6f17b93a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582853100-172.17.0.19-1595394192330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40902,DS-e4e27519-973b-478e-86c6-acc9dc6e0660,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-1e626bd3-8b74-4412-9de2-bd7244e49e12,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-faa323a1-3354-4703-a458-b19c68824126,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-fd6a502d-673f-4d6b-8166-a0c60eb2f75b,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-f0cfbc19-dae0-47a2-9e5c-d3f7905d5032,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-1f33d517-9fbc-4b55-bf25-1f0c47d6bf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-b734517c-fffa-4bc7-ab3f-0e23927d2db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-78e8ccba-c742-498b-befc-d560c5b4cd4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582853100-172.17.0.19-1595394192330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40902,DS-e4e27519-973b-478e-86c6-acc9dc6e0660,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-1e626bd3-8b74-4412-9de2-bd7244e49e12,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-faa323a1-3354-4703-a458-b19c68824126,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-fd6a502d-673f-4d6b-8166-a0c60eb2f75b,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-f0cfbc19-dae0-47a2-9e5c-d3f7905d5032,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-1f33d517-9fbc-4b55-bf25-1f0c47d6bf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-b734517c-fffa-4bc7-ab3f-0e23927d2db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-78e8ccba-c742-498b-befc-d560c5b4cd4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392578379-172.17.0.19-1595394355402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34397,DS-25ba792e-8942-46cf-94af-ab93b8fcebac,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-c2ada075-9314-420b-9f45-6564f11634a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-f62fadb2-a498-4ca5-8523-3cec103838f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-9b8b631b-4338-4a62-b996-e6f5b6e6e463,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-449aa3ef-c56e-46cd-b9f1-2c4dde629cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-1c2e55c1-796a-44a8-af9b-c5a34d11b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-5afcf706-547b-4578-a57e-87bd3241de98,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-41977c5a-475e-4a99-a14f-0ec36eab0d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392578379-172.17.0.19-1595394355402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34397,DS-25ba792e-8942-46cf-94af-ab93b8fcebac,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-c2ada075-9314-420b-9f45-6564f11634a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-f62fadb2-a498-4ca5-8523-3cec103838f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-9b8b631b-4338-4a62-b996-e6f5b6e6e463,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-449aa3ef-c56e-46cd-b9f1-2c4dde629cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-1c2e55c1-796a-44a8-af9b-c5a34d11b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-5afcf706-547b-4578-a57e-87bd3241de98,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-41977c5a-475e-4a99-a14f-0ec36eab0d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409020989-172.17.0.19-1595394472946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41191,DS-ca1856c1-3a33-4b75-b19e-9a959e18fc71,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-e17e4148-95f7-4a8c-92dd-a3ef0c013cff,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-3ed38150-a8c9-4fc5-ad01-36394340672c,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-8a25c054-e73c-4a7a-b690-e3bdc8489b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-15490944-eccc-4fe6-816d-1b23699cf498,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-4c21b2d8-affc-4788-b23a-5ffb9824bd31,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-10f0f682-c3f3-4de2-ab44-e5636bebde14,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-99ac30a8-341d-46b4-b608-60693cc00c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409020989-172.17.0.19-1595394472946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41191,DS-ca1856c1-3a33-4b75-b19e-9a959e18fc71,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-e17e4148-95f7-4a8c-92dd-a3ef0c013cff,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-3ed38150-a8c9-4fc5-ad01-36394340672c,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-8a25c054-e73c-4a7a-b690-e3bdc8489b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-15490944-eccc-4fe6-816d-1b23699cf498,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-4c21b2d8-affc-4788-b23a-5ffb9824bd31,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-10f0f682-c3f3-4de2-ab44-e5636bebde14,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-99ac30a8-341d-46b4-b608-60693cc00c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397376587-172.17.0.19-1595394988216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-b09592e3-3614-400c-9278-6008998c30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-02199715-76ea-4978-9e23-ac70c621f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-c162e0d1-e86d-44f7-909d-0c8b50539641,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-f9f9da36-efcd-478f-b89e-b94bc35e0877,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-029f78bf-f843-47d9-a0e0-abdf9085c6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-96a6b360-dbf7-4ee1-927f-cf67173d0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-d72684b3-68de-4b7b-b3db-e0e64c851a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-5d58695b-c34e-406b-ae1d-d6900c94b712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397376587-172.17.0.19-1595394988216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-b09592e3-3614-400c-9278-6008998c30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-02199715-76ea-4978-9e23-ac70c621f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-c162e0d1-e86d-44f7-909d-0c8b50539641,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-f9f9da36-efcd-478f-b89e-b94bc35e0877,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-029f78bf-f843-47d9-a0e0-abdf9085c6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-96a6b360-dbf7-4ee1-927f-cf67173d0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-d72684b3-68de-4b7b-b3db-e0e64c851a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-5d58695b-c34e-406b-ae1d-d6900c94b712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872420424-172.17.0.19-1595395154048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39922,DS-0ede36bf-6747-4d09-b48e-e35e242024ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-a4310373-df5e-4be3-87da-c43134ddaa60,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-b255025a-bb5b-45e8-b13b-76197538bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-a4021abf-0f9f-4cc6-a5c9-30f7b6353d24,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-dab516c5-a949-4bf0-8f21-dd11011dfb44,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-0b170e01-f0ba-423e-bb0e-1e6664e4940a,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-d1881cfc-a776-4d6b-b5d1-cc534473255a,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-05a32e3b-d78c-495a-91b3-ba03760039d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872420424-172.17.0.19-1595395154048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39922,DS-0ede36bf-6747-4d09-b48e-e35e242024ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-a4310373-df5e-4be3-87da-c43134ddaa60,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-b255025a-bb5b-45e8-b13b-76197538bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-a4021abf-0f9f-4cc6-a5c9-30f7b6353d24,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-dab516c5-a949-4bf0-8f21-dd11011dfb44,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-0b170e01-f0ba-423e-bb0e-1e6664e4940a,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-d1881cfc-a776-4d6b-b5d1-cc534473255a,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-05a32e3b-d78c-495a-91b3-ba03760039d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446790153-172.17.0.19-1595396359514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-07cfb48d-f8c5-4827-aaef-93cb2d33a9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-fb30e816-52ba-4185-aae3-2136887e41bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-01b4cd4e-ba05-49f8-8469-1f2c175a7ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-ca204a5c-c6e8-4179-8939-b3ea819d1840,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-a4b25120-8a9d-41df-8e2b-5033f726f043,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-80750a81-a18f-4c14-8d0f-3c69c5cea66d,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-d9294554-f5a0-44d5-8adf-8c0193fa4538,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-55a769fa-9cb3-4714-a433-395de6f629b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446790153-172.17.0.19-1595396359514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-07cfb48d-f8c5-4827-aaef-93cb2d33a9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-fb30e816-52ba-4185-aae3-2136887e41bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-01b4cd4e-ba05-49f8-8469-1f2c175a7ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-ca204a5c-c6e8-4179-8939-b3ea819d1840,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-a4b25120-8a9d-41df-8e2b-5033f726f043,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-80750a81-a18f-4c14-8d0f-3c69c5cea66d,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-d9294554-f5a0-44d5-8adf-8c0193fa4538,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-55a769fa-9cb3-4714-a433-395de6f629b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832475856-172.17.0.19-1595396565700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-0666df4d-f6e1-47ca-827c-6e623cca9e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-945f1163-1d7c-439e-8eae-716acb4f599d,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-05af5e87-235c-48ac-a95e-670bf7f81714,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-312fe1cc-a4b2-4dc7-9a9f-18fdcf751994,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-5d0e38c4-b52d-462f-b2e3-0db6dc17f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-abf971b4-8853-421c-b7e6-e58c1582b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-d0c97960-6933-46b0-8863-e5941fc4f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-5d29a12f-2232-4d1d-8036-5cd093138f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832475856-172.17.0.19-1595396565700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-0666df4d-f6e1-47ca-827c-6e623cca9e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-945f1163-1d7c-439e-8eae-716acb4f599d,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-05af5e87-235c-48ac-a95e-670bf7f81714,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-312fe1cc-a4b2-4dc7-9a9f-18fdcf751994,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-5d0e38c4-b52d-462f-b2e3-0db6dc17f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-abf971b4-8853-421c-b7e6-e58c1582b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-d0c97960-6933-46b0-8863-e5941fc4f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-5d29a12f-2232-4d1d-8036-5cd093138f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-552768086-172.17.0.19-1595397005725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-9dac506f-db71-40bc-9e7a-134a0976546b,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-48a8017c-a452-4715-b982-811fec1e6fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-90cdd862-a6fb-4e55-a96d-e1d6a0ff5713,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-d6c239f5-3492-404f-bc23-ba4938381e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-e1673e1a-d7e0-47d5-b4f3-e4d4b210d069,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-dec29693-4079-4902-bb6c-d48d9b5a7551,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-1e995199-5329-47db-bac9-45adfffaad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-0ef83dd3-9aa2-4867-b38a-2b9149266007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-552768086-172.17.0.19-1595397005725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-9dac506f-db71-40bc-9e7a-134a0976546b,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-48a8017c-a452-4715-b982-811fec1e6fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-90cdd862-a6fb-4e55-a96d-e1d6a0ff5713,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-d6c239f5-3492-404f-bc23-ba4938381e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-e1673e1a-d7e0-47d5-b4f3-e4d4b210d069,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-dec29693-4079-4902-bb6c-d48d9b5a7551,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-1e995199-5329-47db-bac9-45adfffaad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-0ef83dd3-9aa2-4867-b38a-2b9149266007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429070559-172.17.0.19-1595397401252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-685b343f-e04e-4e5e-b4cc-f572a3051e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-755e2cf0-16ff-45b8-8aa5-f835719f3567,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-60688caf-adec-4d4e-b47c-ced67a069df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-eaf82acc-5212-4b20-a6d9-4f5da82991c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-2843806c-af57-447c-86b1-bb1c8dd39c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-7c55dfd6-b3fc-46b2-8a70-65b86f2f2679,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-61ac2baa-fc2b-4f58-a5f8-b03b7a13b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-48f7b8d7-e88f-45c2-a22b-1a19185d3b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429070559-172.17.0.19-1595397401252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-685b343f-e04e-4e5e-b4cc-f572a3051e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-755e2cf0-16ff-45b8-8aa5-f835719f3567,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-60688caf-adec-4d4e-b47c-ced67a069df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-eaf82acc-5212-4b20-a6d9-4f5da82991c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-2843806c-af57-447c-86b1-bb1c8dd39c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-7c55dfd6-b3fc-46b2-8a70-65b86f2f2679,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-61ac2baa-fc2b-4f58-a5f8-b03b7a13b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-48f7b8d7-e88f-45c2-a22b-1a19185d3b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797615080-172.17.0.19-1595398119515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46690,DS-c4074be9-939a-47fd-84d9-593d682cafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-e18e8e3b-bf77-43b0-9b41-69241ab8921b,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-3e281b5e-e6e6-40be-a43a-a03d5db9edcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-d0c7a2a8-3f80-4f43-b0ff-d2fe06bac673,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-562cb1d6-6dc2-4abf-b443-e8ee7030f242,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-60014f39-b482-418c-a021-0d9bb1204c39,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-de0bcc01-cecc-4faf-9a80-44052addad74,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-93ce9873-a6dc-4f89-9196-02caf210be04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797615080-172.17.0.19-1595398119515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46690,DS-c4074be9-939a-47fd-84d9-593d682cafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-e18e8e3b-bf77-43b0-9b41-69241ab8921b,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-3e281b5e-e6e6-40be-a43a-a03d5db9edcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-d0c7a2a8-3f80-4f43-b0ff-d2fe06bac673,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-562cb1d6-6dc2-4abf-b443-e8ee7030f242,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-60014f39-b482-418c-a021-0d9bb1204c39,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-de0bcc01-cecc-4faf-9a80-44052addad74,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-93ce9873-a6dc-4f89-9196-02caf210be04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770782500-172.17.0.19-1595398376276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37808,DS-4bdecc8c-8387-40f0-a147-f89983dddf65,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-3fcc37f5-e260-4cdf-a7e1-7050cc63d545,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-4a987327-4151-43ff-9599-a8c870f84d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-5ae4e0c2-453c-480c-a1c1-8f89ce0b9218,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-4008e95e-11ff-4601-8b2a-cd354db3f656,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-f6f2f856-a771-4c15-9fb0-964108d9de8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-8ea2f89f-371f-417b-9876-e6d62b5d3240,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-1a3553c8-48c9-43d3-b181-14e3941db8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770782500-172.17.0.19-1595398376276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37808,DS-4bdecc8c-8387-40f0-a147-f89983dddf65,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-3fcc37f5-e260-4cdf-a7e1-7050cc63d545,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-4a987327-4151-43ff-9599-a8c870f84d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-5ae4e0c2-453c-480c-a1c1-8f89ce0b9218,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-4008e95e-11ff-4601-8b2a-cd354db3f656,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-f6f2f856-a771-4c15-9fb0-964108d9de8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-8ea2f89f-371f-417b-9876-e6d62b5d3240,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-1a3553c8-48c9-43d3-b181-14e3941db8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851365188-172.17.0.19-1595398805978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45240,DS-6d24d3f5-d859-489c-bb56-8a0ddcf6cfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-d7a45cbe-e71b-45ff-854c-7c200dedd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-5f4ccc2b-1593-46a6-8697-e5dec0eeb8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-ac97103d-a3a6-463f-a009-0e2e047bffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-c4b03c6e-900e-45ae-97ee-beacf9523e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-5c1b54c0-0553-4a88-92c0-4b2768c8b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-68f35f41-2359-4cb8-8808-657b51939b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-565991d4-1072-4478-bd88-a7a6223a3c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851365188-172.17.0.19-1595398805978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45240,DS-6d24d3f5-d859-489c-bb56-8a0ddcf6cfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-d7a45cbe-e71b-45ff-854c-7c200dedd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-5f4ccc2b-1593-46a6-8697-e5dec0eeb8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-ac97103d-a3a6-463f-a009-0e2e047bffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-c4b03c6e-900e-45ae-97ee-beacf9523e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-5c1b54c0-0553-4a88-92c0-4b2768c8b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-68f35f41-2359-4cb8-8808-657b51939b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-565991d4-1072-4478-bd88-a7a6223a3c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316238076-172.17.0.19-1595398946277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-e63c8716-fea2-4ff8-8782-af301c47647b,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-03db4578-2e7a-40a5-b838-6f34446f6ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-184b6325-2e31-41f3-8e03-a945ce2b8ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-92cc52ed-35b4-46b7-ba3c-fabec711c6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-402b40fa-d94b-4bf8-87aa-1ac101f1983b,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-0b0ffbe7-027d-4a4a-8800-f50ddc4cd2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-0a579b13-d444-4881-9ae1-a6713f19a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-6fd256f1-b2c7-4a42-b880-dead1614d3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316238076-172.17.0.19-1595398946277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-e63c8716-fea2-4ff8-8782-af301c47647b,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-03db4578-2e7a-40a5-b838-6f34446f6ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-184b6325-2e31-41f3-8e03-a945ce2b8ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-92cc52ed-35b4-46b7-ba3c-fabec711c6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-402b40fa-d94b-4bf8-87aa-1ac101f1983b,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-0b0ffbe7-027d-4a4a-8800-f50ddc4cd2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-0a579b13-d444-4881-9ae1-a6713f19a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-6fd256f1-b2c7-4a42-b880-dead1614d3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672630333-172.17.0.19-1595399103091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-896032c5-4f19-4f9e-8012-9a3960848edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-f576e61d-e00b-41e2-807b-64db471140ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-82e7a549-8deb-40d4-ab66-d47bd00baf70,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-ac4665ab-2b77-4858-a423-e3e3ea1a84c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-470c2671-4b78-4052-8b88-5610804d9983,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-60fabd3e-76c3-40a4-a297-f3a3cfcf5683,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-f23066fe-490b-49c8-9ae6-87d80801f218,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-af19770c-48c2-4d3f-ad60-fa77e3512a47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672630333-172.17.0.19-1595399103091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-896032c5-4f19-4f9e-8012-9a3960848edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-f576e61d-e00b-41e2-807b-64db471140ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-82e7a549-8deb-40d4-ab66-d47bd00baf70,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-ac4665ab-2b77-4858-a423-e3e3ea1a84c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-470c2671-4b78-4052-8b88-5610804d9983,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-60fabd3e-76c3-40a4-a297-f3a3cfcf5683,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-f23066fe-490b-49c8-9ae6-87d80801f218,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-af19770c-48c2-4d3f-ad60-fa77e3512a47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6426
