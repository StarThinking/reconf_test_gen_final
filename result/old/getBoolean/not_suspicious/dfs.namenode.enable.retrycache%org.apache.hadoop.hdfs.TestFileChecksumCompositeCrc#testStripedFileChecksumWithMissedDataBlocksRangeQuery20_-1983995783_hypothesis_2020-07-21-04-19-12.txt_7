reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589173416-172.17.0.17-1595305196801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41500,DS-bc46d4df-861b-4403-8673-2f4bc7077e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-e27c5435-6873-4141-9225-6bd55425051c,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-11b4c567-5010-4650-aa9e-0bae11b2b783,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-70ba7e97-a470-4a81-a221-b7a9ad985475,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-8963d2a7-d35d-4764-b6f3-f26c998df469,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-b8d0d099-b8ae-40c8-969b-43f3b05b515a,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-72b0bdc0-dd30-402b-99fe-f0fc1b3f675a,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-82cb75ac-b230-4077-813c-e657db0990c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589173416-172.17.0.17-1595305196801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41500,DS-bc46d4df-861b-4403-8673-2f4bc7077e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-e27c5435-6873-4141-9225-6bd55425051c,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-11b4c567-5010-4650-aa9e-0bae11b2b783,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-70ba7e97-a470-4a81-a221-b7a9ad985475,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-8963d2a7-d35d-4764-b6f3-f26c998df469,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-b8d0d099-b8ae-40c8-969b-43f3b05b515a,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-72b0bdc0-dd30-402b-99fe-f0fc1b3f675a,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-82cb75ac-b230-4077-813c-e657db0990c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216040627-172.17.0.17-1595305682849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44869,DS-3082565d-2bb3-40a3-95dd-3ab17c320c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-9649fd05-ab78-401f-9db9-b86dd8d6eb03,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-92ed86f9-2e9c-4f4b-951a-fbda070aa344,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-af0c2c34-c4fd-4406-bb07-f06391251e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-5c4e074e-c33c-486f-af82-402d0b919085,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-4afeaddd-a05a-4ff8-8989-7308ed393cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-5074fc44-54dc-4627-96cc-56f71dd6d419,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-1506247b-fd93-4a99-b324-4b206ccb6254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216040627-172.17.0.17-1595305682849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44869,DS-3082565d-2bb3-40a3-95dd-3ab17c320c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-9649fd05-ab78-401f-9db9-b86dd8d6eb03,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-92ed86f9-2e9c-4f4b-951a-fbda070aa344,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-af0c2c34-c4fd-4406-bb07-f06391251e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-5c4e074e-c33c-486f-af82-402d0b919085,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-4afeaddd-a05a-4ff8-8989-7308ed393cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-5074fc44-54dc-4627-96cc-56f71dd6d419,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-1506247b-fd93-4a99-b324-4b206ccb6254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52403735-172.17.0.17-1595305987611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42035,DS-1bfbc282-121a-41f8-afc4-7449aed7f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-0e5f4329-d05d-4e85-97e5-cc927153b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-dacd5905-2cf2-4f41-800b-7296fccc5f31,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-b8cb8444-3c67-4700-a18f-8ea1e310410a,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-5949bb3c-2dd4-4290-ac89-05c0cff20067,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-095961c3-2ea4-4b52-9e4b-37af37fdbd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-c55a802b-5bbe-48c3-9656-f16ec227e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-95f64e88-bd75-4348-a5b0-18102ee96078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52403735-172.17.0.17-1595305987611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42035,DS-1bfbc282-121a-41f8-afc4-7449aed7f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-0e5f4329-d05d-4e85-97e5-cc927153b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-dacd5905-2cf2-4f41-800b-7296fccc5f31,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-b8cb8444-3c67-4700-a18f-8ea1e310410a,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-5949bb3c-2dd4-4290-ac89-05c0cff20067,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-095961c3-2ea4-4b52-9e4b-37af37fdbd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-c55a802b-5bbe-48c3-9656-f16ec227e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-95f64e88-bd75-4348-a5b0-18102ee96078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563704468-172.17.0.17-1595306622990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33319,DS-9c3bafcc-8f26-482d-9660-53cb315cd22b,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-3307a62c-64be-40b5-abce-9936da42d7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-215bbbab-eeed-4433-a2bf-d23ec5e90841,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-c32161c1-e593-4a75-9799-21bdd1f82030,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-0a9e0559-7109-4cc9-ab95-ced53de96808,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-9a462ea7-afcf-4b3d-9c17-5dccaa24105e,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-2570203b-1237-4bb5-a652-e9f8b1e7e117,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-524650f4-393a-4518-bdcb-7374c00f05fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563704468-172.17.0.17-1595306622990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33319,DS-9c3bafcc-8f26-482d-9660-53cb315cd22b,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-3307a62c-64be-40b5-abce-9936da42d7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-215bbbab-eeed-4433-a2bf-d23ec5e90841,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-c32161c1-e593-4a75-9799-21bdd1f82030,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-0a9e0559-7109-4cc9-ab95-ced53de96808,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-9a462ea7-afcf-4b3d-9c17-5dccaa24105e,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-2570203b-1237-4bb5-a652-e9f8b1e7e117,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-524650f4-393a-4518-bdcb-7374c00f05fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474571457-172.17.0.17-1595306651866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33597,DS-a5dd1b9d-95e9-49ec-a721-59225e64ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-8dd4580c-4c56-4a63-bff7-3a95a42cddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-7d7f54e0-86be-47d5-bee7-6d6dc635b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-1302b25c-cd9d-4c90-b7ef-a9e16d54dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-0a623b40-6d3d-45b3-ad12-03c6717bb611,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-0200ecc5-2a5a-41da-9dd0-315b80d9e532,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-bb72d959-9fc6-45cf-94f8-7fcef30873bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-a49969b6-97d5-42bc-9156-cb465bce7546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474571457-172.17.0.17-1595306651866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33597,DS-a5dd1b9d-95e9-49ec-a721-59225e64ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-8dd4580c-4c56-4a63-bff7-3a95a42cddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-7d7f54e0-86be-47d5-bee7-6d6dc635b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-1302b25c-cd9d-4c90-b7ef-a9e16d54dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-0a623b40-6d3d-45b3-ad12-03c6717bb611,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-0200ecc5-2a5a-41da-9dd0-315b80d9e532,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-bb72d959-9fc6-45cf-94f8-7fcef30873bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-a49969b6-97d5-42bc-9156-cb465bce7546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825864981-172.17.0.17-1595306744645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39918,DS-48d0b2b8-cff6-4227-94c9-b17795a170c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-36e51fa4-2044-475d-84ea-9ec6268dbf41,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-bac83cc8-2ef4-4a5e-9c0e-86baa245e968,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-5567ac0c-cde9-423c-9959-94a6291dfb16,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-c0655b41-64ed-4670-af06-6243b0c2da75,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-59ad3063-ae77-4741-86da-ac612c448445,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-5f0f8db9-f45e-4b75-b6cb-61250de12bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-c184e85c-98b8-4650-9abd-cde7bfa021ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825864981-172.17.0.17-1595306744645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39918,DS-48d0b2b8-cff6-4227-94c9-b17795a170c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-36e51fa4-2044-475d-84ea-9ec6268dbf41,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-bac83cc8-2ef4-4a5e-9c0e-86baa245e968,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-5567ac0c-cde9-423c-9959-94a6291dfb16,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-c0655b41-64ed-4670-af06-6243b0c2da75,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-59ad3063-ae77-4741-86da-ac612c448445,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-5f0f8db9-f45e-4b75-b6cb-61250de12bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-c184e85c-98b8-4650-9abd-cde7bfa021ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356233923-172.17.0.17-1595306837965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-d48a086b-d5f3-4aaf-8334-ebbb5a63134c,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-72501592-21da-4502-adc6-04da910a14f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-edc9a8ab-6dbc-42e5-be8a-add5b4005b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-05803c9c-76a9-42b4-bb45-627af1de710b,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-172f4bdd-0e99-4faa-b122-0776d2573f63,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-22c77393-61e1-44bc-8f89-fae2cd4120cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-6762f6cd-6243-411e-b0d3-5dd92e1e1e72,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-35618247-af4b-4a57-a2c6-29f5bcbab1c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356233923-172.17.0.17-1595306837965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-d48a086b-d5f3-4aaf-8334-ebbb5a63134c,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-72501592-21da-4502-adc6-04da910a14f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-edc9a8ab-6dbc-42e5-be8a-add5b4005b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-05803c9c-76a9-42b4-bb45-627af1de710b,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-172f4bdd-0e99-4faa-b122-0776d2573f63,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-22c77393-61e1-44bc-8f89-fae2cd4120cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-6762f6cd-6243-411e-b0d3-5dd92e1e1e72,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-35618247-af4b-4a57-a2c6-29f5bcbab1c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222974041-172.17.0.17-1595306972367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46109,DS-128e69a4-8bdb-4b1a-896b-d7deaa2ced37,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-1e9b1935-d546-40d6-93e0-fb7769cbeb54,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-46accc6e-b399-4e7c-a9b9-b329fa99855f,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-3eff95d6-e1a4-4c7b-8914-69bb47e6a4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-fb234dc1-54cf-4482-bda1-2482851435d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-93bcd3be-ab5c-4598-8156-700276f0d164,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-3af595ef-2f19-4917-9917-ca5ef8d457e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-006cdddf-7b21-406a-95a5-3a1295bdecdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222974041-172.17.0.17-1595306972367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46109,DS-128e69a4-8bdb-4b1a-896b-d7deaa2ced37,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-1e9b1935-d546-40d6-93e0-fb7769cbeb54,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-46accc6e-b399-4e7c-a9b9-b329fa99855f,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-3eff95d6-e1a4-4c7b-8914-69bb47e6a4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-fb234dc1-54cf-4482-bda1-2482851435d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-93bcd3be-ab5c-4598-8156-700276f0d164,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-3af595ef-2f19-4917-9917-ca5ef8d457e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-006cdddf-7b21-406a-95a5-3a1295bdecdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616046585-172.17.0.17-1595307811212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-07ba2b59-66bb-4f3e-b7e9-66c8cb321115,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-43dacf68-ce23-4d9d-b6cc-76323d8035bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-866a8145-aff2-4e1e-ac8b-30e478eacd03,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-efa69e3a-ef8e-4d9e-80f4-411f8826949b,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-0ec86212-6cd5-4f69-89f3-75a0cf77ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-37bde181-6108-4d59-8141-d4c9da63c3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-01cf47e5-2aa4-40b2-a2c8-40882dc53e40,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-4f876217-8950-49e0-bd18-97ed2b8d76d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616046585-172.17.0.17-1595307811212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-07ba2b59-66bb-4f3e-b7e9-66c8cb321115,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-43dacf68-ce23-4d9d-b6cc-76323d8035bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-866a8145-aff2-4e1e-ac8b-30e478eacd03,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-efa69e3a-ef8e-4d9e-80f4-411f8826949b,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-0ec86212-6cd5-4f69-89f3-75a0cf77ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-37bde181-6108-4d59-8141-d4c9da63c3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-01cf47e5-2aa4-40b2-a2c8-40882dc53e40,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-4f876217-8950-49e0-bd18-97ed2b8d76d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566210305-172.17.0.17-1595307868810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-3fb32572-8abf-43d5-999f-3ba056c8f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-05f3c500-a2c1-43e8-a537-129f51228d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-8ebcc936-6cce-4730-a4fb-430a6dcf4355,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-0182bab9-a9f8-4468-a89d-6246c16f1c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-70634ad6-54aa-48a5-956e-ad598eec0d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-4082e11c-9cc1-42d0-838f-2c2e902fdaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-6b4889c0-39f7-4d3c-b797-1d393017ab20,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-38545b9a-52e5-4770-8672-23a8d9287eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566210305-172.17.0.17-1595307868810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-3fb32572-8abf-43d5-999f-3ba056c8f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-05f3c500-a2c1-43e8-a537-129f51228d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-8ebcc936-6cce-4730-a4fb-430a6dcf4355,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-0182bab9-a9f8-4468-a89d-6246c16f1c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-70634ad6-54aa-48a5-956e-ad598eec0d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-4082e11c-9cc1-42d0-838f-2c2e902fdaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-6b4889c0-39f7-4d3c-b797-1d393017ab20,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-38545b9a-52e5-4770-8672-23a8d9287eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75930540-172.17.0.17-1595308085790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44833,DS-d0b1752e-5c64-4fb8-a725-232a478ba2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-cf1d93d5-cf56-48db-8e55-1c0684ecf67d,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-9b5a7989-2d24-449f-acbd-48eefd47533f,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-e55bc280-6adb-49bb-9dc6-7c1bf881231d,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-555d44ca-2169-4cdf-a4ff-61e97af99b97,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-541b2284-8d06-4e2b-80a9-4bc7d0059dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-141e3d6f-46e3-470f-ab0a-2b7b1321d416,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-d6717da0-6bb4-46e2-afdc-359c8bbc35b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75930540-172.17.0.17-1595308085790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44833,DS-d0b1752e-5c64-4fb8-a725-232a478ba2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-cf1d93d5-cf56-48db-8e55-1c0684ecf67d,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-9b5a7989-2d24-449f-acbd-48eefd47533f,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-e55bc280-6adb-49bb-9dc6-7c1bf881231d,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-555d44ca-2169-4cdf-a4ff-61e97af99b97,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-541b2284-8d06-4e2b-80a9-4bc7d0059dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-141e3d6f-46e3-470f-ab0a-2b7b1321d416,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-d6717da0-6bb4-46e2-afdc-359c8bbc35b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872756022-172.17.0.17-1595308667542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41875,DS-714f1e9b-47d2-4d58-b6d5-24e103e62eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-2718aa71-50b2-4d32-9341-479741a7f87d,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-33d5c2ac-aef6-4e95-831d-ecc65e16eb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-b050a70d-1e47-4d27-bb95-bf733ebbd5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-ee0266dc-87b6-4200-8cb2-202efea7f0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-ef378660-2f0b-41aa-a05b-bd61a5b764d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-0f6afd4b-6162-4e4d-93d0-8654fa97ce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-462fc23b-e5fb-4a5c-8aef-a7fb90ae5cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872756022-172.17.0.17-1595308667542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41875,DS-714f1e9b-47d2-4d58-b6d5-24e103e62eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-2718aa71-50b2-4d32-9341-479741a7f87d,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-33d5c2ac-aef6-4e95-831d-ecc65e16eb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-b050a70d-1e47-4d27-bb95-bf733ebbd5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-ee0266dc-87b6-4200-8cb2-202efea7f0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-ef378660-2f0b-41aa-a05b-bd61a5b764d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-0f6afd4b-6162-4e4d-93d0-8654fa97ce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-462fc23b-e5fb-4a5c-8aef-a7fb90ae5cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007132493-172.17.0.17-1595308970703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35567,DS-148302b0-d571-4b3f-9ed9-68c0b5c3dac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-92aaf028-ce13-499a-83ac-e36d8be3ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-67c64383-2245-4365-b9d0-a8eea678bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-be63eae0-fb2b-460d-8513-2455c712a2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-8087b7c9-0b99-4040-be75-6aca8dbd7ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-48e94816-6b60-4772-8d5f-735480bb40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-4dd647a0-ae07-4824-a2f7-d2b5371b80ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-2a0b0be8-f596-4c4a-a387-4bbd11d8cf44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007132493-172.17.0.17-1595308970703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35567,DS-148302b0-d571-4b3f-9ed9-68c0b5c3dac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-92aaf028-ce13-499a-83ac-e36d8be3ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-67c64383-2245-4365-b9d0-a8eea678bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-be63eae0-fb2b-460d-8513-2455c712a2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-8087b7c9-0b99-4040-be75-6aca8dbd7ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-48e94816-6b60-4772-8d5f-735480bb40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-4dd647a0-ae07-4824-a2f7-d2b5371b80ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-2a0b0be8-f596-4c4a-a387-4bbd11d8cf44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532724638-172.17.0.17-1595309037177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41386,DS-6f1f4391-e1c6-4f3c-80ef-158f4c7dc880,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-c9a886bc-634f-4fac-8f67-0bb032659836,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-4f63c060-d80c-42a2-8f25-4ade5e48e572,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-bd24cec3-6c1b-4a97-a2b4-5eae99115553,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-9c8d11cd-4f52-4901-baf3-cad93844bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-88613bd0-018c-4c6e-89ef-17cd1323a8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-10a37dec-bb89-43a0-a08a-bd365256f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-5aadb561-2fad-4e25-b0b6-a3aca242de3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532724638-172.17.0.17-1595309037177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41386,DS-6f1f4391-e1c6-4f3c-80ef-158f4c7dc880,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-c9a886bc-634f-4fac-8f67-0bb032659836,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-4f63c060-d80c-42a2-8f25-4ade5e48e572,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-bd24cec3-6c1b-4a97-a2b4-5eae99115553,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-9c8d11cd-4f52-4901-baf3-cad93844bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-88613bd0-018c-4c6e-89ef-17cd1323a8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-10a37dec-bb89-43a0-a08a-bd365256f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-5aadb561-2fad-4e25-b0b6-a3aca242de3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119682143-172.17.0.17-1595309871819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-f208351a-0833-4158-bd95-04673c8ab53c,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-d8fa0b5e-2259-4f09-b6c1-c5f84fe9a7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-6af545b5-7d96-497d-99e4-3ae6c0b01baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-2d0956d6-bc67-4a1d-a848-6b654fe2b50c,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-abf1fe74-a6d3-4ad9-a2e8-3be549538652,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-996df708-91e0-4a0e-b91c-2fbc0e934d80,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-7c76be96-1d3a-4a0c-8536-4e77f93ae9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-0b507504-e6f3-44bd-a749-88ab1d5dbda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119682143-172.17.0.17-1595309871819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-f208351a-0833-4158-bd95-04673c8ab53c,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-d8fa0b5e-2259-4f09-b6c1-c5f84fe9a7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-6af545b5-7d96-497d-99e4-3ae6c0b01baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-2d0956d6-bc67-4a1d-a848-6b654fe2b50c,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-abf1fe74-a6d3-4ad9-a2e8-3be549538652,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-996df708-91e0-4a0e-b91c-2fbc0e934d80,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-7c76be96-1d3a-4a0c-8536-4e77f93ae9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-0b507504-e6f3-44bd-a749-88ab1d5dbda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106604251-172.17.0.17-1595309973000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46802,DS-2b9c0eb8-25f6-4993-bee0-6840c4a07301,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-25c800e4-24f7-477c-b981-98b088dbdc89,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-451e3b26-fb32-4f94-b001-2425e04a7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-5eb98e39-6b35-4115-8e80-680a79ccc164,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-ff758606-3144-4009-81db-a2848b7a31fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-d8a10a44-76cb-4bce-aff4-23c056d31ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-5237f5c7-227e-4591-9995-ea81abe78d55,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-fce3ede4-d8a7-418a-904e-b410f821a0a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106604251-172.17.0.17-1595309973000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46802,DS-2b9c0eb8-25f6-4993-bee0-6840c4a07301,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-25c800e4-24f7-477c-b981-98b088dbdc89,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-451e3b26-fb32-4f94-b001-2425e04a7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-5eb98e39-6b35-4115-8e80-680a79ccc164,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-ff758606-3144-4009-81db-a2848b7a31fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-d8a10a44-76cb-4bce-aff4-23c056d31ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-5237f5c7-227e-4591-9995-ea81abe78d55,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-fce3ede4-d8a7-418a-904e-b410f821a0a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613924782-172.17.0.17-1595310010728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-798d3975-28aa-4fae-8a7b-daf9892c8fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-f51b1537-3126-43f6-880c-974a91329f00,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-ca4d706e-200a-47f1-bbbd-1c93e208a444,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-a0ca7698-faef-475e-b0ba-27f79ed1e48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-6e41e61a-8af1-49b9-8514-89eae1a897ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-b7915b4f-6c8d-416f-90ad-891991ddbd40,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-b1fad7cc-06fb-4ee8-b030-84f1568788c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-7d62a229-6b84-48e9-9c05-28559a377e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613924782-172.17.0.17-1595310010728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-798d3975-28aa-4fae-8a7b-daf9892c8fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-f51b1537-3126-43f6-880c-974a91329f00,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-ca4d706e-200a-47f1-bbbd-1c93e208a444,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-a0ca7698-faef-475e-b0ba-27f79ed1e48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-6e41e61a-8af1-49b9-8514-89eae1a897ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-b7915b4f-6c8d-416f-90ad-891991ddbd40,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-b1fad7cc-06fb-4ee8-b030-84f1568788c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-7d62a229-6b84-48e9-9c05-28559a377e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168714248-172.17.0.17-1595310117480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-c6b4ee87-ec45-4fc3-9b0c-a131e8f658f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-e6c4b788-9650-4b0f-b0a0-cdec48f48742,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-ef6fcc6c-35d9-438e-aef6-3a1f6c6c4582,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-d377eec8-b91a-4a54-8e02-d01e3a623ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-8f494fde-a06b-4382-b7ad-70f982480100,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-8fed9c8d-d014-4870-8bf9-7da1063ad950,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-dfa55083-5fa2-49d4-9a84-090c52e3dc50,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-378979d4-157a-4ce8-82a9-1756df9f2c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168714248-172.17.0.17-1595310117480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-c6b4ee87-ec45-4fc3-9b0c-a131e8f658f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-e6c4b788-9650-4b0f-b0a0-cdec48f48742,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-ef6fcc6c-35d9-438e-aef6-3a1f6c6c4582,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-d377eec8-b91a-4a54-8e02-d01e3a623ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-8f494fde-a06b-4382-b7ad-70f982480100,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-8fed9c8d-d014-4870-8bf9-7da1063ad950,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-dfa55083-5fa2-49d4-9a84-090c52e3dc50,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-378979d4-157a-4ce8-82a9-1756df9f2c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5084
