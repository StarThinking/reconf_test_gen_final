reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430395251-172.17.0.20-1595379112209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38054,DS-9db354a3-0452-4a71-9099-ca4738c78756,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-48f3166f-3aa0-421f-a423-a3a66225bb56,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-21944847-054b-4b2e-908e-1eb1da0f9bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-457cf060-3c75-4b78-a9db-b228499d60ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-29e50ad1-0c21-44eb-a0d6-78501a71efbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-e320fa94-58d7-4102-8d76-60ef90e4d700,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-b7f764e2-8f1a-4759-9b27-8abc748fcf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-99a7085c-b45d-4d89-85f5-9e69f0af8dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430395251-172.17.0.20-1595379112209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38054,DS-9db354a3-0452-4a71-9099-ca4738c78756,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-48f3166f-3aa0-421f-a423-a3a66225bb56,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-21944847-054b-4b2e-908e-1eb1da0f9bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-457cf060-3c75-4b78-a9db-b228499d60ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-29e50ad1-0c21-44eb-a0d6-78501a71efbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-e320fa94-58d7-4102-8d76-60ef90e4d700,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-b7f764e2-8f1a-4759-9b27-8abc748fcf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-99a7085c-b45d-4d89-85f5-9e69f0af8dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994754649-172.17.0.20-1595379410069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33124,DS-9be62634-2aee-45a5-85b6-268ba88d0471,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-8e5c850f-9035-4d32-a3ba-55d38c87b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-073a6b13-443d-4750-8f5d-b5f1db9c8775,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-483c5a4a-6536-410f-a1f3-0ff83512d939,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-51a5e846-9d52-4bd7-af3e-21753d2ba5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-5a6acbd9-fc7b-4fa8-aaa8-18744a14c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-283559fd-f0b5-4a92-85b9-e275d060528e,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-c7040ce5-e4ea-4f6c-a42d-412100e6d530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994754649-172.17.0.20-1595379410069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33124,DS-9be62634-2aee-45a5-85b6-268ba88d0471,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-8e5c850f-9035-4d32-a3ba-55d38c87b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-073a6b13-443d-4750-8f5d-b5f1db9c8775,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-483c5a4a-6536-410f-a1f3-0ff83512d939,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-51a5e846-9d52-4bd7-af3e-21753d2ba5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-5a6acbd9-fc7b-4fa8-aaa8-18744a14c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-283559fd-f0b5-4a92-85b9-e275d060528e,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-c7040ce5-e4ea-4f6c-a42d-412100e6d530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063522150-172.17.0.20-1595379666643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-31aa2a87-7bd9-4441-8bea-a7f8a0938d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-8344119d-fdaa-4267-9616-ec8e5eebf59f,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-fdf9d8c7-70a9-49be-b7ab-314b2c43dc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-a49b6131-61e8-49ee-bcab-4c060d45e449,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-a228ea7e-9908-4773-a5b9-eece4fe8f6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-9a1549db-d257-441f-b239-fb86d92f77c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-a5dcc02a-afbe-4c47-959e-8c0c81fdc635,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-10df2f7e-4ba1-44e1-b6c4-20f78e88a038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063522150-172.17.0.20-1595379666643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-31aa2a87-7bd9-4441-8bea-a7f8a0938d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-8344119d-fdaa-4267-9616-ec8e5eebf59f,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-fdf9d8c7-70a9-49be-b7ab-314b2c43dc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-a49b6131-61e8-49ee-bcab-4c060d45e449,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-a228ea7e-9908-4773-a5b9-eece4fe8f6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-9a1549db-d257-441f-b239-fb86d92f77c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-a5dcc02a-afbe-4c47-959e-8c0c81fdc635,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-10df2f7e-4ba1-44e1-b6c4-20f78e88a038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775819078-172.17.0.20-1595380260716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-f4fe253d-850a-455f-9fc5-2374e58b1145,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-6ab48359-f3a4-42e5-9efe-b228ab4197bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-6b117d4b-35df-4fb6-b73a-328b571581e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-40a99670-d9d1-4c50-8730-55a0240466f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-83c4d1db-ad3e-468b-a184-1752083bc420,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-d21a75ac-c2ab-482a-b1e0-8d789d285580,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-cd40738b-8f2f-4feb-89d7-40055d623860,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-05985467-a8fa-498b-a66c-923cd46bc915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775819078-172.17.0.20-1595380260716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-f4fe253d-850a-455f-9fc5-2374e58b1145,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-6ab48359-f3a4-42e5-9efe-b228ab4197bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-6b117d4b-35df-4fb6-b73a-328b571581e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-40a99670-d9d1-4c50-8730-55a0240466f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-83c4d1db-ad3e-468b-a184-1752083bc420,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-d21a75ac-c2ab-482a-b1e0-8d789d285580,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-cd40738b-8f2f-4feb-89d7-40055d623860,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-05985467-a8fa-498b-a66c-923cd46bc915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629759844-172.17.0.20-1595381268463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-3d6110be-1351-4d62-8430-dec95ada5ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-a5070c06-1adb-41a1-ae87-5ddc29a78f07,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-415adae9-32dd-4ea5-b89a-2551650a2eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-adab610d-7156-43a0-8b53-51ce633c8a51,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-9cdc4e3c-0ac7-4455-a2c0-1a7cc25edcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-3e8a24b1-4fae-4bdb-ad39-ad8f8500402d,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-1845658f-b985-415b-b50f-ce6bad8df70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-34522b1f-2797-48e4-a740-694096c7bbfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629759844-172.17.0.20-1595381268463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-3d6110be-1351-4d62-8430-dec95ada5ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-a5070c06-1adb-41a1-ae87-5ddc29a78f07,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-415adae9-32dd-4ea5-b89a-2551650a2eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-adab610d-7156-43a0-8b53-51ce633c8a51,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-9cdc4e3c-0ac7-4455-a2c0-1a7cc25edcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-3e8a24b1-4fae-4bdb-ad39-ad8f8500402d,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-1845658f-b985-415b-b50f-ce6bad8df70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-34522b1f-2797-48e4-a740-694096c7bbfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833174621-172.17.0.20-1595381300091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-a3ca7ebd-26c9-4c8c-ad7d-ca9378eb7068,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-017af348-5ac8-479f-b7f2-a262b13a0388,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-032c1903-06c4-4a53-a076-7218d36ea6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-edeaa9fe-0395-4668-933e-fab6f032db97,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-2c44ab8b-6cd1-435d-ac01-c5c1db775c04,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-bed3f923-67ba-407d-9e65-a67c44fe3fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-d6825a26-00a0-4426-a2fa-cc6cad72f41e,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-1a922e52-c5cc-42d3-b28d-d5c917fa380b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833174621-172.17.0.20-1595381300091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-a3ca7ebd-26c9-4c8c-ad7d-ca9378eb7068,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-017af348-5ac8-479f-b7f2-a262b13a0388,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-032c1903-06c4-4a53-a076-7218d36ea6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-edeaa9fe-0395-4668-933e-fab6f032db97,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-2c44ab8b-6cd1-435d-ac01-c5c1db775c04,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-bed3f923-67ba-407d-9e65-a67c44fe3fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-d6825a26-00a0-4426-a2fa-cc6cad72f41e,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-1a922e52-c5cc-42d3-b28d-d5c917fa380b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567052610-172.17.0.20-1595382233980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38171,DS-6132bf0c-04c9-4c76-a709-d92476f07532,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-4db574a4-ee5f-4452-af6b-c74c78442fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-c9e86fb4-3cba-4c00-988a-6469cdb95608,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-cbdc553d-cd03-43d0-9d6e-e479ff298ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-382bc108-98a2-428c-b53d-5a3d8f9219e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-d593a3f4-3161-4ede-9961-bf8b32e43f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-3f292af0-5e04-4cdb-aa02-560cc4b49cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-1d111e20-e7ed-4630-98f1-02fff2f30e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567052610-172.17.0.20-1595382233980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38171,DS-6132bf0c-04c9-4c76-a709-d92476f07532,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-4db574a4-ee5f-4452-af6b-c74c78442fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-c9e86fb4-3cba-4c00-988a-6469cdb95608,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-cbdc553d-cd03-43d0-9d6e-e479ff298ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-382bc108-98a2-428c-b53d-5a3d8f9219e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-d593a3f4-3161-4ede-9961-bf8b32e43f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-3f292af0-5e04-4cdb-aa02-560cc4b49cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-1d111e20-e7ed-4630-98f1-02fff2f30e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588184638-172.17.0.20-1595382336879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35991,DS-997e9955-97ef-4df6-abec-5b63fff423d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-7aacf3b7-7462-45e4-9cca-d7c860095b65,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-1e109c95-9e7f-4378-813c-411e565e974e,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-45364f31-b050-41e6-887f-96ddf2d09968,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-a1bc5e7f-897d-4f24-970b-0c83c38254bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-195ed09b-9411-4a47-965f-f6d087287aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-eb5e20d8-6f85-493c-b772-925ff4e44120,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-64a0ee06-df24-45c3-9426-15b1bb801417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588184638-172.17.0.20-1595382336879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35991,DS-997e9955-97ef-4df6-abec-5b63fff423d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-7aacf3b7-7462-45e4-9cca-d7c860095b65,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-1e109c95-9e7f-4378-813c-411e565e974e,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-45364f31-b050-41e6-887f-96ddf2d09968,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-a1bc5e7f-897d-4f24-970b-0c83c38254bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-195ed09b-9411-4a47-965f-f6d087287aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-eb5e20d8-6f85-493c-b772-925ff4e44120,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-64a0ee06-df24-45c3-9426-15b1bb801417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573973217-172.17.0.20-1595382551982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-1e4df7e8-392c-45bf-a70a-25133a0815f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-900c994a-b806-4e8e-b5b0-8378e431af8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-9991fc3a-1198-4c62-9aa4-1aa002516904,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-7c354e9c-bca9-4ecf-a54d-6a455cc7e49c,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-d5bc98bc-fc0c-4a54-aeae-35beefba7e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-f5bbc482-3c6e-4687-8e0c-57a3aa163bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-a8163d87-4dbf-4fc1-af3d-8a98c1bf7d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-7a3e578a-a75b-473b-abdb-ac09e223b973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573973217-172.17.0.20-1595382551982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-1e4df7e8-392c-45bf-a70a-25133a0815f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-900c994a-b806-4e8e-b5b0-8378e431af8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-9991fc3a-1198-4c62-9aa4-1aa002516904,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-7c354e9c-bca9-4ecf-a54d-6a455cc7e49c,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-d5bc98bc-fc0c-4a54-aeae-35beefba7e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-f5bbc482-3c6e-4687-8e0c-57a3aa163bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-a8163d87-4dbf-4fc1-af3d-8a98c1bf7d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-7a3e578a-a75b-473b-abdb-ac09e223b973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634638095-172.17.0.20-1595383079204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34663,DS-a05ce24d-a250-44e2-b84d-8f1287d35392,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-eb24cccc-2fe1-4e55-bb7b-b58dd2c48841,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-f12eada3-e607-4a28-8b9f-f7e42a33c757,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-4c0681be-d264-4f2b-a9c0-2d34e9888a65,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-008a0023-1fb4-4687-837a-e59977b158db,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-ed3c6c97-fa0d-45d6-adbb-6a1449ba3d93,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-18cee57e-ab75-4948-8c2c-d8460181cbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-f919f636-074d-4841-9c4d-4acc04b4af03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634638095-172.17.0.20-1595383079204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34663,DS-a05ce24d-a250-44e2-b84d-8f1287d35392,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-eb24cccc-2fe1-4e55-bb7b-b58dd2c48841,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-f12eada3-e607-4a28-8b9f-f7e42a33c757,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-4c0681be-d264-4f2b-a9c0-2d34e9888a65,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-008a0023-1fb4-4687-837a-e59977b158db,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-ed3c6c97-fa0d-45d6-adbb-6a1449ba3d93,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-18cee57e-ab75-4948-8c2c-d8460181cbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-f919f636-074d-4841-9c4d-4acc04b4af03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 4822
