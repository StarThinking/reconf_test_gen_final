reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326487563-172.17.0.8-1595329040597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40978,DS-7dd6f4af-264a-4fe0-83e1-0683200fe9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-eb18d837-fe5e-44d0-8dba-687048916746,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-793f70f6-ea19-45bb-83cd-08e5b796f3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-c044e7cb-c443-472c-bbcb-1fc9ab999996,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-77424493-073a-415c-bc4c-84fcbc10e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-f6e60f7d-dded-4674-8aaf-605eeaff88db,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-c9be19dd-e07d-4d51-a271-bfe7b49d3f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-81bd6e4d-b7a4-4360-b0f3-e27212894fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326487563-172.17.0.8-1595329040597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40978,DS-7dd6f4af-264a-4fe0-83e1-0683200fe9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-eb18d837-fe5e-44d0-8dba-687048916746,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-793f70f6-ea19-45bb-83cd-08e5b796f3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-c044e7cb-c443-472c-bbcb-1fc9ab999996,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-77424493-073a-415c-bc4c-84fcbc10e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-f6e60f7d-dded-4674-8aaf-605eeaff88db,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-c9be19dd-e07d-4d51-a271-bfe7b49d3f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-81bd6e4d-b7a4-4360-b0f3-e27212894fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62137521-172.17.0.8-1595329509038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36397,DS-20f1275f-ac6b-4169-85f8-d729aeaf6ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-a123cffa-228c-44b8-80f2-0a8565483a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-2a5de11b-7985-459d-83ed-129ba71b599a,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-9b1e6489-ef59-4048-845e-ad235780c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-3961660a-bad6-4ee2-933a-f01e50680669,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-c724a032-ae51-4491-853d-c59b102808eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-b85e28a9-c690-43f5-bb0b-3a331e0f84cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-fc34f604-c6a7-42b0-a25c-b1e74854928f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62137521-172.17.0.8-1595329509038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36397,DS-20f1275f-ac6b-4169-85f8-d729aeaf6ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-a123cffa-228c-44b8-80f2-0a8565483a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-2a5de11b-7985-459d-83ed-129ba71b599a,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-9b1e6489-ef59-4048-845e-ad235780c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-3961660a-bad6-4ee2-933a-f01e50680669,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-c724a032-ae51-4491-853d-c59b102808eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-b85e28a9-c690-43f5-bb0b-3a331e0f84cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-fc34f604-c6a7-42b0-a25c-b1e74854928f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806821775-172.17.0.8-1595329922332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37227,DS-793fb983-1d01-4a54-8745-33316471f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-6594e453-17b2-406d-b22c-92b144b1ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-85293dd4-c7b6-48aa-988a-5dd83819cd74,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-c110b88c-8aa2-4e44-bee8-855ebcd3c479,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-ee13f1d8-6a11-4a16-957a-c62b93420507,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-09bd15df-8bed-41a5-8e63-e88a43ad7833,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-1db94dd3-8b8f-479f-be2d-6a9595bee342,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-5f85b7d8-eb9a-4464-bebd-b33d92df2c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806821775-172.17.0.8-1595329922332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37227,DS-793fb983-1d01-4a54-8745-33316471f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-6594e453-17b2-406d-b22c-92b144b1ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-85293dd4-c7b6-48aa-988a-5dd83819cd74,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-c110b88c-8aa2-4e44-bee8-855ebcd3c479,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-ee13f1d8-6a11-4a16-957a-c62b93420507,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-09bd15df-8bed-41a5-8e63-e88a43ad7833,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-1db94dd3-8b8f-479f-be2d-6a9595bee342,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-5f85b7d8-eb9a-4464-bebd-b33d92df2c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827885105-172.17.0.8-1595330143595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46108,DS-9f2401e6-afb6-4def-823b-bcb71cfd862e,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-f4f2fd3f-ebe1-44f8-8248-f764eb9812a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-4e4ac7a7-8dfd-4e34-babc-03e1ebfa8f07,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-2dcebeba-9ab4-429f-9aa9-4d9afd534ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-671448bc-c38c-4b02-a9d9-cd1d6b2a7eed,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-b4818ee7-b391-422a-9986-ddbc07612da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-94d59c1b-96f1-4a9f-8138-eb966081700b,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1f1c679e-0a39-4af8-87e4-da1076dd956c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827885105-172.17.0.8-1595330143595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46108,DS-9f2401e6-afb6-4def-823b-bcb71cfd862e,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-f4f2fd3f-ebe1-44f8-8248-f764eb9812a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-4e4ac7a7-8dfd-4e34-babc-03e1ebfa8f07,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-2dcebeba-9ab4-429f-9aa9-4d9afd534ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-671448bc-c38c-4b02-a9d9-cd1d6b2a7eed,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-b4818ee7-b391-422a-9986-ddbc07612da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-94d59c1b-96f1-4a9f-8138-eb966081700b,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1f1c679e-0a39-4af8-87e4-da1076dd956c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187094271-172.17.0.8-1595331566036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-01096343-0030-48a7-82d7-e6157df16f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-c1c24822-9912-48db-a6b4-6bd6cface690,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-09451044-ef44-4247-8064-ab604e736a94,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-61724e26-c52b-40c4-b273-f195c6c6cd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-dbb1b3c9-cec1-40e6-9bcf-e4374bf9d249,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-29b97445-c028-48e4-b5f9-a628146c235c,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-e67fc37c-9f91-4215-bf74-f212e50d7b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-1e120d87-69ee-4610-97aa-9f0cf1ca7f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187094271-172.17.0.8-1595331566036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-01096343-0030-48a7-82d7-e6157df16f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-c1c24822-9912-48db-a6b4-6bd6cface690,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-09451044-ef44-4247-8064-ab604e736a94,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-61724e26-c52b-40c4-b273-f195c6c6cd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-dbb1b3c9-cec1-40e6-9bcf-e4374bf9d249,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-29b97445-c028-48e4-b5f9-a628146c235c,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-e67fc37c-9f91-4215-bf74-f212e50d7b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-1e120d87-69ee-4610-97aa-9f0cf1ca7f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526298352-172.17.0.8-1595331756432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35728,DS-8fcfddf7-c3a7-4a3d-957c-c0cea6cba240,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-e694432e-2e32-46a9-b414-749e0d2b0584,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-5182cc04-a8cb-4f00-9198-c4a75629a583,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-67bf9127-5fbb-4931-91d3-609632a853c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-88d3d111-68f0-42eb-9e42-674d28849458,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-9e86de4a-c6ae-4e4d-9e8a-dd877bcc8c12,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-0d0c6e0e-d891-4580-ba08-ed5b994cb0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-d9014c99-f93b-44c0-a522-49e2c2570571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526298352-172.17.0.8-1595331756432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35728,DS-8fcfddf7-c3a7-4a3d-957c-c0cea6cba240,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-e694432e-2e32-46a9-b414-749e0d2b0584,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-5182cc04-a8cb-4f00-9198-c4a75629a583,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-67bf9127-5fbb-4931-91d3-609632a853c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-88d3d111-68f0-42eb-9e42-674d28849458,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-9e86de4a-c6ae-4e4d-9e8a-dd877bcc8c12,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-0d0c6e0e-d891-4580-ba08-ed5b994cb0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-d9014c99-f93b-44c0-a522-49e2c2570571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405840435-172.17.0.8-1595332141835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-a577911f-8645-4e14-872e-caf08b9ba018,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-a5b7cd1f-b713-4bea-aaaa-62492c2b4d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-41232b2b-2c19-4fdf-822f-bd8633be8719,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-0d23a977-5415-44a4-95ab-8ea4bc3b9ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-60126c17-53ba-4593-b358-08c23e7e82f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-136e6c43-4150-4d60-b70d-ae3eb7705835,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-66a812a3-b60e-4920-86ee-7bd03eb00314,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-0edf1a8c-2231-43af-bc36-991309a12177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405840435-172.17.0.8-1595332141835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-a577911f-8645-4e14-872e-caf08b9ba018,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-a5b7cd1f-b713-4bea-aaaa-62492c2b4d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-41232b2b-2c19-4fdf-822f-bd8633be8719,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-0d23a977-5415-44a4-95ab-8ea4bc3b9ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-60126c17-53ba-4593-b358-08c23e7e82f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-136e6c43-4150-4d60-b70d-ae3eb7705835,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-66a812a3-b60e-4920-86ee-7bd03eb00314,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-0edf1a8c-2231-43af-bc36-991309a12177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151309420-172.17.0.8-1595332260649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-7f236427-2cbd-4a0b-92f3-d97d2c7abc76,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-bb71558d-cbb3-43cd-8755-d575064bf86c,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-1b65c0c9-3561-46a7-83e6-e044435a8a28,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-0da0ee44-c34a-42ff-98b4-bfd0b84b1c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-33d92142-09b3-420e-b373-8047f3beedcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-fa4a9602-b330-4c18-9ce1-11365274aba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-0eb88886-31a9-414c-9049-fd8d97c366c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-af09b0aa-b4c5-4b21-9120-fdd9aa0fa5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151309420-172.17.0.8-1595332260649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-7f236427-2cbd-4a0b-92f3-d97d2c7abc76,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-bb71558d-cbb3-43cd-8755-d575064bf86c,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-1b65c0c9-3561-46a7-83e6-e044435a8a28,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-0da0ee44-c34a-42ff-98b4-bfd0b84b1c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-33d92142-09b3-420e-b373-8047f3beedcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-fa4a9602-b330-4c18-9ce1-11365274aba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-0eb88886-31a9-414c-9049-fd8d97c366c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-af09b0aa-b4c5-4b21-9120-fdd9aa0fa5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655422977-172.17.0.8-1595332415647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34315,DS-f8cb9a5d-84fc-4548-b59e-cd8f1af04fee,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-9d467039-cc45-42d2-b24d-3035fb4a6227,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-bcaceded-842d-49ec-b1cc-00277202dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-47bd3c2a-3826-4a95-b4b8-7d5d464fba51,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-7106047d-7624-48cb-8725-0cb15800c6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-5b5d58e2-4258-4ef9-a100-a956a018befb,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-2d5b6c7c-3ca4-4a37-b670-9f18410bbda1,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-aaf11ad6-6b82-4d41-b555-4e9e915c270f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655422977-172.17.0.8-1595332415647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34315,DS-f8cb9a5d-84fc-4548-b59e-cd8f1af04fee,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-9d467039-cc45-42d2-b24d-3035fb4a6227,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-bcaceded-842d-49ec-b1cc-00277202dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-47bd3c2a-3826-4a95-b4b8-7d5d464fba51,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-7106047d-7624-48cb-8725-0cb15800c6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-5b5d58e2-4258-4ef9-a100-a956a018befb,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-2d5b6c7c-3ca4-4a37-b670-9f18410bbda1,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-aaf11ad6-6b82-4d41-b555-4e9e915c270f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115094895-172.17.0.8-1595332837272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-db7515dc-65e9-4467-9735-7ecdc925af63,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-942ff10f-7d38-45db-b656-8342fe534f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-d6c634b5-3cf2-4fb4-b862-7d2a6b9ad8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-26d95dbd-769b-46d8-8f05-44e8d4cda36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-554e366c-a6ca-49e3-940c-97b2f2c94f56,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-b2baaa47-b73b-4081-9b80-b85ca9862ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-def0be03-3267-4eba-b728-5b010dc262b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-815ad451-d770-4e65-8153-24f5f9e23cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115094895-172.17.0.8-1595332837272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-db7515dc-65e9-4467-9735-7ecdc925af63,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-942ff10f-7d38-45db-b656-8342fe534f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-d6c634b5-3cf2-4fb4-b862-7d2a6b9ad8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-26d95dbd-769b-46d8-8f05-44e8d4cda36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-554e366c-a6ca-49e3-940c-97b2f2c94f56,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-b2baaa47-b73b-4081-9b80-b85ca9862ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-def0be03-3267-4eba-b728-5b010dc262b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-815ad451-d770-4e65-8153-24f5f9e23cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651005281-172.17.0.8-1595333098473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33347,DS-3305c09a-75f6-4dc8-968c-024687e372c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-9c816590-1f7d-42fa-9098-588fa65e34e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-a1e951cb-a3c5-4657-90ec-3f6c84f13b63,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-05622002-ba39-452d-9e34-359cdb3e1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-abfc9328-fd57-478c-a502-17095db7dff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-64bf9971-6e2a-4117-8360-2ea2feb85bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-e24a4429-e9fa-49c2-8e09-42a4f3eaecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-8a7d78eb-b861-4df8-9302-9a450269ae2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651005281-172.17.0.8-1595333098473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33347,DS-3305c09a-75f6-4dc8-968c-024687e372c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-9c816590-1f7d-42fa-9098-588fa65e34e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-a1e951cb-a3c5-4657-90ec-3f6c84f13b63,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-05622002-ba39-452d-9e34-359cdb3e1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-abfc9328-fd57-478c-a502-17095db7dff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-64bf9971-6e2a-4117-8360-2ea2feb85bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-e24a4429-e9fa-49c2-8e09-42a4f3eaecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-8a7d78eb-b861-4df8-9302-9a450269ae2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626118446-172.17.0.8-1595333459685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-252af0d1-6591-4a35-a20d-a8d3498b8f24,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-bc8f4d7b-3910-496e-8522-e32380dd2c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-18a2ec86-f3f8-4c18-99e4-6b1fb2afbb66,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-95b15520-71d5-4539-b58b-f73c03db2eef,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-548c0b7c-c67d-4eee-aec8-a80d750540e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-d426a51e-81b2-4e3e-9a5e-788667eaf758,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-9ca110ff-a130-4064-bbb9-710285159dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-825e7b63-bdc1-4b12-8f0c-896373d4a487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626118446-172.17.0.8-1595333459685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-252af0d1-6591-4a35-a20d-a8d3498b8f24,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-bc8f4d7b-3910-496e-8522-e32380dd2c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-18a2ec86-f3f8-4c18-99e4-6b1fb2afbb66,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-95b15520-71d5-4539-b58b-f73c03db2eef,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-548c0b7c-c67d-4eee-aec8-a80d750540e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-d426a51e-81b2-4e3e-9a5e-788667eaf758,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-9ca110ff-a130-4064-bbb9-710285159dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-825e7b63-bdc1-4b12-8f0c-896373d4a487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611063619-172.17.0.8-1595334127788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-736b9276-182e-4fc3-aa5a-aa0edeb226c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-de2465b8-b22f-4de6-9e13-cf9a31adbdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-088a156e-0703-4946-b5ca-90847a918bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-b9da1998-f042-4a6a-adec-a9cd0bf42425,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-9f04caf2-0e42-4f82-8f45-682e0dabce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-e3f7267a-0fbc-4bff-911c-d86d09da64db,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-eea5b7ca-c006-45b0-b0f0-7aa86c33a86a,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-e4014e50-d0bf-4945-b4a6-2142e7d382f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611063619-172.17.0.8-1595334127788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-736b9276-182e-4fc3-aa5a-aa0edeb226c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-de2465b8-b22f-4de6-9e13-cf9a31adbdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-088a156e-0703-4946-b5ca-90847a918bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-b9da1998-f042-4a6a-adec-a9cd0bf42425,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-9f04caf2-0e42-4f82-8f45-682e0dabce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-e3f7267a-0fbc-4bff-911c-d86d09da64db,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-eea5b7ca-c006-45b0-b0f0-7aa86c33a86a,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-e4014e50-d0bf-4945-b4a6-2142e7d382f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5982
