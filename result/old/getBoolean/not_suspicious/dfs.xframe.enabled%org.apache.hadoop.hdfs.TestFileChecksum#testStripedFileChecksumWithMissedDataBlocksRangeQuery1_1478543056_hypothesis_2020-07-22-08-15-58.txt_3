reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654598674-172.17.0.5-1595407671472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33723,DS-555f10f6-b0f8-449a-922f-d23e821dee96,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-0d5ce4b5-8526-4def-a09b-7d9ffc8faad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-a7c11c76-a1be-42cb-af34-ed2543ca35f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-f5158fff-a75b-456a-8074-168660d0f454,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-82a618b9-dd4b-4212-a5fd-26e2b4a5f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-ad443859-9af9-4ade-be39-7de7af254e83,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-63913379-4a2e-4fd6-b4fe-e0326c037dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-af9c4053-5460-4d0d-9256-6c50b7e8b2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654598674-172.17.0.5-1595407671472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33723,DS-555f10f6-b0f8-449a-922f-d23e821dee96,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-0d5ce4b5-8526-4def-a09b-7d9ffc8faad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-a7c11c76-a1be-42cb-af34-ed2543ca35f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-f5158fff-a75b-456a-8074-168660d0f454,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-82a618b9-dd4b-4212-a5fd-26e2b4a5f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-ad443859-9af9-4ade-be39-7de7af254e83,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-63913379-4a2e-4fd6-b4fe-e0326c037dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-af9c4053-5460-4d0d-9256-6c50b7e8b2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252594642-172.17.0.5-1595408271327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33845,DS-7a3e65bb-d13d-489f-993c-fb85f02ed0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-4a136752-1c2d-46cb-81cb-5356cb17dc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-0e4c2ac4-3fe2-4d73-b07e-303bf03698f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-813e5191-7f3a-413c-9882-3d0ca4c4be49,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-c6770457-5b48-4674-8874-2bc97042d650,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-4bdce60f-8c87-4ed6-b50a-e85347c7e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-3d8f8ddd-1b0a-42b9-a796-da67725bdda4,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-70b86ca8-4d6e-49fc-a517-2268d9b3e605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252594642-172.17.0.5-1595408271327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33845,DS-7a3e65bb-d13d-489f-993c-fb85f02ed0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-4a136752-1c2d-46cb-81cb-5356cb17dc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-0e4c2ac4-3fe2-4d73-b07e-303bf03698f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-813e5191-7f3a-413c-9882-3d0ca4c4be49,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-c6770457-5b48-4674-8874-2bc97042d650,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-4bdce60f-8c87-4ed6-b50a-e85347c7e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-3d8f8ddd-1b0a-42b9-a796-da67725bdda4,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-70b86ca8-4d6e-49fc-a517-2268d9b3e605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980871580-172.17.0.5-1595408570707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32845,DS-9fe158b9-f822-48c4-b93c-992bd47e8d56,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-2c7a4b73-086c-48ca-9f2c-c3decf40a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-a242dd77-1578-4ea3-8940-b2421a940e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-e0bfff9e-f681-403b-9cd4-bce66f7f3fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-b8f7cf6e-5623-4a6c-a0fa-7b844ec40f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-7b3ee2d7-5972-432b-9ee1-ca9279f1c77f,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-ef306a72-8346-4883-bb57-8b3352eb7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-97531258-a622-49d7-b2b4-e7bbd265a20c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980871580-172.17.0.5-1595408570707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32845,DS-9fe158b9-f822-48c4-b93c-992bd47e8d56,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-2c7a4b73-086c-48ca-9f2c-c3decf40a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-a242dd77-1578-4ea3-8940-b2421a940e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-e0bfff9e-f681-403b-9cd4-bce66f7f3fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-b8f7cf6e-5623-4a6c-a0fa-7b844ec40f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-7b3ee2d7-5972-432b-9ee1-ca9279f1c77f,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-ef306a72-8346-4883-bb57-8b3352eb7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-97531258-a622-49d7-b2b4-e7bbd265a20c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46793166-172.17.0.5-1595408657294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45563,DS-ba47a7ee-3535-41b2-8ab3-133bb8b7593c,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-c9848035-0b1f-4abb-843d-15a0664c4fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-1334b083-c8c3-49b0-b204-39e4450fa230,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-1ee167bd-29a8-44f8-a1d9-bd4ccc81793f,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-17892b15-bdc0-4352-bcb0-1e5d98ba7a25,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-6c3456c5-8daf-40b4-9858-7b9a1a6152b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-2c295910-0126-4163-b156-992607ee2344,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-1c4f5d69-2bb6-47d2-a263-9d8229ea7346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46793166-172.17.0.5-1595408657294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45563,DS-ba47a7ee-3535-41b2-8ab3-133bb8b7593c,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-c9848035-0b1f-4abb-843d-15a0664c4fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-1334b083-c8c3-49b0-b204-39e4450fa230,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-1ee167bd-29a8-44f8-a1d9-bd4ccc81793f,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-17892b15-bdc0-4352-bcb0-1e5d98ba7a25,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-6c3456c5-8daf-40b4-9858-7b9a1a6152b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-2c295910-0126-4163-b156-992607ee2344,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-1c4f5d69-2bb6-47d2-a263-9d8229ea7346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672804766-172.17.0.5-1595408744377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38205,DS-bf42f7a0-31ac-4009-add1-88ea9819776d,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-18b1676c-fe2b-453f-972a-9098ceedf6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-14616e75-40b6-4368-a8c8-525a4acc9581,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-e609c92f-4241-40ff-a0fd-6ff55701b304,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-60ac2d4d-73c5-4ed1-884b-93b348aec4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-8dce6528-263d-454a-9304-ff9996f38f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-b3c23178-d653-4907-b762-42fc01657aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-ed253a05-ca31-4bbf-a4ff-9597c0c3e228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672804766-172.17.0.5-1595408744377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38205,DS-bf42f7a0-31ac-4009-add1-88ea9819776d,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-18b1676c-fe2b-453f-972a-9098ceedf6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-14616e75-40b6-4368-a8c8-525a4acc9581,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-e609c92f-4241-40ff-a0fd-6ff55701b304,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-60ac2d4d-73c5-4ed1-884b-93b348aec4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-8dce6528-263d-454a-9304-ff9996f38f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-b3c23178-d653-4907-b762-42fc01657aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-ed253a05-ca31-4bbf-a4ff-9597c0c3e228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750405303-172.17.0.5-1595409705538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39015,DS-60654951-ec53-4c90-b722-7d8d7fd88df2,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-10dedf84-2688-4610-8c9b-e2c6b8271a91,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-c026e036-1b00-422f-a0bd-bbe2cd9d5fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-5cc4e1b5-4805-42c5-8f4a-9e9a177ebe23,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-29d5cad0-06fb-40b3-af12-bf5d1e6f01c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-1bcc76ca-6305-41c9-9b2e-876e66a0035f,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-13e0611f-43b8-411b-9a4e-3b8cde5f5996,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-547755a1-411e-4a17-b88e-1bc821caeba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750405303-172.17.0.5-1595409705538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39015,DS-60654951-ec53-4c90-b722-7d8d7fd88df2,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-10dedf84-2688-4610-8c9b-e2c6b8271a91,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-c026e036-1b00-422f-a0bd-bbe2cd9d5fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-5cc4e1b5-4805-42c5-8f4a-9e9a177ebe23,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-29d5cad0-06fb-40b3-af12-bf5d1e6f01c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-1bcc76ca-6305-41c9-9b2e-876e66a0035f,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-13e0611f-43b8-411b-9a4e-3b8cde5f5996,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-547755a1-411e-4a17-b88e-1bc821caeba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332263818-172.17.0.5-1595410655718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46307,DS-2de4b1d0-691c-42cb-ac27-3c4e3c1d43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-83c73c04-0e69-469d-a5c8-21209bfd93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-fadadbc5-81a7-4a7a-a1e3-983048f23eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-225fbc00-231f-43bf-85b3-7ad0b3f9c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-ef878960-cfe7-4ae5-90d7-61c6c36a0abd,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-93f3beba-c8f4-412c-aa7a-80ab89b5f6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-5a8953c2-26dc-44bf-a01e-ac3b1ba49a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-e0860425-7de2-4176-9bf6-8b6d1d6ce8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332263818-172.17.0.5-1595410655718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46307,DS-2de4b1d0-691c-42cb-ac27-3c4e3c1d43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-83c73c04-0e69-469d-a5c8-21209bfd93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-fadadbc5-81a7-4a7a-a1e3-983048f23eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-225fbc00-231f-43bf-85b3-7ad0b3f9c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-ef878960-cfe7-4ae5-90d7-61c6c36a0abd,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-93f3beba-c8f4-412c-aa7a-80ab89b5f6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-5a8953c2-26dc-44bf-a01e-ac3b1ba49a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-e0860425-7de2-4176-9bf6-8b6d1d6ce8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628091969-172.17.0.5-1595411108355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-db7c164a-bea8-4c7e-84fb-3c066f3a3afd,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-2a1b2213-f453-4f39-a207-a21b2cb7900c,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-2daeefd7-8e24-4bc0-80a6-38c86b7f5335,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-af48f32e-e1b4-48aa-a722-d0dc50b623b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-d6293095-82d0-4800-9a63-9297018f78f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-b9140d5a-fbac-40fb-9667-6eef5f0d8399,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-542a13c0-248a-4afd-aff7-50165c165019,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-43b84d0c-d756-4ac0-bb11-c5685949827a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628091969-172.17.0.5-1595411108355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-db7c164a-bea8-4c7e-84fb-3c066f3a3afd,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-2a1b2213-f453-4f39-a207-a21b2cb7900c,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-2daeefd7-8e24-4bc0-80a6-38c86b7f5335,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-af48f32e-e1b4-48aa-a722-d0dc50b623b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-d6293095-82d0-4800-9a63-9297018f78f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-b9140d5a-fbac-40fb-9667-6eef5f0d8399,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-542a13c0-248a-4afd-aff7-50165c165019,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-43b84d0c-d756-4ac0-bb11-c5685949827a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731558270-172.17.0.5-1595411165421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-4c5cb0f6-f24d-4634-8d25-04ccc1c02d85,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-67e52ab2-5def-4d5a-b350-6239c69f301d,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-06af7f8c-1138-4b42-9c4a-5b80f9f9e549,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-d830f66c-2563-463b-af36-0e06ed1b2848,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-1c5a1220-536e-466c-b2ba-a3029b9f93ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-8dba1782-1b6c-4d00-ba57-8454a4f8b609,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-1a3bd2a1-fc18-4984-a410-1de8f268b433,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-def7d6a3-63d0-49e7-8a51-f09e5f8cb716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731558270-172.17.0.5-1595411165421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-4c5cb0f6-f24d-4634-8d25-04ccc1c02d85,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-67e52ab2-5def-4d5a-b350-6239c69f301d,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-06af7f8c-1138-4b42-9c4a-5b80f9f9e549,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-d830f66c-2563-463b-af36-0e06ed1b2848,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-1c5a1220-536e-466c-b2ba-a3029b9f93ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-8dba1782-1b6c-4d00-ba57-8454a4f8b609,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-1a3bd2a1-fc18-4984-a410-1de8f268b433,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-def7d6a3-63d0-49e7-8a51-f09e5f8cb716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444640505-172.17.0.5-1595411207600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-80236c14-8877-4268-b19c-c185f6b80126,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-3b119253-d6b4-421a-bed8-357a9080e476,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-3c4a523f-cf84-4136-83ab-9ea11a11c88c,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-8b69cb3a-61f1-4aa8-ab40-45a3849afee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-f51db905-46e7-49c5-a121-29030448e2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-75a3bf20-2818-467b-8ccb-2c25707979a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-0b643d74-a8a6-452b-b652-461d9a9ec2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-5941b165-37a9-4781-a4c3-9dfa4971ae32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444640505-172.17.0.5-1595411207600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-80236c14-8877-4268-b19c-c185f6b80126,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-3b119253-d6b4-421a-bed8-357a9080e476,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-3c4a523f-cf84-4136-83ab-9ea11a11c88c,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-8b69cb3a-61f1-4aa8-ab40-45a3849afee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-f51db905-46e7-49c5-a121-29030448e2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-75a3bf20-2818-467b-8ccb-2c25707979a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-0b643d74-a8a6-452b-b652-461d9a9ec2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-5941b165-37a9-4781-a4c3-9dfa4971ae32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038905277-172.17.0.5-1595411601863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-42f29c4a-d9d5-48f9-8011-81f86db60d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-84c55b56-7eb9-4003-9c37-9fd2d073dc78,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-2cc2d770-2e65-4f40-bed9-ad1fc2792fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-1fdb1599-695f-432e-8444-c4ee73aea5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-dbc99f58-6751-4921-bb32-860acfa1d9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-2802af83-abd5-413b-aea9-93479db5d8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-0fec927d-697e-48eb-be0b-1ce940ffbd16,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-750f47d6-d5e0-4485-8a95-ab452d14c8f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038905277-172.17.0.5-1595411601863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-42f29c4a-d9d5-48f9-8011-81f86db60d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-84c55b56-7eb9-4003-9c37-9fd2d073dc78,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-2cc2d770-2e65-4f40-bed9-ad1fc2792fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-1fdb1599-695f-432e-8444-c4ee73aea5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-dbc99f58-6751-4921-bb32-860acfa1d9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-2802af83-abd5-413b-aea9-93479db5d8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-0fec927d-697e-48eb-be0b-1ce940ffbd16,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-750f47d6-d5e0-4485-8a95-ab452d14c8f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394614366-172.17.0.5-1595411635240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37534,DS-e97b342f-e5b9-4325-99b4-75224854b974,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-b63e9219-d86c-4727-93bc-8edff78670bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-0cefb43c-2ae5-4691-93f2-e79fecd419d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-fd523858-5cf3-474f-a806-25bcab2f8586,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-075e1163-e418-4589-ae12-68e9d95a07c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-d5c86289-51f5-4909-93e2-2673caf67dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-27c8ff3c-22d9-4d64-8fd2-bcf983db7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-3b8e2b0b-bdff-4a55-a0c9-92be26e6cefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394614366-172.17.0.5-1595411635240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37534,DS-e97b342f-e5b9-4325-99b4-75224854b974,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-b63e9219-d86c-4727-93bc-8edff78670bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-0cefb43c-2ae5-4691-93f2-e79fecd419d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-fd523858-5cf3-474f-a806-25bcab2f8586,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-075e1163-e418-4589-ae12-68e9d95a07c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-d5c86289-51f5-4909-93e2-2673caf67dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-27c8ff3c-22d9-4d64-8fd2-bcf983db7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-3b8e2b0b-bdff-4a55-a0c9-92be26e6cefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6493
