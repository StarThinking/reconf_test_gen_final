reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872167920-172.17.0.12-1595403501279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-347e81c9-fb78-4d9c-a642-59de560b8ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-37143860-a0b3-4947-bd96-9c6a115e8160,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-fb8438a5-8be1-4551-aeab-751cf4fe48ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a22f3719-30b8-4471-b83c-f55ac88c6162,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-41f00aee-467c-43ce-900c-bdf089799902,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-66a5571f-aec4-4b8c-ac53-5a6230e22d14,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-61facdd0-077a-43b3-b538-cef854f2e4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-b29fed50-b63a-4426-809b-4807dbd05a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872167920-172.17.0.12-1595403501279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-347e81c9-fb78-4d9c-a642-59de560b8ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-37143860-a0b3-4947-bd96-9c6a115e8160,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-fb8438a5-8be1-4551-aeab-751cf4fe48ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a22f3719-30b8-4471-b83c-f55ac88c6162,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-41f00aee-467c-43ce-900c-bdf089799902,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-66a5571f-aec4-4b8c-ac53-5a6230e22d14,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-61facdd0-077a-43b3-b538-cef854f2e4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-b29fed50-b63a-4426-809b-4807dbd05a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30955687-172.17.0.12-1595403560729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-cef20a09-6770-4790-91b2-09416c2691cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-957f9d47-b971-4403-8f93-850302c0909c,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-7af8968f-d80f-4aa6-9344-8b56adfc8488,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-04ce1bbc-f534-4a68-9140-f1c32e91e042,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-467a8276-47d4-4f49-858c-af6e3acd2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-6ce4655e-7621-435b-9e28-5595f640f2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-5684ee01-d65f-4ac7-8f83-da69b5bd535c,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-def3e5d1-c108-44d6-bb4d-4ee042b9f8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30955687-172.17.0.12-1595403560729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-cef20a09-6770-4790-91b2-09416c2691cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-957f9d47-b971-4403-8f93-850302c0909c,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-7af8968f-d80f-4aa6-9344-8b56adfc8488,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-04ce1bbc-f534-4a68-9140-f1c32e91e042,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-467a8276-47d4-4f49-858c-af6e3acd2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-6ce4655e-7621-435b-9e28-5595f640f2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-5684ee01-d65f-4ac7-8f83-da69b5bd535c,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-def3e5d1-c108-44d6-bb4d-4ee042b9f8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375944277-172.17.0.12-1595403897238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37542,DS-d6642db3-1b6b-4ad4-b1b9-91d0652bbb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-cf7f097a-656d-4910-ad8d-efb0390b74d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-091f194c-376b-4f32-9d17-9e39dfadc5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-69ccf8bc-d498-4b60-be9e-1c46e8a17269,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-e083537f-b22a-4293-b0a5-cd405183f190,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-b3718a42-cda9-4b39-ae19-72b7427ef3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-5bdf71b6-ff85-4fa2-a419-799172bfd45a,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-ae1309d5-0c71-4a35-b497-85d1e4aad787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375944277-172.17.0.12-1595403897238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37542,DS-d6642db3-1b6b-4ad4-b1b9-91d0652bbb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-cf7f097a-656d-4910-ad8d-efb0390b74d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-091f194c-376b-4f32-9d17-9e39dfadc5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-69ccf8bc-d498-4b60-be9e-1c46e8a17269,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-e083537f-b22a-4293-b0a5-cd405183f190,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-b3718a42-cda9-4b39-ae19-72b7427ef3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-5bdf71b6-ff85-4fa2-a419-799172bfd45a,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-ae1309d5-0c71-4a35-b497-85d1e4aad787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270713389-172.17.0.12-1595404030872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39209,DS-983f1164-10b5-4b6f-95fc-feb317b36a74,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-87a44d2f-192c-4f78-bfa4-decd6910ab88,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-c2f348a0-872e-4130-8f0c-9844f8c8574c,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-f9103437-b32c-4a46-9e64-dfe84d5582c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-566fd8c0-dd19-45d3-b43e-c90499c9a055,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-5dcc2dc2-ef23-49af-b9ff-a43d3f7835b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-cfe76b41-b2e2-493a-874b-2c88aac25e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-b289f55b-0a3d-42fc-ab77-494d2a92a311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270713389-172.17.0.12-1595404030872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39209,DS-983f1164-10b5-4b6f-95fc-feb317b36a74,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-87a44d2f-192c-4f78-bfa4-decd6910ab88,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-c2f348a0-872e-4130-8f0c-9844f8c8574c,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-f9103437-b32c-4a46-9e64-dfe84d5582c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-566fd8c0-dd19-45d3-b43e-c90499c9a055,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-5dcc2dc2-ef23-49af-b9ff-a43d3f7835b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-cfe76b41-b2e2-493a-874b-2c88aac25e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-b289f55b-0a3d-42fc-ab77-494d2a92a311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031821314-172.17.0.12-1595404646327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40530,DS-9189b445-2be6-4d59-be63-08cf9f1bb782,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-80d41f54-474a-4c4a-b07e-599c242eb354,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-bd584779-2e0d-4e4b-90be-16121953d6de,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-2d93db80-e3c5-4533-9cd2-d75e50fe023d,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-3c8c17bb-c396-478e-9096-0cf8f5551782,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-ddde03b7-9fb4-4965-9d21-4446c3ddd0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-792245a6-feff-4fa5-9b18-4735b9752d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-96bd98fa-c54e-4668-aa9a-2ff1840f5a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031821314-172.17.0.12-1595404646327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40530,DS-9189b445-2be6-4d59-be63-08cf9f1bb782,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-80d41f54-474a-4c4a-b07e-599c242eb354,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-bd584779-2e0d-4e4b-90be-16121953d6de,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-2d93db80-e3c5-4533-9cd2-d75e50fe023d,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-3c8c17bb-c396-478e-9096-0cf8f5551782,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-ddde03b7-9fb4-4965-9d21-4446c3ddd0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-792245a6-feff-4fa5-9b18-4735b9752d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-96bd98fa-c54e-4668-aa9a-2ff1840f5a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566073564-172.17.0.12-1595404713356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44390,DS-7c25f1cd-381c-4c35-9564-f3f3107bea71,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-c7ffdf89-3ab2-4fd0-8163-43c0da3c8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b1f55254-93df-4408-9227-c5792b702a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-b7da4141-7673-4bb3-8b8e-c1e7b5237e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-5e73e2ed-0206-40d5-87b2-2f94efc66fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-2ce7ff17-8f57-42ad-8af1-f9e4bae198e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-8a3e5437-d654-4f22-a840-fce809be2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-e00f119f-210d-464b-8c62-0d46997017e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566073564-172.17.0.12-1595404713356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44390,DS-7c25f1cd-381c-4c35-9564-f3f3107bea71,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-c7ffdf89-3ab2-4fd0-8163-43c0da3c8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b1f55254-93df-4408-9227-c5792b702a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-b7da4141-7673-4bb3-8b8e-c1e7b5237e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-5e73e2ed-0206-40d5-87b2-2f94efc66fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-2ce7ff17-8f57-42ad-8af1-f9e4bae198e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-8a3e5437-d654-4f22-a840-fce809be2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-e00f119f-210d-464b-8c62-0d46997017e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069769526-172.17.0.12-1595404834787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-cd8a58f8-4037-4bf1-b309-d92fcf7d2550,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-2999ccd7-a013-4e49-985c-295203d572e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-8f8a92ad-f172-4383-9587-215f909b5c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-6a02a363-c251-4142-a494-e5b64efa1b21,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-714d1ca0-d959-4296-aa27-15b4b9db3d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-373bcdcf-ec5c-4e85-ae3b-15a97f7c2f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-8f12ee58-cb9b-482a-bd00-f6c2755672d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-d307bda1-e9aa-4fd4-84f5-e555bc936761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069769526-172.17.0.12-1595404834787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-cd8a58f8-4037-4bf1-b309-d92fcf7d2550,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-2999ccd7-a013-4e49-985c-295203d572e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-8f8a92ad-f172-4383-9587-215f909b5c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-6a02a363-c251-4142-a494-e5b64efa1b21,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-714d1ca0-d959-4296-aa27-15b4b9db3d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-373bcdcf-ec5c-4e85-ae3b-15a97f7c2f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-8f12ee58-cb9b-482a-bd00-f6c2755672d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-d307bda1-e9aa-4fd4-84f5-e555bc936761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206728596-172.17.0.12-1595404870747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33502,DS-0be035b0-faed-44bc-9166-122a445eced6,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-89b19118-9b4e-4cd3-bdce-c47c3443ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-0ad85623-b4a3-41ab-99eb-9f92ceed62a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-bdd1cb01-2fb4-4327-b8c6-97938e636a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-e14c174d-138b-4ce8-b2b2-ffc82afcdab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-cff63268-3cfa-4556-a4e8-3ff0196578e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-e06dea99-cae5-4055-8311-ed9617f5c26a,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-723322f3-6c3b-44e9-a356-47e5f151dbe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206728596-172.17.0.12-1595404870747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33502,DS-0be035b0-faed-44bc-9166-122a445eced6,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-89b19118-9b4e-4cd3-bdce-c47c3443ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-0ad85623-b4a3-41ab-99eb-9f92ceed62a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-bdd1cb01-2fb4-4327-b8c6-97938e636a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-e14c174d-138b-4ce8-b2b2-ffc82afcdab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-cff63268-3cfa-4556-a4e8-3ff0196578e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-e06dea99-cae5-4055-8311-ed9617f5c26a,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-723322f3-6c3b-44e9-a356-47e5f151dbe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550474345-172.17.0.12-1595405461526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36139,DS-ca9fe0c9-058e-42fe-b24f-4a33057d320a,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-a66cae98-7b81-4c63-b64c-61f2b7252843,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-711118c2-e239-41ff-8641-646468195076,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-6e5b71d5-608c-44db-a93f-2429253f6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-88845de7-6c48-439f-8c32-9e1adce4d6db,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-8b59e4c2-af97-4771-a0a8-3e50ff53e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-0d9bbf83-31db-4c8d-ad4e-ce84a2c69846,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-ed9ab93d-7d1b-4f3b-a939-7072f9f8f580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550474345-172.17.0.12-1595405461526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36139,DS-ca9fe0c9-058e-42fe-b24f-4a33057d320a,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-a66cae98-7b81-4c63-b64c-61f2b7252843,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-711118c2-e239-41ff-8641-646468195076,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-6e5b71d5-608c-44db-a93f-2429253f6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-88845de7-6c48-439f-8c32-9e1adce4d6db,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-8b59e4c2-af97-4771-a0a8-3e50ff53e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-0d9bbf83-31db-4c8d-ad4e-ce84a2c69846,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-ed9ab93d-7d1b-4f3b-a939-7072f9f8f580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607892801-172.17.0.12-1595405949024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-1830ff8d-378e-482e-8a56-74ebcfaa1ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-f409f0dd-aa28-4b96-b125-4ac2cb8895aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-03493990-4665-4ae6-bbb5-5f91d474fd88,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-5dc0d85f-c668-4478-a323-ba570c7c1e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-f0c0cef0-3865-4601-9edf-fff241d6ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-782072f3-9dd5-46e6-9177-1bddcafb64ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-52fdeee9-b88e-4e46-a245-982f11867ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-69df4e20-b880-4c0a-835d-18fb0d29e4de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607892801-172.17.0.12-1595405949024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-1830ff8d-378e-482e-8a56-74ebcfaa1ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-f409f0dd-aa28-4b96-b125-4ac2cb8895aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-03493990-4665-4ae6-bbb5-5f91d474fd88,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-5dc0d85f-c668-4478-a323-ba570c7c1e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-f0c0cef0-3865-4601-9edf-fff241d6ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-782072f3-9dd5-46e6-9177-1bddcafb64ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-52fdeee9-b88e-4e46-a245-982f11867ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-69df4e20-b880-4c0a-835d-18fb0d29e4de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949999433-172.17.0.12-1595406449402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37743,DS-f494febf-af1d-4b39-bec2-4dab06b98255,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-22926f73-cc44-4059-b488-91e48f7b5190,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-b5cb68ab-9302-4585-aa00-a1a6c73842eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-af7db1b0-d737-431d-912d-4e5f37cc5129,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-c4bb8267-5cb6-4d3b-a328-67164903559a,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-56a743df-6483-4fa8-842b-ff4a64ff17ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-ccf8065e-ccc0-4c4d-83f1-d13f65af45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-88b38411-983b-4369-8ad8-79cb72820b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949999433-172.17.0.12-1595406449402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37743,DS-f494febf-af1d-4b39-bec2-4dab06b98255,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-22926f73-cc44-4059-b488-91e48f7b5190,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-b5cb68ab-9302-4585-aa00-a1a6c73842eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-af7db1b0-d737-431d-912d-4e5f37cc5129,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-c4bb8267-5cb6-4d3b-a328-67164903559a,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-56a743df-6483-4fa8-842b-ff4a64ff17ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-ccf8065e-ccc0-4c4d-83f1-d13f65af45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-88b38411-983b-4369-8ad8-79cb72820b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943013054-172.17.0.12-1595407107860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-a6851ec6-26e2-452b-96fe-8fd832abec1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-9fc3552e-9a18-4311-8c49-5453be5b2aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-e6efd59e-dabc-4653-bde5-7d367f6a9c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-0083e9de-cf75-43d1-ba2e-9556c4580aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-c6ab240e-349f-495e-bc65-cb46edd1d4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-c321d59f-8cb9-47ed-9479-962d8e3b020a,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-47c855f0-2282-4069-922f-7f106e48b27e,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-900cdc9f-b093-4138-bbf6-e825b592b62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943013054-172.17.0.12-1595407107860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-a6851ec6-26e2-452b-96fe-8fd832abec1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-9fc3552e-9a18-4311-8c49-5453be5b2aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-e6efd59e-dabc-4653-bde5-7d367f6a9c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-0083e9de-cf75-43d1-ba2e-9556c4580aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-c6ab240e-349f-495e-bc65-cb46edd1d4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-c321d59f-8cb9-47ed-9479-962d8e3b020a,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-47c855f0-2282-4069-922f-7f106e48b27e,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-900cdc9f-b093-4138-bbf6-e825b592b62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679336001-172.17.0.12-1595407303144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32832,DS-85dfd391-68f2-4276-8c5e-3605b348110f,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-59720ba1-3af7-4158-a82b-513313db5cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-5d5f0fab-5f66-4738-aa76-90b3b8fbee44,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-542aea73-e0c9-460f-995b-f6179e742133,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-fd5545ca-9585-40ba-b26e-7ba34afbab39,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-60bf5e14-51ee-42c9-9533-6f1af561ef90,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-2f15524b-0331-49d8-aa5d-7455c259f60c,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-78aaf5b9-0c94-4bb1-8323-dd2082db60a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679336001-172.17.0.12-1595407303144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32832,DS-85dfd391-68f2-4276-8c5e-3605b348110f,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-59720ba1-3af7-4158-a82b-513313db5cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-5d5f0fab-5f66-4738-aa76-90b3b8fbee44,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-542aea73-e0c9-460f-995b-f6179e742133,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-fd5545ca-9585-40ba-b26e-7ba34afbab39,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-60bf5e14-51ee-42c9-9533-6f1af561ef90,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-2f15524b-0331-49d8-aa5d-7455c259f60c,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-78aaf5b9-0c94-4bb1-8323-dd2082db60a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697425921-172.17.0.12-1595407454634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43632,DS-cfb03286-bdf8-4a08-85ca-b73e24afb524,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-aadd77ca-f648-458c-8161-30458c27c721,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-003e28da-8c1e-4cf0-a945-f6dd63b6691e,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-0d34cfe6-0df3-418d-a9bc-d05fd9ed1762,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-7d526379-a66e-4ae7-8831-33294937030c,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-72dff285-701e-4f66-9277-379a0ef62452,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-0248d480-2b2b-4217-9279-1a5830ab4855,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-f8cef4a8-1e6a-44e8-9b67-783fa3150845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697425921-172.17.0.12-1595407454634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43632,DS-cfb03286-bdf8-4a08-85ca-b73e24afb524,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-aadd77ca-f648-458c-8161-30458c27c721,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-003e28da-8c1e-4cf0-a945-f6dd63b6691e,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-0d34cfe6-0df3-418d-a9bc-d05fd9ed1762,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-7d526379-a66e-4ae7-8831-33294937030c,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-72dff285-701e-4f66-9277-379a0ef62452,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-0248d480-2b2b-4217-9279-1a5830ab4855,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-f8cef4a8-1e6a-44e8-9b67-783fa3150845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067411375-172.17.0.12-1595407640753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45863,DS-25b20c74-f982-4960-8ee8-b611db78d547,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-762bf0cb-58f5-4487-aca1-70282e132cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-d7dc34f7-bcd7-4b2e-9c3c-5121fe3128ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-e1a33584-021f-4832-9f29-cbf7f43af30b,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-0929d5c6-b724-4add-ab10-2fececc36838,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-0b4d9dcc-c1ae-4316-b30b-ff4e547ae292,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-1c67e2d2-ef70-4be5-9a62-b4e4dc6faae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-3a54990a-0293-479f-90bf-57d389f4ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067411375-172.17.0.12-1595407640753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45863,DS-25b20c74-f982-4960-8ee8-b611db78d547,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-762bf0cb-58f5-4487-aca1-70282e132cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-d7dc34f7-bcd7-4b2e-9c3c-5121fe3128ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-e1a33584-021f-4832-9f29-cbf7f43af30b,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-0929d5c6-b724-4add-ab10-2fececc36838,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-0b4d9dcc-c1ae-4316-b30b-ff4e547ae292,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-1c67e2d2-ef70-4be5-9a62-b4e4dc6faae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-3a54990a-0293-479f-90bf-57d389f4ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546215079-172.17.0.12-1595408575232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-71683127-34fc-43ed-86bc-62c2aabb648d,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-abd975f7-4283-43bb-b681-35952caf2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-8513ed56-8268-4fee-9bb3-96b114a8b035,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-d6b3c20a-8b07-4383-a35d-f866ac4c2270,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-ec62d26e-2d4a-4ed1-9c34-627e958ea1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-0d40f580-88db-49ce-8777-73deddaf1c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-12bcd45d-911b-47c3-a744-b37b02e75e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-18b9275e-14f2-42c2-ba05-b1ce337ccdf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546215079-172.17.0.12-1595408575232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-71683127-34fc-43ed-86bc-62c2aabb648d,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-abd975f7-4283-43bb-b681-35952caf2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-8513ed56-8268-4fee-9bb3-96b114a8b035,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-d6b3c20a-8b07-4383-a35d-f866ac4c2270,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-ec62d26e-2d4a-4ed1-9c34-627e958ea1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-0d40f580-88db-49ce-8777-73deddaf1c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-12bcd45d-911b-47c3-a744-b37b02e75e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-18b9275e-14f2-42c2-ba05-b1ce337ccdf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872293768-172.17.0.12-1595408647528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43319,DS-84ddffa1-6d5a-43f8-9594-b5fc666257d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-ed39a401-5f9c-4d9b-be82-cbddb0e36b95,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-07b081d5-f472-4128-a7be-826240b88bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-316a89a6-339a-4c99-a323-6302fbfbf759,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-eb2060e4-1826-4781-b748-93b6bac1aae2,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-12af0026-4aac-43ef-ac3d-b03a235d4aab,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-da86c977-28e0-41b8-b21e-8c0b97f0bf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-839852d2-c05a-4e36-87f9-b49b221968c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872293768-172.17.0.12-1595408647528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43319,DS-84ddffa1-6d5a-43f8-9594-b5fc666257d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-ed39a401-5f9c-4d9b-be82-cbddb0e36b95,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-07b081d5-f472-4128-a7be-826240b88bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-316a89a6-339a-4c99-a323-6302fbfbf759,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-eb2060e4-1826-4781-b748-93b6bac1aae2,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-12af0026-4aac-43ef-ac3d-b03a235d4aab,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-da86c977-28e0-41b8-b21e-8c0b97f0bf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-839852d2-c05a-4e36-87f9-b49b221968c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5595
