reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780217592-172.17.0.9-1595356069412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42434,DS-8a01c2a5-bbe6-40e3-89f1-98d3bbc32bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-ddb58fe5-acb7-4b66-a5e3-7d6d93d1deab,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-c7418690-5f64-4061-aab3-e6464dffa063,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-8fd0471e-5845-4846-ad97-0c5c5b3069f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-e0b0b733-7198-404e-9bc0-abb8866333f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-43f0bdfd-ee50-45da-b2b6-9a85e6fb312d,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-00866637-5ab3-4c98-9a8d-137efad0afde,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-a4c4ffbd-7a9d-4b80-9163-7eeffab99e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780217592-172.17.0.9-1595356069412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42434,DS-8a01c2a5-bbe6-40e3-89f1-98d3bbc32bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-ddb58fe5-acb7-4b66-a5e3-7d6d93d1deab,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-c7418690-5f64-4061-aab3-e6464dffa063,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-8fd0471e-5845-4846-ad97-0c5c5b3069f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-e0b0b733-7198-404e-9bc0-abb8866333f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-43f0bdfd-ee50-45da-b2b6-9a85e6fb312d,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-00866637-5ab3-4c98-9a8d-137efad0afde,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-a4c4ffbd-7a9d-4b80-9163-7eeffab99e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787640784-172.17.0.9-1595357340577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-721b5cf2-3b23-483d-b67a-e03a6d08ae25,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-fe4c89f4-7713-4340-935c-5eef3eaab290,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-75057256-07a4-420b-bd8c-21f85bb04842,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-072e9291-b4ca-40f1-a16b-0ab78e1aeca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-9aa6c461-8b5a-4356-b74a-1175e29a7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-09aaacdb-d7f6-4bb2-9d3d-e4e4004c4571,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-e9a5663b-f650-4397-b539-67536d47cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-61ae336c-1f9f-4f59-bfb6-072e35b04367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787640784-172.17.0.9-1595357340577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-721b5cf2-3b23-483d-b67a-e03a6d08ae25,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-fe4c89f4-7713-4340-935c-5eef3eaab290,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-75057256-07a4-420b-bd8c-21f85bb04842,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-072e9291-b4ca-40f1-a16b-0ab78e1aeca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-9aa6c461-8b5a-4356-b74a-1175e29a7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-09aaacdb-d7f6-4bb2-9d3d-e4e4004c4571,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-e9a5663b-f650-4397-b539-67536d47cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-61ae336c-1f9f-4f59-bfb6-072e35b04367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548009439-172.17.0.9-1595357486390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-924777fa-9dfe-4597-bb8c-722472519998,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-bb8f9f57-385d-4869-ad04-7e49d753f24c,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-ce773604-c8e5-4b23-8a7b-8729f9b8d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-7d359e3c-d6b0-44b6-85a6-ed3c16f6c612,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-97b7e92b-392a-4250-9951-acf4d0594566,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-a8de5a46-54dd-4d1b-8c8e-090f1299e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-b50a1fc0-66f9-45ac-b47e-17219cca1f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-1aa6d237-1a7e-4652-a1f0-e7d0afd5d8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548009439-172.17.0.9-1595357486390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-924777fa-9dfe-4597-bb8c-722472519998,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-bb8f9f57-385d-4869-ad04-7e49d753f24c,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-ce773604-c8e5-4b23-8a7b-8729f9b8d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-7d359e3c-d6b0-44b6-85a6-ed3c16f6c612,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-97b7e92b-392a-4250-9951-acf4d0594566,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-a8de5a46-54dd-4d1b-8c8e-090f1299e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-b50a1fc0-66f9-45ac-b47e-17219cca1f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-1aa6d237-1a7e-4652-a1f0-e7d0afd5d8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320196036-172.17.0.9-1595358456166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-ed0430c3-efae-4164-af6e-7950775c7f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-6cb42905-ca41-4ee2-bfaf-15b36d49fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-7df8b03a-04b9-4558-adea-38c9a662f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-e3e7dd4c-a254-40ce-aeac-002e33abd9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-c88477e6-4a9e-4cd0-8e0e-6a68b79a328a,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-22c5c0c3-edba-4cb0-897f-38c81191bc49,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-2661971d-6f45-4b97-bcd6-17a7730e77e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-d8ccc10d-8794-4d5d-99fc-902a1f4ce768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320196036-172.17.0.9-1595358456166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-ed0430c3-efae-4164-af6e-7950775c7f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-6cb42905-ca41-4ee2-bfaf-15b36d49fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-7df8b03a-04b9-4558-adea-38c9a662f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-e3e7dd4c-a254-40ce-aeac-002e33abd9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-c88477e6-4a9e-4cd0-8e0e-6a68b79a328a,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-22c5c0c3-edba-4cb0-897f-38c81191bc49,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-2661971d-6f45-4b97-bcd6-17a7730e77e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-d8ccc10d-8794-4d5d-99fc-902a1f4ce768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619424954-172.17.0.9-1595358879296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35833,DS-0c238a83-7247-4b43-80ca-7509530d5897,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-ae726bd4-874c-434c-888f-4f61778d57f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-4f278334-777c-4a72-96cc-d0d2a59f5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-6c6e4141-9557-432e-a89d-29e4ce5db4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-5a4b0a69-45ec-4e8a-a7ec-ad4cecbce454,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-0ff3f585-8323-4b3e-bf1a-efd66a35f461,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-aacd4843-d6cf-47b3-8eb6-1c0c49a61b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-384bb2e9-de18-45e5-8f1a-b7459e7c97fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619424954-172.17.0.9-1595358879296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35833,DS-0c238a83-7247-4b43-80ca-7509530d5897,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-ae726bd4-874c-434c-888f-4f61778d57f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-4f278334-777c-4a72-96cc-d0d2a59f5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-6c6e4141-9557-432e-a89d-29e4ce5db4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-5a4b0a69-45ec-4e8a-a7ec-ad4cecbce454,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-0ff3f585-8323-4b3e-bf1a-efd66a35f461,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-aacd4843-d6cf-47b3-8eb6-1c0c49a61b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-384bb2e9-de18-45e5-8f1a-b7459e7c97fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758736038-172.17.0.9-1595359190959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44820,DS-7e139a36-66ec-49e5-93b3-33b1efb0afa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-e7f32e1b-c143-4dfc-a103-57f829eb2442,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-0d76d40a-c75b-462d-83c9-85c5d7da06b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-9355a4bf-0cc6-45e5-870f-c5b830ae1b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-26fb0f08-964a-42fd-98af-fee0c358391e,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-5ae8e21f-e45b-4f41-bc93-6f2a3a14eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-0bb30f9d-e212-4d9d-b236-10f02e3b5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-7f3a4a94-19bd-4d4b-84c1-06f648677553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758736038-172.17.0.9-1595359190959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44820,DS-7e139a36-66ec-49e5-93b3-33b1efb0afa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-e7f32e1b-c143-4dfc-a103-57f829eb2442,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-0d76d40a-c75b-462d-83c9-85c5d7da06b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-9355a4bf-0cc6-45e5-870f-c5b830ae1b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-26fb0f08-964a-42fd-98af-fee0c358391e,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-5ae8e21f-e45b-4f41-bc93-6f2a3a14eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-0bb30f9d-e212-4d9d-b236-10f02e3b5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-7f3a4a94-19bd-4d4b-84c1-06f648677553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238470101-172.17.0.9-1595359768317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-19b41286-cdad-4e09-8561-3d042cdbe28a,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-59d04938-dbd9-4e60-8cf5-74b5a10f564c,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-2d0b024f-a003-4753-bcff-0d3dbc499ece,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-a4e3b9d9-d81e-4d84-8477-d885305d64c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-cb460efb-8244-409d-8c55-848ef5182895,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-9688fb11-e5a4-46ae-8420-c1d3e496b1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-6f85525a-bb9b-40b5-b48d-f8c9ceb54d01,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-346c63b6-c52a-4189-aef9-b7adbe147c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238470101-172.17.0.9-1595359768317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-19b41286-cdad-4e09-8561-3d042cdbe28a,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-59d04938-dbd9-4e60-8cf5-74b5a10f564c,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-2d0b024f-a003-4753-bcff-0d3dbc499ece,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-a4e3b9d9-d81e-4d84-8477-d885305d64c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-cb460efb-8244-409d-8c55-848ef5182895,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-9688fb11-e5a4-46ae-8420-c1d3e496b1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-6f85525a-bb9b-40b5-b48d-f8c9ceb54d01,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-346c63b6-c52a-4189-aef9-b7adbe147c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792234295-172.17.0.9-1595360071810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45738,DS-d1d1ac4f-a56b-4010-8190-27689e505b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-3d2de679-ea03-477b-86d5-e5e166e2ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-d34aed36-2c5f-4780-adf4-6a321886896d,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-7b0fdc3e-fee6-42e2-94d9-797cfeb39904,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-9ba3edab-2faf-4d84-a1ad-90995a79c711,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-21073324-03e2-47c9-885c-e20c0ccba412,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-4ccc5555-2386-4c87-ad53-436337089e01,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-f66f98fc-c9a8-46c8-a681-a4e73448033e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792234295-172.17.0.9-1595360071810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45738,DS-d1d1ac4f-a56b-4010-8190-27689e505b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-3d2de679-ea03-477b-86d5-e5e166e2ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-d34aed36-2c5f-4780-adf4-6a321886896d,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-7b0fdc3e-fee6-42e2-94d9-797cfeb39904,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-9ba3edab-2faf-4d84-a1ad-90995a79c711,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-21073324-03e2-47c9-885c-e20c0ccba412,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-4ccc5555-2386-4c87-ad53-436337089e01,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-f66f98fc-c9a8-46c8-a681-a4e73448033e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047663878-172.17.0.9-1595360265212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-00918b3d-2f7e-476d-822d-aac1e4c4cb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-fa461ae3-edaa-479d-b23c-fa5628fbe39a,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-38fbeac1-fa15-4f3b-bdfa-db226a2da25f,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-85015e4f-6715-4ef6-9480-209c63d9a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-ca4b4aa1-b8de-4496-90ed-fe5a8ce7c044,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-5ceed566-a4f8-41e8-a464-a52f695ff0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-d061c18a-3abc-41c1-b09d-1518aafb59e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-36a99a4e-b8ed-4f92-a173-decdd06d1ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047663878-172.17.0.9-1595360265212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-00918b3d-2f7e-476d-822d-aac1e4c4cb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-fa461ae3-edaa-479d-b23c-fa5628fbe39a,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-38fbeac1-fa15-4f3b-bdfa-db226a2da25f,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-85015e4f-6715-4ef6-9480-209c63d9a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-ca4b4aa1-b8de-4496-90ed-fe5a8ce7c044,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-5ceed566-a4f8-41e8-a464-a52f695ff0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-d061c18a-3abc-41c1-b09d-1518aafb59e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-36a99a4e-b8ed-4f92-a173-decdd06d1ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628644194-172.17.0.9-1595360687808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-ab1fea75-4a44-4e9e-a1c0-1cc3e5f8cd97,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-d3267287-199f-4c62-b194-7a79da300e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-edbf8cfa-e5eb-4700-9723-27c7e25c9ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-8aacc0ae-d54c-4f21-8a04-7bebf1cf2334,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-2adc12cb-bb05-48f3-a2fd-eddadfcb2999,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-57f679ab-ecc7-4684-ab15-7619d884fb98,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-eef8c6c0-3686-4a82-b4f8-a4bd8d40210b,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-f78bda98-e33a-46d2-89b7-ec150d88536c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628644194-172.17.0.9-1595360687808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-ab1fea75-4a44-4e9e-a1c0-1cc3e5f8cd97,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-d3267287-199f-4c62-b194-7a79da300e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-edbf8cfa-e5eb-4700-9723-27c7e25c9ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-8aacc0ae-d54c-4f21-8a04-7bebf1cf2334,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-2adc12cb-bb05-48f3-a2fd-eddadfcb2999,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-57f679ab-ecc7-4684-ab15-7619d884fb98,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-eef8c6c0-3686-4a82-b4f8-a4bd8d40210b,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-f78bda98-e33a-46d2-89b7-ec150d88536c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21077827-172.17.0.9-1595361004584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36265,DS-fa2a685e-9125-4895-84f2-58d66fccde6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-99906076-d3d9-4480-867c-5ca340c29040,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-cd5a5675-bedd-46f8-a30f-bd791de02432,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-b2fdb7fd-89e5-4673-a111-7d6a12dd1f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-69da96ec-b6ee-4dde-b696-5b9f4197417f,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-04e43f82-724f-4769-9182-ac452238d54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-b0344066-13de-4354-8414-94e50707dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-140192c3-7afe-4cec-89d5-f5a42553febd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21077827-172.17.0.9-1595361004584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36265,DS-fa2a685e-9125-4895-84f2-58d66fccde6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-99906076-d3d9-4480-867c-5ca340c29040,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-cd5a5675-bedd-46f8-a30f-bd791de02432,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-b2fdb7fd-89e5-4673-a111-7d6a12dd1f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-69da96ec-b6ee-4dde-b696-5b9f4197417f,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-04e43f82-724f-4769-9182-ac452238d54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-b0344066-13de-4354-8414-94e50707dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-140192c3-7afe-4cec-89d5-f5a42553febd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974025098-172.17.0.9-1595361140618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-9dddaac8-875d-42cc-86bf-cdcfa2cc6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-0a24edfc-49ee-465b-8e32-3d8856ef124b,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-788aeb5f-90cd-4248-985b-b85bf138cd77,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-826d929a-0087-47ec-bc54-e7cab19e1bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-b3e7bcaf-258e-44f1-bcba-86801960d108,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-bf3bf192-45d3-44c2-aede-784b4679e581,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-e5ccae98-0aeb-4bca-a9de-d54859fe0536,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-8fea1634-014a-41db-93e5-e62c9142daa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974025098-172.17.0.9-1595361140618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-9dddaac8-875d-42cc-86bf-cdcfa2cc6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-0a24edfc-49ee-465b-8e32-3d8856ef124b,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-788aeb5f-90cd-4248-985b-b85bf138cd77,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-826d929a-0087-47ec-bc54-e7cab19e1bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-b3e7bcaf-258e-44f1-bcba-86801960d108,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-bf3bf192-45d3-44c2-aede-784b4679e581,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-e5ccae98-0aeb-4bca-a9de-d54859fe0536,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-8fea1634-014a-41db-93e5-e62c9142daa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113748989-172.17.0.9-1595361176894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38167,DS-250a7329-a75a-4ec7-a5b9-19b35b7e12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-6723d840-e006-4378-b29e-aa4e3677d002,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-8e379d2f-8d5a-4303-b188-2c70350abfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-addd257a-6319-4e7d-a33e-d3ab9ba48bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-16bc3e86-de98-4510-8efc-f5bda11c0789,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-660c9266-8e93-474a-87e4-062252063b21,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-eb6b526b-909f-40a7-b4a9-a304109f0372,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-5ff1cce1-3b40-4051-8aa4-976a937840e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113748989-172.17.0.9-1595361176894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38167,DS-250a7329-a75a-4ec7-a5b9-19b35b7e12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-6723d840-e006-4378-b29e-aa4e3677d002,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-8e379d2f-8d5a-4303-b188-2c70350abfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-addd257a-6319-4e7d-a33e-d3ab9ba48bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-16bc3e86-de98-4510-8efc-f5bda11c0789,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-660c9266-8e93-474a-87e4-062252063b21,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-eb6b526b-909f-40a7-b4a9-a304109f0372,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-5ff1cce1-3b40-4051-8aa4-976a937840e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5374
