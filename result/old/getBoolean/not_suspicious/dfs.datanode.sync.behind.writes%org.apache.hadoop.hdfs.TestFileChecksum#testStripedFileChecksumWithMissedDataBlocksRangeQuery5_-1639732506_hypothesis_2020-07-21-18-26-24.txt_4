reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424017595-172.17.0.19-1595356272447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46089,DS-ea1af28c-5fc2-471e-a424-28bbe9ef7070,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-07b1b197-dc6c-4b2b-b03b-84bf4af42dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-cff3f25e-785e-42ad-b315-da083c5e33f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-5ada7cd3-357c-4691-951f-b3badc2e29c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-1a66f66b-1dad-42c2-8058-a1689581556d,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-50f945af-6a2a-445c-acb1-18cd6cd4ce76,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-9232b5cf-34a0-4b88-a780-8dec2e082f72,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-1e19dc17-4b8f-476d-b5b0-e20ed12b52d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424017595-172.17.0.19-1595356272447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46089,DS-ea1af28c-5fc2-471e-a424-28bbe9ef7070,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-07b1b197-dc6c-4b2b-b03b-84bf4af42dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-cff3f25e-785e-42ad-b315-da083c5e33f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-5ada7cd3-357c-4691-951f-b3badc2e29c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-1a66f66b-1dad-42c2-8058-a1689581556d,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-50f945af-6a2a-445c-acb1-18cd6cd4ce76,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-9232b5cf-34a0-4b88-a780-8dec2e082f72,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-1e19dc17-4b8f-476d-b5b0-e20ed12b52d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230275321-172.17.0.19-1595356482748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36789,DS-3f42b83b-ef67-4bf6-b1dc-2d6ec7bb8013,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-0736495c-efb4-4142-8e6b-75fd82fcc060,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-0fa2234c-d3fc-4c54-a389-a17233f29017,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b3c8d44d-d963-4164-8eee-6f7564c489fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-4d593869-45d0-433e-985a-606c60ddf088,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-9c7f5285-8e36-4e44-bf6c-0ed680ac32cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-8d39c3fb-3a11-44f3-97eb-9b4e54380fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-f44c74b1-69f1-4a10-890a-fb843d753549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230275321-172.17.0.19-1595356482748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36789,DS-3f42b83b-ef67-4bf6-b1dc-2d6ec7bb8013,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-0736495c-efb4-4142-8e6b-75fd82fcc060,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-0fa2234c-d3fc-4c54-a389-a17233f29017,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b3c8d44d-d963-4164-8eee-6f7564c489fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-4d593869-45d0-433e-985a-606c60ddf088,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-9c7f5285-8e36-4e44-bf6c-0ed680ac32cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-8d39c3fb-3a11-44f3-97eb-9b4e54380fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-f44c74b1-69f1-4a10-890a-fb843d753549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092080983-172.17.0.19-1595356694065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34308,DS-70d63c28-a689-46f8-a233-a074331f0fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-6ce4ab02-0437-4819-b37f-9e57dc19466e,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-316e5e8e-7461-482f-b1d1-3a179f6d01ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-f0bcced3-5bed-4988-9c92-7ec8c248c0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-bbbd2b49-4557-4659-9058-10e27b62186a,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-7e0822de-7d4c-45fe-8a20-f0f7b3da433d,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-41e4bcd1-1240-437c-8f43-91522bf0435d,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-d10a8fb3-19b0-4032-bf36-b5bdcdb1898d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092080983-172.17.0.19-1595356694065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34308,DS-70d63c28-a689-46f8-a233-a074331f0fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-6ce4ab02-0437-4819-b37f-9e57dc19466e,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-316e5e8e-7461-482f-b1d1-3a179f6d01ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-f0bcced3-5bed-4988-9c92-7ec8c248c0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-bbbd2b49-4557-4659-9058-10e27b62186a,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-7e0822de-7d4c-45fe-8a20-f0f7b3da433d,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-41e4bcd1-1240-437c-8f43-91522bf0435d,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-d10a8fb3-19b0-4032-bf36-b5bdcdb1898d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842109151-172.17.0.19-1595356982391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38864,DS-3aff4fb1-3336-47ee-88c6-df525ca76daf,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-d27bf465-d148-482e-b9bc-8c33bb238512,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-c469a187-1a58-4dee-a1bd-3e85542b79f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-be2cee8f-c3ff-4193-9e3a-a73b844a876b,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-d96cf375-4fcd-4959-8a60-cf7ee50fbee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-7fa209c7-29cb-4e5c-825f-cc2a1ea015c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-ccdd8c63-da01-4632-a536-4adefea52475,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-c52bd133-e29a-4cb2-95d5-314aa3f731ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842109151-172.17.0.19-1595356982391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38864,DS-3aff4fb1-3336-47ee-88c6-df525ca76daf,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-d27bf465-d148-482e-b9bc-8c33bb238512,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-c469a187-1a58-4dee-a1bd-3e85542b79f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-be2cee8f-c3ff-4193-9e3a-a73b844a876b,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-d96cf375-4fcd-4959-8a60-cf7ee50fbee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-7fa209c7-29cb-4e5c-825f-cc2a1ea015c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-ccdd8c63-da01-4632-a536-4adefea52475,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-c52bd133-e29a-4cb2-95d5-314aa3f731ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990591295-172.17.0.19-1595357660099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-c5c64802-c1af-448b-9f14-0ffe775cc926,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-7121c255-5209-4e2f-9e07-d2b7e5c6be96,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-abb5e739-49af-4951-a52c-f6db9921d554,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-6a694ec3-eed9-4a44-8fd3-5a53c6fda99d,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-d80d9d9e-d619-488b-b4ff-0bdca1b9c191,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-af563adc-26ae-4055-9b04-ca2c0cdf2f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-a4a7d9b9-2b51-4983-88ed-a8b851ae565d,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-bc85de97-a91f-47e8-9098-b41afc28557a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990591295-172.17.0.19-1595357660099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-c5c64802-c1af-448b-9f14-0ffe775cc926,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-7121c255-5209-4e2f-9e07-d2b7e5c6be96,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-abb5e739-49af-4951-a52c-f6db9921d554,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-6a694ec3-eed9-4a44-8fd3-5a53c6fda99d,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-d80d9d9e-d619-488b-b4ff-0bdca1b9c191,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-af563adc-26ae-4055-9b04-ca2c0cdf2f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-a4a7d9b9-2b51-4983-88ed-a8b851ae565d,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-bc85de97-a91f-47e8-9098-b41afc28557a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532922866-172.17.0.19-1595359551561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36587,DS-db6139f7-eaee-4370-a580-5ef917a70b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-0c00085a-31d7-43de-9b97-0b17acb8838c,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-55f276bd-eba7-4908-b10e-dc1a8b2f2acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-2e9167f1-5176-4ccc-9734-c3a135ab180e,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-6583eb72-7b04-4471-a801-6ec30abe45a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-2802d510-3dd9-4ab0-b4f4-bd5db1afd738,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-0b69f8fb-b979-4c3b-9bdd-2da8969644ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-d8f88049-67d3-46a5-bec9-cb92c2dd0681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532922866-172.17.0.19-1595359551561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36587,DS-db6139f7-eaee-4370-a580-5ef917a70b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-0c00085a-31d7-43de-9b97-0b17acb8838c,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-55f276bd-eba7-4908-b10e-dc1a8b2f2acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-2e9167f1-5176-4ccc-9734-c3a135ab180e,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-6583eb72-7b04-4471-a801-6ec30abe45a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-2802d510-3dd9-4ab0-b4f4-bd5db1afd738,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-0b69f8fb-b979-4c3b-9bdd-2da8969644ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-d8f88049-67d3-46a5-bec9-cb92c2dd0681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209805488-172.17.0.19-1595359721827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-512a0a48-19f7-41ca-b6dd-61fe87e59af0,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-b7af0dad-7cf7-4f36-a6cf-535b74297091,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a0a03d77-3355-45a0-9876-694c6eea47c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-9003dcc4-7f2e-4752-8ae2-596ed8e636ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-d7f12233-d488-4ee1-b473-3903fae8e89a,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-9c3be804-86ba-4ae3-8788-aa9418751b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-b28c6a44-2de7-4fa4-8ab1-8ecc3eeca507,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-b61a5191-a68f-40cd-aa46-746ac790229b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209805488-172.17.0.19-1595359721827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-512a0a48-19f7-41ca-b6dd-61fe87e59af0,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-b7af0dad-7cf7-4f36-a6cf-535b74297091,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a0a03d77-3355-45a0-9876-694c6eea47c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-9003dcc4-7f2e-4752-8ae2-596ed8e636ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-d7f12233-d488-4ee1-b473-3903fae8e89a,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-9c3be804-86ba-4ae3-8788-aa9418751b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-b28c6a44-2de7-4fa4-8ab1-8ecc3eeca507,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-b61a5191-a68f-40cd-aa46-746ac790229b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421658929-172.17.0.19-1595360216007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-30a256e6-010b-4d34-905c-0fd3591be6db,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-7894ac0d-e831-4f4c-b4c0-f48bf1f6141b,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-a3df09e7-e514-46aa-ae44-d5c502778916,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-c23e928b-ea49-4b17-a78c-f49f75b2bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-7adc4aeb-703c-40fd-8276-179e7dc543bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-6739411a-aa71-48be-82cd-59c2624d4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-3e8770c8-5fc0-46ef-870d-4085010263f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-40970cd6-2b1e-4f37-a1da-979c9950b8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421658929-172.17.0.19-1595360216007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-30a256e6-010b-4d34-905c-0fd3591be6db,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-7894ac0d-e831-4f4c-b4c0-f48bf1f6141b,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-a3df09e7-e514-46aa-ae44-d5c502778916,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-c23e928b-ea49-4b17-a78c-f49f75b2bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-7adc4aeb-703c-40fd-8276-179e7dc543bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-6739411a-aa71-48be-82cd-59c2624d4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-3e8770c8-5fc0-46ef-870d-4085010263f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-40970cd6-2b1e-4f37-a1da-979c9950b8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486464900-172.17.0.19-1595360263642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-25278965-ecab-483c-b395-16ea4486fb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-737d14dd-9230-4389-8810-39f2ccd564c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-13a3bf54-f567-4173-a36e-682ee8a78489,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-87ffe42b-3697-4b12-94ba-8e3aeb88a081,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-c7c52049-90ba-4b6d-8094-e677fdc2bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-dd8d3f79-f479-42c8-8c34-7bad2c6622a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-96bc7684-70ec-42aa-af40-29c059a311e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-de16afae-4dee-419d-9555-4995d264ef3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486464900-172.17.0.19-1595360263642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-25278965-ecab-483c-b395-16ea4486fb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-737d14dd-9230-4389-8810-39f2ccd564c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-13a3bf54-f567-4173-a36e-682ee8a78489,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-87ffe42b-3697-4b12-94ba-8e3aeb88a081,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-c7c52049-90ba-4b6d-8094-e677fdc2bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-dd8d3f79-f479-42c8-8c34-7bad2c6622a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-96bc7684-70ec-42aa-af40-29c059a311e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-de16afae-4dee-419d-9555-4995d264ef3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058001417-172.17.0.19-1595360311563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36686,DS-682657b2-b0c0-4379-b92b-4f88ce024083,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-c3b9977a-fa3d-4722-a936-3a3dcd55d316,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-40683422-8cf1-4432-848e-97359fcf69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-ab3cd685-4c85-4e3c-b999-3f5f5222ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-9829dd36-2a82-43b6-ba25-8a3b750104a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-076ead87-faa0-4c52-be17-1da9ff01ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-5bdd2a1e-1620-490f-bff8-e32e8d3b37c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-4f7abdfe-98e2-4a74-9f4c-15978f0a37b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058001417-172.17.0.19-1595360311563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36686,DS-682657b2-b0c0-4379-b92b-4f88ce024083,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-c3b9977a-fa3d-4722-a936-3a3dcd55d316,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-40683422-8cf1-4432-848e-97359fcf69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-ab3cd685-4c85-4e3c-b999-3f5f5222ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-9829dd36-2a82-43b6-ba25-8a3b750104a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-076ead87-faa0-4c52-be17-1da9ff01ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-5bdd2a1e-1620-490f-bff8-e32e8d3b37c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-4f7abdfe-98e2-4a74-9f4c-15978f0a37b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058140937-172.17.0.19-1595360667646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41658,DS-6c5fd3b7-06a6-4c5b-bd51-d28e740dc0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-2a9d139f-e8f4-420e-a963-280e6a7f32a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-7014acaf-062f-4637-9bbd-e20c6e091c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-ca072fc5-15ee-43d7-b557-04d8843bf805,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-9151bbb7-b890-4031-b265-4fb82caa634d,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-3c0fca7a-9a8f-469a-990a-f129626494f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-593a3199-f2ba-4558-91c7-36c6bd9ba5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-9ca0e879-41dd-4453-9ac0-82bd0d261170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058140937-172.17.0.19-1595360667646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41658,DS-6c5fd3b7-06a6-4c5b-bd51-d28e740dc0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-2a9d139f-e8f4-420e-a963-280e6a7f32a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-7014acaf-062f-4637-9bbd-e20c6e091c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-ca072fc5-15ee-43d7-b557-04d8843bf805,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-9151bbb7-b890-4031-b265-4fb82caa634d,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-3c0fca7a-9a8f-469a-990a-f129626494f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-593a3199-f2ba-4558-91c7-36c6bd9ba5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-9ca0e879-41dd-4453-9ac0-82bd0d261170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305893972-172.17.0.19-1595361164132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39837,DS-cc903a5b-99b6-4a3f-8f92-fdfcbad49fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-4c563824-dd9d-4c7d-825d-cb799c822525,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-1a41496c-79f1-4506-a4b2-93907d69ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-8fd0b3b8-030e-4d8d-b6d7-1dde4203ae30,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-3828c722-c035-4c93-9a8d-ba42f70fad73,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-424c8b4d-821f-479c-a1ef-374cfcc0ddce,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-6f88c954-7028-4eb2-818c-348cee3104ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-ee190d15-6344-48fb-a145-319ff5536f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305893972-172.17.0.19-1595361164132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39837,DS-cc903a5b-99b6-4a3f-8f92-fdfcbad49fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-4c563824-dd9d-4c7d-825d-cb799c822525,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-1a41496c-79f1-4506-a4b2-93907d69ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-8fd0b3b8-030e-4d8d-b6d7-1dde4203ae30,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-3828c722-c035-4c93-9a8d-ba42f70fad73,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-424c8b4d-821f-479c-a1ef-374cfcc0ddce,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-6f88c954-7028-4eb2-818c-348cee3104ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-ee190d15-6344-48fb-a145-319ff5536f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864958287-172.17.0.19-1595361454002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-e46a70eb-38a1-4a3c-a0b0-35450d2461f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-dc52a0c4-6e54-4c38-901e-10137f415c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-10ad1f1f-29ad-40c1-8f0c-91b7a92984ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-119211af-cd5f-41ef-a807-39ecbb057be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-cff6c863-1aa9-4e5e-a15c-395024587373,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-0aae2c06-e759-46e9-80e9-084c103db508,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-17fbd249-9cc1-4e92-a7a7-e57e84753947,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-f3872ab1-90d3-482e-bf28-39bd1680cce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864958287-172.17.0.19-1595361454002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-e46a70eb-38a1-4a3c-a0b0-35450d2461f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-dc52a0c4-6e54-4c38-901e-10137f415c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-10ad1f1f-29ad-40c1-8f0c-91b7a92984ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-119211af-cd5f-41ef-a807-39ecbb057be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-cff6c863-1aa9-4e5e-a15c-395024587373,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-0aae2c06-e759-46e9-80e9-084c103db508,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-17fbd249-9cc1-4e92-a7a7-e57e84753947,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-f3872ab1-90d3-482e-bf28-39bd1680cce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848767147-172.17.0.19-1595361491943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-d46e8537-b659-4968-b697-be373b7352ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-315dec3e-9278-44af-bef1-892161d9982a,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-216c9f6b-591c-4c68-a71a-a6edbb442edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-77582e27-85a6-4d3f-a438-4badad7de89e,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-9cd7d001-7c04-4652-b18c-33be8b6ee4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-6763a55c-2c10-41cd-83e5-f7df48d89d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-a15394a9-426e-465d-a6f6-2c3c689b16af,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-d4d46971-8acc-4fed-bf1a-a4a68b82593b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848767147-172.17.0.19-1595361491943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-d46e8537-b659-4968-b697-be373b7352ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-315dec3e-9278-44af-bef1-892161d9982a,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-216c9f6b-591c-4c68-a71a-a6edbb442edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-77582e27-85a6-4d3f-a438-4badad7de89e,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-9cd7d001-7c04-4652-b18c-33be8b6ee4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-6763a55c-2c10-41cd-83e5-f7df48d89d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-a15394a9-426e-465d-a6f6-2c3c689b16af,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-d4d46971-8acc-4fed-bf1a-a4a68b82593b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483221450-172.17.0.19-1595361575105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-1dcb0210-3e24-4a95-87c2-ff5ed5734fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-eb5ffb40-ac1f-4630-8f6b-31ea243350e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-f2e15e39-9cc4-4961-b75f-f9456c222eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-c0c3631c-d49f-4b66-8764-7966ff32e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-a93085b3-aa58-4672-b941-833c9c431084,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-e416e7c6-f30f-4f82-9de4-7f7edee5a8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-23e767e9-25b6-44a5-a0c3-a5c6ba02adec,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-d3536145-cea4-4fc4-be24-e375ce994715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483221450-172.17.0.19-1595361575105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-1dcb0210-3e24-4a95-87c2-ff5ed5734fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-eb5ffb40-ac1f-4630-8f6b-31ea243350e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-f2e15e39-9cc4-4961-b75f-f9456c222eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-c0c3631c-d49f-4b66-8764-7966ff32e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-a93085b3-aa58-4672-b941-833c9c431084,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-e416e7c6-f30f-4f82-9de4-7f7edee5a8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-23e767e9-25b6-44a5-a0c3-a5c6ba02adec,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-d3536145-cea4-4fc4-be24-e375ce994715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872474857-172.17.0.19-1595361843335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45981,DS-47df2e64-cc47-4173-82ef-7dadfd5bf2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-a273303e-9087-4334-b9c5-5d051fb8ef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-4edf15a9-2a54-4cf6-9460-d5a398429250,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-f81f1ba2-e477-4880-a7f9-bbc71fde3718,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-f224438f-d69f-4855-ba52-a4f0d83eb146,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-ae827c60-427b-4046-8596-c680e0d304f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-648ba82b-b019-42b9-8c89-c07dd3531b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-ee870220-7db8-46c7-b5b1-054ef2c5f7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872474857-172.17.0.19-1595361843335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45981,DS-47df2e64-cc47-4173-82ef-7dadfd5bf2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-a273303e-9087-4334-b9c5-5d051fb8ef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-4edf15a9-2a54-4cf6-9460-d5a398429250,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-f81f1ba2-e477-4880-a7f9-bbc71fde3718,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-f224438f-d69f-4855-ba52-a4f0d83eb146,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-ae827c60-427b-4046-8596-c680e0d304f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-648ba82b-b019-42b9-8c89-c07dd3531b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-ee870220-7db8-46c7-b5b1-054ef2c5f7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390580410-172.17.0.19-1595361919256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-567cea17-4751-468c-a603-39341048ee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-931cb32e-43b3-48f9-96d7-1c29e1d3560b,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-d2ffc539-4e07-45be-b5d6-5c8253072997,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-3a815786-e5f0-4786-a49a-9815c6ca530d,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-80f2e876-ff9a-48f2-9e25-b68cdeeee63c,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-621dc5a7-db13-45f7-9b77-4a8d62327ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-df130036-c10f-4d0b-8e38-53967dc6509b,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-68fc4a91-dce0-48a6-8196-d6d5524a5f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390580410-172.17.0.19-1595361919256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-567cea17-4751-468c-a603-39341048ee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-931cb32e-43b3-48f9-96d7-1c29e1d3560b,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-d2ffc539-4e07-45be-b5d6-5c8253072997,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-3a815786-e5f0-4786-a49a-9815c6ca530d,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-80f2e876-ff9a-48f2-9e25-b68cdeeee63c,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-621dc5a7-db13-45f7-9b77-4a8d62327ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-df130036-c10f-4d0b-8e38-53967dc6509b,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-68fc4a91-dce0-48a6-8196-d6d5524a5f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625117487-172.17.0.19-1595362447463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-18ecca16-74b9-43fe-93db-640be0d10ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-02b5af68-5196-4163-bb72-96c8335d460a,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-450b8d16-4fbf-464e-bda3-a64588fc0cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-9e7ac49a-149c-4a4c-a1b0-fee7511adaae,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-9c28cf6a-e7d0-41c6-b44b-1d707e8281da,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-db0e0642-3ae6-42ee-8e29-9e7da3fe8627,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-f20b2591-bd99-4573-a51b-3328f740f4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-fb5c7fd7-8314-4ebf-9d66-a3b4dc424f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625117487-172.17.0.19-1595362447463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-18ecca16-74b9-43fe-93db-640be0d10ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-02b5af68-5196-4163-bb72-96c8335d460a,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-450b8d16-4fbf-464e-bda3-a64588fc0cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-9e7ac49a-149c-4a4c-a1b0-fee7511adaae,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-9c28cf6a-e7d0-41c6-b44b-1d707e8281da,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-db0e0642-3ae6-42ee-8e29-9e7da3fe8627,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-f20b2591-bd99-4573-a51b-3328f740f4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-fb5c7fd7-8314-4ebf-9d66-a3b4dc424f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6524
