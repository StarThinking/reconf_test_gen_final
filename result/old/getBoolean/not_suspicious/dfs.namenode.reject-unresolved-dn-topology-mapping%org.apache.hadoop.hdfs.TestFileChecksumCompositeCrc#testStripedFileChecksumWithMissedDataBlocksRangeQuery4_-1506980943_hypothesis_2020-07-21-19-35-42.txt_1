reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66751132-172.17.0.15-1595360344814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-f43df3c0-c03d-434b-8b41-33e6a2bd3082,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-0ad1fd08-44db-408e-86ee-af3ba2a4e790,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-a507f182-fb87-40a3-b611-5fcb7afecea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-f8493457-0258-4d6e-ae66-867b2f62260e,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-3e8ae8c4-6705-4b64-8757-65313ea97353,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-36cc6cda-7201-4ae9-996f-eec143ca5985,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-55d6fc48-fc2c-4199-8122-db57d4246e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-ecf26b25-8e71-4ee4-8841-5818ecd35522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66751132-172.17.0.15-1595360344814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-f43df3c0-c03d-434b-8b41-33e6a2bd3082,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-0ad1fd08-44db-408e-86ee-af3ba2a4e790,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-a507f182-fb87-40a3-b611-5fcb7afecea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-f8493457-0258-4d6e-ae66-867b2f62260e,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-3e8ae8c4-6705-4b64-8757-65313ea97353,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-36cc6cda-7201-4ae9-996f-eec143ca5985,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-55d6fc48-fc2c-4199-8122-db57d4246e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-ecf26b25-8e71-4ee4-8841-5818ecd35522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380322818-172.17.0.15-1595361135498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38330,DS-199443d9-a200-4245-bccc-03734ec1e533,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-d2c35961-d39a-4697-ae66-bee47c04f287,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-0d3d26be-7bf7-4466-9a6f-f86eea5cb42a,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-dafd5f3e-31f2-44c4-a8e0-a8635cf02855,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-c414abcd-783c-45b8-91f8-b61152a5da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-ebb47b7a-21bb-4c86-b0c2-7861afc6f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-53144fb0-80d4-4b09-b9af-f56ada6b9f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-c05ce519-4782-49f3-ae7a-042b7041c768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380322818-172.17.0.15-1595361135498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38330,DS-199443d9-a200-4245-bccc-03734ec1e533,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-d2c35961-d39a-4697-ae66-bee47c04f287,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-0d3d26be-7bf7-4466-9a6f-f86eea5cb42a,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-dafd5f3e-31f2-44c4-a8e0-a8635cf02855,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-c414abcd-783c-45b8-91f8-b61152a5da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-ebb47b7a-21bb-4c86-b0c2-7861afc6f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-53144fb0-80d4-4b09-b9af-f56ada6b9f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-c05ce519-4782-49f3-ae7a-042b7041c768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759390148-172.17.0.15-1595362641237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42381,DS-a228fba9-f3aa-44a0-bc89-cec756718644,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-ed0e06d8-0c34-42cb-8afb-65fe49434fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-7a6ad4eb-e21b-4c48-b0cc-85e4650ca928,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-273ebf76-2566-4a01-983b-1f1533507b33,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-9245e31e-c6a5-42c6-b521-1dc85896474b,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-714bab34-1af4-450d-aadd-08bdce279eec,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-d7223fc5-24a4-4a8e-92cf-3da72f529381,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-be04c88e-fd1f-4d2f-9373-4bc6ca35f289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759390148-172.17.0.15-1595362641237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42381,DS-a228fba9-f3aa-44a0-bc89-cec756718644,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-ed0e06d8-0c34-42cb-8afb-65fe49434fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-7a6ad4eb-e21b-4c48-b0cc-85e4650ca928,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-273ebf76-2566-4a01-983b-1f1533507b33,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-9245e31e-c6a5-42c6-b521-1dc85896474b,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-714bab34-1af4-450d-aadd-08bdce279eec,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-d7223fc5-24a4-4a8e-92cf-3da72f529381,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-be04c88e-fd1f-4d2f-9373-4bc6ca35f289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551742254-172.17.0.15-1595362715703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-e33436e4-e80e-4617-9f25-e999ff63f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-12b67a72-bd7f-45a5-b52d-edb9ffc18142,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-3d9a1adc-bafc-42a5-9887-a766219e43b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-e3539136-d9f5-471b-9f61-7ef1712a56bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-dbdfe57e-d880-4b17-82fe-67e7a82317cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-85afc12e-d505-41fc-ba3d-3831ca535d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-b0b1fcef-7a3a-4ad3-bc77-0873b3d58e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-b9b34834-9aa8-47d6-8eb9-f3e888ee0feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551742254-172.17.0.15-1595362715703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-e33436e4-e80e-4617-9f25-e999ff63f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-12b67a72-bd7f-45a5-b52d-edb9ffc18142,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-3d9a1adc-bafc-42a5-9887-a766219e43b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-e3539136-d9f5-471b-9f61-7ef1712a56bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-dbdfe57e-d880-4b17-82fe-67e7a82317cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-85afc12e-d505-41fc-ba3d-3831ca535d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-b0b1fcef-7a3a-4ad3-bc77-0873b3d58e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-b9b34834-9aa8-47d6-8eb9-f3e888ee0feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092422647-172.17.0.15-1595362889590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35643,DS-e9a40a20-8ca1-47e5-a9fa-8df061597749,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-399f3f2e-0a33-4685-8c0c-36c0a001559f,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-7204bb2b-f40c-4a9c-af6f-f814587474ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-b32f75c8-43a3-416f-8f63-d52ad30a3f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-bb8e42c0-96fe-4d72-8b2f-c94d753b4ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-264ab8af-70e5-4e9a-a4ac-962561498f51,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-695dfd68-a0b5-44c8-abae-73508e786427,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-02ca1f0a-c4d4-498e-84ed-965174db87a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092422647-172.17.0.15-1595362889590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35643,DS-e9a40a20-8ca1-47e5-a9fa-8df061597749,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-399f3f2e-0a33-4685-8c0c-36c0a001559f,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-7204bb2b-f40c-4a9c-af6f-f814587474ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-b32f75c8-43a3-416f-8f63-d52ad30a3f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-bb8e42c0-96fe-4d72-8b2f-c94d753b4ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-264ab8af-70e5-4e9a-a4ac-962561498f51,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-695dfd68-a0b5-44c8-abae-73508e786427,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-02ca1f0a-c4d4-498e-84ed-965174db87a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347906185-172.17.0.15-1595363351876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38876,DS-6298ff71-6b3d-4c70-b0ed-0e7b4c049225,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-d0864fe7-c5bd-4e01-a495-00a947d984ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-45e019c1-58ba-4186-ab1b-041d702f071b,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-928d63b8-ac14-435f-ab43-f7bdb5b90fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-c41bf93e-e467-448d-86ba-4c3e0d6d2cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-63bf6b17-0ee7-4b5d-9cee-50e358eb06fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-f0e20700-397b-4408-bc1f-44c7a7aea8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-af13295c-18c9-4b8b-9e60-eab765210593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347906185-172.17.0.15-1595363351876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38876,DS-6298ff71-6b3d-4c70-b0ed-0e7b4c049225,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-d0864fe7-c5bd-4e01-a495-00a947d984ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-45e019c1-58ba-4186-ab1b-041d702f071b,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-928d63b8-ac14-435f-ab43-f7bdb5b90fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-c41bf93e-e467-448d-86ba-4c3e0d6d2cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-63bf6b17-0ee7-4b5d-9cee-50e358eb06fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-f0e20700-397b-4408-bc1f-44c7a7aea8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-af13295c-18c9-4b8b-9e60-eab765210593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633346731-172.17.0.15-1595363656413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-78ffb94d-4956-4305-8954-1db4f5a4339b,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-c9a72103-b280-4c8d-89d1-d44b41a4cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-c677d3f6-c7e4-4fd9-b1ca-a6a951a4ebdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-c5601880-8c93-4c35-a1a4-ce6a45055b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-727d01c6-c910-48bb-ae7a-c72ed7964962,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-e3836a9c-cad3-4e9e-9ae9-4b7bf73f744f,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-812e5e9a-ef4b-4bbc-b101-1f3d23a3fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-a9d7585b-39fc-43c0-bd0b-8e9d77e85a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633346731-172.17.0.15-1595363656413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-78ffb94d-4956-4305-8954-1db4f5a4339b,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-c9a72103-b280-4c8d-89d1-d44b41a4cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-c677d3f6-c7e4-4fd9-b1ca-a6a951a4ebdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-c5601880-8c93-4c35-a1a4-ce6a45055b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-727d01c6-c910-48bb-ae7a-c72ed7964962,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-e3836a9c-cad3-4e9e-9ae9-4b7bf73f744f,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-812e5e9a-ef4b-4bbc-b101-1f3d23a3fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-a9d7585b-39fc-43c0-bd0b-8e9d77e85a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461825394-172.17.0.15-1595364124038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38429,DS-fa5544dd-d462-4c6e-a5a6-515e24030930,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-62dded7e-3d46-4168-ac22-ec5cd2707187,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-e0b742fb-6200-402f-8004-614451079bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-624ddf91-4006-4d53-85ec-ea340f2364ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-4bff2f72-5770-46de-a675-2340369dc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-79a303cb-17b5-4cb7-8caa-e6e4aca0d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-cd4faf67-dc3d-4b6d-a60f-c4e4d2f89b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-92125d0b-d7fe-4f14-bbe9-06fcc93e0768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461825394-172.17.0.15-1595364124038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38429,DS-fa5544dd-d462-4c6e-a5a6-515e24030930,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-62dded7e-3d46-4168-ac22-ec5cd2707187,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-e0b742fb-6200-402f-8004-614451079bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-624ddf91-4006-4d53-85ec-ea340f2364ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-4bff2f72-5770-46de-a675-2340369dc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-79a303cb-17b5-4cb7-8caa-e6e4aca0d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-cd4faf67-dc3d-4b6d-a60f-c4e4d2f89b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-92125d0b-d7fe-4f14-bbe9-06fcc93e0768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831449639-172.17.0.15-1595364162278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-3a7fb1dc-ef76-4e38-be1e-b30deed31058,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-1a3cb2bf-0c5f-44f8-88a5-108c30cdf59a,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-b4f996e6-27ea-4ded-8b79-d524661e47b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-659833fb-1772-444c-95be-1c4a507e0880,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-d1f84219-ca18-41ee-8f64-fd8521d5ecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-c7618eb5-3a00-4dd7-8934-1dca927e71c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-09253fed-660f-486e-8ec7-eeae46ae4da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-0bca925c-82fc-46b5-995f-f11f208cd653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831449639-172.17.0.15-1595364162278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-3a7fb1dc-ef76-4e38-be1e-b30deed31058,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-1a3cb2bf-0c5f-44f8-88a5-108c30cdf59a,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-b4f996e6-27ea-4ded-8b79-d524661e47b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-659833fb-1772-444c-95be-1c4a507e0880,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-d1f84219-ca18-41ee-8f64-fd8521d5ecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-c7618eb5-3a00-4dd7-8934-1dca927e71c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-09253fed-660f-486e-8ec7-eeae46ae4da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-0bca925c-82fc-46b5-995f-f11f208cd653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375346301-172.17.0.15-1595364210004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-a3912b13-f2c7-44b4-a18d-2489a45df8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-a60963e2-e407-4672-a84b-7ab7aa03f2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-da244970-b6b5-42ff-aac9-fcfbbc252ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-e854d31c-6177-4ab6-8161-ca8aaf48d962,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-7ca7e7a3-d680-4af7-9c20-79d7ec595151,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-8e29b4a7-1296-4561-a168-4592e0944bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-833070d5-b004-4b51-bea8-b64c6ba7e411,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-639e76e9-a5ca-4acc-a58c-0391f2870258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375346301-172.17.0.15-1595364210004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-a3912b13-f2c7-44b4-a18d-2489a45df8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-a60963e2-e407-4672-a84b-7ab7aa03f2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-da244970-b6b5-42ff-aac9-fcfbbc252ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-e854d31c-6177-4ab6-8161-ca8aaf48d962,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-7ca7e7a3-d680-4af7-9c20-79d7ec595151,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-8e29b4a7-1296-4561-a168-4592e0944bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-833070d5-b004-4b51-bea8-b64c6ba7e411,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-639e76e9-a5ca-4acc-a58c-0391f2870258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235433670-172.17.0.15-1595364279910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42326,DS-05975762-eaf4-4812-9e88-3fd1d79c1b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-6e207d30-f79e-45f0-899a-669e3d338910,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-97c7cb1b-c4c2-4ece-8d91-41f0bd09ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-0673d203-2032-467a-a212-37db927dcd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-8bf5f7e1-e51c-405a-b127-6ec0d37930fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-8cc99ec4-3b87-4d90-b8cd-520c498cbeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-01ddab24-571a-4763-a6b1-d573deb01a00,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-cdccc1f0-b880-4267-a1ae-11d5c9f858f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235433670-172.17.0.15-1595364279910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42326,DS-05975762-eaf4-4812-9e88-3fd1d79c1b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-6e207d30-f79e-45f0-899a-669e3d338910,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-97c7cb1b-c4c2-4ece-8d91-41f0bd09ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-0673d203-2032-467a-a212-37db927dcd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-8bf5f7e1-e51c-405a-b127-6ec0d37930fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-8cc99ec4-3b87-4d90-b8cd-520c498cbeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-01ddab24-571a-4763-a6b1-d573deb01a00,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-cdccc1f0-b880-4267-a1ae-11d5c9f858f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208329920-172.17.0.15-1595364824600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45626,DS-6acd9f34-9ae8-4b80-8912-9aba63246b30,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-c6b25028-6c49-48fc-bb50-d7845fc786a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-1ea05f38-b56c-43fc-955f-60e32f98a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-4b5f2b97-a64b-49e0-9c39-983fd9968d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-0ca79a23-1fc3-4f12-a902-2cc31b17f091,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-d38b447f-2eb8-4db0-872c-61affc099ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-6a350433-d85c-46ac-a0eb-006568912cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-ff3f9f9a-f746-4b22-aec7-9515e2c101ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208329920-172.17.0.15-1595364824600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45626,DS-6acd9f34-9ae8-4b80-8912-9aba63246b30,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-c6b25028-6c49-48fc-bb50-d7845fc786a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-1ea05f38-b56c-43fc-955f-60e32f98a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-4b5f2b97-a64b-49e0-9c39-983fd9968d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-0ca79a23-1fc3-4f12-a902-2cc31b17f091,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-d38b447f-2eb8-4db0-872c-61affc099ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-6a350433-d85c-46ac-a0eb-006568912cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-ff3f9f9a-f746-4b22-aec7-9515e2c101ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348150922-172.17.0.15-1595365233336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-ff539d19-a4d7-4b70-9d50-39fe4941d025,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-8525f359-edb6-4108-99b5-25108f835256,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-480b6b65-08e6-4dfe-b1c2-2e8187d64b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-2bb5811b-2a2d-4f53-b0d1-ef8f5bdea57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-f7d50633-617a-4479-8101-e8859ce5255d,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-ae35c427-02bb-4b2b-a184-5ceada4bd61c,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-c925df53-4d06-4382-ac97-cb72615be106,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-3ed49bdf-95d2-427f-9b03-af69e132b0f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348150922-172.17.0.15-1595365233336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-ff539d19-a4d7-4b70-9d50-39fe4941d025,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-8525f359-edb6-4108-99b5-25108f835256,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-480b6b65-08e6-4dfe-b1c2-2e8187d64b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-2bb5811b-2a2d-4f53-b0d1-ef8f5bdea57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-f7d50633-617a-4479-8101-e8859ce5255d,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-ae35c427-02bb-4b2b-a184-5ceada4bd61c,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-c925df53-4d06-4382-ac97-cb72615be106,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-3ed49bdf-95d2-427f-9b03-af69e132b0f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331390721-172.17.0.15-1595365409281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-20281995-0ea6-45ac-b819-1a656d477223,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-69f4d990-7ede-442f-ad47-d34add00bf47,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-1a5c12ad-e3c3-4de5-8509-0af6fd89e6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-a346ba5a-b021-46c7-bd0d-3e76f1767a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-8dd0f509-a12a-4df9-8d67-bc2502e1480c,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-2a741a6c-ca5f-4ae0-a566-6183ce893cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-14b9530b-b4be-40f3-a5ac-970e5082aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-f3829ffc-3308-44c5-a11e-668e41edc764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331390721-172.17.0.15-1595365409281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-20281995-0ea6-45ac-b819-1a656d477223,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-69f4d990-7ede-442f-ad47-d34add00bf47,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-1a5c12ad-e3c3-4de5-8509-0af6fd89e6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-a346ba5a-b021-46c7-bd0d-3e76f1767a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-8dd0f509-a12a-4df9-8d67-bc2502e1480c,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-2a741a6c-ca5f-4ae0-a566-6183ce893cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-14b9530b-b4be-40f3-a5ac-970e5082aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-f3829ffc-3308-44c5-a11e-668e41edc764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803863788-172.17.0.15-1595365486142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36569,DS-11965cf9-e62c-4567-af0b-02ae4299852a,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-97573d1f-6e9b-4a0a-9c64-aa65ff8e4cea,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-878b8d9b-1169-49bf-b5da-e07ca4fb1185,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-4158d652-eafd-4e2c-b3e2-277cf73351b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-61f7bd6b-8bc2-4fe8-9bcb-17264653ec49,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-c57b5d64-7b39-4c1b-92a6-dcb6799d3799,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-268de841-4c4e-4799-8707-1e112000ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-f4216559-c5b6-4e51-9e23-af4bc6fff823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803863788-172.17.0.15-1595365486142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36569,DS-11965cf9-e62c-4567-af0b-02ae4299852a,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-97573d1f-6e9b-4a0a-9c64-aa65ff8e4cea,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-878b8d9b-1169-49bf-b5da-e07ca4fb1185,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-4158d652-eafd-4e2c-b3e2-277cf73351b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-61f7bd6b-8bc2-4fe8-9bcb-17264653ec49,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-c57b5d64-7b39-4c1b-92a6-dcb6799d3799,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-268de841-4c4e-4799-8707-1e112000ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-f4216559-c5b6-4e51-9e23-af4bc6fff823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5439
