reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026786610-172.17.0.21-1595305076440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-373267a1-b144-45c5-a47c-f5a09e08d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-2efcc995-10ae-4f91-a666-0658b5881b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-6519744c-aee1-4005-891a-926513c7a99b,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-c1cdb798-5f46-4dae-a4fb-c66419dd231a,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-b364f935-c91a-4540-82ea-1fa452e0f9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-5272d561-c86f-46af-b969-4892cfdbac60,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-24606399-65b6-4c10-8afc-e16388ba6863,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-f1079776-f04d-4731-9c96-745d38889695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026786610-172.17.0.21-1595305076440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-373267a1-b144-45c5-a47c-f5a09e08d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-2efcc995-10ae-4f91-a666-0658b5881b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-6519744c-aee1-4005-891a-926513c7a99b,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-c1cdb798-5f46-4dae-a4fb-c66419dd231a,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-b364f935-c91a-4540-82ea-1fa452e0f9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-5272d561-c86f-46af-b969-4892cfdbac60,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-24606399-65b6-4c10-8afc-e16388ba6863,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-f1079776-f04d-4731-9c96-745d38889695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063499500-172.17.0.21-1595305411929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-0fa54b8d-f99d-428e-b80d-f83cdae82315,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-82b6de01-457d-4465-9d9b-763f32283498,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-8a587bff-b475-424d-8d77-ec2e938e66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-975ef44c-6370-4f77-8d73-22a4dc039969,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-f67330d2-9494-4076-9d8a-a2cb89d54c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-a62a0fcb-d4b4-40c8-b36a-36d89b594339,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-6f67c75e-c232-43d8-a0d9-25c999d406c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-f3c41533-4ad1-40bc-8df1-672eb809ba9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063499500-172.17.0.21-1595305411929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-0fa54b8d-f99d-428e-b80d-f83cdae82315,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-82b6de01-457d-4465-9d9b-763f32283498,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-8a587bff-b475-424d-8d77-ec2e938e66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-975ef44c-6370-4f77-8d73-22a4dc039969,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-f67330d2-9494-4076-9d8a-a2cb89d54c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-a62a0fcb-d4b4-40c8-b36a-36d89b594339,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-6f67c75e-c232-43d8-a0d9-25c999d406c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-f3c41533-4ad1-40bc-8df1-672eb809ba9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783656503-172.17.0.21-1595305966993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-ea25b30b-0c82-4cfa-aa79-41a023d2ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-384d390f-99b2-42cb-a888-081e22a604d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-e67c63c8-2ae9-4221-aeb1-ca27bab0f4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-e0fa88dc-ecb0-4eed-b7fb-c4597c46e778,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-12201cab-7eaf-4593-a819-544c2a80c484,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-5c17d726-0874-463d-bcc5-de9032251f17,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-8c30bd8e-5058-45ef-b235-57c587b300e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-c6fc6af6-de27-42ea-904b-4a07510cb2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783656503-172.17.0.21-1595305966993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-ea25b30b-0c82-4cfa-aa79-41a023d2ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-384d390f-99b2-42cb-a888-081e22a604d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-e67c63c8-2ae9-4221-aeb1-ca27bab0f4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-e0fa88dc-ecb0-4eed-b7fb-c4597c46e778,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-12201cab-7eaf-4593-a819-544c2a80c484,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-5c17d726-0874-463d-bcc5-de9032251f17,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-8c30bd8e-5058-45ef-b235-57c587b300e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-c6fc6af6-de27-42ea-904b-4a07510cb2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473842069-172.17.0.21-1595306156590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-73e4e36c-a818-43a4-8da5-b68195e0cf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-1470e2f6-c4c4-4565-b583-b330596cf1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-cd75cbf4-e982-48f8-a33b-8f41d4300e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-361ca0e3-3565-457d-9c8b-43806a85ee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-87772bd4-6a8d-48de-a54d-65742a1b0062,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-38a40a7f-ab47-4fbc-a7d4-d44d876114fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-71805f33-6bec-4df8-b107-3c904ad769ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-bea5ac9d-783a-4b1b-ae00-1f3218a9fcc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473842069-172.17.0.21-1595306156590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-73e4e36c-a818-43a4-8da5-b68195e0cf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-1470e2f6-c4c4-4565-b583-b330596cf1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-cd75cbf4-e982-48f8-a33b-8f41d4300e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-361ca0e3-3565-457d-9c8b-43806a85ee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-87772bd4-6a8d-48de-a54d-65742a1b0062,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-38a40a7f-ab47-4fbc-a7d4-d44d876114fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-71805f33-6bec-4df8-b107-3c904ad769ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-bea5ac9d-783a-4b1b-ae00-1f3218a9fcc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483997168-172.17.0.21-1595306517772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35658,DS-9b2147e2-c9fe-4ed6-8144-13e8e1199e79,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-7ea2e6d8-848c-4d9c-a2ce-44c6d58bc476,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-b52fbd6c-82aa-443a-903a-0c46e24f8573,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-be3063f8-92cd-4fb8-8cd5-7ccfcb24fc78,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-74863cdc-4337-4a2a-b058-d995fabf0926,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-7e2c98e8-0e25-43aa-bb5e-422c91884579,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-db4396c2-13b2-4aa5-8d3b-a785fe140b71,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-ac6a5f02-384c-4dfd-b62b-2f23d1c8fe93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483997168-172.17.0.21-1595306517772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35658,DS-9b2147e2-c9fe-4ed6-8144-13e8e1199e79,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-7ea2e6d8-848c-4d9c-a2ce-44c6d58bc476,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-b52fbd6c-82aa-443a-903a-0c46e24f8573,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-be3063f8-92cd-4fb8-8cd5-7ccfcb24fc78,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-74863cdc-4337-4a2a-b058-d995fabf0926,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-7e2c98e8-0e25-43aa-bb5e-422c91884579,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-db4396c2-13b2-4aa5-8d3b-a785fe140b71,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-ac6a5f02-384c-4dfd-b62b-2f23d1c8fe93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628713468-172.17.0.21-1595306996275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39642,DS-c76286fd-9164-4b1f-9b70-83ff00f6e43f,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-423a0a90-e92a-442d-a958-394e9e25f24b,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-a9ee0d61-ac63-403b-8b3f-791b50f408da,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-b0ce3db3-eb46-4e88-ac64-3a0e752f1ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-d10f8e76-9a33-4ce7-b89f-d022e46dd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-074a6661-0e3d-4eea-b158-141d9045f4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-745e111f-b55a-43e5-88c4-7a943ff712b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-8c54f6c2-a94e-4003-8702-ce7492df5db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628713468-172.17.0.21-1595306996275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39642,DS-c76286fd-9164-4b1f-9b70-83ff00f6e43f,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-423a0a90-e92a-442d-a958-394e9e25f24b,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-a9ee0d61-ac63-403b-8b3f-791b50f408da,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-b0ce3db3-eb46-4e88-ac64-3a0e752f1ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-d10f8e76-9a33-4ce7-b89f-d022e46dd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-074a6661-0e3d-4eea-b158-141d9045f4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-745e111f-b55a-43e5-88c4-7a943ff712b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-8c54f6c2-a94e-4003-8702-ce7492df5db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54994573-172.17.0.21-1595307231884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44497,DS-ad5e604c-0bcd-467e-9fd2-d8e49b1cf8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-a15d456d-c2f6-44be-8b80-bc458c99a556,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-f8c0fcce-d57a-4893-8089-487a93c8d3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-acf93b1d-aa60-493b-b96a-76fa0bcd4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-b2412675-7946-4299-862a-e6fb6da99414,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-1479c653-f8ae-448f-9863-0e6e6f4018c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-54c9f9aa-81ea-4e6c-9298-7378a1f09e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-f0cddd88-f7de-463a-9106-388741aadd2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54994573-172.17.0.21-1595307231884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44497,DS-ad5e604c-0bcd-467e-9fd2-d8e49b1cf8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-a15d456d-c2f6-44be-8b80-bc458c99a556,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-f8c0fcce-d57a-4893-8089-487a93c8d3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-acf93b1d-aa60-493b-b96a-76fa0bcd4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-b2412675-7946-4299-862a-e6fb6da99414,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-1479c653-f8ae-448f-9863-0e6e6f4018c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-54c9f9aa-81ea-4e6c-9298-7378a1f09e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-f0cddd88-f7de-463a-9106-388741aadd2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318674384-172.17.0.21-1595308106154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39323,DS-80c8e31d-87a0-4c2e-a48c-79f22af0f1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-bba24ddc-3f90-48e7-8bc7-f75ac0e85946,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-2b9c306e-a5a5-4ff7-b339-fff606ddd44e,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-86bc1939-755d-4df2-8f9d-e5fbe1a83622,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-e4f19bd3-1f7c-4538-9efd-13fee75d8116,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-0f525615-ad73-473c-8dcf-7ae95404bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-b44fe619-f0c3-4021-af54-5a9c0ee061ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-8ee7fcd5-4349-4987-b3b7-dc2692c4f017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318674384-172.17.0.21-1595308106154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39323,DS-80c8e31d-87a0-4c2e-a48c-79f22af0f1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-bba24ddc-3f90-48e7-8bc7-f75ac0e85946,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-2b9c306e-a5a5-4ff7-b339-fff606ddd44e,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-86bc1939-755d-4df2-8f9d-e5fbe1a83622,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-e4f19bd3-1f7c-4538-9efd-13fee75d8116,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-0f525615-ad73-473c-8dcf-7ae95404bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-b44fe619-f0c3-4021-af54-5a9c0ee061ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-8ee7fcd5-4349-4987-b3b7-dc2692c4f017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851023487-172.17.0.21-1595308211623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46643,DS-f55d0423-823e-4c16-a30b-810a17a6244c,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-cfde7cd4-20e1-42d5-8fa8-eb5d26fde644,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-cfaeca01-f14f-4ad5-9bc6-5e9dc6a7affd,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-b925c419-94bd-4916-b698-61309fd903ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-cf168403-e95c-4455-8c45-c990855ac59a,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-6ce05c05-862e-473e-a368-92db95ba4724,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-25445f16-413a-458f-a93e-c8cd61e84ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-171351c7-eac0-47e7-a5c7-a2ab3945d954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851023487-172.17.0.21-1595308211623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46643,DS-f55d0423-823e-4c16-a30b-810a17a6244c,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-cfde7cd4-20e1-42d5-8fa8-eb5d26fde644,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-cfaeca01-f14f-4ad5-9bc6-5e9dc6a7affd,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-b925c419-94bd-4916-b698-61309fd903ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-cf168403-e95c-4455-8c45-c990855ac59a,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-6ce05c05-862e-473e-a368-92db95ba4724,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-25445f16-413a-458f-a93e-c8cd61e84ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-171351c7-eac0-47e7-a5c7-a2ab3945d954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472162633-172.17.0.21-1595308319029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46782,DS-d80c798b-1797-497f-93ae-da375e224c07,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-40a1a17e-e056-4582-90e1-a92e0a53be82,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-c254f9ce-4a50-4f13-816e-2989d0be726b,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-648856cc-86a8-456c-8e28-b8678fa33c88,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-366b6641-9c7d-4388-8eb7-c113d8d7d609,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-16b92c1f-12a1-40e2-9436-f37ec934a703,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-68f403a3-c1a3-4387-ae77-82185f088874,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-84b507fe-740d-40c7-ab23-6c3f3a3e624b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472162633-172.17.0.21-1595308319029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46782,DS-d80c798b-1797-497f-93ae-da375e224c07,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-40a1a17e-e056-4582-90e1-a92e0a53be82,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-c254f9ce-4a50-4f13-816e-2989d0be726b,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-648856cc-86a8-456c-8e28-b8678fa33c88,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-366b6641-9c7d-4388-8eb7-c113d8d7d609,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-16b92c1f-12a1-40e2-9436-f37ec934a703,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-68f403a3-c1a3-4387-ae77-82185f088874,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-84b507fe-740d-40c7-ab23-6c3f3a3e624b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061962917-172.17.0.21-1595308400675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36173,DS-7bb1f1fe-1582-4483-8871-4317b6900168,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-5764e7ef-a10a-47e1-9fd1-7bea35015186,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-9baa16cf-43a7-4f5f-af79-b90ddef15d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-8c5aeb90-9326-4ffa-b4e4-f1bc2bcf655a,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-508875c1-845d-42d2-a149-facf3a3bbe5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-74ead154-69b2-48fe-9d2d-ca29806af62b,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-9e8b018a-16b0-4cbd-9a14-3aec81ccc60e,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-f3552c39-81cb-48c0-8ebc-8b7bae891723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061962917-172.17.0.21-1595308400675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36173,DS-7bb1f1fe-1582-4483-8871-4317b6900168,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-5764e7ef-a10a-47e1-9fd1-7bea35015186,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-9baa16cf-43a7-4f5f-af79-b90ddef15d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-8c5aeb90-9326-4ffa-b4e4-f1bc2bcf655a,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-508875c1-845d-42d2-a149-facf3a3bbe5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-74ead154-69b2-48fe-9d2d-ca29806af62b,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-9e8b018a-16b0-4cbd-9a14-3aec81ccc60e,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-f3552c39-81cb-48c0-8ebc-8b7bae891723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851858675-172.17.0.21-1595308439654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-813c12b7-6122-47d1-9004-f98c127ec609,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-94592a83-c955-4e9f-ae71-fdf54c8d6889,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-34b3f015-37cd-42f8-a923-46045fdfc066,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-32dd44e8-54e5-4979-94a6-b2b146db2af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-5f4edf67-0800-4ce8-b15f-eafffbd9f3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-10fae1f5-306e-4011-bbed-45bdbd69bfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-716b8197-b7a7-4248-96e7-590b85bd6d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-4a3bce87-4571-4d68-b6e7-18682d170ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851858675-172.17.0.21-1595308439654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-813c12b7-6122-47d1-9004-f98c127ec609,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-94592a83-c955-4e9f-ae71-fdf54c8d6889,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-34b3f015-37cd-42f8-a923-46045fdfc066,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-32dd44e8-54e5-4979-94a6-b2b146db2af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-5f4edf67-0800-4ce8-b15f-eafffbd9f3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-10fae1f5-306e-4011-bbed-45bdbd69bfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-716b8197-b7a7-4248-96e7-590b85bd6d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-4a3bce87-4571-4d68-b6e7-18682d170ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510508850-172.17.0.21-1595308611905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-beda235d-0eef-4236-9630-1a48e7407d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-67b6dda5-b748-4832-a4b4-e80668311d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-bc9d1776-3196-4382-b7dd-80d65aa75d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-bbe2614e-a33b-4e05-b8e7-d986036d1f65,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-5e421530-f403-4425-bf15-b27e93779485,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-40885d34-4504-49d9-9a78-1c06dfe469d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-a68af12e-d468-442c-8761-0b172886c145,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-dde076cc-9490-4324-bc32-150d90d8f206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510508850-172.17.0.21-1595308611905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-beda235d-0eef-4236-9630-1a48e7407d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-67b6dda5-b748-4832-a4b4-e80668311d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-bc9d1776-3196-4382-b7dd-80d65aa75d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-bbe2614e-a33b-4e05-b8e7-d986036d1f65,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-5e421530-f403-4425-bf15-b27e93779485,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-40885d34-4504-49d9-9a78-1c06dfe469d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-a68af12e-d468-442c-8761-0b172886c145,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-dde076cc-9490-4324-bc32-150d90d8f206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442842422-172.17.0.21-1595309603324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-45e3b4be-18a9-41b8-8901-c9565a97bc62,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-ccd4ffc7-d0bd-4d6e-9ec6-fe0e0160e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-335a7877-4125-47b1-86a9-602c4e7a979e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-42196918-94ef-4583-868d-ed1289d5666e,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-42152754-a678-4d74-b9f8-ca3495b589ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-0663d036-a610-4287-9cd5-ed877d080c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-c84a6dc4-f0b4-4fc4-a031-59c6c7b9dada,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-1f0dc3d0-0f17-448a-a9d5-602e169f0edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442842422-172.17.0.21-1595309603324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-45e3b4be-18a9-41b8-8901-c9565a97bc62,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-ccd4ffc7-d0bd-4d6e-9ec6-fe0e0160e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-335a7877-4125-47b1-86a9-602c4e7a979e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-42196918-94ef-4583-868d-ed1289d5666e,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-42152754-a678-4d74-b9f8-ca3495b589ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-0663d036-a610-4287-9cd5-ed877d080c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-c84a6dc4-f0b4-4fc4-a031-59c6c7b9dada,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-1f0dc3d0-0f17-448a-a9d5-602e169f0edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861063876-172.17.0.21-1595310065588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36507,DS-ed5b2654-a557-4d5b-a3ff-f0f1694e8e05,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-a8119be2-0167-48ee-a666-2c1941e96a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-6f226ec7-2247-4ab6-84ac-7c74c44003c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-709b63dd-f6d5-47a5-9fc0-4dba07d9acac,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-0a6b0050-dc5b-48a2-b357-263b03e610f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-e9ede6ca-ec51-401a-bc08-4e00c2fc2985,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-08f695f5-72df-4359-9e87-f09c02c357af,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-774b70c4-61cf-4e83-92d2-3214f4a27766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861063876-172.17.0.21-1595310065588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36507,DS-ed5b2654-a557-4d5b-a3ff-f0f1694e8e05,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-a8119be2-0167-48ee-a666-2c1941e96a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-6f226ec7-2247-4ab6-84ac-7c74c44003c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-709b63dd-f6d5-47a5-9fc0-4dba07d9acac,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-0a6b0050-dc5b-48a2-b357-263b03e610f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-e9ede6ca-ec51-401a-bc08-4e00c2fc2985,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-08f695f5-72df-4359-9e87-f09c02c357af,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-774b70c4-61cf-4e83-92d2-3214f4a27766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102308310-172.17.0.21-1595310093422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-acd31059-0414-4fc6-a9f4-29460f7282e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-82c71d1f-5b77-46a1-88bd-000fd332cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-f18274c4-656e-4cd1-8d4b-528be47f6248,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-44bddb3a-b08d-47f3-8596-b7b36d3bb407,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-49a31e4e-0f0b-4e60-9d23-a0ab730ee24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-7a0fa32a-e602-4af4-9b50-5a776e53bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-d2b7945d-11f8-4bc8-9031-04749cffcfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-fdf6b1a8-75cf-4def-95d8-e7c98da590d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102308310-172.17.0.21-1595310093422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-acd31059-0414-4fc6-a9f4-29460f7282e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-82c71d1f-5b77-46a1-88bd-000fd332cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-f18274c4-656e-4cd1-8d4b-528be47f6248,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-44bddb3a-b08d-47f3-8596-b7b36d3bb407,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-49a31e4e-0f0b-4e60-9d23-a0ab730ee24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-7a0fa32a-e602-4af4-9b50-5a776e53bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-d2b7945d-11f8-4bc8-9031-04749cffcfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-fdf6b1a8-75cf-4def-95d8-e7c98da590d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929723751-172.17.0.21-1595310263640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35868,DS-5e300883-8035-49a8-803c-03e1c89a701d,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-8eb0e097-304d-44d4-9343-5d10264a9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-41ac095f-193d-4ca1-9e8a-ff4b4b789da9,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-b7adce11-6749-47d3-ae19-7f67fa3eb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-77e2900d-c9ca-486b-99d8-6c6527fbdbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-83c929f5-2381-4b38-b9d9-7a25d15b8880,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-a79d8ae8-2617-4063-a947-037cec15a560,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-3ce58ce1-9ba8-470f-8c9c-e4fbae34d8ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929723751-172.17.0.21-1595310263640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35868,DS-5e300883-8035-49a8-803c-03e1c89a701d,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-8eb0e097-304d-44d4-9343-5d10264a9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-41ac095f-193d-4ca1-9e8a-ff4b4b789da9,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-b7adce11-6749-47d3-ae19-7f67fa3eb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-77e2900d-c9ca-486b-99d8-6c6527fbdbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-83c929f5-2381-4b38-b9d9-7a25d15b8880,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-a79d8ae8-2617-4063-a947-037cec15a560,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-3ce58ce1-9ba8-470f-8c9c-e4fbae34d8ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5329
