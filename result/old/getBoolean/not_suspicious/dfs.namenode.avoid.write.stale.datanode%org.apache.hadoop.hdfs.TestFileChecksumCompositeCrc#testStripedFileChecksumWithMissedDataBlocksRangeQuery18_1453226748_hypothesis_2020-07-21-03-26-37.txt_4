reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969238280-172.17.0.2-1595302013266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-2333a475-6311-4742-a37d-a85bbaf19e20,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-55858aab-55a2-4fd2-8271-d98b1ac088b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-e2a5daaa-c9be-47e8-9b11-13a8f53a32d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-a827b63c-723c-4174-8d4c-82500427ca96,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-d2bddc48-3a7b-48d1-a5f2-323903b1b04b,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-e4a56314-4819-4df2-a533-0664b0ab7945,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-a2449ba5-b184-4356-bef4-c60dfa379c19,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-33f724c6-523a-476b-a50d-3109f10c188f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969238280-172.17.0.2-1595302013266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-2333a475-6311-4742-a37d-a85bbaf19e20,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-55858aab-55a2-4fd2-8271-d98b1ac088b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-e2a5daaa-c9be-47e8-9b11-13a8f53a32d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-a827b63c-723c-4174-8d4c-82500427ca96,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-d2bddc48-3a7b-48d1-a5f2-323903b1b04b,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-e4a56314-4819-4df2-a533-0664b0ab7945,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-a2449ba5-b184-4356-bef4-c60dfa379c19,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-33f724c6-523a-476b-a50d-3109f10c188f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816196959-172.17.0.2-1595302550753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-fab3450b-97fe-43a8-bae7-26c8d6e6d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-54d22c3a-9a21-4fab-9cad-aa1ef7b56416,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-35930161-f60a-49e6-bbab-b939be093217,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-f4964df6-f4de-4a9e-9f48-75784f051fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-bd515dfd-d8d7-43b7-b6b4-1ba85d5b2425,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-06992086-2375-43bc-8c13-62644a72987f,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-3ad22fb8-77f6-47a5-9cf5-ce19d7b6892b,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-e93d54e9-703b-423f-823c-53531f5793b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816196959-172.17.0.2-1595302550753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-fab3450b-97fe-43a8-bae7-26c8d6e6d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-54d22c3a-9a21-4fab-9cad-aa1ef7b56416,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-35930161-f60a-49e6-bbab-b939be093217,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-f4964df6-f4de-4a9e-9f48-75784f051fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-bd515dfd-d8d7-43b7-b6b4-1ba85d5b2425,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-06992086-2375-43bc-8c13-62644a72987f,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-3ad22fb8-77f6-47a5-9cf5-ce19d7b6892b,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-e93d54e9-703b-423f-823c-53531f5793b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871614147-172.17.0.2-1595302654432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40759,DS-4c746329-701c-45cd-8b03-a05bc6ef12c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-84a232a3-2eb1-4d26-b74d-04acba3b3a99,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-3f2a6f84-bf0d-4083-a6de-c9a3fbbf7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-b4f888fb-4836-460b-b0ee-de19570d9cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-7cb0bbab-2809-4215-8f3f-345b8b42e2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-71562371-4250-40ca-a762-a7b31ec38f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-9f86dc1f-52b8-4ab3-bbc4-871b314759be,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-6f21f23f-f521-4d11-86cb-0ce0ace8599f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871614147-172.17.0.2-1595302654432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40759,DS-4c746329-701c-45cd-8b03-a05bc6ef12c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-84a232a3-2eb1-4d26-b74d-04acba3b3a99,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-3f2a6f84-bf0d-4083-a6de-c9a3fbbf7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-b4f888fb-4836-460b-b0ee-de19570d9cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-7cb0bbab-2809-4215-8f3f-345b8b42e2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-71562371-4250-40ca-a762-a7b31ec38f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-9f86dc1f-52b8-4ab3-bbc4-871b314759be,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-6f21f23f-f521-4d11-86cb-0ce0ace8599f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195349506-172.17.0.2-1595302693968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37459,DS-5836d8db-4f0b-4a1f-b0cd-656a5cfd6649,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-3b4ef814-0f31-4b2e-9999-38385ecd6f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-af7838c7-3ba1-4274-ad49-2583aaf2c484,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-097eca9f-3e97-4b27-9f7f-9e89a3a6ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-f28abbfd-1a53-4c67-983f-0a50077f63f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-a690e9d3-1ad6-4687-972d-6004de4ae1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-55daaa1f-f28e-4a2f-aa73-b332f27c8f59,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-f0a6ce04-283c-4446-836a-8e70bdbf8acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195349506-172.17.0.2-1595302693968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37459,DS-5836d8db-4f0b-4a1f-b0cd-656a5cfd6649,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-3b4ef814-0f31-4b2e-9999-38385ecd6f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-af7838c7-3ba1-4274-ad49-2583aaf2c484,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-097eca9f-3e97-4b27-9f7f-9e89a3a6ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-f28abbfd-1a53-4c67-983f-0a50077f63f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-a690e9d3-1ad6-4687-972d-6004de4ae1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-55daaa1f-f28e-4a2f-aa73-b332f27c8f59,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-f0a6ce04-283c-4446-836a-8e70bdbf8acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903928687-172.17.0.2-1595304399005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43274,DS-04de7335-d674-43aa-9fbd-00b3c7f13b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-e5af9453-8137-4ae0-9961-e3c42b36e851,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-1a7b6a67-c0aa-45b4-9cfb-c21b27c190c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-3ae84d6f-b5fa-4920-94d7-f81eed59c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-c1bcddb2-98b8-4d87-b641-e303bb7e2c46,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-02e5d457-3d31-43c7-b299-be26b7c62daf,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-aebe98de-6737-4f83-b0a4-343961a4aa98,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-bbc118f3-e5f5-44d8-ace0-0bdd7bc45c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903928687-172.17.0.2-1595304399005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43274,DS-04de7335-d674-43aa-9fbd-00b3c7f13b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-e5af9453-8137-4ae0-9961-e3c42b36e851,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-1a7b6a67-c0aa-45b4-9cfb-c21b27c190c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-3ae84d6f-b5fa-4920-94d7-f81eed59c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-c1bcddb2-98b8-4d87-b641-e303bb7e2c46,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-02e5d457-3d31-43c7-b299-be26b7c62daf,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-aebe98de-6737-4f83-b0a4-343961a4aa98,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-bbc118f3-e5f5-44d8-ace0-0bdd7bc45c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963007657-172.17.0.2-1595304608701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36037,DS-d5e5f3ba-ea8d-4eba-9ef6-00217ded4ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-5955c577-5f1f-469c-ace8-e18e8f313712,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-5c603a54-8d33-436c-b364-fe6990350cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-43442225-8cc4-47c9-9c47-1a1fce988e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-a0759430-40fe-4476-b73f-d3fa3e38bbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-2d4d50c4-6247-4886-9c2d-3d083ddc44cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-6b01ef58-ef37-45b9-8838-20a3c8888765,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-672bc5e9-c9c7-48ae-9cdf-f4cd8373e5b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963007657-172.17.0.2-1595304608701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36037,DS-d5e5f3ba-ea8d-4eba-9ef6-00217ded4ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-5955c577-5f1f-469c-ace8-e18e8f313712,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-5c603a54-8d33-436c-b364-fe6990350cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-43442225-8cc4-47c9-9c47-1a1fce988e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-a0759430-40fe-4476-b73f-d3fa3e38bbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-2d4d50c4-6247-4886-9c2d-3d083ddc44cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-6b01ef58-ef37-45b9-8838-20a3c8888765,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-672bc5e9-c9c7-48ae-9cdf-f4cd8373e5b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798507769-172.17.0.2-1595304879061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38604,DS-805ba0b1-ed5d-4327-a282-23a31ca2b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-4c3709d4-39e7-4020-a4c4-32d9694742f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-b1085519-9478-4ecc-ac02-5aa105b1bcea,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-4f672a6f-2de3-4d93-91df-f2da6c1aa44b,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-a07a7685-f5db-41c0-b8bb-fb57e4c30a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-85c84b8a-9c54-46dc-8d75-5db9aeaaf18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-4ded839d-5e88-42cc-9b34-9ee820da8734,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-b2eade06-77ae-4096-962f-7223e5a2abb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798507769-172.17.0.2-1595304879061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38604,DS-805ba0b1-ed5d-4327-a282-23a31ca2b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-4c3709d4-39e7-4020-a4c4-32d9694742f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-b1085519-9478-4ecc-ac02-5aa105b1bcea,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-4f672a6f-2de3-4d93-91df-f2da6c1aa44b,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-a07a7685-f5db-41c0-b8bb-fb57e4c30a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-85c84b8a-9c54-46dc-8d75-5db9aeaaf18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-4ded839d-5e88-42cc-9b34-9ee820da8734,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-b2eade06-77ae-4096-962f-7223e5a2abb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991717682-172.17.0.2-1595305445222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-f8ed1149-0b02-4d87-a810-34bc5a4f95b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-e1a6868d-f5f0-4280-a6f6-de4b24a4782f,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-b7f8de6c-4e32-473d-846a-4685ead889f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-374dc93f-55ac-4f86-92f2-920e5c7bfc02,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-b0198831-0260-4191-961d-259d5d74c3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-702a7f63-7895-4d74-ad43-18787b61b043,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-1f558364-402c-4c5e-90e1-08efab36e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-812bbb56-1299-4ddc-9d1d-472dfb6a243f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991717682-172.17.0.2-1595305445222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-f8ed1149-0b02-4d87-a810-34bc5a4f95b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-e1a6868d-f5f0-4280-a6f6-de4b24a4782f,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-b7f8de6c-4e32-473d-846a-4685ead889f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-374dc93f-55ac-4f86-92f2-920e5c7bfc02,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-b0198831-0260-4191-961d-259d5d74c3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-702a7f63-7895-4d74-ad43-18787b61b043,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-1f558364-402c-4c5e-90e1-08efab36e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-812bbb56-1299-4ddc-9d1d-472dfb6a243f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22641043-172.17.0.2-1595306051066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44142,DS-1bbb4610-f211-471b-a697-78ff67ba5cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-bf47dc8b-e1ad-4351-aa55-20dc9d660596,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-567d5da8-3fe2-42cd-a3ca-19949225a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-e7d5a45d-eff7-4936-b0a1-e95b1e6598fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-3e47fc96-2f57-48de-8dea-86145401b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-bca85a87-97b4-4fd1-a268-3c2615dbd4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-533290ea-e768-4cc4-a5b8-e3e63d776070,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-9a1ecddd-1879-4948-a3b0-f8623c8ac25c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22641043-172.17.0.2-1595306051066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44142,DS-1bbb4610-f211-471b-a697-78ff67ba5cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-bf47dc8b-e1ad-4351-aa55-20dc9d660596,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-567d5da8-3fe2-42cd-a3ca-19949225a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-e7d5a45d-eff7-4936-b0a1-e95b1e6598fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-3e47fc96-2f57-48de-8dea-86145401b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-bca85a87-97b4-4fd1-a268-3c2615dbd4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-533290ea-e768-4cc4-a5b8-e3e63d776070,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-9a1ecddd-1879-4948-a3b0-f8623c8ac25c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690459627-172.17.0.2-1595306561917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34684,DS-7761e634-5735-4fb0-b313-526494065780,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-84729777-b756-4c95-b720-542aee1d9944,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8c4eb75e-2d74-47c0-a61f-504ad3620ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-9bfa0365-4473-46c7-b9bb-ad58ef009ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-8e7f06b8-e7cb-40b2-aea6-22a36391f44b,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-094dc2f4-b6e7-444c-86ce-f9ff32a1c274,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-db9342c6-3ed2-47da-8460-7dbfc4d8c5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-a37448a5-6217-4606-baa9-37000514d75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690459627-172.17.0.2-1595306561917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34684,DS-7761e634-5735-4fb0-b313-526494065780,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-84729777-b756-4c95-b720-542aee1d9944,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8c4eb75e-2d74-47c0-a61f-504ad3620ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-9bfa0365-4473-46c7-b9bb-ad58ef009ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-8e7f06b8-e7cb-40b2-aea6-22a36391f44b,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-094dc2f4-b6e7-444c-86ce-f9ff32a1c274,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-db9342c6-3ed2-47da-8460-7dbfc4d8c5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-a37448a5-6217-4606-baa9-37000514d75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109866322-172.17.0.2-1595306951514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-ae17d86f-1219-48ca-86a1-bdb87edd3591,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-295bdd35-3947-4eca-99ff-a9aa2188811b,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-0f774948-4b52-45c4-b3d4-b79500e8b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-ae47f941-b058-42f8-9203-c66b2a213de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-3348ad8b-6fba-4f44-bbdb-6e5724752327,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-0d9aa699-c8d3-417e-9812-198da06d2cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-b12cd2dc-d98b-4d39-b33e-85df487311af,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-7069c4c2-4f3b-442f-aae4-38f95871cc0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109866322-172.17.0.2-1595306951514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-ae17d86f-1219-48ca-86a1-bdb87edd3591,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-295bdd35-3947-4eca-99ff-a9aa2188811b,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-0f774948-4b52-45c4-b3d4-b79500e8b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-ae47f941-b058-42f8-9203-c66b2a213de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-3348ad8b-6fba-4f44-bbdb-6e5724752327,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-0d9aa699-c8d3-417e-9812-198da06d2cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-b12cd2dc-d98b-4d39-b33e-85df487311af,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-7069c4c2-4f3b-442f-aae4-38f95871cc0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5257
