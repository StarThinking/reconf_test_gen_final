reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208948749-172.17.0.5-1595329251263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33800,DS-2bf5425c-f2ca-4dc7-b818-7b811cb5625b,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-a160dc8a-5dba-4916-b4fd-72db007c3ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-5335dc69-0727-4ee2-ab3f-47a29d9a0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-90b1ae76-baf2-47e9-adff-574a8ce462a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-c2353f57-2b98-4465-97f2-099834201a55,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-1cd0e3b9-adef-4c8d-9384-fc2843a5fd54,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-c45b61bc-d84d-4232-adb2-5597c93f539b,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-3d3705c1-2a0e-4f61-8f29-e724147219c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208948749-172.17.0.5-1595329251263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33800,DS-2bf5425c-f2ca-4dc7-b818-7b811cb5625b,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-a160dc8a-5dba-4916-b4fd-72db007c3ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-5335dc69-0727-4ee2-ab3f-47a29d9a0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-90b1ae76-baf2-47e9-adff-574a8ce462a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-c2353f57-2b98-4465-97f2-099834201a55,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-1cd0e3b9-adef-4c8d-9384-fc2843a5fd54,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-c45b61bc-d84d-4232-adb2-5597c93f539b,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-3d3705c1-2a0e-4f61-8f29-e724147219c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857282587-172.17.0.5-1595329385452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38568,DS-ea2a5048-0f18-4b66-af63-df3116b4eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-32248287-6773-4c83-9c0c-446baedb5012,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-b178fa59-eed8-4615-8528-6c9d5b009c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-be2155cb-8010-4b85-a488-9276955019e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-e0889a50-fea7-4843-a99d-eb582ab8b36e,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-a85182dc-a194-47dd-9f52-4735836677f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-cfd8539b-c263-4a8e-bae7-78aecd00263f,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-89ce3875-fd1d-47e9-8e16-51f131df713f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857282587-172.17.0.5-1595329385452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38568,DS-ea2a5048-0f18-4b66-af63-df3116b4eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-32248287-6773-4c83-9c0c-446baedb5012,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-b178fa59-eed8-4615-8528-6c9d5b009c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-be2155cb-8010-4b85-a488-9276955019e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-e0889a50-fea7-4843-a99d-eb582ab8b36e,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-a85182dc-a194-47dd-9f52-4735836677f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-cfd8539b-c263-4a8e-bae7-78aecd00263f,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-89ce3875-fd1d-47e9-8e16-51f131df713f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136117436-172.17.0.5-1595329458955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36868,DS-d06409f2-28b8-43c1-8e2f-b040bee33bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-5f896620-2fc0-42d8-be70-6f35d86e39c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-ed2e2c70-6ada-4a93-8032-dbb4f8f5b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-07cdfbc9-ff98-40aa-b579-c3052e98f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-85493ea7-a86c-4e9e-a4a2-4b3b965ba0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-84442089-f9b8-471b-ab74-df1a449e0dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-935b3177-3c1d-4522-b578-574e98f6fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-a673a3aa-17a6-4526-af4f-12e6eb9b801f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136117436-172.17.0.5-1595329458955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36868,DS-d06409f2-28b8-43c1-8e2f-b040bee33bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-5f896620-2fc0-42d8-be70-6f35d86e39c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-ed2e2c70-6ada-4a93-8032-dbb4f8f5b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-07cdfbc9-ff98-40aa-b579-c3052e98f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-85493ea7-a86c-4e9e-a4a2-4b3b965ba0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-84442089-f9b8-471b-ab74-df1a449e0dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-935b3177-3c1d-4522-b578-574e98f6fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-a673a3aa-17a6-4526-af4f-12e6eb9b801f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371183170-172.17.0.5-1595329666104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-57cf3bb4-3e8e-4868-91e9-0bba2f63fc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-80254009-a6af-406f-bcff-4c42f2f86eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-3df59b8d-2802-47b1-a19d-bd0d0b1f0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-94056736-0cfb-4751-a2ae-7d30e52b7ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-290a18bb-74a2-4266-9856-ded387536d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-e7182180-a266-418e-9c8f-16fff73131fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-a2f703d0-fb3b-47bf-ba99-e1dc85cd54ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-3d445d38-ff40-4eef-86da-5c4c3badf033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371183170-172.17.0.5-1595329666104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-57cf3bb4-3e8e-4868-91e9-0bba2f63fc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-80254009-a6af-406f-bcff-4c42f2f86eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-3df59b8d-2802-47b1-a19d-bd0d0b1f0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-94056736-0cfb-4751-a2ae-7d30e52b7ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-290a18bb-74a2-4266-9856-ded387536d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-e7182180-a266-418e-9c8f-16fff73131fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-a2f703d0-fb3b-47bf-ba99-e1dc85cd54ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-3d445d38-ff40-4eef-86da-5c4c3badf033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744423886-172.17.0.5-1595329957271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-fd042454-7989-4d3d-8888-eb15019d7037,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-88925ebb-50e6-45ce-9a74-1768bdc89f29,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-186c89f9-96fc-4eab-a390-de3cc263312c,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-82d1e83b-1f57-4426-9252-09809a841109,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-18ef67a6-e880-4a17-8597-f56060786b61,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-4b2cd9cd-b3b6-4320-9a7c-b884dec7ee81,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-d670c611-8f42-4c79-bc72-51cf1b66fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-43185b4c-7de1-4328-81d5-270ec4609297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744423886-172.17.0.5-1595329957271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-fd042454-7989-4d3d-8888-eb15019d7037,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-88925ebb-50e6-45ce-9a74-1768bdc89f29,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-186c89f9-96fc-4eab-a390-de3cc263312c,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-82d1e83b-1f57-4426-9252-09809a841109,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-18ef67a6-e880-4a17-8597-f56060786b61,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-4b2cd9cd-b3b6-4320-9a7c-b884dec7ee81,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-d670c611-8f42-4c79-bc72-51cf1b66fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-43185b4c-7de1-4328-81d5-270ec4609297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713449089-172.17.0.5-1595330285877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-6743a160-4151-402e-9944-f9db7d9069f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-2fb98b5c-d17a-427c-a323-d1048b55e0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-8f8ed4e2-0554-4e41-be3c-dc1b9e05cce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-7bf68ffe-2140-4aa5-9d8e-c420edd4f252,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-d26d8de0-be1f-43ae-aead-6fca28ee2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-0fc64943-ccfc-4b4a-a942-bb0c2a546d08,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-62beaa1e-e8b8-46e8-9120-980e89560367,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-b37e33a0-4acf-491a-b797-164e5f44f8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713449089-172.17.0.5-1595330285877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-6743a160-4151-402e-9944-f9db7d9069f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-2fb98b5c-d17a-427c-a323-d1048b55e0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-8f8ed4e2-0554-4e41-be3c-dc1b9e05cce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-7bf68ffe-2140-4aa5-9d8e-c420edd4f252,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-d26d8de0-be1f-43ae-aead-6fca28ee2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-0fc64943-ccfc-4b4a-a942-bb0c2a546d08,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-62beaa1e-e8b8-46e8-9120-980e89560367,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-b37e33a0-4acf-491a-b797-164e5f44f8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632346696-172.17.0.5-1595330433311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41529,DS-701a0774-4e49-47e4-9ef0-2369072f13f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-ba258636-0a5d-48c2-b8ab-8aef8a36e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-c143cf38-007b-4c4c-a67b-d0c3a2bce758,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-9a2fb69c-9446-4503-8e5d-39bcd1c22d68,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-0e44a839-b2a1-4626-b7f8-8ac12394c4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-269edee8-7815-44e0-9041-fb3a5ea5c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-241cd65d-4b26-4b58-bc58-feabb194aff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-f6ea6915-5bc2-4dee-894f-bdb3ae232693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632346696-172.17.0.5-1595330433311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41529,DS-701a0774-4e49-47e4-9ef0-2369072f13f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-ba258636-0a5d-48c2-b8ab-8aef8a36e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-c143cf38-007b-4c4c-a67b-d0c3a2bce758,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-9a2fb69c-9446-4503-8e5d-39bcd1c22d68,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-0e44a839-b2a1-4626-b7f8-8ac12394c4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-269edee8-7815-44e0-9041-fb3a5ea5c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-241cd65d-4b26-4b58-bc58-feabb194aff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-f6ea6915-5bc2-4dee-894f-bdb3ae232693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225425097-172.17.0.5-1595330918823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46838,DS-57039b77-c358-428f-bc91-abd0c8f09e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-8e830156-5622-44ea-92fd-6924952dc0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-38d96bf2-8f14-4cce-bdf8-10ab9188aa88,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-01910b05-ddc7-472b-85ce-b23509028eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-5392f813-8c15-4119-addc-efedcf265032,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-4d511274-aef9-424f-95a7-6206a24bbb49,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-1673e112-c882-4a58-873d-8874e7b2c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-3b58b04a-2460-450c-abb5-6ea419b3d1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225425097-172.17.0.5-1595330918823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46838,DS-57039b77-c358-428f-bc91-abd0c8f09e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-8e830156-5622-44ea-92fd-6924952dc0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-38d96bf2-8f14-4cce-bdf8-10ab9188aa88,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-01910b05-ddc7-472b-85ce-b23509028eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-5392f813-8c15-4119-addc-efedcf265032,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-4d511274-aef9-424f-95a7-6206a24bbb49,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-1673e112-c882-4a58-873d-8874e7b2c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-3b58b04a-2460-450c-abb5-6ea419b3d1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304972346-172.17.0.5-1595331184421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-96c8f99b-d577-4614-9fa0-2f13235cac53,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-0073978a-9652-46e0-9974-eeabfdc18591,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-89709e46-93f8-4415-a94c-86319563cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-7fd2d0e7-8f0a-4b29-aad2-094e71c9ed4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-1f020b01-3273-4e67-8daa-dabda66d85c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-666650e4-b647-4653-8e62-3c5ed6897bea,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-93c05811-c349-4ed4-afb2-b6367c44d922,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-2342f488-53c1-4de4-80b1-ddb56738fdac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304972346-172.17.0.5-1595331184421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-96c8f99b-d577-4614-9fa0-2f13235cac53,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-0073978a-9652-46e0-9974-eeabfdc18591,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-89709e46-93f8-4415-a94c-86319563cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-7fd2d0e7-8f0a-4b29-aad2-094e71c9ed4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-1f020b01-3273-4e67-8daa-dabda66d85c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-666650e4-b647-4653-8e62-3c5ed6897bea,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-93c05811-c349-4ed4-afb2-b6367c44d922,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-2342f488-53c1-4de4-80b1-ddb56738fdac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526112067-172.17.0.5-1595331386016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45846,DS-56058dab-7f05-4867-8756-25b8b7dfa27b,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-9961db0e-77df-4c4c-9160-8cc2da526809,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-95a50ac6-4b94-498d-a58d-a8e101d54cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-dbf461f3-4a9a-4c6b-b88a-6f474657feed,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-ba2c2d0d-f49f-4392-a0ca-6f3d78d13e29,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-b47b3592-78c7-40d0-9e72-8c19c550071a,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-21b36596-5339-435d-ae9c-521a88c30738,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-2781283f-7f52-4849-9462-971104d3c237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526112067-172.17.0.5-1595331386016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45846,DS-56058dab-7f05-4867-8756-25b8b7dfa27b,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-9961db0e-77df-4c4c-9160-8cc2da526809,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-95a50ac6-4b94-498d-a58d-a8e101d54cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-dbf461f3-4a9a-4c6b-b88a-6f474657feed,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-ba2c2d0d-f49f-4392-a0ca-6f3d78d13e29,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-b47b3592-78c7-40d0-9e72-8c19c550071a,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-21b36596-5339-435d-ae9c-521a88c30738,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-2781283f-7f52-4849-9462-971104d3c237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756375311-172.17.0.5-1595331459189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-e2e1e64c-e196-4652-8b9b-c97d68164cff,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-9745f252-2d91-4cf4-b90c-c4c627da6a45,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-b7ebb797-e9d4-4c5d-88db-059e6964ae98,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-78094b59-0ce3-48d2-b91d-8bcdd8929080,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-c4c8dbe8-cdc0-4b9c-9806-e8f61cd63e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-a71bdeaf-b659-4f9d-87b2-2725bffba2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-50e6b5e8-9ac9-4644-a0c1-86fc353ea79f,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-de462229-24c5-4b74-99ca-c6d8be539da8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756375311-172.17.0.5-1595331459189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-e2e1e64c-e196-4652-8b9b-c97d68164cff,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-9745f252-2d91-4cf4-b90c-c4c627da6a45,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-b7ebb797-e9d4-4c5d-88db-059e6964ae98,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-78094b59-0ce3-48d2-b91d-8bcdd8929080,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-c4c8dbe8-cdc0-4b9c-9806-e8f61cd63e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-a71bdeaf-b659-4f9d-87b2-2725bffba2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-50e6b5e8-9ac9-4644-a0c1-86fc353ea79f,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-de462229-24c5-4b74-99ca-c6d8be539da8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351059838-172.17.0.5-1595331632225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34667,DS-86ccb37b-4b86-4460-964d-7b9a641ab660,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-437651a8-daf7-4686-92e4-2ed1f3e124ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-f0261351-cb2a-4fb8-b914-43a39e50235d,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-dd0af86f-427f-47a9-bfd9-8ed82a12766e,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-dcd8aa95-d37f-4d80-84c6-12a66ba7dbad,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-1794c92e-a8b5-46e1-a9c7-7a6a39c9e19d,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-4cee9685-340c-407b-93cf-b39e966581b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-d1fd9d46-136c-4fc9-9944-e264d8da1f11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351059838-172.17.0.5-1595331632225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34667,DS-86ccb37b-4b86-4460-964d-7b9a641ab660,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-437651a8-daf7-4686-92e4-2ed1f3e124ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-f0261351-cb2a-4fb8-b914-43a39e50235d,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-dd0af86f-427f-47a9-bfd9-8ed82a12766e,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-dcd8aa95-d37f-4d80-84c6-12a66ba7dbad,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-1794c92e-a8b5-46e1-a9c7-7a6a39c9e19d,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-4cee9685-340c-407b-93cf-b39e966581b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-d1fd9d46-136c-4fc9-9944-e264d8da1f11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360518146-172.17.0.5-1595333556412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-3a98f455-2b7e-4e62-8a06-29367f85910c,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-e0dd50e7-5041-4c51-b344-9cb95ae00208,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-5c9bf01d-ea8a-4eb3-b4da-b5b7a5fc0652,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-14279678-5559-4222-a3a2-b94d74204ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-045ef869-2fa3-4af1-aa20-53345af19830,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-8195f7a9-e947-4925-a95c-16e49fbaeb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-3f544a7b-c2fc-40d3-9464-5d7645899bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-c5f45528-fbcd-4755-b9c8-bea0b1b7760b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360518146-172.17.0.5-1595333556412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-3a98f455-2b7e-4e62-8a06-29367f85910c,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-e0dd50e7-5041-4c51-b344-9cb95ae00208,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-5c9bf01d-ea8a-4eb3-b4da-b5b7a5fc0652,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-14279678-5559-4222-a3a2-b94d74204ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-045ef869-2fa3-4af1-aa20-53345af19830,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-8195f7a9-e947-4925-a95c-16e49fbaeb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-3f544a7b-c2fc-40d3-9464-5d7645899bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-c5f45528-fbcd-4755-b9c8-bea0b1b7760b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5111
