reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485819823-172.17.0.3-1595429016007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42122,DS-23139cc6-70fa-4c88-ac19-33727f06c039,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-3284c45e-d857-4dea-9f03-ca82298ab492,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-55a3b38c-5f08-4965-aedd-3980bb601519,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-f609a228-f5db-41f5-8c46-b8811634b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-91e46140-a255-4aa3-b01c-29655074b70c,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-593a2267-281f-4a5a-b218-f7cc17f2c669,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-50cf47e2-fa8e-499e-b10e-657ab1d2fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-c7c05629-bc23-40c1-90c2-61c82c1f852a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485819823-172.17.0.3-1595429016007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42122,DS-23139cc6-70fa-4c88-ac19-33727f06c039,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-3284c45e-d857-4dea-9f03-ca82298ab492,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-55a3b38c-5f08-4965-aedd-3980bb601519,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-f609a228-f5db-41f5-8c46-b8811634b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-91e46140-a255-4aa3-b01c-29655074b70c,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-593a2267-281f-4a5a-b218-f7cc17f2c669,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-50cf47e2-fa8e-499e-b10e-657ab1d2fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-c7c05629-bc23-40c1-90c2-61c82c1f852a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891839493-172.17.0.3-1595429055747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-5edcf76e-9672-4701-ac0a-7ed10020bab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-e0739abe-d1dd-4c9f-859c-7df08299e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-1fa8b585-e6e6-4f88-9018-b41ade728ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-956357a4-1a76-4884-8baf-a3cdfd217321,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-9a89bc24-deec-4ed7-8e83-9319647210c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-f0b7b738-7a06-49d1-8df7-bdb3c820a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-a11f7fa5-9fbc-4d53-80cb-3871c5dd4958,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-2634e2ed-3462-4bae-9422-f43a59962758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891839493-172.17.0.3-1595429055747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-5edcf76e-9672-4701-ac0a-7ed10020bab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-e0739abe-d1dd-4c9f-859c-7df08299e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-1fa8b585-e6e6-4f88-9018-b41ade728ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-956357a4-1a76-4884-8baf-a3cdfd217321,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-9a89bc24-deec-4ed7-8e83-9319647210c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-f0b7b738-7a06-49d1-8df7-bdb3c820a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-a11f7fa5-9fbc-4d53-80cb-3871c5dd4958,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-2634e2ed-3462-4bae-9422-f43a59962758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683941011-172.17.0.3-1595429138774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34814,DS-70abc793-2497-44aa-92a9-41bbf3a563c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-0572a1d5-2d08-4a3a-993f-6ac082c68e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-cc736940-cb7e-48cd-912a-7d996aa1c99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-1d172dfd-3336-4789-9fe2-bd2c5af9e9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-8c336a96-0c8d-4708-bd32-da592b49bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-9efca927-482e-44b9-ad8f-43b29ae11243,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-728f2c0c-7431-4790-8ba3-e8cb5bd55b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-a5a63aca-3d36-4b7b-ae50-a739ff1a5ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683941011-172.17.0.3-1595429138774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34814,DS-70abc793-2497-44aa-92a9-41bbf3a563c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-0572a1d5-2d08-4a3a-993f-6ac082c68e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-cc736940-cb7e-48cd-912a-7d996aa1c99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-1d172dfd-3336-4789-9fe2-bd2c5af9e9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-8c336a96-0c8d-4708-bd32-da592b49bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-9efca927-482e-44b9-ad8f-43b29ae11243,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-728f2c0c-7431-4790-8ba3-e8cb5bd55b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-a5a63aca-3d36-4b7b-ae50-a739ff1a5ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260777364-172.17.0.3-1595429225805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-92514ac3-0894-4593-be6f-2f9c6d601f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-fd4b3795-a384-4f93-ba3c-c2cbce97c383,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-08de5861-3d11-435d-bbc9-0de3ea381ead,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-78c3a37b-593a-4761-9b82-cdc75d5dd231,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-0eb3b962-1839-4296-a4d3-eb49f1841c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-8595b635-7a31-424a-867f-c1f052c5101d,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-e4a01f9a-2bba-4e23-aa1e-9d2df7055c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-5403660c-31b0-4dbd-8f85-a46ea388c328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260777364-172.17.0.3-1595429225805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-92514ac3-0894-4593-be6f-2f9c6d601f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-fd4b3795-a384-4f93-ba3c-c2cbce97c383,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-08de5861-3d11-435d-bbc9-0de3ea381ead,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-78c3a37b-593a-4761-9b82-cdc75d5dd231,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-0eb3b962-1839-4296-a4d3-eb49f1841c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-8595b635-7a31-424a-867f-c1f052c5101d,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-e4a01f9a-2bba-4e23-aa1e-9d2df7055c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-5403660c-31b0-4dbd-8f85-a46ea388c328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494910223-172.17.0.3-1595429336805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-6aeb4c1f-cadb-4329-bd82-d1d7fda8b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-19bec67f-e990-4149-9a7a-58d4ff3f02e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-ef283165-ff2a-42e9-9240-2107c7043629,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-1ceaafa0-fccd-42c3-9b73-2d7f103a11e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-a6bd9242-bb67-4efc-9e46-fc0d7e02e136,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-f60bf1d2-fdc6-4d2d-a037-75ed4746cbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-bf616836-96dc-49e9-91cf-684d1d15ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-7f5f1d8e-1f29-4fb1-9ae2-382bd85d1d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494910223-172.17.0.3-1595429336805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-6aeb4c1f-cadb-4329-bd82-d1d7fda8b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-19bec67f-e990-4149-9a7a-58d4ff3f02e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-ef283165-ff2a-42e9-9240-2107c7043629,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-1ceaafa0-fccd-42c3-9b73-2d7f103a11e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-a6bd9242-bb67-4efc-9e46-fc0d7e02e136,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-f60bf1d2-fdc6-4d2d-a037-75ed4746cbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-bf616836-96dc-49e9-91cf-684d1d15ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-7f5f1d8e-1f29-4fb1-9ae2-382bd85d1d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533868437-172.17.0.3-1595429635501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37239,DS-2f181699-c4e6-468e-a321-ad7bc6f8b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-1d919802-1ae9-4436-b4a1-038ee7610909,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-dbbc761a-a648-45f5-9920-f18581e54b13,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-0f15ec43-1c15-4bf9-a23b-cc58bcc28c37,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-6cf9706e-2315-475c-a3ce-ebe4820b4c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-d9f4d769-21c1-48b8-ae18-9715120e48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-2c8eeb76-4be2-4879-93e7-b501b726bbec,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-38bfe259-8b1d-4ac1-9303-5434aa90d95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533868437-172.17.0.3-1595429635501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37239,DS-2f181699-c4e6-468e-a321-ad7bc6f8b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-1d919802-1ae9-4436-b4a1-038ee7610909,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-dbbc761a-a648-45f5-9920-f18581e54b13,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-0f15ec43-1c15-4bf9-a23b-cc58bcc28c37,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-6cf9706e-2315-475c-a3ce-ebe4820b4c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-d9f4d769-21c1-48b8-ae18-9715120e48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-2c8eeb76-4be2-4879-93e7-b501b726bbec,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-38bfe259-8b1d-4ac1-9303-5434aa90d95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407252164-172.17.0.3-1595429727030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38562,DS-83d3e261-f54b-44d4-8107-1fbb76133d68,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-5731f023-5c96-47c5-b2a0-808b179172cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-a9a0ea48-f0d8-4b28-be0d-9028463bec88,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-83b1f621-0e6c-4165-b43c-61533980a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-540ab310-76f6-41ae-b4a7-ec050230dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-cdd09a6a-6832-46ff-adc1-dc534d0770b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-cd70486f-0677-4ee0-9911-354d3c3fd795,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-475b573c-35a6-4bb0-83f3-34c91fb71c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407252164-172.17.0.3-1595429727030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38562,DS-83d3e261-f54b-44d4-8107-1fbb76133d68,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-5731f023-5c96-47c5-b2a0-808b179172cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-a9a0ea48-f0d8-4b28-be0d-9028463bec88,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-83b1f621-0e6c-4165-b43c-61533980a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-540ab310-76f6-41ae-b4a7-ec050230dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-cdd09a6a-6832-46ff-adc1-dc534d0770b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-cd70486f-0677-4ee0-9911-354d3c3fd795,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-475b573c-35a6-4bb0-83f3-34c91fb71c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062406094-172.17.0.3-1595430642540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-1387297b-119b-4008-84c6-1789bdd7a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-9420b627-3aec-4173-b1c7-d2cf2f80f161,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-5fff14f7-e17a-4a6f-a1ce-c6be603268d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-ca7557ef-9cf4-468d-b427-44019f7817fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-1dff11b9-3629-426d-be6a-adab20b5635d,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-8eeb4fec-e0d3-40a4-a6fd-913d44ec8440,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-7f97ae04-c7cd-4044-b910-8e497cec82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-5925adc6-c176-41cc-bbc6-4ad2111dd8d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062406094-172.17.0.3-1595430642540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-1387297b-119b-4008-84c6-1789bdd7a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-9420b627-3aec-4173-b1c7-d2cf2f80f161,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-5fff14f7-e17a-4a6f-a1ce-c6be603268d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-ca7557ef-9cf4-468d-b427-44019f7817fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-1dff11b9-3629-426d-be6a-adab20b5635d,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-8eeb4fec-e0d3-40a4-a6fd-913d44ec8440,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-7f97ae04-c7cd-4044-b910-8e497cec82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-5925adc6-c176-41cc-bbc6-4ad2111dd8d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174738321-172.17.0.3-1595431306892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-bfcff044-6e70-4ea5-bce3-70a91e934f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-f485d70a-d05b-49a9-8458-d8e992b0817c,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-e47c8cb5-a7b5-4c3e-aa6f-68d8e5d3ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-64d9c18a-9bb1-420b-94bf-89c7b4c9acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-605eb98e-3646-43b1-8076-df901b3bd898,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-9616d957-deb6-4750-bd48-01336854e309,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-024e83fd-c4b7-44a9-8731-7cfd10d38249,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-c980ace5-506f-4d9e-93e4-3d452bbdca78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174738321-172.17.0.3-1595431306892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-bfcff044-6e70-4ea5-bce3-70a91e934f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-f485d70a-d05b-49a9-8458-d8e992b0817c,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-e47c8cb5-a7b5-4c3e-aa6f-68d8e5d3ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-64d9c18a-9bb1-420b-94bf-89c7b4c9acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-605eb98e-3646-43b1-8076-df901b3bd898,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-9616d957-deb6-4750-bd48-01336854e309,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-024e83fd-c4b7-44a9-8731-7cfd10d38249,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-c980ace5-506f-4d9e-93e4-3d452bbdca78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554997910-172.17.0.3-1595431395672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33792,DS-e913ba20-d74e-44a2-bf18-cc93cd4462b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-8d424fa1-07ac-49b9-8a92-ae07456dd2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-fb7c3cc7-9886-482f-b489-1aed093ceb01,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-5246ce8b-175d-4d12-a5a4-b9a3e3228e02,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-a0d71645-c5d7-4022-b84e-f81d5a3b2c45,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-25679a0c-531e-464d-9aa1-3fffa0dfbc93,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-8f018180-d2f5-4af4-b009-de753c74f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-dd1fff26-da0d-4e89-b7f2-cd8ca0836e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554997910-172.17.0.3-1595431395672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33792,DS-e913ba20-d74e-44a2-bf18-cc93cd4462b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-8d424fa1-07ac-49b9-8a92-ae07456dd2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-fb7c3cc7-9886-482f-b489-1aed093ceb01,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-5246ce8b-175d-4d12-a5a4-b9a3e3228e02,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-a0d71645-c5d7-4022-b84e-f81d5a3b2c45,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-25679a0c-531e-464d-9aa1-3fffa0dfbc93,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-8f018180-d2f5-4af4-b009-de753c74f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-dd1fff26-da0d-4e89-b7f2-cd8ca0836e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783843313-172.17.0.3-1595431611542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-aa45d550-9fa4-4196-88e4-59f6b1b5e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-cbd2ad2d-4ad9-4599-8d45-255392702402,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-a2f345ac-022d-4638-8216-b405f37af435,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-3590d47e-f2cf-4f28-bfc1-0d65d1cb6fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-e5065ec7-6e58-4e1c-a549-c96166d1ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-dad0d28c-ded8-49c8-b1c3-a6fc11614a26,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-37a16305-a4fd-4c47-bb2b-1287856323ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-812fb0cd-9b4f-4987-8981-a2c96b49f7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783843313-172.17.0.3-1595431611542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-aa45d550-9fa4-4196-88e4-59f6b1b5e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-cbd2ad2d-4ad9-4599-8d45-255392702402,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-a2f345ac-022d-4638-8216-b405f37af435,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-3590d47e-f2cf-4f28-bfc1-0d65d1cb6fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-e5065ec7-6e58-4e1c-a549-c96166d1ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-dad0d28c-ded8-49c8-b1c3-a6fc11614a26,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-37a16305-a4fd-4c47-bb2b-1287856323ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-812fb0cd-9b4f-4987-8981-a2c96b49f7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407121353-172.17.0.3-1595431899249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42179,DS-d5956df8-a3dc-4519-a226-8272cb888eec,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-aea6e05f-6db7-41bc-8a20-73fde8081d73,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-1a792aac-0977-482d-9eb1-ff67753e0efd,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-1dea5b57-25e2-4b73-a862-b57010d1bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-e3baa0d7-d632-4bf5-90f0-5f380c114aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-fef062c5-59bb-45dd-8f84-0f81d478c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-f3a01201-7375-4b6b-a94b-4f7fe8126350,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-6a5f799e-3846-4c69-913e-b9e1e1428e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407121353-172.17.0.3-1595431899249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42179,DS-d5956df8-a3dc-4519-a226-8272cb888eec,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-aea6e05f-6db7-41bc-8a20-73fde8081d73,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-1a792aac-0977-482d-9eb1-ff67753e0efd,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-1dea5b57-25e2-4b73-a862-b57010d1bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-e3baa0d7-d632-4bf5-90f0-5f380c114aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-fef062c5-59bb-45dd-8f84-0f81d478c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-f3a01201-7375-4b6b-a94b-4f7fe8126350,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-6a5f799e-3846-4c69-913e-b9e1e1428e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985122901-172.17.0.3-1595432379100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38626,DS-b1c48feb-ead1-4bd0-980d-40d4fc18cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-b0413313-8d8d-4b26-af7d-34403d02145e,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-bcf30499-c2dd-45f9-b112-c6e3329707ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-5ae7d6ff-6849-40ce-9536-a5bf0ff72c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-557433dc-565a-46e5-b894-948fd1f6f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-67b381ad-27ad-49c5-8509-c453ceb1b56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-e7200814-e06d-4524-8c45-96a4cabc94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-b65f2488-66e2-45dd-84b6-d751f8c21d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985122901-172.17.0.3-1595432379100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38626,DS-b1c48feb-ead1-4bd0-980d-40d4fc18cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-b0413313-8d8d-4b26-af7d-34403d02145e,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-bcf30499-c2dd-45f9-b112-c6e3329707ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-5ae7d6ff-6849-40ce-9536-a5bf0ff72c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-557433dc-565a-46e5-b894-948fd1f6f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-67b381ad-27ad-49c5-8509-c453ceb1b56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-e7200814-e06d-4524-8c45-96a4cabc94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-b65f2488-66e2-45dd-84b6-d751f8c21d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691429909-172.17.0.3-1595432801025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-9eae6255-b526-4eeb-bdcd-898a5584623d,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-b3fe24ab-0245-4f03-a1fc-c0fdce569486,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-1fc2e594-695a-4472-ac72-a58494707c99,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-7e432362-9748-4067-865a-208134a384d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-39a8090e-33d4-4c1c-8ebf-0fad776cfab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-3dc9388f-2a58-46c3-a151-048b9329d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-ce397f6a-85c3-4ff0-981a-84252376ba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-8116de7f-bbc9-47a9-9a23-e97016c44e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691429909-172.17.0.3-1595432801025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-9eae6255-b526-4eeb-bdcd-898a5584623d,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-b3fe24ab-0245-4f03-a1fc-c0fdce569486,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-1fc2e594-695a-4472-ac72-a58494707c99,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-7e432362-9748-4067-865a-208134a384d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-39a8090e-33d4-4c1c-8ebf-0fad776cfab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-3dc9388f-2a58-46c3-a151-048b9329d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-ce397f6a-85c3-4ff0-981a-84252376ba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-8116de7f-bbc9-47a9-9a23-e97016c44e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297942273-172.17.0.3-1595432957413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-b55b5497-3848-4bb9-905e-a3d4eac4a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-3cace3cb-470b-4dd2-9e43-0ef7202adb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-371ba9c2-9569-4ced-9385-9d64a7386405,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-2ca3a341-f7dc-44de-96fa-fa2069dbe341,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-437fe3e8-45a1-4e54-af76-efa0961dccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-3f5b9d96-966e-4624-aad9-495cabcbc181,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-f380e14d-1db1-4e6f-859e-cb6e6ed198c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-74938b79-67c1-4096-892b-e218203cea2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297942273-172.17.0.3-1595432957413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-b55b5497-3848-4bb9-905e-a3d4eac4a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-3cace3cb-470b-4dd2-9e43-0ef7202adb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-371ba9c2-9569-4ced-9385-9d64a7386405,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-2ca3a341-f7dc-44de-96fa-fa2069dbe341,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-437fe3e8-45a1-4e54-af76-efa0961dccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-3f5b9d96-966e-4624-aad9-495cabcbc181,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-f380e14d-1db1-4e6f-859e-cb6e6ed198c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-74938b79-67c1-4096-892b-e218203cea2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786696226-172.17.0.3-1595432999964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-cf20d0a6-7a9d-4222-83fd-1114531a4642,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-bf4afc06-3505-4632-ba99-a2b4b8fd3926,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-b9099c86-40c9-4043-a3f9-e290ba3e7199,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-c5a9d06f-b64f-4d50-bebb-2c549b889033,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-a1409b53-97d5-4e6f-b53f-770697626ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-1b689efa-c59d-4369-897e-44f6a3b9c850,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-fd063aa0-126d-4349-8373-f6d230eac77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-ee56b977-0cdb-41d6-916c-19b9bc4487af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786696226-172.17.0.3-1595432999964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-cf20d0a6-7a9d-4222-83fd-1114531a4642,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-bf4afc06-3505-4632-ba99-a2b4b8fd3926,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-b9099c86-40c9-4043-a3f9-e290ba3e7199,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-c5a9d06f-b64f-4d50-bebb-2c549b889033,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-a1409b53-97d5-4e6f-b53f-770697626ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-1b689efa-c59d-4369-897e-44f6a3b9c850,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-fd063aa0-126d-4349-8373-f6d230eac77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-ee56b977-0cdb-41d6-916c-19b9bc4487af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684307683-172.17.0.3-1595433432639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39989,DS-b1f93aa6-ece8-4487-bfbc-af586c66368d,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-bf1cc88a-e889-4f5f-9649-724d5d25196c,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-0f7a402a-2c5d-4a1b-857a-4a6aa2645f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-9201eba8-0f14-4529-acc5-accdc8fbe0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-9c725c49-e5bb-4553-a594-1cbd82d3604d,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-4eb73c02-5ac2-4586-8153-9e5a0a938e98,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-5554eb37-2d9a-444d-b1d9-46984341a985,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-90f682f0-a68b-4994-ac15-3c8043bb66b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684307683-172.17.0.3-1595433432639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39989,DS-b1f93aa6-ece8-4487-bfbc-af586c66368d,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-bf1cc88a-e889-4f5f-9649-724d5d25196c,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-0f7a402a-2c5d-4a1b-857a-4a6aa2645f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-9201eba8-0f14-4529-acc5-accdc8fbe0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-9c725c49-e5bb-4553-a594-1cbd82d3604d,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-4eb73c02-5ac2-4586-8153-9e5a0a938e98,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-5554eb37-2d9a-444d-b1d9-46984341a985,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-90f682f0-a68b-4994-ac15-3c8043bb66b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405267642-172.17.0.3-1595433562117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37168,DS-068724f8-7926-41c2-a00b-325fea5e3e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-845305ea-5ae4-4f0a-8eb9-14c83c8aa957,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-b3bb55b4-89a5-433d-bd6e-c88f29eeef2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-75071c68-c39c-437e-94f4-ffee862ddef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-8bc3ca74-5c52-4cf6-9586-8dfaff5f35d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-508f00c4-9d81-4454-aa7c-2ef11ff79dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-d944e751-2e51-49e3-9f82-23ce38a909c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-cd180fc9-05cf-4e11-830a-d3267a563c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405267642-172.17.0.3-1595433562117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37168,DS-068724f8-7926-41c2-a00b-325fea5e3e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-845305ea-5ae4-4f0a-8eb9-14c83c8aa957,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-b3bb55b4-89a5-433d-bd6e-c88f29eeef2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-75071c68-c39c-437e-94f4-ffee862ddef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-8bc3ca74-5c52-4cf6-9586-8dfaff5f35d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-508f00c4-9d81-4454-aa7c-2ef11ff79dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-d944e751-2e51-49e3-9f82-23ce38a909c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-cd180fc9-05cf-4e11-830a-d3267a563c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118943674-172.17.0.3-1595434074987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33882,DS-42f6a109-ed44-40aa-a4b6-10ec294d185e,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-cfcc6d18-9595-488c-9ab7-d03d9a9e452d,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-042950e8-33c5-4319-8474-7f5f0eea2484,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-340d0d45-c983-47e2-916e-b1400633bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-f8179fea-150c-49b9-91aa-5d1151389544,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-b3496ab6-9abd-4be5-9988-718caa6bc335,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-bb3f954c-9271-4078-8595-81bd66edde7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-a1c25cba-0802-4705-a6cc-a8fc73b0beea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118943674-172.17.0.3-1595434074987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33882,DS-42f6a109-ed44-40aa-a4b6-10ec294d185e,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-cfcc6d18-9595-488c-9ab7-d03d9a9e452d,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-042950e8-33c5-4319-8474-7f5f0eea2484,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-340d0d45-c983-47e2-916e-b1400633bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-f8179fea-150c-49b9-91aa-5d1151389544,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-b3496ab6-9abd-4be5-9988-718caa6bc335,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-bb3f954c-9271-4078-8595-81bd66edde7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-a1c25cba-0802-4705-a6cc-a8fc73b0beea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824276793-172.17.0.3-1595434163423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-e1879024-9581-45be-9241-edc6412565cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-b5b47a41-c0fa-4511-90c1-c4caa6ac57e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-4e6b5196-1cf3-4212-a2b3-d93754b8966a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-b3d92c62-27ff-44c1-b276-1adb99b23b31,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-f7517195-0845-4103-9a21-f88e90bbbb95,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-81930a72-ca2e-43bb-ae82-fbc099d5468e,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-fca65fc6-d763-45a7-a644-8742cd709a90,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-d2ac5d1b-eb00-4f1c-9407-17ba1f28e0b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824276793-172.17.0.3-1595434163423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-e1879024-9581-45be-9241-edc6412565cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-b5b47a41-c0fa-4511-90c1-c4caa6ac57e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-4e6b5196-1cf3-4212-a2b3-d93754b8966a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-b3d92c62-27ff-44c1-b276-1adb99b23b31,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-f7517195-0845-4103-9a21-f88e90bbbb95,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-81930a72-ca2e-43bb-ae82-fbc099d5468e,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-fca65fc6-d763-45a7-a644-8742cd709a90,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-d2ac5d1b-eb00-4f1c-9407-17ba1f28e0b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516397293-172.17.0.3-1595435161271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43937,DS-e378044d-62dd-4ef2-81e1-6e70ec14c849,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-ec6108b6-ccb9-4fd6-a2a4-5088db42ee17,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-874cf970-2f87-45d5-8051-5e2fb12b8bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-220bb2d6-967b-456a-b077-bc7e3cfc6529,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-77361585-ed6b-47e3-beb4-7cf66c4a84a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-8333ff40-0105-493e-bd56-4aa10f94fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-24afa3fa-affb-4829-a597-0f7bcbb066e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-57c7980d-779a-4ee6-86af-ab664207e542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516397293-172.17.0.3-1595435161271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43937,DS-e378044d-62dd-4ef2-81e1-6e70ec14c849,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-ec6108b6-ccb9-4fd6-a2a4-5088db42ee17,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-874cf970-2f87-45d5-8051-5e2fb12b8bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-220bb2d6-967b-456a-b077-bc7e3cfc6529,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-77361585-ed6b-47e3-beb4-7cf66c4a84a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-8333ff40-0105-493e-bd56-4aa10f94fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-24afa3fa-affb-4829-a597-0f7bcbb066e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-57c7980d-779a-4ee6-86af-ab664207e542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6377
