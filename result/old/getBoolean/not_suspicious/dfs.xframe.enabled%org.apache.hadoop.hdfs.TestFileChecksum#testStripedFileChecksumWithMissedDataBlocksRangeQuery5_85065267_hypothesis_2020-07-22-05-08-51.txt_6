reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151743795-172.17.0.2-1595394543232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39100,DS-10f03a20-efc5-4e92-85f3-4f76e0154896,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-f23cee52-581d-485e-9c1d-6e15be25262c,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-91ceae5b-6acd-4a5c-871e-6f82476adbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-4798e3ec-c02f-4247-b022-76bb9db0a7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-c60b118f-ab21-4160-a4ce-a60c65685e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-f6dbcc67-9581-4c16-9e53-ac3bbce4f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-cfbf6aaa-cbd3-4f4f-87c1-4d2df775e916,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-2f0bc519-6ad9-4f0e-976d-914587c0e994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151743795-172.17.0.2-1595394543232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39100,DS-10f03a20-efc5-4e92-85f3-4f76e0154896,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-f23cee52-581d-485e-9c1d-6e15be25262c,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-91ceae5b-6acd-4a5c-871e-6f82476adbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-4798e3ec-c02f-4247-b022-76bb9db0a7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-c60b118f-ab21-4160-a4ce-a60c65685e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-f6dbcc67-9581-4c16-9e53-ac3bbce4f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-cfbf6aaa-cbd3-4f4f-87c1-4d2df775e916,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-2f0bc519-6ad9-4f0e-976d-914587c0e994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830619931-172.17.0.2-1595394680214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-fea9365a-fb50-465a-8709-2f4232707c84,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-b4ce4014-7195-48b3-ba28-e8a1c7deb1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-3a400003-c920-4ff8-9cf2-45fa7581108a,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-7dca0310-61de-4818-a7c1-8eaded9afcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-538384f3-3417-4b6f-8336-b44fba2395f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-363a379f-f8fe-4fe2-8f2e-a030c5b07ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-1b8a4d2c-62ca-4f38-a898-34273e520182,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-9327c5cc-eb29-46fb-a254-5cca045deb83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830619931-172.17.0.2-1595394680214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-fea9365a-fb50-465a-8709-2f4232707c84,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-b4ce4014-7195-48b3-ba28-e8a1c7deb1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-3a400003-c920-4ff8-9cf2-45fa7581108a,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-7dca0310-61de-4818-a7c1-8eaded9afcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-538384f3-3417-4b6f-8336-b44fba2395f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-363a379f-f8fe-4fe2-8f2e-a030c5b07ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-1b8a4d2c-62ca-4f38-a898-34273e520182,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-9327c5cc-eb29-46fb-a254-5cca045deb83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290279815-172.17.0.2-1595394770034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34807,DS-2a540aa6-5417-4b2c-9b96-cebb70779287,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-9647ae76-a322-417e-b78f-3db14c793608,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-73a4e79d-797a-4be1-8b54-fb80c0619085,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-ba8ca29e-af43-4970-9c3f-0017915367f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-c914f0c2-b771-47fd-b7ef-067821461954,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-db52740e-768e-45ce-8851-dd5bffb53731,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-686b4d2d-f8b9-4637-9b20-18a1edb889c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-bc6981c6-3c5d-4433-b468-b00150dfaf7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290279815-172.17.0.2-1595394770034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34807,DS-2a540aa6-5417-4b2c-9b96-cebb70779287,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-9647ae76-a322-417e-b78f-3db14c793608,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-73a4e79d-797a-4be1-8b54-fb80c0619085,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-ba8ca29e-af43-4970-9c3f-0017915367f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-c914f0c2-b771-47fd-b7ef-067821461954,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-db52740e-768e-45ce-8851-dd5bffb53731,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-686b4d2d-f8b9-4637-9b20-18a1edb889c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-bc6981c6-3c5d-4433-b468-b00150dfaf7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465391867-172.17.0.2-1595394998486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-789538ba-6fbe-465c-b6f9-a54f948f7dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-d5f611f9-b3e3-4958-8976-9449011fbc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-438a262e-d146-4dde-919b-1e56ac469092,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-dce5a443-a7bd-48e6-b352-71eae1096efb,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-41e8100d-e822-436c-bf9f-7241aba35653,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-f01d9333-21b7-4bb7-9cdb-9df68e725642,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-f36fb41e-1b27-4ef5-b2c3-f4af096b7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-8cf27bdc-487b-4550-8d6e-dfec2fe5741c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465391867-172.17.0.2-1595394998486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-789538ba-6fbe-465c-b6f9-a54f948f7dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-d5f611f9-b3e3-4958-8976-9449011fbc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-438a262e-d146-4dde-919b-1e56ac469092,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-dce5a443-a7bd-48e6-b352-71eae1096efb,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-41e8100d-e822-436c-bf9f-7241aba35653,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-f01d9333-21b7-4bb7-9cdb-9df68e725642,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-f36fb41e-1b27-4ef5-b2c3-f4af096b7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-8cf27bdc-487b-4550-8d6e-dfec2fe5741c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731508415-172.17.0.2-1595395309217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38242,DS-b3e984b9-5a50-4847-8fb7-39767339b505,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-d780c5c9-f638-413e-8268-d8d4db3c14fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-77e2dc55-0004-480e-a90a-285d579573f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-49db5dd7-7fe4-4abf-9002-ec2a2476ef53,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-390960f2-a1cd-4305-b8f2-269f8af5a4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-b6cc0f93-3d28-448a-9f74-9476f7fe8bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-73b2b3a5-d39c-475f-bf0e-fc94652ad878,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-70ec32c5-5802-41c4-89a6-fc9dcb684ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731508415-172.17.0.2-1595395309217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38242,DS-b3e984b9-5a50-4847-8fb7-39767339b505,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-d780c5c9-f638-413e-8268-d8d4db3c14fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-77e2dc55-0004-480e-a90a-285d579573f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-49db5dd7-7fe4-4abf-9002-ec2a2476ef53,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-390960f2-a1cd-4305-b8f2-269f8af5a4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-b6cc0f93-3d28-448a-9f74-9476f7fe8bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-73b2b3a5-d39c-475f-bf0e-fc94652ad878,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-70ec32c5-5802-41c4-89a6-fc9dcb684ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012795083-172.17.0.2-1595395390926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-8f3ec253-1ad0-4b66-829c-f1229857f173,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-0c91b50a-ac33-47c5-b4dd-73d5aced6df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-bf0f52f8-c396-4ecc-8517-db5f379b5369,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-096caa76-9ceb-4e7f-85bc-a1673a5da1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-60647984-c56e-416b-88f9-50853e082588,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-3230d1d6-b2a4-440a-97c4-ba6a43a55871,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-b04fc05f-4836-4f43-b59e-278629c17660,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-d5c681b9-b431-4d75-9b6e-55375f497dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012795083-172.17.0.2-1595395390926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-8f3ec253-1ad0-4b66-829c-f1229857f173,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-0c91b50a-ac33-47c5-b4dd-73d5aced6df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-bf0f52f8-c396-4ecc-8517-db5f379b5369,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-096caa76-9ceb-4e7f-85bc-a1673a5da1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-60647984-c56e-416b-88f9-50853e082588,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-3230d1d6-b2a4-440a-97c4-ba6a43a55871,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-b04fc05f-4836-4f43-b59e-278629c17660,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-d5c681b9-b431-4d75-9b6e-55375f497dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52156363-172.17.0.2-1595395842365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33362,DS-06492c18-a406-4b45-9d41-5e66b1e64e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-8a982cff-4866-4eb2-bce7-e0f93441a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-96234d86-9b7b-414a-8659-488a11f74201,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-d0f76064-8a20-45fc-b832-3f68c41e63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-d9b8d9f7-8f7d-46b3-85a8-6cbc8272d131,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-8711ebe9-57f9-4041-b33a-22f2b89a9cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-f8c88961-b06e-4497-a31f-57b616e5a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-e2acb870-b3f1-4e88-9ec6-22c202aef583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52156363-172.17.0.2-1595395842365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33362,DS-06492c18-a406-4b45-9d41-5e66b1e64e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-8a982cff-4866-4eb2-bce7-e0f93441a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-96234d86-9b7b-414a-8659-488a11f74201,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-d0f76064-8a20-45fc-b832-3f68c41e63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-d9b8d9f7-8f7d-46b3-85a8-6cbc8272d131,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-8711ebe9-57f9-4041-b33a-22f2b89a9cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-f8c88961-b06e-4497-a31f-57b616e5a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-e2acb870-b3f1-4e88-9ec6-22c202aef583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181452722-172.17.0.2-1595396019397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39867,DS-0f06f65a-6ec2-4aa0-9152-291da381f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-153efd92-7478-4f65-bffb-8612c43554e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-9c2116bc-89a2-4106-b4b4-6e6730f75fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-24775579-2625-4850-86ff-3c02f1b8afa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-5d981406-3dbf-4828-bb8c-2ac4d50b35a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-b35a1dfc-f849-4b4f-8ae6-0fe86ea12874,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-34760d09-7b7e-4667-940d-dcc191d44c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-58a3f229-dd04-467c-b965-58901c2c3f82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181452722-172.17.0.2-1595396019397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39867,DS-0f06f65a-6ec2-4aa0-9152-291da381f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-153efd92-7478-4f65-bffb-8612c43554e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-9c2116bc-89a2-4106-b4b4-6e6730f75fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-24775579-2625-4850-86ff-3c02f1b8afa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-5d981406-3dbf-4828-bb8c-2ac4d50b35a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-b35a1dfc-f849-4b4f-8ae6-0fe86ea12874,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-34760d09-7b7e-4667-940d-dcc191d44c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-58a3f229-dd04-467c-b965-58901c2c3f82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232838170-172.17.0.2-1595396623751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-729ea846-c38c-4d0d-a743-daac9ce8bdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-0981496c-69d6-4c00-b22f-274a9defdb41,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-399c08b5-0566-47e4-8692-17404f212872,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-ab9c5099-5990-4f36-bf0c-e70c153165da,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-bdfbebd9-959c-4e20-977c-3a24cb800bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a4189f1e-507f-4198-af6f-078ed8fe45cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-bdf61b2e-d0b3-4a6f-a7b3-0584d0efc232,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-7cc64b31-ffde-4eb7-9219-2cbd635fa0f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232838170-172.17.0.2-1595396623751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-729ea846-c38c-4d0d-a743-daac9ce8bdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-0981496c-69d6-4c00-b22f-274a9defdb41,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-399c08b5-0566-47e4-8692-17404f212872,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-ab9c5099-5990-4f36-bf0c-e70c153165da,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-bdfbebd9-959c-4e20-977c-3a24cb800bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a4189f1e-507f-4198-af6f-078ed8fe45cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-bdf61b2e-d0b3-4a6f-a7b3-0584d0efc232,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-7cc64b31-ffde-4eb7-9219-2cbd635fa0f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855165455-172.17.0.2-1595396657364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46031,DS-a4e37fa8-81ff-428b-85c8-f4289eeb03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-17dbce06-6753-4044-ba44-6f92f0ef1936,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-0742914f-8d89-4520-bfe8-857b6e2e7170,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-11d917e2-69b5-4339-a83c-3086fd1444e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-120d657e-edfe-4e0a-81ec-308cf46b166d,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-5a647b00-1b60-4c3a-832a-883b10321549,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-b51f6b23-3979-47a2-9f38-abd2ea141119,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-86b7192d-9545-4ec2-85fa-ca4b2d4fee49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855165455-172.17.0.2-1595396657364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46031,DS-a4e37fa8-81ff-428b-85c8-f4289eeb03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-17dbce06-6753-4044-ba44-6f92f0ef1936,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-0742914f-8d89-4520-bfe8-857b6e2e7170,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-11d917e2-69b5-4339-a83c-3086fd1444e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-120d657e-edfe-4e0a-81ec-308cf46b166d,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-5a647b00-1b60-4c3a-832a-883b10321549,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-b51f6b23-3979-47a2-9f38-abd2ea141119,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-86b7192d-9545-4ec2-85fa-ca4b2d4fee49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837778530-172.17.0.2-1595396807491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-d5d49a46-2d40-4a7f-ab88-edd8435be2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-95a31c72-445f-457c-92f0-92f135399dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-7b74af1b-e8a7-484b-af76-f2532d38ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-c53c77a4-c37c-49e7-9619-e9fdb6a17809,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-a7703757-604b-4520-8762-a6f8e448a3db,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-ea9f1993-16d8-4113-b3d2-f7a268b5fb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-8fabc643-6917-4f6c-9fa2-dae43c54e77a,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-f8eb976d-9613-40ac-b5bc-810cd61890df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837778530-172.17.0.2-1595396807491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-d5d49a46-2d40-4a7f-ab88-edd8435be2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-95a31c72-445f-457c-92f0-92f135399dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-7b74af1b-e8a7-484b-af76-f2532d38ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-c53c77a4-c37c-49e7-9619-e9fdb6a17809,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-a7703757-604b-4520-8762-a6f8e448a3db,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-ea9f1993-16d8-4113-b3d2-f7a268b5fb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-8fabc643-6917-4f6c-9fa2-dae43c54e77a,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-f8eb976d-9613-40ac-b5bc-810cd61890df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401998678-172.17.0.2-1595396848088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43322,DS-09e13ab7-fed3-46b3-8e06-92dd774977ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-ace9e08d-d4d4-4004-832a-b7fc2f927823,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-d6e03ea5-d080-4d2f-ae5c-761124477217,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-e2a8a0cd-8f56-490e-8cf2-9aa27ae841fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-d7b5d919-8e29-4a76-a563-2fa6b30d8abd,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-b9eb5900-9bb9-4e48-b060-c6b539dccb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-df7e63b3-8159-4afc-80bb-249a2afd68f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-d55ecf1e-2ae0-4e4d-9637-ffc799fdd401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401998678-172.17.0.2-1595396848088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43322,DS-09e13ab7-fed3-46b3-8e06-92dd774977ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-ace9e08d-d4d4-4004-832a-b7fc2f927823,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-d6e03ea5-d080-4d2f-ae5c-761124477217,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-e2a8a0cd-8f56-490e-8cf2-9aa27ae841fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-d7b5d919-8e29-4a76-a563-2fa6b30d8abd,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-b9eb5900-9bb9-4e48-b060-c6b539dccb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-df7e63b3-8159-4afc-80bb-249a2afd68f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-d55ecf1e-2ae0-4e4d-9637-ffc799fdd401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133433641-172.17.0.2-1595396964860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-52f1a71c-aed4-41ac-974f-e3b46f0a5674,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-546957c1-c7df-476f-8a7d-8f891e7cdc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-fce7280f-b008-48ec-9fcc-91146f86ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-83c3e2b2-966d-4857-be28-727a6f8686da,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-ab4b44b5-9a4e-43d3-9130-27b4818dbada,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-26059a03-eff9-4d30-97f2-8a9a1e2c4392,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-fd1356f7-3de1-43ea-a1cb-b4ca4ea28751,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-388a24f5-6667-437e-b5ed-db01b182d905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133433641-172.17.0.2-1595396964860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-52f1a71c-aed4-41ac-974f-e3b46f0a5674,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-546957c1-c7df-476f-8a7d-8f891e7cdc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-fce7280f-b008-48ec-9fcc-91146f86ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-83c3e2b2-966d-4857-be28-727a6f8686da,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-ab4b44b5-9a4e-43d3-9130-27b4818dbada,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-26059a03-eff9-4d30-97f2-8a9a1e2c4392,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-fd1356f7-3de1-43ea-a1cb-b4ca4ea28751,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-388a24f5-6667-437e-b5ed-db01b182d905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427518358-172.17.0.2-1595397096325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35437,DS-27249b58-f4f4-4f4c-bf3e-bf3f34a936ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-2d2ad3e4-83be-4f94-97f1-26a3d6e979af,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-43d16c3b-ed24-45b7-b8c1-44a55ef32189,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-9399ada4-88fc-4f6c-921b-d5d80cbf0755,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-0268ea3c-9e77-4340-b169-dc722ec11292,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-b0b69e38-1ba1-47fc-bf1a-94d421131d11,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-a800e0f1-37b4-4239-b20a-b7d1f30e9bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-39d2fa1e-9505-463a-8ec7-3928b422b044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427518358-172.17.0.2-1595397096325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35437,DS-27249b58-f4f4-4f4c-bf3e-bf3f34a936ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-2d2ad3e4-83be-4f94-97f1-26a3d6e979af,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-43d16c3b-ed24-45b7-b8c1-44a55ef32189,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-9399ada4-88fc-4f6c-921b-d5d80cbf0755,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-0268ea3c-9e77-4340-b169-dc722ec11292,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-b0b69e38-1ba1-47fc-bf1a-94d421131d11,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-a800e0f1-37b4-4239-b20a-b7d1f30e9bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-39d2fa1e-9505-463a-8ec7-3928b422b044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220981158-172.17.0.2-1595397422589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-e82df8d2-3d0b-47bc-9086-ba439a4768f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-a6fe5601-37d8-4d6f-9ffb-a018b1149f82,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-2921829e-c021-4df7-bd85-ea116df6050a,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-6b671be8-1851-47ba-9870-6e1377b3d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-8c9e5be1-6757-4e7a-93bd-2e1311dbc52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-ab3d940d-f9f4-4c31-a071-04a7132d4bab,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-b3733351-9f37-4d55-bbc5-14d9c11ce824,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-1f12ce64-5b5c-4d57-b71e-66da6baf56ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220981158-172.17.0.2-1595397422589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-e82df8d2-3d0b-47bc-9086-ba439a4768f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-a6fe5601-37d8-4d6f-9ffb-a018b1149f82,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-2921829e-c021-4df7-bd85-ea116df6050a,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-6b671be8-1851-47ba-9870-6e1377b3d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-8c9e5be1-6757-4e7a-93bd-2e1311dbc52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-ab3d940d-f9f4-4c31-a071-04a7132d4bab,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-b3733351-9f37-4d55-bbc5-14d9c11ce824,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-1f12ce64-5b5c-4d57-b71e-66da6baf56ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024750824-172.17.0.2-1595398204747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43371,DS-4a6d8f50-c7b9-4296-8d80-e0406c5eef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-8baea629-9273-4212-bf0a-73517a8bf848,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-bfc0e31f-7753-4210-a774-0f412ddebb42,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-3fa2a25a-7e3d-446b-8c87-6612b562bb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-4e400711-fc46-4410-8cb1-dd3af1e70e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-a7cd52a9-c620-4e20-ac70-e19a6b9e8f70,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-d285343f-800c-4784-a6cc-98a974334b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-4f94b09b-37b9-49be-9ecb-8d106ec261ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024750824-172.17.0.2-1595398204747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43371,DS-4a6d8f50-c7b9-4296-8d80-e0406c5eef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-8baea629-9273-4212-bf0a-73517a8bf848,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-bfc0e31f-7753-4210-a774-0f412ddebb42,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-3fa2a25a-7e3d-446b-8c87-6612b562bb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-4e400711-fc46-4410-8cb1-dd3af1e70e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-a7cd52a9-c620-4e20-ac70-e19a6b9e8f70,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-d285343f-800c-4784-a6cc-98a974334b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-4f94b09b-37b9-49be-9ecb-8d106ec261ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834316257-172.17.0.2-1595398381588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45615,DS-75aa76ba-f9be-4caa-8e06-2b40c1a68b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-1d433113-6ebe-4c5a-83bb-22571f23864a,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-ccc07ae7-0ca8-42a9-abf0-217429974e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-90a98d2e-b8f8-4947-a0ad-40c3b5415ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-7c3c6961-93a9-435a-9c39-a6e25bda72ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-7f4c95e2-6768-4b51-bf2d-c514120fd901,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-bd89c883-4e15-401a-9821-c3396aed2ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-73efc410-e813-4107-ac5b-ce1a1321ecaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834316257-172.17.0.2-1595398381588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45615,DS-75aa76ba-f9be-4caa-8e06-2b40c1a68b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-1d433113-6ebe-4c5a-83bb-22571f23864a,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-ccc07ae7-0ca8-42a9-abf0-217429974e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-90a98d2e-b8f8-4947-a0ad-40c3b5415ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-7c3c6961-93a9-435a-9c39-a6e25bda72ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-7f4c95e2-6768-4b51-bf2d-c514120fd901,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-bd89c883-4e15-401a-9821-c3396aed2ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-73efc410-e813-4107-ac5b-ce1a1321ecaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288622138-172.17.0.2-1595399691519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-f32dde93-9b98-4c66-b38f-0c0322e494c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-ebce57a2-546f-4c23-a00f-e5fda7a26063,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-3fdcb6a5-3713-47f7-a9e4-639e34d5584e,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-3910612a-fd8d-403e-bf9b-e534f3d7e593,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-96fdc522-1e2b-4e66-b076-fd94acc49c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-13805d8d-b72d-429c-b542-2f8d4a1f65c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-8db2eced-9f09-4718-aeb7-df119172673d,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-21367cf6-11f7-4979-a280-b43761dfee7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288622138-172.17.0.2-1595399691519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-f32dde93-9b98-4c66-b38f-0c0322e494c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-ebce57a2-546f-4c23-a00f-e5fda7a26063,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-3fdcb6a5-3713-47f7-a9e4-639e34d5584e,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-3910612a-fd8d-403e-bf9b-e534f3d7e593,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-96fdc522-1e2b-4e66-b076-fd94acc49c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-13805d8d-b72d-429c-b542-2f8d4a1f65c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-8db2eced-9f09-4718-aeb7-df119172673d,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-21367cf6-11f7-4979-a280-b43761dfee7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5184
