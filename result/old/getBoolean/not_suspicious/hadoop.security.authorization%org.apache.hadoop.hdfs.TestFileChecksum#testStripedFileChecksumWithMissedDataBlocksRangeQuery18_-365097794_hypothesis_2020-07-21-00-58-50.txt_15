reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066272588-172.17.0.21-1595293144963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-8ee25138-c577-4cdd-8ed0-0d59c7cbb2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-a7183d58-8fb5-45b3-b7f8-8b8cb8c9cbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-3b077abb-46db-47e5-a5da-c369591ece56,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-0bc30cb6-e95b-40e3-be5c-d294155c0151,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-32539fed-bf11-4677-8a82-fbbe71074d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-7b8e9afa-1632-4fb9-a4e8-f80609330006,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-707a1663-8fa6-4ef3-a98d-f5ecd32e252a,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-01de87ac-6acb-455e-b85f-97b3cda9c709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066272588-172.17.0.21-1595293144963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-8ee25138-c577-4cdd-8ed0-0d59c7cbb2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-a7183d58-8fb5-45b3-b7f8-8b8cb8c9cbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-3b077abb-46db-47e5-a5da-c369591ece56,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-0bc30cb6-e95b-40e3-be5c-d294155c0151,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-32539fed-bf11-4677-8a82-fbbe71074d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-7b8e9afa-1632-4fb9-a4e8-f80609330006,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-707a1663-8fa6-4ef3-a98d-f5ecd32e252a,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-01de87ac-6acb-455e-b85f-97b3cda9c709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234234776-172.17.0.21-1595293209355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-53a878ee-f1e2-417c-b19a-417c16e16f95,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-ea71ea08-5cbe-448b-9d45-3b4dd06a65c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-926196ed-aeca-4367-879f-13433e8c66c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-d3cdf84f-2b06-45ca-b41b-23bc0f4a886f,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-75d1ff5b-55a0-4635-b3b1-9f77da5a2995,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-20b0a29e-2313-4baa-a9a1-42cb4d32468a,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f0fbaabb-97e9-4468-a9fc-9adfd7320298,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-0186b00b-42f5-47e7-b500-ada7de1dd519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234234776-172.17.0.21-1595293209355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-53a878ee-f1e2-417c-b19a-417c16e16f95,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-ea71ea08-5cbe-448b-9d45-3b4dd06a65c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-926196ed-aeca-4367-879f-13433e8c66c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-d3cdf84f-2b06-45ca-b41b-23bc0f4a886f,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-75d1ff5b-55a0-4635-b3b1-9f77da5a2995,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-20b0a29e-2313-4baa-a9a1-42cb4d32468a,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f0fbaabb-97e9-4468-a9fc-9adfd7320298,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-0186b00b-42f5-47e7-b500-ada7de1dd519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798635633-172.17.0.21-1595293385758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-e9fbbe6a-65b5-4777-8713-e10d7b7a6e08,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-4fb7d9cb-4850-4d12-b0d6-13fa312378aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-1189e115-1401-4d6e-b5ee-59568fc1887e,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-f856a922-6dfb-4183-a07d-af71621c7960,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-64fc7597-8d03-4735-8ef8-a29d9db78cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-6456caa8-819c-4da4-95e2-ece4c4d67378,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-8eea2c10-d373-4923-83d7-9e96566562d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-de867788-2188-4bc8-9144-bd2af132fc7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798635633-172.17.0.21-1595293385758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-e9fbbe6a-65b5-4777-8713-e10d7b7a6e08,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-4fb7d9cb-4850-4d12-b0d6-13fa312378aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-1189e115-1401-4d6e-b5ee-59568fc1887e,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-f856a922-6dfb-4183-a07d-af71621c7960,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-64fc7597-8d03-4735-8ef8-a29d9db78cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-6456caa8-819c-4da4-95e2-ece4c4d67378,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-8eea2c10-d373-4923-83d7-9e96566562d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-de867788-2188-4bc8-9144-bd2af132fc7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163505600-172.17.0.21-1595294066616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40380,DS-0e567dc6-d448-4651-9914-53671b77891f,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-10ef9287-21a7-45c3-a5bc-1da5e39f6cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-9015099c-591c-4dda-b5f0-ad45968bf222,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-ecd8fd21-9610-4e2f-85ad-287211f42d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-b33f2134-304b-4d23-8c23-975a9f9db1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-74d3ece6-4247-42b0-bc7b-b16889e3c139,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-aaf13d99-766c-49ec-a569-047c2b8f30cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-c131c1fb-bd02-4113-9c2e-d1affc7cec02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163505600-172.17.0.21-1595294066616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40380,DS-0e567dc6-d448-4651-9914-53671b77891f,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-10ef9287-21a7-45c3-a5bc-1da5e39f6cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-9015099c-591c-4dda-b5f0-ad45968bf222,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-ecd8fd21-9610-4e2f-85ad-287211f42d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-b33f2134-304b-4d23-8c23-975a9f9db1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-74d3ece6-4247-42b0-bc7b-b16889e3c139,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-aaf13d99-766c-49ec-a569-047c2b8f30cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-c131c1fb-bd02-4113-9c2e-d1affc7cec02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582084128-172.17.0.21-1595294450128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42961,DS-d7121304-caec-4235-ad1a-bc4832163dac,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-890a82cb-f07e-4797-9b5a-e36b11b3d571,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-ca95ab2b-7f9c-4c8d-978e-753a7af2ea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-1e9f3c2c-7a36-422a-b79c-184424a63d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-b34bf3b6-4efc-407d-bc8e-b9a823d12eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-a3b4e25d-208a-472d-94cf-6745cbc4ae11,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-8db885cd-18e1-42e8-b2e0-2d24c6dd69aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-74f3cdb8-872c-42d2-acba-c76bb02e5276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582084128-172.17.0.21-1595294450128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42961,DS-d7121304-caec-4235-ad1a-bc4832163dac,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-890a82cb-f07e-4797-9b5a-e36b11b3d571,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-ca95ab2b-7f9c-4c8d-978e-753a7af2ea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-1e9f3c2c-7a36-422a-b79c-184424a63d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-b34bf3b6-4efc-407d-bc8e-b9a823d12eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-a3b4e25d-208a-472d-94cf-6745cbc4ae11,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-8db885cd-18e1-42e8-b2e0-2d24c6dd69aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-74f3cdb8-872c-42d2-acba-c76bb02e5276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212156265-172.17.0.21-1595294625481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41195,DS-52ed01e6-9fed-4071-8ee7-44ba94a7015d,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-aef5d8db-77c5-4087-8765-01963e39b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-f0c65ea7-5b94-4c3b-a4b3-03e21f774da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-c65c98db-c393-4920-b51d-1c8960ddb198,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-218e2af9-a605-4319-8bee-c6c50b6d7882,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-b42bf0a7-d1fd-4a5b-b6ee-e92094231377,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-2eac0e54-9762-4441-8872-b57fd9024e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-e9859d1f-d631-45dc-a15d-ecc84c5f4a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212156265-172.17.0.21-1595294625481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41195,DS-52ed01e6-9fed-4071-8ee7-44ba94a7015d,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-aef5d8db-77c5-4087-8765-01963e39b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-f0c65ea7-5b94-4c3b-a4b3-03e21f774da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-c65c98db-c393-4920-b51d-1c8960ddb198,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-218e2af9-a605-4319-8bee-c6c50b6d7882,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-b42bf0a7-d1fd-4a5b-b6ee-e92094231377,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-2eac0e54-9762-4441-8872-b57fd9024e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-e9859d1f-d631-45dc-a15d-ecc84c5f4a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653140-172.17.0.21-1595294686957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43530,DS-96394c89-a6c5-4e80-9cfc-132b118ba59d,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-a8ec873e-fc86-4341-b413-60eb2f1038b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-469427c1-5752-461d-b97d-850ca548e772,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-4ffe1ee7-f355-44fc-ab26-9c710b600bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-5fbefac6-8320-48e2-9e23-3c771f970db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-0129876a-b552-4aea-b0b4-85d2e41a2910,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-778c143a-4c40-48ec-a420-f3b3d7281c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-94fc5992-64c1-4ed7-9f30-bc1a5842cc4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653140-172.17.0.21-1595294686957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43530,DS-96394c89-a6c5-4e80-9cfc-132b118ba59d,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-a8ec873e-fc86-4341-b413-60eb2f1038b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-469427c1-5752-461d-b97d-850ca548e772,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-4ffe1ee7-f355-44fc-ab26-9c710b600bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-5fbefac6-8320-48e2-9e23-3c771f970db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-0129876a-b552-4aea-b0b4-85d2e41a2910,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-778c143a-4c40-48ec-a420-f3b3d7281c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-94fc5992-64c1-4ed7-9f30-bc1a5842cc4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074889735-172.17.0.21-1595294718021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33779,DS-b09b7f3d-32b1-4e3d-8a79-f2f76ca375b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-a5380914-1858-4eb5-bd8c-f66edc54fc45,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-615f949d-4774-4a7d-a8bb-9ee4f48e5419,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-a58e3361-8b56-4105-bc13-362308fdacde,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-f1923276-0ff2-4f6e-b730-437172815297,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-5f6e159e-0298-4978-85ba-726a1e1f2ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-f016bae7-1eed-442d-a596-24c5eea4aab6,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-518adfe4-f8b3-4e66-b47c-b247b7b3fd4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074889735-172.17.0.21-1595294718021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33779,DS-b09b7f3d-32b1-4e3d-8a79-f2f76ca375b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-a5380914-1858-4eb5-bd8c-f66edc54fc45,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-615f949d-4774-4a7d-a8bb-9ee4f48e5419,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-a58e3361-8b56-4105-bc13-362308fdacde,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-f1923276-0ff2-4f6e-b730-437172815297,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-5f6e159e-0298-4978-85ba-726a1e1f2ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-f016bae7-1eed-442d-a596-24c5eea4aab6,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-518adfe4-f8b3-4e66-b47c-b247b7b3fd4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559329183-172.17.0.21-1595295182667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35711,DS-6e1739a3-88c2-43d1-821f-2839669b0cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-db861089-9fa8-4eb4-a4fa-c48eee58be6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-b5469823-9f17-4d83-ac86-9fb7dafdb46e,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-df491594-4e76-44a9-b722-ae0e599ad443,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-44b61ea1-1450-49a3-93e3-920e072ddd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-f2185aa2-cd58-423f-be7d-43fbcb897e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-4cf3ccab-b2bc-4960-8dc6-1ed557dbb84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-62bd7efd-a9b6-41c9-842d-c38989fcf7ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559329183-172.17.0.21-1595295182667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35711,DS-6e1739a3-88c2-43d1-821f-2839669b0cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-db861089-9fa8-4eb4-a4fa-c48eee58be6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-b5469823-9f17-4d83-ac86-9fb7dafdb46e,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-df491594-4e76-44a9-b722-ae0e599ad443,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-44b61ea1-1450-49a3-93e3-920e072ddd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-f2185aa2-cd58-423f-be7d-43fbcb897e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-4cf3ccab-b2bc-4960-8dc6-1ed557dbb84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-62bd7efd-a9b6-41c9-842d-c38989fcf7ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901153586-172.17.0.21-1595295519429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36550,DS-08be2238-0492-4478-b4ea-e9f9fd3d6728,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-30defbe5-353e-442d-a06d-b76d45dc1712,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-99f7d71e-cd41-4e89-a3f2-0e190e60e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-a01edfc5-bf43-4056-a148-9009347bde27,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-77fe1cc7-4b88-4ce6-9017-68954dc4757c,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-fdf21c0d-b311-4a3f-a84c-16cb8d698415,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-f0cd0ffb-0fb8-4269-9d7c-14da11b7865d,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-515903ec-d508-4e8b-89bc-bcaba681b7ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901153586-172.17.0.21-1595295519429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36550,DS-08be2238-0492-4478-b4ea-e9f9fd3d6728,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-30defbe5-353e-442d-a06d-b76d45dc1712,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-99f7d71e-cd41-4e89-a3f2-0e190e60e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-a01edfc5-bf43-4056-a148-9009347bde27,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-77fe1cc7-4b88-4ce6-9017-68954dc4757c,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-fdf21c0d-b311-4a3f-a84c-16cb8d698415,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-f0cd0ffb-0fb8-4269-9d7c-14da11b7865d,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-515903ec-d508-4e8b-89bc-bcaba681b7ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233833307-172.17.0.21-1595296558971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-77fc3a1f-0a97-48fb-9378-9d8e4cf148e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-cc699ae4-8b34-41eb-b687-bdd9579a8092,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-06f57d84-414f-4804-bc45-2975645c1cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-922e9ac6-f296-44c0-9038-b9bd0529fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c862bc0b-6563-41cb-8f7e-a1687cea17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-416f988a-7331-4531-9e66-d720b005c323,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-ba9d0a6c-9240-455f-aa97-0788754a6227,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-8053da3d-3e29-49a9-8bdb-668572671bd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233833307-172.17.0.21-1595296558971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-77fc3a1f-0a97-48fb-9378-9d8e4cf148e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-cc699ae4-8b34-41eb-b687-bdd9579a8092,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-06f57d84-414f-4804-bc45-2975645c1cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-922e9ac6-f296-44c0-9038-b9bd0529fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c862bc0b-6563-41cb-8f7e-a1687cea17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-416f988a-7331-4531-9e66-d720b005c323,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-ba9d0a6c-9240-455f-aa97-0788754a6227,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-8053da3d-3e29-49a9-8bdb-668572671bd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746611408-172.17.0.21-1595297483951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40703,DS-72508b4e-7b6b-4856-9ab8-8817f0a6a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-f8ae5d72-a537-49a5-8cd1-7075a38ad205,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-2fdd5722-5358-40b3-aa2c-72ad5a1b85c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-f5e25114-ee2c-4eaa-8ab8-c5efc812cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-c4fd74bc-0eb5-4499-96ed-23ef999fc6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-b0b11e36-c697-4282-8f84-5082424e454d,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-8f02a53a-a598-4286-9e91-cd558841e561,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-d983100c-bb58-45c8-946d-e5b710abf19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746611408-172.17.0.21-1595297483951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40703,DS-72508b4e-7b6b-4856-9ab8-8817f0a6a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-f8ae5d72-a537-49a5-8cd1-7075a38ad205,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-2fdd5722-5358-40b3-aa2c-72ad5a1b85c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-f5e25114-ee2c-4eaa-8ab8-c5efc812cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-c4fd74bc-0eb5-4499-96ed-23ef999fc6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-b0b11e36-c697-4282-8f84-5082424e454d,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-8f02a53a-a598-4286-9e91-cd558841e561,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-d983100c-bb58-45c8-946d-e5b710abf19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373712312-172.17.0.21-1595297686169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43892,DS-205a7303-8efd-49a1-a0d0-2958b5b4cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-77921f45-7e2f-439b-9276-8d4996706c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-623cc7fe-a0ae-45bc-81e6-f1d3cbaee1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-1ef4d257-4705-454f-bfa7-6ce4ee4b5f05,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-141bf15a-6f24-4912-afaa-36a1d57085ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-ebfd4336-7b17-4c43-a33d-e3e317f99a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-948bbf18-4fa1-40e2-bfb5-0f0522a48bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-ba81362e-0599-4eca-ab5e-2e2c972a5df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373712312-172.17.0.21-1595297686169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43892,DS-205a7303-8efd-49a1-a0d0-2958b5b4cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-77921f45-7e2f-439b-9276-8d4996706c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-623cc7fe-a0ae-45bc-81e6-f1d3cbaee1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-1ef4d257-4705-454f-bfa7-6ce4ee4b5f05,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-141bf15a-6f24-4912-afaa-36a1d57085ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-ebfd4336-7b17-4c43-a33d-e3e317f99a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-948bbf18-4fa1-40e2-bfb5-0f0522a48bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-ba81362e-0599-4eca-ab5e-2e2c972a5df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700856026-172.17.0.21-1595298022941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39056,DS-800ac80e-ec43-419b-8f8a-7a5d80b9de1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-d7f0023b-27bd-4365-a387-61291c061f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-9e33306f-05e8-41dd-bdbc-4b77acccc02e,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-6a85b7a5-1255-44d4-b545-85c1bc8df1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-d7c45af6-1586-4a51-8d15-a4ba6e69e370,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-d7870fc7-527d-4812-b33f-774080919613,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-98c4415f-cb4c-41ee-b4ba-90a23c4f1e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-3d18a14c-e31c-42c1-afe2-da68f6a4079e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700856026-172.17.0.21-1595298022941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39056,DS-800ac80e-ec43-419b-8f8a-7a5d80b9de1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-d7f0023b-27bd-4365-a387-61291c061f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-9e33306f-05e8-41dd-bdbc-4b77acccc02e,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-6a85b7a5-1255-44d4-b545-85c1bc8df1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-d7c45af6-1586-4a51-8d15-a4ba6e69e370,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-d7870fc7-527d-4812-b33f-774080919613,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-98c4415f-cb4c-41ee-b4ba-90a23c4f1e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-3d18a14c-e31c-42c1-afe2-da68f6a4079e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129382132-172.17.0.21-1595298055250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-778831af-3e40-4765-a2e1-3014a7d763eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-52a287fb-b259-40be-b347-5d0f5e415607,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-066632a2-8c86-4298-b07f-38ba1f5198e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-08925cda-bff8-49c8-be3c-4089598faee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-193ad92d-eed3-49ba-be39-c98c09aae234,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-9c4d7723-3397-4588-9d94-c5f4d0b10329,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-f80a05f1-a3b3-4878-b9d4-ac674fe92c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-691b70eb-f675-47ba-945e-216807ff5f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129382132-172.17.0.21-1595298055250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-778831af-3e40-4765-a2e1-3014a7d763eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-52a287fb-b259-40be-b347-5d0f5e415607,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-066632a2-8c86-4298-b07f-38ba1f5198e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-08925cda-bff8-49c8-be3c-4089598faee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-193ad92d-eed3-49ba-be39-c98c09aae234,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-9c4d7723-3397-4588-9d94-c5f4d0b10329,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-f80a05f1-a3b3-4878-b9d4-ac674fe92c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-691b70eb-f675-47ba-945e-216807ff5f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434726603-172.17.0.21-1595298122397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43983,DS-9439df31-512e-47dc-a229-b2f2f29dc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-04dbaece-c27e-4997-8d1e-e2f0ee9e9363,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-bfd4cb99-a46f-4632-bb83-d0e75c73e703,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-7b6d8284-7c67-4604-81c0-4d4b1c28e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-b5e92546-4620-4eef-ba80-c62d5135fb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-48a64250-c8c7-4812-bc1c-59e81310cdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-8e320380-0b6d-4303-ad6d-b628b1d6c1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-0d880b85-8212-4784-abde-85d58016c4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434726603-172.17.0.21-1595298122397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43983,DS-9439df31-512e-47dc-a229-b2f2f29dc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-04dbaece-c27e-4997-8d1e-e2f0ee9e9363,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-bfd4cb99-a46f-4632-bb83-d0e75c73e703,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-7b6d8284-7c67-4604-81c0-4d4b1c28e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-b5e92546-4620-4eef-ba80-c62d5135fb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-48a64250-c8c7-4812-bc1c-59e81310cdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-8e320380-0b6d-4303-ad6d-b628b1d6c1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-0d880b85-8212-4784-abde-85d58016c4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5077
