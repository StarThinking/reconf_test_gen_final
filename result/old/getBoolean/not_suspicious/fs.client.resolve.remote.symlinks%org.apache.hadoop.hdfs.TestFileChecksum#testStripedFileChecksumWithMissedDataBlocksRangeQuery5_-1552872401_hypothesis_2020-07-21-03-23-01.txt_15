reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175342878-172.17.0.2-1595301974350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-c0e4f028-48e5-424a-842b-b1874a9e486f,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-717e1dfe-7146-4e47-bb7e-c025cc86dfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-0f44f74b-7a17-47e6-8e7e-548843cecfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-0dc36290-ce04-4727-aa56-af9b362dfab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-21b6ced1-789f-45ad-b331-c9bf29f3ec09,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-b9ec2c3a-c3fd-4947-91fb-095ad3ecfc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-bd2c655d-1b20-45d1-acbf-35dfb71dca30,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-241bc90a-c092-4d66-8568-0179329855fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175342878-172.17.0.2-1595301974350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-c0e4f028-48e5-424a-842b-b1874a9e486f,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-717e1dfe-7146-4e47-bb7e-c025cc86dfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-0f44f74b-7a17-47e6-8e7e-548843cecfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-0dc36290-ce04-4727-aa56-af9b362dfab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-21b6ced1-789f-45ad-b331-c9bf29f3ec09,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-b9ec2c3a-c3fd-4947-91fb-095ad3ecfc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-bd2c655d-1b20-45d1-acbf-35dfb71dca30,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-241bc90a-c092-4d66-8568-0179329855fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930068640-172.17.0.2-1595302639517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-1258f6dd-bbcb-4cd3-94a6-2b5f7a5dfc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-a83780e2-868a-4f4f-9839-6c869e6e4139,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-50adfca5-e642-404f-96d1-d6ad2cf9d75f,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-06d63a5c-3ea1-48ad-a284-be326c5816d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-5a85c153-3068-4eb7-bbcb-50988bd29c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-7ba8ace5-85d0-4ce3-94bf-17e4cd1b2c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-21e02525-030a-4e8a-95ee-3f67900c5446,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-9f92bcdf-1ed7-48fe-bfe0-4fdb279853cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930068640-172.17.0.2-1595302639517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-1258f6dd-bbcb-4cd3-94a6-2b5f7a5dfc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-a83780e2-868a-4f4f-9839-6c869e6e4139,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-50adfca5-e642-404f-96d1-d6ad2cf9d75f,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-06d63a5c-3ea1-48ad-a284-be326c5816d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-5a85c153-3068-4eb7-bbcb-50988bd29c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-7ba8ace5-85d0-4ce3-94bf-17e4cd1b2c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-21e02525-030a-4e8a-95ee-3f67900c5446,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-9f92bcdf-1ed7-48fe-bfe0-4fdb279853cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157904891-172.17.0.2-1595302717233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36968,DS-90b48e8e-b492-4511-b62c-859f138a9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-e9bc8208-d719-42a8-b1c4-3379b476408d,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-aabba7e1-4a00-4a90-8072-ca7cfa3f7d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-2ef5f2af-1a6a-40fe-94f2-7d5adc7c0573,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-cd3cfe5c-b72c-4b6b-825c-34a7d0bf192f,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-17a49afb-457e-4d3d-afc3-485ae4704832,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-df311d0c-13eb-47a5-87b0-f0997ff145ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-5fac4de7-f2e2-48da-af7e-b1b220d269de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157904891-172.17.0.2-1595302717233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36968,DS-90b48e8e-b492-4511-b62c-859f138a9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-e9bc8208-d719-42a8-b1c4-3379b476408d,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-aabba7e1-4a00-4a90-8072-ca7cfa3f7d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-2ef5f2af-1a6a-40fe-94f2-7d5adc7c0573,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-cd3cfe5c-b72c-4b6b-825c-34a7d0bf192f,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-17a49afb-457e-4d3d-afc3-485ae4704832,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-df311d0c-13eb-47a5-87b0-f0997ff145ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-5fac4de7-f2e2-48da-af7e-b1b220d269de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600511389-172.17.0.2-1595302855738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-ed167d89-c0dd-47a2-abda-393d35ccd97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-c32b877b-b8f9-41c3-81b9-175c5e8d7d48,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-1c157dcd-7016-4bde-9a8e-55e83d4c5fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-33927f1a-e39b-4f85-98eb-a026d93a964b,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-96a4b96e-a91c-40e7-aeb6-939eb5bcfe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-7b3311b5-a71b-4fa0-8291-5ca9d336fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-ef0c7e10-1bf8-498d-a067-f4d04cca5c59,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-61bef8c1-12de-49eb-99e5-1ed7e0c538a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600511389-172.17.0.2-1595302855738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-ed167d89-c0dd-47a2-abda-393d35ccd97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-c32b877b-b8f9-41c3-81b9-175c5e8d7d48,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-1c157dcd-7016-4bde-9a8e-55e83d4c5fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-33927f1a-e39b-4f85-98eb-a026d93a964b,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-96a4b96e-a91c-40e7-aeb6-939eb5bcfe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-7b3311b5-a71b-4fa0-8291-5ca9d336fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-ef0c7e10-1bf8-498d-a067-f4d04cca5c59,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-61bef8c1-12de-49eb-99e5-1ed7e0c538a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803408130-172.17.0.2-1595303820139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45701,DS-8cbf8f31-e13a-48e1-a1a4-3689558000b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-1f6790a4-3ca4-4dcb-a113-9c19ffa30996,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-be1c4321-f7c4-470b-9467-315b1ad43f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-78e92536-7d33-4818-a1cf-eeffb6d6eb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-551be603-0d43-4bf2-b886-7bc304c5613e,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-582f8ceb-de22-412e-9353-826411571373,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-1bff31f4-a418-4005-9e13-5f5e74825896,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-8f5dcf22-4b92-4ad2-ad89-b8d0de80d9c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803408130-172.17.0.2-1595303820139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45701,DS-8cbf8f31-e13a-48e1-a1a4-3689558000b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-1f6790a4-3ca4-4dcb-a113-9c19ffa30996,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-be1c4321-f7c4-470b-9467-315b1ad43f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-78e92536-7d33-4818-a1cf-eeffb6d6eb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-551be603-0d43-4bf2-b886-7bc304c5613e,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-582f8ceb-de22-412e-9353-826411571373,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-1bff31f4-a418-4005-9e13-5f5e74825896,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-8f5dcf22-4b92-4ad2-ad89-b8d0de80d9c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134956117-172.17.0.2-1595303861213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36933,DS-61c4e69c-6bc9-49a3-8685-8ba72bf1e023,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-7f03ad4a-42b3-4987-be81-59338767cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-3aaaf571-2aaa-4961-87af-f1016937dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-6736142c-0ab4-49a8-b719-2a96096af560,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-0e3daac6-bc84-47a4-90d6-0562b743082f,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-fbaae6ed-aa3d-413b-9e34-35408c5e5cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-91a74baf-2991-4743-9133-caf784dc5661,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-85d846fd-56fa-4927-ad56-853ad6a5f167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134956117-172.17.0.2-1595303861213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36933,DS-61c4e69c-6bc9-49a3-8685-8ba72bf1e023,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-7f03ad4a-42b3-4987-be81-59338767cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-3aaaf571-2aaa-4961-87af-f1016937dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-6736142c-0ab4-49a8-b719-2a96096af560,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-0e3daac6-bc84-47a4-90d6-0562b743082f,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-fbaae6ed-aa3d-413b-9e34-35408c5e5cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-91a74baf-2991-4743-9133-caf784dc5661,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-85d846fd-56fa-4927-ad56-853ad6a5f167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639896970-172.17.0.2-1595303976982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36787,DS-7bf75dcf-cd2a-4b4b-81f7-0fb578d2ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-f8f541e6-161b-47eb-b41a-7890ae2a838e,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-a22abc7b-b903-4e5f-a6cc-f75be16e7589,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-bf730c1c-6e33-48c0-859e-1c6179d9c815,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-ac709f01-7e63-4e9c-9600-f85874f496ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-03660fc8-c50f-47eb-99d7-7937685b0370,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-48b43eee-aaf8-49c3-91e0-aeb031e5e207,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-dd34e7d0-ac55-4198-a533-32cff8a36e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639896970-172.17.0.2-1595303976982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36787,DS-7bf75dcf-cd2a-4b4b-81f7-0fb578d2ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-f8f541e6-161b-47eb-b41a-7890ae2a838e,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-a22abc7b-b903-4e5f-a6cc-f75be16e7589,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-bf730c1c-6e33-48c0-859e-1c6179d9c815,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-ac709f01-7e63-4e9c-9600-f85874f496ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-03660fc8-c50f-47eb-99d7-7937685b0370,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-48b43eee-aaf8-49c3-91e0-aeb031e5e207,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-dd34e7d0-ac55-4198-a533-32cff8a36e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258176955-172.17.0.2-1595304428992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-d16b2708-b58c-4618-b98b-7107546de9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-2675171e-a45a-47cd-9b93-4827ba0164d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-5a4d02c4-572e-47f4-b363-6ea2e2311903,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-e9a59801-8173-4e6c-bb4a-9a9d8f24de19,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-968915ff-454a-470f-982f-6c5f93307fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-2978feef-a79e-4c3f-8874-91bb9616e901,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-0ead4541-0b05-4bb6-8529-ad17d7091795,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-2afadb6b-bba9-4290-b34c-546a1d20656f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258176955-172.17.0.2-1595304428992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-d16b2708-b58c-4618-b98b-7107546de9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-2675171e-a45a-47cd-9b93-4827ba0164d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-5a4d02c4-572e-47f4-b363-6ea2e2311903,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-e9a59801-8173-4e6c-bb4a-9a9d8f24de19,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-968915ff-454a-470f-982f-6c5f93307fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-2978feef-a79e-4c3f-8874-91bb9616e901,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-0ead4541-0b05-4bb6-8529-ad17d7091795,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-2afadb6b-bba9-4290-b34c-546a1d20656f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972479239-172.17.0.2-1595304503407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34589,DS-d938ea89-ee16-49b4-9cb2-fbd52a73c561,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-1b4d217d-a9d4-4c36-9709-48f697385933,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-6fee7606-779e-44d1-84f0-41ea18298b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-c9f07788-54a9-4804-a2f7-3dafb9826c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-bc65b634-bc5c-4a70-a136-eecff6ce4815,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-04d710c1-24b1-427f-8b54-564915217962,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-309b5a08-a50a-4a17-9ae8-17ffede8f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-ce384202-524a-45ea-9afb-cb3086a96b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972479239-172.17.0.2-1595304503407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34589,DS-d938ea89-ee16-49b4-9cb2-fbd52a73c561,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-1b4d217d-a9d4-4c36-9709-48f697385933,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-6fee7606-779e-44d1-84f0-41ea18298b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-c9f07788-54a9-4804-a2f7-3dafb9826c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-bc65b634-bc5c-4a70-a136-eecff6ce4815,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-04d710c1-24b1-427f-8b54-564915217962,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-309b5a08-a50a-4a17-9ae8-17ffede8f5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-ce384202-524a-45ea-9afb-cb3086a96b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234956069-172.17.0.2-1595304702554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41675,DS-1f562fdf-0f31-485c-b63b-7f23c4d668f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-a519fea5-6f7a-435d-8659-2fc865ae101b,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-86c85ad7-33da-4d1c-ab35-0d6456f94c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-10420aab-7ecf-48bb-b321-b936903f6682,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-cef74de3-cf16-4e21-b418-5726ca3774cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-5c7c04ca-ea10-4256-9a5a-e65479e46e14,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-7965dab6-7f29-4db0-b80e-6de06b84faee,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-a3b24518-b602-409f-a553-22c3bb0c13c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234956069-172.17.0.2-1595304702554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41675,DS-1f562fdf-0f31-485c-b63b-7f23c4d668f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-a519fea5-6f7a-435d-8659-2fc865ae101b,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-86c85ad7-33da-4d1c-ab35-0d6456f94c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-10420aab-7ecf-48bb-b321-b936903f6682,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-cef74de3-cf16-4e21-b418-5726ca3774cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-5c7c04ca-ea10-4256-9a5a-e65479e46e14,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-7965dab6-7f29-4db0-b80e-6de06b84faee,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-a3b24518-b602-409f-a553-22c3bb0c13c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965369100-172.17.0.2-1595304769667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41019,DS-875f70b1-f6c7-4d07-b8a6-e0d65857a186,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-87c6e010-92f4-4b86-92fa-7e388e2687ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-8ac99aea-39a7-4d4b-af45-60411b46f7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-5636d4c7-cda8-438d-9801-2a8436f6c259,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-11c7d1d5-f166-41d5-8511-d5489980f7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-882cadde-b2d0-48ea-b778-52a003cb1cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-76b6e9e0-4c60-4f17-b135-816849953e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-5678230c-b672-4a1c-870b-0c4b5129efda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965369100-172.17.0.2-1595304769667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41019,DS-875f70b1-f6c7-4d07-b8a6-e0d65857a186,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-87c6e010-92f4-4b86-92fa-7e388e2687ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-8ac99aea-39a7-4d4b-af45-60411b46f7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-5636d4c7-cda8-438d-9801-2a8436f6c259,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-11c7d1d5-f166-41d5-8511-d5489980f7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-882cadde-b2d0-48ea-b778-52a003cb1cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-76b6e9e0-4c60-4f17-b135-816849953e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-5678230c-b672-4a1c-870b-0c4b5129efda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453081714-172.17.0.2-1595304963007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-f9116174-9a7f-4beb-baab-4f38f7de1f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-497b0376-48d9-4aa4-8a14-7bea51d16464,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-16086d8b-9914-4175-ab8c-7150e984419a,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-cb158b84-7a52-4c69-970f-c3e3ad5d306c,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-eb974764-9917-4e7d-a812-d404a90c6c92,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-9d94cfca-18b8-43ec-a6f9-2a65ccd81592,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-c5d1b221-1e4f-4065-bc53-09a0df965676,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-cd07149f-8d7b-4509-987d-86ce56c7f492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453081714-172.17.0.2-1595304963007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-f9116174-9a7f-4beb-baab-4f38f7de1f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-497b0376-48d9-4aa4-8a14-7bea51d16464,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-16086d8b-9914-4175-ab8c-7150e984419a,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-cb158b84-7a52-4c69-970f-c3e3ad5d306c,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-eb974764-9917-4e7d-a812-d404a90c6c92,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-9d94cfca-18b8-43ec-a6f9-2a65ccd81592,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-c5d1b221-1e4f-4065-bc53-09a0df965676,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-cd07149f-8d7b-4509-987d-86ce56c7f492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9890934-172.17.0.2-1595305000254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-526a8d90-d210-4f79-8e09-6b39411cb038,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-5117a118-1d7a-495c-8e31-b826b86f0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-0b61e0a8-368d-470a-b064-0cb0b49e5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-be224c55-5f3f-4bd2-b8bd-7fcd1c6404b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-e98642f0-478d-4867-9a94-93f84fa50ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-b7ea48ea-1377-49c2-8101-2e3e3c2ba665,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-f8e6296b-8b0f-438d-8970-6a0a3db18680,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-cc69a3e0-f3af-4703-943e-24944f32adf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9890934-172.17.0.2-1595305000254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-526a8d90-d210-4f79-8e09-6b39411cb038,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-5117a118-1d7a-495c-8e31-b826b86f0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-0b61e0a8-368d-470a-b064-0cb0b49e5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-be224c55-5f3f-4bd2-b8bd-7fcd1c6404b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-e98642f0-478d-4867-9a94-93f84fa50ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-b7ea48ea-1377-49c2-8101-2e3e3c2ba665,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-f8e6296b-8b0f-438d-8970-6a0a3db18680,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-cc69a3e0-f3af-4703-943e-24944f32adf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992519096-172.17.0.2-1595305497610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-0286acff-9756-4941-8086-de74782a7f41,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-c3f97af8-cc5a-44c2-92ed-aac4084cfc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-dabba7c1-5fd5-48ac-9ad9-bad458bc75a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-c1a4c331-b1d8-42d5-9273-f60d88fa2034,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-0d834b7e-6f49-45c5-aebb-75eb49c6bf62,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-d6b9c2b0-a7f6-4d1f-92e8-781bb3cb66e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-e4abd70b-6461-49b1-a1b7-03ada4d6560b,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-8b19b050-268b-4539-a6aa-6445d30ba7b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992519096-172.17.0.2-1595305497610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-0286acff-9756-4941-8086-de74782a7f41,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-c3f97af8-cc5a-44c2-92ed-aac4084cfc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-dabba7c1-5fd5-48ac-9ad9-bad458bc75a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-c1a4c331-b1d8-42d5-9273-f60d88fa2034,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-0d834b7e-6f49-45c5-aebb-75eb49c6bf62,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-d6b9c2b0-a7f6-4d1f-92e8-781bb3cb66e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-e4abd70b-6461-49b1-a1b7-03ada4d6560b,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-8b19b050-268b-4539-a6aa-6445d30ba7b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836278220-172.17.0.2-1595305773145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42826,DS-e28b7511-efb6-492c-8e7b-a9c0f74681a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-5355f332-6c4e-4721-93d3-678c90a8fa90,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-0466fb9a-bba4-455f-99ee-5d572bc7014c,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-4528dc4c-d5f5-4945-b4ee-7d5a74277a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-81c77e28-27c5-4e6e-873e-b06a6d19af99,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-354c9780-b6a6-4f5e-a13b-9baf2a40b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-80435420-da5e-4bd5-9d07-ab6a9a458880,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-6288a9b8-c21d-4eb4-8528-58b744757074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836278220-172.17.0.2-1595305773145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42826,DS-e28b7511-efb6-492c-8e7b-a9c0f74681a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-5355f332-6c4e-4721-93d3-678c90a8fa90,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-0466fb9a-bba4-455f-99ee-5d572bc7014c,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-4528dc4c-d5f5-4945-b4ee-7d5a74277a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-81c77e28-27c5-4e6e-873e-b06a6d19af99,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-354c9780-b6a6-4f5e-a13b-9baf2a40b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-80435420-da5e-4bd5-9d07-ab6a9a458880,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-6288a9b8-c21d-4eb4-8528-58b744757074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012501503-172.17.0.2-1595307095550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-e1730d4f-31d6-4f52-ba80-cab87f2af096,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-34a21ba9-0119-43c7-bcee-9ea8ccdb5f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-7c584fce-8737-4c7c-a6cb-9afc8569fb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-55734178-6628-4b03-a51b-92e8b359f10f,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-ea8b342c-c05e-4feb-94c3-db778445caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-7f1ae5fe-9dea-4afd-b900-644aeb44f402,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-16c02720-a80a-467b-9ad2-46dad5282fed,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-eadabd95-d600-4cbf-aadb-146ae8e00871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012501503-172.17.0.2-1595307095550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-e1730d4f-31d6-4f52-ba80-cab87f2af096,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-34a21ba9-0119-43c7-bcee-9ea8ccdb5f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-7c584fce-8737-4c7c-a6cb-9afc8569fb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-55734178-6628-4b03-a51b-92e8b359f10f,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-ea8b342c-c05e-4feb-94c3-db778445caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-7f1ae5fe-9dea-4afd-b900-644aeb44f402,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-16c02720-a80a-467b-9ad2-46dad5282fed,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-eadabd95-d600-4cbf-aadb-146ae8e00871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982568469-172.17.0.2-1595307197903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-af21d3b7-0ed3-4bb0-8ccb-bd31371070ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-f2369905-365c-4feb-94ba-ac41699044b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-e134b3ef-76cb-426c-990c-950af03db36b,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-b485bd0e-6b7d-4207-8aa8-15eb0c11b135,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-142c39b0-99c2-4944-b340-197e0e821197,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-056cbfa7-3527-45ff-ac10-b4c4c4c2beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-8e12d07e-6481-4ebe-9737-a53c9cc89d57,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-27a0f043-02b1-42ac-a199-d8d92b592edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982568469-172.17.0.2-1595307197903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-af21d3b7-0ed3-4bb0-8ccb-bd31371070ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-f2369905-365c-4feb-94ba-ac41699044b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-e134b3ef-76cb-426c-990c-950af03db36b,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-b485bd0e-6b7d-4207-8aa8-15eb0c11b135,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-142c39b0-99c2-4944-b340-197e0e821197,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-056cbfa7-3527-45ff-ac10-b4c4c4c2beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-8e12d07e-6481-4ebe-9737-a53c9cc89d57,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-27a0f043-02b1-42ac-a199-d8d92b592edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5597
