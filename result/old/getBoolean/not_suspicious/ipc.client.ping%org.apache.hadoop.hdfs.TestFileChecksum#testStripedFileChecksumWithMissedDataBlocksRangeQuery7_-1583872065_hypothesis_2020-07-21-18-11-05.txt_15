reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470032167-172.17.0.14-1595355213979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43244,DS-6166d7b4-a5c0-4e60-9f79-0617f43f92bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-e5be557c-5620-4e7d-87e2-ad4ea4fddbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-768d6737-1802-4aa0-9b9c-c5553b103f77,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-39f84f68-c21d-425c-920c-32048b94e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-11399ee8-71ad-4467-bb3a-2e95f99c6a96,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-ede1a540-d420-4bc8-b37a-1cd7cd16fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-4fadcba5-5dc1-490f-aa8a-e4247dd6ddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-7f21f78d-4e76-4c11-bebd-a413718bff44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470032167-172.17.0.14-1595355213979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43244,DS-6166d7b4-a5c0-4e60-9f79-0617f43f92bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-e5be557c-5620-4e7d-87e2-ad4ea4fddbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-768d6737-1802-4aa0-9b9c-c5553b103f77,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-39f84f68-c21d-425c-920c-32048b94e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-11399ee8-71ad-4467-bb3a-2e95f99c6a96,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-ede1a540-d420-4bc8-b37a-1cd7cd16fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-4fadcba5-5dc1-490f-aa8a-e4247dd6ddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-7f21f78d-4e76-4c11-bebd-a413718bff44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274331822-172.17.0.14-1595355357855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41753,DS-9eb8fe12-43f5-4918-b4f3-9ef919b17e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-07567f47-cb49-42d1-a355-96a4b2a15419,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-c4251c6b-fb9e-4edb-8edf-78c09c6c92e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-a6cc091e-9f39-40bc-b479-2a79598b0ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-8d80baea-cc9d-4d6d-a617-f9fb742cb725,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-3f3f0465-d8af-425b-baa8-c3d07aa7ccc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-f9d8204b-74ac-46a4-a1cd-9811ebb9e7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-3e9199c8-91b8-4256-97bb-7d31edbae775,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274331822-172.17.0.14-1595355357855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41753,DS-9eb8fe12-43f5-4918-b4f3-9ef919b17e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-07567f47-cb49-42d1-a355-96a4b2a15419,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-c4251c6b-fb9e-4edb-8edf-78c09c6c92e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-a6cc091e-9f39-40bc-b479-2a79598b0ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-8d80baea-cc9d-4d6d-a617-f9fb742cb725,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-3f3f0465-d8af-425b-baa8-c3d07aa7ccc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-f9d8204b-74ac-46a4-a1cd-9811ebb9e7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-3e9199c8-91b8-4256-97bb-7d31edbae775,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192459778-172.17.0.14-1595355520059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36495,DS-ce37224c-b458-441a-92ab-dd56850e8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-64ce9dab-0e7b-4b15-85d4-243ff902ee10,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-f9c62875-6fd2-41bd-9475-62775323e459,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-8f004bdb-14e6-461f-bf3d-c8b784d1bb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-e74cf57a-afee-4f72-96f3-e2efdfe65788,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-a3c873ad-4794-498d-8533-3e9301a89213,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-4bac1d6d-fe0a-4b40-9709-d406d27eef18,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-01ee061b-8de0-49c7-aeb9-7369ce92b278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192459778-172.17.0.14-1595355520059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36495,DS-ce37224c-b458-441a-92ab-dd56850e8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-64ce9dab-0e7b-4b15-85d4-243ff902ee10,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-f9c62875-6fd2-41bd-9475-62775323e459,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-8f004bdb-14e6-461f-bf3d-c8b784d1bb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-e74cf57a-afee-4f72-96f3-e2efdfe65788,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-a3c873ad-4794-498d-8533-3e9301a89213,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-4bac1d6d-fe0a-4b40-9709-d406d27eef18,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-01ee061b-8de0-49c7-aeb9-7369ce92b278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239392440-172.17.0.14-1595355631940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-dbac5ad6-ad06-4960-9d1e-9e1b23590792,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-39fa4b2e-0883-4bb6-bf1f-bac6dc6680da,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-b9e65eef-65bf-4fb0-8a6b-3f3f917ff2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-b74bc684-cd51-4b65-8ddc-62a2f482f603,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-1292746c-158d-4056-8382-72ee48e24eca,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-77f2560a-19ca-4f24-aa6d-c9ef8ff3f13e,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-85ffde4f-141d-4c01-b0c5-b2fcf5580063,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-b2357fd3-140a-4c74-b9de-3240c55790be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239392440-172.17.0.14-1595355631940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-dbac5ad6-ad06-4960-9d1e-9e1b23590792,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-39fa4b2e-0883-4bb6-bf1f-bac6dc6680da,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-b9e65eef-65bf-4fb0-8a6b-3f3f917ff2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-b74bc684-cd51-4b65-8ddc-62a2f482f603,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-1292746c-158d-4056-8382-72ee48e24eca,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-77f2560a-19ca-4f24-aa6d-c9ef8ff3f13e,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-85ffde4f-141d-4c01-b0c5-b2fcf5580063,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-b2357fd3-140a-4c74-b9de-3240c55790be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842390786-172.17.0.14-1595355781831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38037,DS-2e93e402-70a2-4472-bcc4-13dab56f7304,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-ac30716c-88f2-420f-8b52-ca3b0ab4f159,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-2ddacfc6-adee-4b53-89d3-336279ac0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-f6d2b868-7910-4686-be0c-f549424f3bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-f3e218f7-27ec-4d7d-9cdd-a399941adf30,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-5f7e3eb3-fa11-4b91-8c87-eb80976ea39e,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-17912490-2af2-420d-a4f5-e8500e39e1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-f9123494-f92b-4c7d-ac4f-f01933e043ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842390786-172.17.0.14-1595355781831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38037,DS-2e93e402-70a2-4472-bcc4-13dab56f7304,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-ac30716c-88f2-420f-8b52-ca3b0ab4f159,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-2ddacfc6-adee-4b53-89d3-336279ac0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-f6d2b868-7910-4686-be0c-f549424f3bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-f3e218f7-27ec-4d7d-9cdd-a399941adf30,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-5f7e3eb3-fa11-4b91-8c87-eb80976ea39e,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-17912490-2af2-420d-a4f5-e8500e39e1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-f9123494-f92b-4c7d-ac4f-f01933e043ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685116968-172.17.0.14-1595355869754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43923,DS-e5f44fe0-b63e-482f-acdc-c43939ed963b,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-4c999435-88fa-4003-98f1-7e02559f93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-1e9ab6f9-81e3-43c4-b08a-a8b60407d968,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-c58c4161-446a-4f42-85cc-30727d24fc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-35049213-e467-4bd3-9a8e-ea7d4d57f40b,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-815e9ecd-e325-46b7-8709-816ff15282a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-b00290c5-1114-4395-a865-d2da0a25dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-a14a9ff7-f1e4-4cd0-9be0-7680dc140ab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685116968-172.17.0.14-1595355869754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43923,DS-e5f44fe0-b63e-482f-acdc-c43939ed963b,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-4c999435-88fa-4003-98f1-7e02559f93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-1e9ab6f9-81e3-43c4-b08a-a8b60407d968,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-c58c4161-446a-4f42-85cc-30727d24fc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-35049213-e467-4bd3-9a8e-ea7d4d57f40b,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-815e9ecd-e325-46b7-8709-816ff15282a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-b00290c5-1114-4395-a865-d2da0a25dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-a14a9ff7-f1e4-4cd0-9be0-7680dc140ab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102273151-172.17.0.14-1595355904575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45231,DS-9621660f-1321-4c32-b6c8-d0eb38f81924,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-0fd81ff7-8d7d-4ee9-a210-370dd112afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-13300d2f-de06-4dfd-b247-8052b1082088,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-4b218dde-ad47-49af-b17b-b14ccd0b2a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-1c62014c-207e-42ca-b0c9-a835b67d5d87,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-68fb8384-2dc1-4181-98d2-57f1352d7c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-94b396f3-ba05-4ecc-8c9c-a9ae1b9b5597,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-3fc728f7-cbc6-4875-8c90-b04f911f35d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102273151-172.17.0.14-1595355904575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45231,DS-9621660f-1321-4c32-b6c8-d0eb38f81924,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-0fd81ff7-8d7d-4ee9-a210-370dd112afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-13300d2f-de06-4dfd-b247-8052b1082088,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-4b218dde-ad47-49af-b17b-b14ccd0b2a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-1c62014c-207e-42ca-b0c9-a835b67d5d87,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-68fb8384-2dc1-4181-98d2-57f1352d7c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-94b396f3-ba05-4ecc-8c9c-a9ae1b9b5597,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-3fc728f7-cbc6-4875-8c90-b04f911f35d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338043346-172.17.0.14-1595356198124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-6ec5b565-0b61-41c4-8cbe-2294f014b10e,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-349c5c64-fa80-4c03-b395-d72b14d0352e,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-52746111-eaae-4a19-8b75-880109af6a23,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-4b809f92-3aa5-4f1b-9b9c-7a8c8d7387aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-4ec179cb-9c8c-4648-9dac-8c787b871636,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-b7aa43f3-e5b1-4b10-829e-c141f75ab41a,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-602a769c-d041-4451-bfcc-8f6e02020441,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-e6067108-fdae-4d31-a7f7-b7ae6b549b4d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338043346-172.17.0.14-1595356198124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-6ec5b565-0b61-41c4-8cbe-2294f014b10e,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-349c5c64-fa80-4c03-b395-d72b14d0352e,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-52746111-eaae-4a19-8b75-880109af6a23,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-4b809f92-3aa5-4f1b-9b9c-7a8c8d7387aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-4ec179cb-9c8c-4648-9dac-8c787b871636,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-b7aa43f3-e5b1-4b10-829e-c141f75ab41a,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-602a769c-d041-4451-bfcc-8f6e02020441,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-e6067108-fdae-4d31-a7f7-b7ae6b549b4d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185399470-172.17.0.14-1595356256459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42846,DS-fea965b2-8b78-4e3e-b88e-85dfa3044563,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-4f18de2f-a0d1-4f8e-87e1-2a496c4c8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-58838bda-6abc-4376-abea-4f602e03fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-2e455f54-581b-4c1e-bfe3-f60505392539,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-dc442786-6a74-4643-bf03-c1dc79293e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-b80d187e-120d-4c33-b910-51ac8d65e2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-4466e383-c1f8-428c-92fb-e13fe0037c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-02a44982-e861-46c3-ad3f-8f6df4c32782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185399470-172.17.0.14-1595356256459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42846,DS-fea965b2-8b78-4e3e-b88e-85dfa3044563,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-4f18de2f-a0d1-4f8e-87e1-2a496c4c8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-58838bda-6abc-4376-abea-4f602e03fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-2e455f54-581b-4c1e-bfe3-f60505392539,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-dc442786-6a74-4643-bf03-c1dc79293e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-b80d187e-120d-4c33-b910-51ac8d65e2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-4466e383-c1f8-428c-92fb-e13fe0037c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-02a44982-e861-46c3-ad3f-8f6df4c32782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84421731-172.17.0.14-1595356293923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33815,DS-ec4bc20d-e5f9-4de7-a8f3-a3d63695a5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-fade18b6-0c2c-4e0d-9e12-0e619a7808f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-30271b5e-ddfa-403a-a3e1-142cd56be59e,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-3d35ff53-bf46-4895-bc99-489751c2e103,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-2dec1d64-7b2d-4d10-904a-487aac73227a,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-1c206bef-8c9e-4466-baf8-73c5f27cda69,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-3cf22727-5dac-47e5-8c6e-b2af0a89ad11,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-32250297-137c-4edd-bd6a-c7f796a35755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84421731-172.17.0.14-1595356293923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33815,DS-ec4bc20d-e5f9-4de7-a8f3-a3d63695a5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-fade18b6-0c2c-4e0d-9e12-0e619a7808f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-30271b5e-ddfa-403a-a3e1-142cd56be59e,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-3d35ff53-bf46-4895-bc99-489751c2e103,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-2dec1d64-7b2d-4d10-904a-487aac73227a,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-1c206bef-8c9e-4466-baf8-73c5f27cda69,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-3cf22727-5dac-47e5-8c6e-b2af0a89ad11,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-32250297-137c-4edd-bd6a-c7f796a35755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812362296-172.17.0.14-1595356510044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-0b592c6e-1591-4142-b1f4-28b209435da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-1fef52fc-eaf0-4f35-97cd-fd3410958e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-512973f8-5ac0-4865-8ad0-0e074b5d3bca,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-e6938957-4f59-45da-9a14-de155177b60c,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-5b6ddf63-cc51-4e4b-be87-6cea00e8c248,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-bc2def5a-79f3-4138-b305-a35ede70831b,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-c0185c1e-fee4-42fb-8046-787727888560,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-4c456b84-df86-422c-8b81-f190ad8ade7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812362296-172.17.0.14-1595356510044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-0b592c6e-1591-4142-b1f4-28b209435da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-1fef52fc-eaf0-4f35-97cd-fd3410958e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-512973f8-5ac0-4865-8ad0-0e074b5d3bca,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-e6938957-4f59-45da-9a14-de155177b60c,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-5b6ddf63-cc51-4e4b-be87-6cea00e8c248,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-bc2def5a-79f3-4138-b305-a35ede70831b,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-c0185c1e-fee4-42fb-8046-787727888560,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-4c456b84-df86-422c-8b81-f190ad8ade7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237135977-172.17.0.14-1595356782542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35419,DS-b297a08f-9648-4c26-a74b-9d5681e10d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-11d8ddb1-b4a0-4a03-916b-1ac31f9d28d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-c77836b3-123c-45fa-9d77-43fcb94f9477,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-850dc360-194a-4bb2-8a5a-e1a6d6d99e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-289bfae8-6b8a-436d-ac95-d75aeeb18a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-05ac1d2a-36d0-41dc-8f61-f788f6db03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-f112cbf0-8172-41d4-8ebd-05a28db51102,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-1d7721fe-48b2-4052-be9b-2ef9e7a23ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237135977-172.17.0.14-1595356782542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35419,DS-b297a08f-9648-4c26-a74b-9d5681e10d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-11d8ddb1-b4a0-4a03-916b-1ac31f9d28d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-c77836b3-123c-45fa-9d77-43fcb94f9477,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-850dc360-194a-4bb2-8a5a-e1a6d6d99e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-289bfae8-6b8a-436d-ac95-d75aeeb18a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-05ac1d2a-36d0-41dc-8f61-f788f6db03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-f112cbf0-8172-41d4-8ebd-05a28db51102,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-1d7721fe-48b2-4052-be9b-2ef9e7a23ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822057865-172.17.0.14-1595356965911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-925a2f20-a123-4a1f-9cd4-6dabf0555d17,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-ee64ad8d-d25d-4bad-8771-a0b172a6eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-3eae22c9-417c-46f8-9aeb-c579230e0e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-b4374c35-ec96-40ff-81aa-87d214cef8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-f9fdfbd3-45ae-4b78-bdbb-2d6fecc8d203,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-8a1cd8b7-f9dd-4372-81be-7f881c22fd10,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-f6612c45-68dd-4996-a844-44e52a0a0f30,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-e11c3911-3953-4600-a419-7f9b319a583d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822057865-172.17.0.14-1595356965911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-925a2f20-a123-4a1f-9cd4-6dabf0555d17,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-ee64ad8d-d25d-4bad-8771-a0b172a6eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-3eae22c9-417c-46f8-9aeb-c579230e0e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-b4374c35-ec96-40ff-81aa-87d214cef8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-f9fdfbd3-45ae-4b78-bdbb-2d6fecc8d203,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-8a1cd8b7-f9dd-4372-81be-7f881c22fd10,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-f6612c45-68dd-4996-a844-44e52a0a0f30,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-e11c3911-3953-4600-a419-7f9b319a583d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263718245-172.17.0.14-1595357454157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-78ec5966-289e-41cd-860e-87798709006c,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-916b13d3-f94c-4900-9064-94f29c0f2477,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-259086d1-b775-4212-97e9-ca9e2967f511,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-9600a382-da61-4960-ad21-8e5e3d80caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-bee0dd73-c099-4e52-9e65-8ef11d6ebd79,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-b4a3e03c-b995-4fc4-99e5-f5f4714bc672,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-504442e4-5aea-4d76-bc8c-5058643f7aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-71871d18-7131-4261-a3db-d21bb71d9730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263718245-172.17.0.14-1595357454157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-78ec5966-289e-41cd-860e-87798709006c,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-916b13d3-f94c-4900-9064-94f29c0f2477,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-259086d1-b775-4212-97e9-ca9e2967f511,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-9600a382-da61-4960-ad21-8e5e3d80caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-bee0dd73-c099-4e52-9e65-8ef11d6ebd79,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-b4a3e03c-b995-4fc4-99e5-f5f4714bc672,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-504442e4-5aea-4d76-bc8c-5058643f7aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-71871d18-7131-4261-a3db-d21bb71d9730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343698961-172.17.0.14-1595357553908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44313,DS-62cca855-acbb-4d00-a0dd-1d7dc4dcf813,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-0f7cd057-a035-4954-b24f-2f0e21e15e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-964370d5-099e-45cc-b3b2-053d0f346a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-b48c6482-ccef-4dc4-afde-ed9af939f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-12888255-c7be-468a-9e17-71ad322e8bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-6d740fa9-284c-4a80-88cf-df8f67a08a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-5a6b6dea-b5b5-4114-9641-7f120216c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-e850a885-44b9-42b6-bda3-5de16fd84e38,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343698961-172.17.0.14-1595357553908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44313,DS-62cca855-acbb-4d00-a0dd-1d7dc4dcf813,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-0f7cd057-a035-4954-b24f-2f0e21e15e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-964370d5-099e-45cc-b3b2-053d0f346a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-b48c6482-ccef-4dc4-afde-ed9af939f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-12888255-c7be-468a-9e17-71ad322e8bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-6d740fa9-284c-4a80-88cf-df8f67a08a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-5a6b6dea-b5b5-4114-9641-7f120216c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-e850a885-44b9-42b6-bda3-5de16fd84e38,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560002004-172.17.0.14-1595357587794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-8d5ba44d-c929-4f4b-9d03-3df9d9d4b896,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-1bb48409-e76b-44be-a279-19ff05bdeae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-a8b2a331-7142-4bd7-9479-6c729dc31102,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-113f2d2e-e544-4871-a91d-dd0b7f330948,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-4db2fad7-e6b8-4be9-9663-f93452949abf,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-1146f0c9-e062-47bd-aa32-9485c8f04281,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-16fe45b4-f330-4f3e-be3a-8fb8590c7fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-cfb114e7-2dd1-4c10-a32d-92c84f7abe2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560002004-172.17.0.14-1595357587794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-8d5ba44d-c929-4f4b-9d03-3df9d9d4b896,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-1bb48409-e76b-44be-a279-19ff05bdeae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-a8b2a331-7142-4bd7-9479-6c729dc31102,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-113f2d2e-e544-4871-a91d-dd0b7f330948,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-4db2fad7-e6b8-4be9-9663-f93452949abf,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-1146f0c9-e062-47bd-aa32-9485c8f04281,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-16fe45b4-f330-4f3e-be3a-8fb8590c7fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-cfb114e7-2dd1-4c10-a32d-92c84f7abe2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488289071-172.17.0.14-1595357663543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41871,DS-f41ee5dd-6f58-4b68-9b69-a02590c3c180,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-ed00ad72-1612-455d-a478-f8b854ce9834,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-ec839a79-df49-4a46-a4cb-4c24f45aca25,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-b1919ee7-c38e-47b5-b78e-e92b1c071c46,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-ddf615ba-4293-45dd-8a7e-715a20d2d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-83ae571b-77d3-46be-8b9e-2a3de820b154,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-782b14e7-afcd-4786-b9a6-3bd69647568d,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-205a813f-b8a2-4109-b2a6-e162b3f967ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488289071-172.17.0.14-1595357663543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41871,DS-f41ee5dd-6f58-4b68-9b69-a02590c3c180,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-ed00ad72-1612-455d-a478-f8b854ce9834,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-ec839a79-df49-4a46-a4cb-4c24f45aca25,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-b1919ee7-c38e-47b5-b78e-e92b1c071c46,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-ddf615ba-4293-45dd-8a7e-715a20d2d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-83ae571b-77d3-46be-8b9e-2a3de820b154,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-782b14e7-afcd-4786-b9a6-3bd69647568d,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-205a813f-b8a2-4109-b2a6-e162b3f967ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108158257-172.17.0.14-1595357694106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45054,DS-d7ca3748-b3ff-4ae6-ac42-fc7962b4a151,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-80f4795a-366d-4512-888d-f68e9214ff05,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-e262956e-75aa-40b9-9071-f7454a367de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-a6e7e25f-5c60-4c5a-a6bc-b20bd63e3366,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-ff030deb-d3c5-4555-ae4b-b73cf97094ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-9e38cebb-5648-478a-8f01-fc6e9c49922c,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-f371a07c-fd64-41db-926a-6a3f3fd5ed98,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-b8693ae5-4ec8-4c42-91eb-afee0bac2e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108158257-172.17.0.14-1595357694106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45054,DS-d7ca3748-b3ff-4ae6-ac42-fc7962b4a151,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-80f4795a-366d-4512-888d-f68e9214ff05,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-e262956e-75aa-40b9-9071-f7454a367de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-a6e7e25f-5c60-4c5a-a6bc-b20bd63e3366,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-ff030deb-d3c5-4555-ae4b-b73cf97094ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-9e38cebb-5648-478a-8f01-fc6e9c49922c,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-f371a07c-fd64-41db-926a-6a3f3fd5ed98,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-b8693ae5-4ec8-4c42-91eb-afee0bac2e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547646352-172.17.0.14-1595357838523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39084,DS-db8a0b9c-ecde-428d-8069-e186c3bcecda,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-9a652b35-578c-494f-9d78-eab6bfd76e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-fbb84bd5-7961-4f38-ae26-a6c2ff30c334,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-9e9824c3-6e42-4ae1-a416-7cb3e83a9d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-5098a55f-8d1d-432c-98a6-ba20a84cdeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-4d4401d4-0fe6-461d-9eb6-83bc7ffd6bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-dc4788bf-e0be-440a-b5be-11b19668a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-b2cb9729-6815-4092-88af-51d46d63e7c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547646352-172.17.0.14-1595357838523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39084,DS-db8a0b9c-ecde-428d-8069-e186c3bcecda,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-9a652b35-578c-494f-9d78-eab6bfd76e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-fbb84bd5-7961-4f38-ae26-a6c2ff30c334,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-9e9824c3-6e42-4ae1-a416-7cb3e83a9d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-5098a55f-8d1d-432c-98a6-ba20a84cdeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-4d4401d4-0fe6-461d-9eb6-83bc7ffd6bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-dc4788bf-e0be-440a-b5be-11b19668a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-b2cb9729-6815-4092-88af-51d46d63e7c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399080583-172.17.0.14-1595358084117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33852,DS-d8038f60-f3f1-4ea6-8b47-152922cf2568,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-b5ed979a-30d0-46c5-8788-d193ce4234bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-6d672877-bfbc-4e00-b219-2e0e860f1178,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-63c864ea-ebf5-4e89-9db7-3e1159782e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-f8afbe5e-381d-414d-8bca-7945d123ff23,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-a6d7156f-c3b4-4a7c-8162-b6f3cbba3446,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-eb2759e7-d033-4f3d-a4d1-442c72d945e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-61d5edba-5894-4e70-a375-1eddfc8d5837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399080583-172.17.0.14-1595358084117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33852,DS-d8038f60-f3f1-4ea6-8b47-152922cf2568,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-b5ed979a-30d0-46c5-8788-d193ce4234bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-6d672877-bfbc-4e00-b219-2e0e860f1178,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-63c864ea-ebf5-4e89-9db7-3e1159782e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-f8afbe5e-381d-414d-8bca-7945d123ff23,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-a6d7156f-c3b4-4a7c-8162-b6f3cbba3446,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-eb2759e7-d033-4f3d-a4d1-442c72d945e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-61d5edba-5894-4e70-a375-1eddfc8d5837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666999609-172.17.0.14-1595358292897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-c0cd3cea-120b-4332-8ae8-1383e2011217,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-81447351-f524-4820-97f3-83eeaff6a905,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-25a8543a-9501-4d03-8122-e5ef9a8208e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-9b667b70-fef0-4297-8664-40f204452880,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-f3f45bf8-2525-4956-8d5a-ebc5eefe233f,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-db74c0c5-0b17-42df-ac5e-21cb6e540554,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-fc8b4f45-624e-4cfd-97e3-cdba60d81311,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-a34aa047-2a79-4c71-b2db-0e0ce27c2900,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666999609-172.17.0.14-1595358292897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-c0cd3cea-120b-4332-8ae8-1383e2011217,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-81447351-f524-4820-97f3-83eeaff6a905,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-25a8543a-9501-4d03-8122-e5ef9a8208e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-9b667b70-fef0-4297-8664-40f204452880,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-f3f45bf8-2525-4956-8d5a-ebc5eefe233f,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-db74c0c5-0b17-42df-ac5e-21cb6e540554,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-fc8b4f45-624e-4cfd-97e3-cdba60d81311,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-a34aa047-2a79-4c71-b2db-0e0ce27c2900,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060420275-172.17.0.14-1595358364047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-cad391d4-d6c2-405e-a805-002f28502ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-c228d38b-c550-4348-9b76-85847a3da758,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-d0f2785d-bada-44e9-b74f-d1ab069ad892,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-5ce127ee-860b-470e-b0bb-defe896898f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-342aa50a-1035-47c0-8f20-e34876936423,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-62f7e130-deb3-4a9c-bdd9-bf1f680428ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-782edf90-eacd-418b-ac25-742206e73b74,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-8b3f823d-01ba-4883-86b6-c19a29ca5959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060420275-172.17.0.14-1595358364047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-cad391d4-d6c2-405e-a805-002f28502ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-c228d38b-c550-4348-9b76-85847a3da758,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-d0f2785d-bada-44e9-b74f-d1ab069ad892,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-5ce127ee-860b-470e-b0bb-defe896898f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-342aa50a-1035-47c0-8f20-e34876936423,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-62f7e130-deb3-4a9c-bdd9-bf1f680428ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-782edf90-eacd-418b-ac25-742206e73b74,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-8b3f823d-01ba-4883-86b6-c19a29ca5959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623050815-172.17.0.14-1595358739705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42231,DS-3e3b08f8-cb77-4e5f-9f46-5e238fe0bc20,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-508c202a-be7b-4cb6-85ee-1be826c3125d,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-81615c0d-0ec7-4f0f-9622-39465c80f703,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-b4423307-c497-48d2-ae7e-83349d70dbba,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-30f4ef1f-3ee2-4312-adf1-89348516ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-b14da2c5-0b99-4dd5-9ac2-90b744f9bc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-36b4e541-4a8b-45fe-8d61-b4490bddb503,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-76b82917-9468-4f16-9ddf-07d7f72fdf89,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623050815-172.17.0.14-1595358739705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42231,DS-3e3b08f8-cb77-4e5f-9f46-5e238fe0bc20,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-508c202a-be7b-4cb6-85ee-1be826c3125d,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-81615c0d-0ec7-4f0f-9622-39465c80f703,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-b4423307-c497-48d2-ae7e-83349d70dbba,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-30f4ef1f-3ee2-4312-adf1-89348516ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-b14da2c5-0b99-4dd5-9ac2-90b744f9bc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-36b4e541-4a8b-45fe-8d61-b4490bddb503,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-76b82917-9468-4f16-9ddf-07d7f72fdf89,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145056560-172.17.0.14-1595358972835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-7b99cc22-9d26-445a-bba0-bf01fbcbbdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-cca24865-aadc-406d-84ac-291a9aec7349,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-817d3b55-df11-490a-a8c4-3d601594de65,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-2bf0a062-b582-4a21-a3e9-aba4067d943b,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-c7f19f1e-d5db-4a8e-afc5-44a0547f7954,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-14b9aed6-858a-4f70-b42b-b0d849f28550,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-990ccba2-d909-44e4-b39d-e6722e016fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-14b96e54-abe6-4aa8-b120-c5283364647f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145056560-172.17.0.14-1595358972835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-7b99cc22-9d26-445a-bba0-bf01fbcbbdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-cca24865-aadc-406d-84ac-291a9aec7349,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-817d3b55-df11-490a-a8c4-3d601594de65,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-2bf0a062-b582-4a21-a3e9-aba4067d943b,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-c7f19f1e-d5db-4a8e-afc5-44a0547f7954,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-14b9aed6-858a-4f70-b42b-b0d849f28550,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-990ccba2-d909-44e4-b39d-e6722e016fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-14b96e54-abe6-4aa8-b120-c5283364647f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895786247-172.17.0.14-1595359005806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-1016828a-8dae-4294-afdf-4e7e5da624cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-a53eab06-a36c-4135-a97f-19ea73078869,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-ef6f5038-637d-4a73-8445-63bb21832e40,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-450db74a-7264-49e1-84f0-ca903e002b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-232be005-ce88-4cd9-87dd-d76edc4aed2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-fd96be76-9b96-4bb1-88ac-27d5cb9888a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-b5ff2075-fa5f-44c2-b04d-480fdcdc6338,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-2efb6d87-d200-44eb-94d1-cf908f95b63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895786247-172.17.0.14-1595359005806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36319,DS-1016828a-8dae-4294-afdf-4e7e5da624cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-a53eab06-a36c-4135-a97f-19ea73078869,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-ef6f5038-637d-4a73-8445-63bb21832e40,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-450db74a-7264-49e1-84f0-ca903e002b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-232be005-ce88-4cd9-87dd-d76edc4aed2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-fd96be76-9b96-4bb1-88ac-27d5cb9888a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-b5ff2075-fa5f-44c2-b04d-480fdcdc6338,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-2efb6d87-d200-44eb-94d1-cf908f95b63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44315171-172.17.0.14-1595359137189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35214,DS-1fb135da-b36f-438f-b825-c85a7c8008fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-46448e86-721d-49fd-95ca-78d289aa05a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-0938e86a-4d85-447c-8151-ad74b4022740,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-70b9487f-06f5-46f4-a625-551a04c4c4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-ce07a633-45ae-4c30-ab00-b359d025289b,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-43241f31-79d6-40ef-a1b4-6882a40e88b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-fc4288ae-5670-40ed-bfdb-491e806d32dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-34546e36-4bcf-4da2-b573-678bbcfe4a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44315171-172.17.0.14-1595359137189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35214,DS-1fb135da-b36f-438f-b825-c85a7c8008fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-46448e86-721d-49fd-95ca-78d289aa05a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-0938e86a-4d85-447c-8151-ad74b4022740,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-70b9487f-06f5-46f4-a625-551a04c4c4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-ce07a633-45ae-4c30-ab00-b359d025289b,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-43241f31-79d6-40ef-a1b4-6882a40e88b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-fc4288ae-5670-40ed-bfdb-491e806d32dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-34546e36-4bcf-4da2-b573-678bbcfe4a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887863853-172.17.0.14-1595359333550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-aed82044-4fb3-47c4-9474-22d8bf0a0d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-11ac8879-2d1b-4509-8de2-f2498f542cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-1a00ad02-bac1-4c0f-a1c8-89bb324f1671,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-c335e66a-ba0e-4018-a131-d6298f150623,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-2250be56-31f8-4413-ba9a-b38c55c86984,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-64afcfea-f499-48ec-9294-f3e56a9fa31b,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-6883de58-1028-45da-8445-aa9a43be6358,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-2e0c25c3-3877-4753-adae-c98aeb1f890c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887863853-172.17.0.14-1595359333550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-aed82044-4fb3-47c4-9474-22d8bf0a0d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-11ac8879-2d1b-4509-8de2-f2498f542cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-1a00ad02-bac1-4c0f-a1c8-89bb324f1671,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-c335e66a-ba0e-4018-a131-d6298f150623,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-2250be56-31f8-4413-ba9a-b38c55c86984,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-64afcfea-f499-48ec-9294-f3e56a9fa31b,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-6883de58-1028-45da-8445-aa9a43be6358,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-2e0c25c3-3877-4753-adae-c98aeb1f890c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002966878-172.17.0.14-1595359402253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45377,DS-8b330355-61f1-4299-b5dd-3cb373483b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-35bdd571-2254-454e-951a-f9f6577ff8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-dff0478d-ae19-4350-b964-e1c656f32c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-491854ff-2995-4e7f-8fb8-c3e858c9f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-7a9d1a2a-f000-4657-9fe4-b8a13faf2771,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-f96b1a39-9325-4ce0-86ab-66337db5264c,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-fd8b921a-4b70-4c10-97fd-38d0ce1efe5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-0c2a9bf6-5767-466f-b136-c789348a04b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002966878-172.17.0.14-1595359402253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45377,DS-8b330355-61f1-4299-b5dd-3cb373483b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-35bdd571-2254-454e-951a-f9f6577ff8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-dff0478d-ae19-4350-b964-e1c656f32c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-491854ff-2995-4e7f-8fb8-c3e858c9f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-7a9d1a2a-f000-4657-9fe4-b8a13faf2771,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-f96b1a39-9325-4ce0-86ab-66337db5264c,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-fd8b921a-4b70-4c10-97fd-38d0ce1efe5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-0c2a9bf6-5767-466f-b136-c789348a04b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299209341-172.17.0.14-1595359470954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-8943777b-ae78-4ffc-ab1d-884c4d907955,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-a2ec6c19-dc3c-4c5b-9e10-885ddc678b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-d6240838-663e-4d0f-8880-288ddbcde7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-01fbbdf4-6fb2-499c-b7ea-2cc1a12a1c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-173894f9-eb43-47a0-8e23-6561982a3ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-6db2dcb9-1ff9-40fe-aad9-37fc04d40a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-69c8a96c-8ae0-4132-a780-e2cfb83a193c,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-7bcaf65b-a94b-4403-896d-20224252846d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299209341-172.17.0.14-1595359470954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-8943777b-ae78-4ffc-ab1d-884c4d907955,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-a2ec6c19-dc3c-4c5b-9e10-885ddc678b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-d6240838-663e-4d0f-8880-288ddbcde7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-01fbbdf4-6fb2-499c-b7ea-2cc1a12a1c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-173894f9-eb43-47a0-8e23-6561982a3ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-6db2dcb9-1ff9-40fe-aad9-37fc04d40a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-69c8a96c-8ae0-4132-a780-e2cfb83a193c,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-7bcaf65b-a94b-4403-896d-20224252846d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194234828-172.17.0.14-1595359604351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-9b8bc256-4ca6-4457-ae5e-028c9812fa17,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-c1a2fa9b-68f0-460c-9b1b-d4dead01a1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-aaceb485-84d3-4bf5-a10f-c8756fbd458b,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-ea6c5863-af0d-43e8-8970-c9235aba1542,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-fcb1031e-69c7-48d8-a3f6-934216c93132,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-8a72320e-0d4b-47c7-b5cc-1e77538a7c12,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-5e4c40c1-edc5-4c4f-ab9d-82764dc30a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-1f7d9216-92a1-41a9-b4de-98553a565664,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194234828-172.17.0.14-1595359604351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-9b8bc256-4ca6-4457-ae5e-028c9812fa17,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-c1a2fa9b-68f0-460c-9b1b-d4dead01a1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-aaceb485-84d3-4bf5-a10f-c8756fbd458b,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-ea6c5863-af0d-43e8-8970-c9235aba1542,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-fcb1031e-69c7-48d8-a3f6-934216c93132,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-8a72320e-0d4b-47c7-b5cc-1e77538a7c12,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-5e4c40c1-edc5-4c4f-ab9d-82764dc30a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-1f7d9216-92a1-41a9-b4de-98553a565664,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345242754-172.17.0.14-1595359695259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34196,DS-b808ce0f-6565-403d-a3cd-aa02cc46da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-9ee7f61e-e4b8-4acd-abac-63439a3e516b,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-6a6eb58e-8174-4578-b3e1-0fdc0edaa92d,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-f1db5782-ee11-4066-9485-c02b76773c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-ef2c855a-4042-4462-8e99-cca049c833b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-94991445-b4a9-4d5c-870e-9d505edfd1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-caf746e1-57b0-415c-91ce-592199890a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-bf68529c-56e2-4c3d-917b-9da4bf23a942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345242754-172.17.0.14-1595359695259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34196,DS-b808ce0f-6565-403d-a3cd-aa02cc46da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-9ee7f61e-e4b8-4acd-abac-63439a3e516b,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-6a6eb58e-8174-4578-b3e1-0fdc0edaa92d,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-f1db5782-ee11-4066-9485-c02b76773c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-ef2c855a-4042-4462-8e99-cca049c833b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-94991445-b4a9-4d5c-870e-9d505edfd1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-caf746e1-57b0-415c-91ce-592199890a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-bf68529c-56e2-4c3d-917b-9da4bf23a942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842443508-172.17.0.14-1595359840240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-4f8ea2d7-2eea-47ce-9c6c-b7859be914c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-3704a737-21c3-4193-80fd-8dc1fba102e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-5fea05a0-5763-49d3-b62e-83d932671460,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-1e2c1df8-06af-4a1b-8b6d-39973467827d,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-c732d1c8-ed54-4660-9305-f22e0102ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-8b539165-4711-477f-a33f-d0cbd79877f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-07ad4622-449a-496a-8f3d-c80c904c73b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-09cbebfb-badf-4253-b35d-7bd2ad489f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842443508-172.17.0.14-1595359840240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-4f8ea2d7-2eea-47ce-9c6c-b7859be914c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-3704a737-21c3-4193-80fd-8dc1fba102e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-5fea05a0-5763-49d3-b62e-83d932671460,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-1e2c1df8-06af-4a1b-8b6d-39973467827d,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-c732d1c8-ed54-4660-9305-f22e0102ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-8b539165-4711-477f-a33f-d0cbd79877f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-07ad4622-449a-496a-8f3d-c80c904c73b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-09cbebfb-badf-4253-b35d-7bd2ad489f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605653998-172.17.0.14-1595359906782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-f5881b3d-e25e-42ef-b268-ddb757dc1b59,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-4bebb061-215b-49ee-997b-d44c4a77aac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-5e010ba4-8030-4bd6-97b5-f0bdc58cb273,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-d868ee74-501d-497c-aa7a-0902e09d44d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-cf682738-e6e5-4419-a5c4-388ace086658,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-0e99483a-7444-4497-a7a1-c437b81df872,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-10b53cb2-4a77-45f3-ac1d-50bc4a56098a,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-c1b51874-4dbc-463d-bf00-276160ba28c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605653998-172.17.0.14-1595359906782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-f5881b3d-e25e-42ef-b268-ddb757dc1b59,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-4bebb061-215b-49ee-997b-d44c4a77aac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-5e010ba4-8030-4bd6-97b5-f0bdc58cb273,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-d868ee74-501d-497c-aa7a-0902e09d44d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-cf682738-e6e5-4419-a5c4-388ace086658,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-0e99483a-7444-4497-a7a1-c437b81df872,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-10b53cb2-4a77-45f3-ac1d-50bc4a56098a,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-c1b51874-4dbc-463d-bf00-276160ba28c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360356490-172.17.0.14-1595359936606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-19130993-b74e-49a6-9bb2-e3c9a56ad634,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-d6468eb7-4966-48e5-8aef-611778fb744b,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-264c518e-9270-47fa-b56b-c7fb9897c6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-714a38c9-7aaf-4445-8d81-a16a8f451441,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-bf51c6f2-db50-44e8-866a-5a5d9086419b,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-e7945e9f-73ea-457a-ab74-67352f7245f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-73dccb7a-8771-4ed3-841e-a21a80c6dcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-3cb72c95-9e2d-4d2d-a7d1-e9d312137cfa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360356490-172.17.0.14-1595359936606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-19130993-b74e-49a6-9bb2-e3c9a56ad634,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-d6468eb7-4966-48e5-8aef-611778fb744b,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-264c518e-9270-47fa-b56b-c7fb9897c6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-714a38c9-7aaf-4445-8d81-a16a8f451441,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-bf51c6f2-db50-44e8-866a-5a5d9086419b,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-e7945e9f-73ea-457a-ab74-67352f7245f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-73dccb7a-8771-4ed3-841e-a21a80c6dcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-3cb72c95-9e2d-4d2d-a7d1-e9d312137cfa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129218922-172.17.0.14-1595359976695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43148,DS-10423a9d-70dc-4edc-b990-524fa1d7bb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-13162ce7-cc41-47a7-a5eb-5236f88d2048,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-993f0642-c758-4f50-af8d-dddfb7eca40a,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-3691d785-0c19-4652-aa2f-bf55b71727a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-7f48df0d-035b-4233-bd98-8c9f8e228348,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-2e502488-53a7-4ed1-b7fb-b6e47fefc17a,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-4e8f6713-9b4e-402f-ad9c-cb74c953ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-6e02c605-7720-41ca-9ad3-0b15182ddd44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129218922-172.17.0.14-1595359976695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43148,DS-10423a9d-70dc-4edc-b990-524fa1d7bb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-13162ce7-cc41-47a7-a5eb-5236f88d2048,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-993f0642-c758-4f50-af8d-dddfb7eca40a,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-3691d785-0c19-4652-aa2f-bf55b71727a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-7f48df0d-035b-4233-bd98-8c9f8e228348,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-2e502488-53a7-4ed1-b7fb-b6e47fefc17a,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-4e8f6713-9b4e-402f-ad9c-cb74c953ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-6e02c605-7720-41ca-9ad3-0b15182ddd44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5278
