reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899230792-172.17.0.13-1595362055547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34026,DS-3301bfad-654f-4674-ab3f-db6436725232,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-240d7794-c822-4f0e-b7c1-be8b26d49da5,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-2896670f-c332-42af-a7cb-72cc148b0b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-e8d89b29-fa5e-4754-98f7-fe58bb135941,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-8c9077b5-12c1-4f2b-9b57-019d4ffc82f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-29499f5f-42d9-4b58-986c-65e45a8c82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-86aa6423-fd2f-431a-b0b4-95dc481ec0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-1169f42f-f12f-40e0-8271-57a896325605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899230792-172.17.0.13-1595362055547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34026,DS-3301bfad-654f-4674-ab3f-db6436725232,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-240d7794-c822-4f0e-b7c1-be8b26d49da5,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-2896670f-c332-42af-a7cb-72cc148b0b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-e8d89b29-fa5e-4754-98f7-fe58bb135941,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-8c9077b5-12c1-4f2b-9b57-019d4ffc82f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-29499f5f-42d9-4b58-986c-65e45a8c82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-86aa6423-fd2f-431a-b0b4-95dc481ec0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-1169f42f-f12f-40e0-8271-57a896325605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278725297-172.17.0.13-1595362229040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-49b357e6-c3bc-494c-a3bc-97ea26cf18bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-c4e923e4-6f92-4d1c-82f6-c3f6b87b902b,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-559aa2a4-62af-4d6c-81d2-fe6266209763,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-9a41fe1e-dfef-44fa-8049-bcd989e8b069,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-b08f78f9-851e-41a7-8b90-91b71698d404,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-9a4cc46e-fb59-48e4-9719-3c01c0e4be90,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-52776f39-7d84-4b2d-bd34-d86d134ba1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-32137769-59ce-4d9a-ae40-b7432b46a15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278725297-172.17.0.13-1595362229040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-49b357e6-c3bc-494c-a3bc-97ea26cf18bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-c4e923e4-6f92-4d1c-82f6-c3f6b87b902b,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-559aa2a4-62af-4d6c-81d2-fe6266209763,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-9a41fe1e-dfef-44fa-8049-bcd989e8b069,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-b08f78f9-851e-41a7-8b90-91b71698d404,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-9a4cc46e-fb59-48e4-9719-3c01c0e4be90,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-52776f39-7d84-4b2d-bd34-d86d134ba1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-32137769-59ce-4d9a-ae40-b7432b46a15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501833127-172.17.0.13-1595362562049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-92877632-83f2-4b36-908b-330cace14209,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-db215ed8-cc79-497f-a28e-5c0e7ef73afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-a7c79a84-956d-4be5-bd39-2561dce63e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-ab212966-65f8-4024-98ba-a4921d891370,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-5277ae7e-c687-4802-9314-1e9a51d013d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-fd1c2dd6-b94d-4629-a69d-d5643f189ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-9d691324-5121-4cb3-9942-8f10b3f1a816,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-e2ab1004-e278-4612-b19b-e644c1db1ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501833127-172.17.0.13-1595362562049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-92877632-83f2-4b36-908b-330cace14209,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-db215ed8-cc79-497f-a28e-5c0e7ef73afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-a7c79a84-956d-4be5-bd39-2561dce63e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-ab212966-65f8-4024-98ba-a4921d891370,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-5277ae7e-c687-4802-9314-1e9a51d013d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-fd1c2dd6-b94d-4629-a69d-d5643f189ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-9d691324-5121-4cb3-9942-8f10b3f1a816,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-e2ab1004-e278-4612-b19b-e644c1db1ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186096740-172.17.0.13-1595363141387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45158,DS-55f3af10-2c8d-45c1-9ad1-285ce73d8764,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-32e99e1f-35ff-4f1a-b0d3-3bae9604cfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-abde0c9a-6df7-4eac-94d9-08b179feb6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-321be904-d30c-4e49-a16e-8d1706675b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-b4876de4-b8c1-4c75-a80c-79a161d5fe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-6dc577ac-08fd-42bc-896d-3c623caecc71,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-e523710b-8ed0-4967-9935-ec98d0114bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-f8886ee2-f1b7-4ec5-8c4c-78294078ae0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186096740-172.17.0.13-1595363141387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45158,DS-55f3af10-2c8d-45c1-9ad1-285ce73d8764,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-32e99e1f-35ff-4f1a-b0d3-3bae9604cfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-abde0c9a-6df7-4eac-94d9-08b179feb6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-321be904-d30c-4e49-a16e-8d1706675b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-b4876de4-b8c1-4c75-a80c-79a161d5fe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-6dc577ac-08fd-42bc-896d-3c623caecc71,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-e523710b-8ed0-4967-9935-ec98d0114bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-f8886ee2-f1b7-4ec5-8c4c-78294078ae0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203182261-172.17.0.13-1595364200781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-e0b1a368-5bb3-471a-89c4-aab536a26ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-d871ccf6-51d7-41b6-94dc-b106fa38a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-905f484c-d093-43cb-8d25-4f3d716b9f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-3f3d88b6-4de3-4501-8d6b-946de318d2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-ee163847-1ad6-4f7d-8d2a-d5f0cf7966d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-e244908b-6603-4aa8-a4d4-cef39dbefca9,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-25b26068-7d4d-41f3-bd06-4e8e0df85edb,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-fa33a2f0-a4a5-4d86-b632-903da843c0e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203182261-172.17.0.13-1595364200781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-e0b1a368-5bb3-471a-89c4-aab536a26ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-d871ccf6-51d7-41b6-94dc-b106fa38a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-905f484c-d093-43cb-8d25-4f3d716b9f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-3f3d88b6-4de3-4501-8d6b-946de318d2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-ee163847-1ad6-4f7d-8d2a-d5f0cf7966d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-e244908b-6603-4aa8-a4d4-cef39dbefca9,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-25b26068-7d4d-41f3-bd06-4e8e0df85edb,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-fa33a2f0-a4a5-4d86-b632-903da843c0e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90575886-172.17.0.13-1595364773963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-06fb3aa4-ba7a-4e99-9f7f-3926be88d34e,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-07348a28-5b1f-4e44-a5a7-92d34a9552f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-237510b2-be90-4fd8-99b5-afcd11530cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-e417d89f-b048-4fc0-a3be-03ab4a9b61bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-973de1ee-7de4-42de-a4dd-09bb7d0f1594,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-507780d5-faa5-4125-b0c9-2e3b6bceed68,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-e1c6469c-5cff-4615-bae7-e27c68053e16,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1175fa20-cca7-43c5-87fc-a8d7a9ef0d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90575886-172.17.0.13-1595364773963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-06fb3aa4-ba7a-4e99-9f7f-3926be88d34e,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-07348a28-5b1f-4e44-a5a7-92d34a9552f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-237510b2-be90-4fd8-99b5-afcd11530cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-e417d89f-b048-4fc0-a3be-03ab4a9b61bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-973de1ee-7de4-42de-a4dd-09bb7d0f1594,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-507780d5-faa5-4125-b0c9-2e3b6bceed68,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-e1c6469c-5cff-4615-bae7-e27c68053e16,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1175fa20-cca7-43c5-87fc-a8d7a9ef0d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45046562-172.17.0.13-1595365064702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39756,DS-875a5194-88ec-4e2f-b0d0-9f657bf22a22,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-90889789-81d2-4432-b67a-681ff1d81bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-63ca2dca-d55a-4ec4-b64a-c6f444ebe0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-c0fdedf5-ce2a-414f-90c3-8dbf213d00a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-0014988d-0e4e-4ef2-9d54-72f21e09c793,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-6ef4f7d2-83d2-47af-85ea-6fe4f973d8db,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-b9f65707-83d4-436c-a918-4bfb445139f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-b0a60669-6a2b-4c4d-ba32-6a2a58af15d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45046562-172.17.0.13-1595365064702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39756,DS-875a5194-88ec-4e2f-b0d0-9f657bf22a22,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-90889789-81d2-4432-b67a-681ff1d81bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-63ca2dca-d55a-4ec4-b64a-c6f444ebe0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-c0fdedf5-ce2a-414f-90c3-8dbf213d00a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-0014988d-0e4e-4ef2-9d54-72f21e09c793,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-6ef4f7d2-83d2-47af-85ea-6fe4f973d8db,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-b9f65707-83d4-436c-a918-4bfb445139f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-b0a60669-6a2b-4c4d-ba32-6a2a58af15d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391858073-172.17.0.13-1595365168536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-51f7dad2-9c17-45f7-b795-14e0489f06c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-f4a0e1eb-e302-4198-8e69-d5d23e41c179,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-ce2aedb3-3c1b-405b-a4a9-42b413459b14,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-d9b52f0d-d5be-4d26-9b61-909190196466,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-4f97ef09-6ee7-482f-9f19-687429ca90fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-9a083117-fa80-48e5-b31a-4b9191c00104,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-fb489ad4-db6a-4b32-84de-e27ea7b55635,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-097cd57a-aa1f-4cc6-a140-b7e7eb7a30dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391858073-172.17.0.13-1595365168536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-51f7dad2-9c17-45f7-b795-14e0489f06c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-f4a0e1eb-e302-4198-8e69-d5d23e41c179,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-ce2aedb3-3c1b-405b-a4a9-42b413459b14,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-d9b52f0d-d5be-4d26-9b61-909190196466,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-4f97ef09-6ee7-482f-9f19-687429ca90fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-9a083117-fa80-48e5-b31a-4b9191c00104,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-fb489ad4-db6a-4b32-84de-e27ea7b55635,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-097cd57a-aa1f-4cc6-a140-b7e7eb7a30dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944830088-172.17.0.13-1595365236987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-72ea20f4-712f-46b9-91f1-29f057d39d56,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-1c9974e5-7830-4a1f-8edc-ef9ec11853f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-6e9d076c-4947-44f4-b586-ff3be2b90ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-1d8da8c8-e8b5-489e-ad3f-1ae6a8111e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-854ed7fc-e953-4a2b-9b59-aec8dc6d2630,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-acd7d173-d02e-4613-af57-3b83350021f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-d60b2952-26d8-4215-99de-7a73310af49e,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-96651843-f291-4fac-b954-d30911b8d84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944830088-172.17.0.13-1595365236987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-72ea20f4-712f-46b9-91f1-29f057d39d56,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-1c9974e5-7830-4a1f-8edc-ef9ec11853f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-6e9d076c-4947-44f4-b586-ff3be2b90ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-1d8da8c8-e8b5-489e-ad3f-1ae6a8111e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-854ed7fc-e953-4a2b-9b59-aec8dc6d2630,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-acd7d173-d02e-4613-af57-3b83350021f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-d60b2952-26d8-4215-99de-7a73310af49e,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-96651843-f291-4fac-b954-d30911b8d84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482811161-172.17.0.13-1595365509962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-8f7dec17-ea9b-40cf-85a3-5a7fcf29e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-f0eebbdd-41a3-4cb2-9bc3-4b7e37373bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-01cde27d-c582-4bb5-b26a-da71b5475d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-4c5474b9-dc14-4447-ae84-99ce31fad614,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-4d233e03-281b-4927-beb1-9af72296bae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-b98dc37a-89a5-4773-891c-8142548e11b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-4f8d606a-cee2-40ec-b3c6-5f015901053d,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-13df5a3a-f4b1-43c9-a630-3887404f0e66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482811161-172.17.0.13-1595365509962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-8f7dec17-ea9b-40cf-85a3-5a7fcf29e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-f0eebbdd-41a3-4cb2-9bc3-4b7e37373bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-01cde27d-c582-4bb5-b26a-da71b5475d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-4c5474b9-dc14-4447-ae84-99ce31fad614,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-4d233e03-281b-4927-beb1-9af72296bae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-b98dc37a-89a5-4773-891c-8142548e11b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-4f8d606a-cee2-40ec-b3c6-5f015901053d,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-13df5a3a-f4b1-43c9-a630-3887404f0e66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290949033-172.17.0.13-1595366321191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35989,DS-40ef9d1a-e44c-4abf-b651-b222f1ef5c56,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-b916d347-ad5b-449e-9061-523c5ee2fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-b7530c22-5bef-4815-b1a7-b95acba6d040,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-cdd5442e-d88e-4cd1-a1ef-956ab29be98d,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-285c6007-d4c3-45fa-9fee-2a0f91a0d850,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-80ff647c-a557-4484-bd75-8aaebf282b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-8bc9095f-c526-4022-81b3-b711f23a7c34,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-2fb65666-b8ab-462d-971e-06c8dae8f6f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290949033-172.17.0.13-1595366321191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35989,DS-40ef9d1a-e44c-4abf-b651-b222f1ef5c56,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-b916d347-ad5b-449e-9061-523c5ee2fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-b7530c22-5bef-4815-b1a7-b95acba6d040,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-cdd5442e-d88e-4cd1-a1ef-956ab29be98d,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-285c6007-d4c3-45fa-9fee-2a0f91a0d850,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-80ff647c-a557-4484-bd75-8aaebf282b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-8bc9095f-c526-4022-81b3-b711f23a7c34,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-2fb65666-b8ab-462d-971e-06c8dae8f6f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356479523-172.17.0.13-1595366933064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-1d6a60d5-8101-4627-ae7c-318b8e8b9d80,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-8f99d0d9-fffb-47d8-87a5-f3008019b727,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-8538361a-ca26-4ee7-9930-5443f381f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-c4fb8c03-3b98-43f3-b81e-f27c3bc25f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-d615916a-ffc6-4f77-9118-6727fbb0288e,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-8d182bed-ffc3-4c58-af52-50c559705606,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-d262eb3b-7c88-4883-9803-c86ca5e3a645,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-044864c5-5548-4323-a3a5-f7a19cc46480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356479523-172.17.0.13-1595366933064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-1d6a60d5-8101-4627-ae7c-318b8e8b9d80,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-8f99d0d9-fffb-47d8-87a5-f3008019b727,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-8538361a-ca26-4ee7-9930-5443f381f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-c4fb8c03-3b98-43f3-b81e-f27c3bc25f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-d615916a-ffc6-4f77-9118-6727fbb0288e,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-8d182bed-ffc3-4c58-af52-50c559705606,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-d262eb3b-7c88-4883-9803-c86ca5e3a645,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-044864c5-5548-4323-a3a5-f7a19cc46480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5290
