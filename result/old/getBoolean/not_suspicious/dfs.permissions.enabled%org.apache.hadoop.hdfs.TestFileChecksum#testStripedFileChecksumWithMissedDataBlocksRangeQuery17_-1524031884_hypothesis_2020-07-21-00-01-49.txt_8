reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397190991-172.17.0.7-1595289913233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37145,DS-ed17ca54-d8ea-46ee-880f-720a34913e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-ee1c5d99-9969-40fb-8114-5689f9dd0ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-8f9c0595-88c6-4d8a-9974-787755971b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-691d0e20-8b7a-423a-99d3-45ef31199339,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-b8660391-519d-45e2-b833-52e9076b2974,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-d1bdd3d0-4fe7-4cde-8804-2905bd915bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-d3522487-42e0-4489-82bc-66b6f6eca9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-efc5a5be-6856-4cca-81c8-44b2408ef3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397190991-172.17.0.7-1595289913233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37145,DS-ed17ca54-d8ea-46ee-880f-720a34913e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-ee1c5d99-9969-40fb-8114-5689f9dd0ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-8f9c0595-88c6-4d8a-9974-787755971b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-691d0e20-8b7a-423a-99d3-45ef31199339,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-b8660391-519d-45e2-b833-52e9076b2974,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-d1bdd3d0-4fe7-4cde-8804-2905bd915bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-d3522487-42e0-4489-82bc-66b6f6eca9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-efc5a5be-6856-4cca-81c8-44b2408ef3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550359252-172.17.0.7-1595290179128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-4e7b7381-6c6f-44cf-85d0-e7773ef51578,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-a6e0fbb1-8afc-4a40-837d-cb6c6b0627de,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-5a039b90-3ba5-4cfc-b030-8d7fd1b0c516,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-f51f37c3-9f65-4327-a2a8-9d63774ea695,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-4a8490b5-85cc-4f0b-8f57-d6179e477e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-d6032bdd-cfbb-44a5-b70e-92aa6a98ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f1b412bf-12c4-485e-a29f-9b8bac00cee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-8aa4bb50-68e9-466d-8a68-28bbaa993a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550359252-172.17.0.7-1595290179128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-4e7b7381-6c6f-44cf-85d0-e7773ef51578,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-a6e0fbb1-8afc-4a40-837d-cb6c6b0627de,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-5a039b90-3ba5-4cfc-b030-8d7fd1b0c516,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-f51f37c3-9f65-4327-a2a8-9d63774ea695,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-4a8490b5-85cc-4f0b-8f57-d6179e477e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-d6032bdd-cfbb-44a5-b70e-92aa6a98ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f1b412bf-12c4-485e-a29f-9b8bac00cee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-8aa4bb50-68e9-466d-8a68-28bbaa993a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566394630-172.17.0.7-1595290244789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42669,DS-a44d6c49-e33d-4b89-b485-32880d0604f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-8ce68acd-7da8-47f6-a422-2f49e297ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-c5f9e618-f4b7-4e54-afbe-67eb5a9e993d,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-73384ad8-82ba-4f1b-bbcf-afe3d301c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-523c4027-603f-4b2d-812c-598ad61b8300,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-f9a08112-d5bd-4caa-aa0b-b9d032527620,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-bcf03bca-e432-4816-b6d6-7725f591fbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-dfe7d201-20fd-4c6a-a80d-0fc2fab71ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566394630-172.17.0.7-1595290244789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42669,DS-a44d6c49-e33d-4b89-b485-32880d0604f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-8ce68acd-7da8-47f6-a422-2f49e297ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-c5f9e618-f4b7-4e54-afbe-67eb5a9e993d,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-73384ad8-82ba-4f1b-bbcf-afe3d301c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-523c4027-603f-4b2d-812c-598ad61b8300,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-f9a08112-d5bd-4caa-aa0b-b9d032527620,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-bcf03bca-e432-4816-b6d6-7725f591fbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-dfe7d201-20fd-4c6a-a80d-0fc2fab71ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438567876-172.17.0.7-1595290871526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45677,DS-161a4aa4-ac15-454c-9832-4b205756efb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-31fd74f2-8c6a-40e1-a223-51ccce86cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-8275f961-b105-4855-b773-efc8706bf4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-edd14861-a15b-4164-a9c5-64f00ab1fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-fe7c48e5-4fe6-4359-9c92-bf14baa19012,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-68154b69-7780-4f92-85d6-fc3fa6092269,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-d1b25d48-4b3b-45d9-aa55-3f85592e598e,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-46975dea-cd25-4a1d-8869-7ed1b85d9ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438567876-172.17.0.7-1595290871526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45677,DS-161a4aa4-ac15-454c-9832-4b205756efb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-31fd74f2-8c6a-40e1-a223-51ccce86cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-8275f961-b105-4855-b773-efc8706bf4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-edd14861-a15b-4164-a9c5-64f00ab1fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-fe7c48e5-4fe6-4359-9c92-bf14baa19012,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-68154b69-7780-4f92-85d6-fc3fa6092269,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-d1b25d48-4b3b-45d9-aa55-3f85592e598e,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-46975dea-cd25-4a1d-8869-7ed1b85d9ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085676357-172.17.0.7-1595291012420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-03aa262e-b1e9-4706-b975-8ca68bf9c8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-a4178961-0b79-4af5-b65a-5fdb91b38d98,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-7a500c00-435d-43ee-a612-42122f07e736,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-ba0f5b0c-974f-4767-9a67-8e98f1227f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-faee3e07-e864-462c-9a76-5d61d696e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-656dc3de-56f1-42b0-865b-97a49eaa2a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-e7f12568-816e-49ed-a6e8-57af02796c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-66030393-7a13-45e2-9b62-c489acbd7b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085676357-172.17.0.7-1595291012420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-03aa262e-b1e9-4706-b975-8ca68bf9c8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-a4178961-0b79-4af5-b65a-5fdb91b38d98,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-7a500c00-435d-43ee-a612-42122f07e736,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-ba0f5b0c-974f-4767-9a67-8e98f1227f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-faee3e07-e864-462c-9a76-5d61d696e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-656dc3de-56f1-42b0-865b-97a49eaa2a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-e7f12568-816e-49ed-a6e8-57af02796c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-66030393-7a13-45e2-9b62-c489acbd7b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869309645-172.17.0.7-1595291057383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33662,DS-4bf248b4-a92a-4dc6-a12e-8e5f9b410ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-9fea7aa1-0bbf-4384-b00e-b123311110e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-fd828551-8dec-4443-99da-7d9ea6176aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-f24a5055-91bb-44b2-aeba-8392a07b1892,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-784f3368-0bbc-4090-9f97-c52d9ce21ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-bf9b170d-e966-4df6-acb3-f91590fb0d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-15a914b8-981a-4888-a0b4-4e24cddd8ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-ef2f4f55-3741-4985-ab29-8fe1970663b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869309645-172.17.0.7-1595291057383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33662,DS-4bf248b4-a92a-4dc6-a12e-8e5f9b410ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-9fea7aa1-0bbf-4384-b00e-b123311110e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-fd828551-8dec-4443-99da-7d9ea6176aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-f24a5055-91bb-44b2-aeba-8392a07b1892,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-784f3368-0bbc-4090-9f97-c52d9ce21ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-bf9b170d-e966-4df6-acb3-f91590fb0d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-15a914b8-981a-4888-a0b4-4e24cddd8ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-ef2f4f55-3741-4985-ab29-8fe1970663b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113493372-172.17.0.7-1595291240611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-1994e663-b53f-4043-8185-627cec05490f,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-37efb24f-485b-4d9a-bcf2-750e23dc09fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-334cbe1e-badf-4c98-904d-3307f9aab281,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-e285bc35-f9d9-4823-ab62-4e5e439b4c47,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-e38b1d46-0037-4128-8650-c6a56a3a2668,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-9891b782-053a-422e-a75b-7b991c66be22,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-a1f66684-7477-45e4-a3fa-6e47a7cab241,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-cdc11e88-5d64-42db-8c3e-bb6d269df029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113493372-172.17.0.7-1595291240611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-1994e663-b53f-4043-8185-627cec05490f,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-37efb24f-485b-4d9a-bcf2-750e23dc09fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-334cbe1e-badf-4c98-904d-3307f9aab281,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-e285bc35-f9d9-4823-ab62-4e5e439b4c47,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-e38b1d46-0037-4128-8650-c6a56a3a2668,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-9891b782-053a-422e-a75b-7b991c66be22,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-a1f66684-7477-45e4-a3fa-6e47a7cab241,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-cdc11e88-5d64-42db-8c3e-bb6d269df029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1304388774-172.17.0.7-1595292892961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-e232a430-26ab-49ec-b7a8-26a2a960f129,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-f48a00b0-a69c-419e-9682-c40610c6702f,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-73fce65b-00e5-4ed4-ab87-87bf0fd00314,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-78631e24-4a01-4f78-be15-2a3b33a3bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-8591cc85-4ff4-47d2-b935-8ac8cd4a724c,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-b20e71fb-aaee-4677-99a9-00c7c17f75c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-d67d86f3-d8bf-49d3-88d2-a0c08196b56a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-8c046651-a6f6-4a42-aa58-3bc2cc17d97c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1304388774-172.17.0.7-1595292892961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-e232a430-26ab-49ec-b7a8-26a2a960f129,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-f48a00b0-a69c-419e-9682-c40610c6702f,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-73fce65b-00e5-4ed4-ab87-87bf0fd00314,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-78631e24-4a01-4f78-be15-2a3b33a3bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-8591cc85-4ff4-47d2-b935-8ac8cd4a724c,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-b20e71fb-aaee-4677-99a9-00c7c17f75c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-d67d86f3-d8bf-49d3-88d2-a0c08196b56a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-8c046651-a6f6-4a42-aa58-3bc2cc17d97c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788779571-172.17.0.7-1595293050846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43666,DS-37c63be2-4432-4c65-9e76-a52165e6c38f,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-a3659ab7-68c2-459d-9f81-e73f9ea1afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-eb4a8dbc-f914-45b5-b7c9-525c748dd5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-c7a9d047-6015-4074-8856-2809fcbc9764,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-342eaf51-5e71-4e51-829f-01028a579352,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-941118a3-96f3-4fac-bd2f-d343b4b7f426,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-b254d7fb-19c5-48b3-a6aa-3a0420e38953,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-85fac35c-762e-43e7-a7de-04c4781c7b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788779571-172.17.0.7-1595293050846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43666,DS-37c63be2-4432-4c65-9e76-a52165e6c38f,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-a3659ab7-68c2-459d-9f81-e73f9ea1afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-eb4a8dbc-f914-45b5-b7c9-525c748dd5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-c7a9d047-6015-4074-8856-2809fcbc9764,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-342eaf51-5e71-4e51-829f-01028a579352,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-941118a3-96f3-4fac-bd2f-d343b4b7f426,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-b254d7fb-19c5-48b3-a6aa-3a0420e38953,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-85fac35c-762e-43e7-a7de-04c4781c7b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951713153-172.17.0.7-1595293165151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-ac4862fa-aeea-4243-ad23-9f66e4c15113,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-70ae3a74-b1f7-497e-bcdd-ac7ec179004d,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-d797a8e6-8aca-431a-985e-2365983a0c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-bba4cafd-32fc-4b64-94fc-9e593e04aa07,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-fffbefe8-c120-4906-a248-fad35b8d69e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-6ab4dcbe-b310-4b8b-bef1-72ee5db76c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-ee6488d9-1080-43e6-bea8-a9688d7c6bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-5dd32b97-a732-45e4-9d15-c7ca8f8f3353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951713153-172.17.0.7-1595293165151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-ac4862fa-aeea-4243-ad23-9f66e4c15113,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-70ae3a74-b1f7-497e-bcdd-ac7ec179004d,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-d797a8e6-8aca-431a-985e-2365983a0c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-bba4cafd-32fc-4b64-94fc-9e593e04aa07,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-fffbefe8-c120-4906-a248-fad35b8d69e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-6ab4dcbe-b310-4b8b-bef1-72ee5db76c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-ee6488d9-1080-43e6-bea8-a9688d7c6bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-5dd32b97-a732-45e4-9d15-c7ca8f8f3353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587230702-172.17.0.7-1595294476649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46384,DS-fa20b950-f830-4c5d-8e1d-44b514011f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-12df8275-61bc-41de-941f-6cdf7ca5ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-eeae6f03-680c-4cf5-b0ee-29835ae43426,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-e55a9a69-15b3-49bd-a425-5ccd8d517a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-649d2825-99b0-4663-b2dc-4e83a67e5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-39e50d68-0786-4691-9cf7-76b9a85bafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-e8f8a655-edcb-4523-b39f-b801412737e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-eb391446-30fc-4187-9926-dc4e8fdb40b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587230702-172.17.0.7-1595294476649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46384,DS-fa20b950-f830-4c5d-8e1d-44b514011f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-12df8275-61bc-41de-941f-6cdf7ca5ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-eeae6f03-680c-4cf5-b0ee-29835ae43426,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-e55a9a69-15b3-49bd-a425-5ccd8d517a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-649d2825-99b0-4663-b2dc-4e83a67e5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-39e50d68-0786-4691-9cf7-76b9a85bafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-e8f8a655-edcb-4523-b39f-b801412737e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-eb391446-30fc-4187-9926-dc4e8fdb40b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830013814-172.17.0.7-1595294659656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-2190b22f-eee3-42c7-b357-a9c3c5b4771c,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-da8ca45e-1e48-47bf-b7e7-6fd5d6a2f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-c24e1674-65fa-41b7-84ef-629624f2a32d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-d3afcbf7-07ce-4abf-bbb4-11a619c77321,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-005a0785-5ef2-425f-b747-6a52e64cf31f,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-512a9498-cc2a-4f38-8171-7dcdce569ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-5fa07b20-b3bf-455b-a7c4-8ab860918f96,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-3cc5ab4d-3f3d-47f9-af8c-3b29821c1fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830013814-172.17.0.7-1595294659656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-2190b22f-eee3-42c7-b357-a9c3c5b4771c,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-da8ca45e-1e48-47bf-b7e7-6fd5d6a2f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-c24e1674-65fa-41b7-84ef-629624f2a32d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-d3afcbf7-07ce-4abf-bbb4-11a619c77321,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-005a0785-5ef2-425f-b747-6a52e64cf31f,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-512a9498-cc2a-4f38-8171-7dcdce569ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-5fa07b20-b3bf-455b-a7c4-8ab860918f96,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-3cc5ab4d-3f3d-47f9-af8c-3b29821c1fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459289245-172.17.0.7-1595294758341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45396,DS-88540489-4f41-46bd-b5ab-c015d7c9d561,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-61c79ad5-579c-494a-a4d6-c7fd584a0930,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-f223fc3d-c6c9-47e6-bed8-b03fb765731e,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-1847117c-b155-4abe-aae9-3c875a960550,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-5eab2372-416b-4d8d-b0c9-922bd41d6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-014a2c9b-4669-40b0-9088-bf9ee125beac,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-4f91e76a-3816-4088-a75f-9d661f48e513,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-8ac646ac-da8b-48fd-a081-59ea78199bdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459289245-172.17.0.7-1595294758341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45396,DS-88540489-4f41-46bd-b5ab-c015d7c9d561,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-61c79ad5-579c-494a-a4d6-c7fd584a0930,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-f223fc3d-c6c9-47e6-bed8-b03fb765731e,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-1847117c-b155-4abe-aae9-3c875a960550,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-5eab2372-416b-4d8d-b0c9-922bd41d6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-014a2c9b-4669-40b0-9088-bf9ee125beac,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-4f91e76a-3816-4088-a75f-9d661f48e513,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-8ac646ac-da8b-48fd-a081-59ea78199bdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934334223-172.17.0.7-1595294826680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-47a26e95-d52a-4802-b3dd-ab77a519fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-56df7b0c-8cee-430d-a1e3-a0a0ee4dbd05,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-d3beddc0-f876-4c50-925a-4f8548d3f39c,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-1c845547-0882-4710-9728-e335235c2358,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-52273c81-18fb-45e8-b03c-7307a9480d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-c1cf10aa-a5ba-4015-9df0-f4357e3bb826,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-c3b338f7-bb6c-48e0-bce5-7360f0d517fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-be5cb730-bfd9-41c3-9e27-4662fa65f84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934334223-172.17.0.7-1595294826680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-47a26e95-d52a-4802-b3dd-ab77a519fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-56df7b0c-8cee-430d-a1e3-a0a0ee4dbd05,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-d3beddc0-f876-4c50-925a-4f8548d3f39c,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-1c845547-0882-4710-9728-e335235c2358,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-52273c81-18fb-45e8-b03c-7307a9480d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-c1cf10aa-a5ba-4015-9df0-f4357e3bb826,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-c3b338f7-bb6c-48e0-bce5-7360f0d517fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-be5cb730-bfd9-41c3-9e27-4662fa65f84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5237
