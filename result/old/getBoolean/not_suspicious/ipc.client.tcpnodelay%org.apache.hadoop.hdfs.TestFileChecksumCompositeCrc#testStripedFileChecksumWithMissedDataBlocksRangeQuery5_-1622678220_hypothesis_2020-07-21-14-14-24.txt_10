reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102048288-172.17.0.15-1595341617043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45344,DS-0cd552ed-1cd2-43c7-bf5a-13ee617c8b23,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-365f86e0-4e93-4d2f-b21f-ece7faff6950,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-2742cc91-4946-4b52-ad17-41beaa7183e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-6fa5fa62-99ea-43a8-96c3-77caff59b403,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-95318573-5863-4ee5-bfb3-a28c6fb55d15,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-0b591d9a-de18-494f-b784-7eec479e845c,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-b42ecb0e-312f-4d71-acdc-88e664653a01,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-d965b053-6fae-499b-87d0-b6109705c7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102048288-172.17.0.15-1595341617043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45344,DS-0cd552ed-1cd2-43c7-bf5a-13ee617c8b23,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-365f86e0-4e93-4d2f-b21f-ece7faff6950,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-2742cc91-4946-4b52-ad17-41beaa7183e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-6fa5fa62-99ea-43a8-96c3-77caff59b403,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-95318573-5863-4ee5-bfb3-a28c6fb55d15,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-0b591d9a-de18-494f-b784-7eec479e845c,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-b42ecb0e-312f-4d71-acdc-88e664653a01,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-d965b053-6fae-499b-87d0-b6109705c7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264194155-172.17.0.15-1595341852244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-625ced1a-2ad6-4e8a-b9a0-f239d4403add,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-4e6af433-bdab-42e8-8759-d875765a48f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-bb912b80-9663-462f-9e9d-f97794944e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-18ef639f-7b67-4078-9278-d3fb3ee4355d,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-0e07885e-2eed-4a4f-a44c-f4293fd0c244,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-ac1e4b0a-9007-47e9-8a09-99f6dba7ad3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-0628747e-7ed1-45ff-940b-df72f2d0513d,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-5ab54552-2967-4774-99eb-c65d4c31f006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264194155-172.17.0.15-1595341852244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-625ced1a-2ad6-4e8a-b9a0-f239d4403add,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-4e6af433-bdab-42e8-8759-d875765a48f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-bb912b80-9663-462f-9e9d-f97794944e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-18ef639f-7b67-4078-9278-d3fb3ee4355d,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-0e07885e-2eed-4a4f-a44c-f4293fd0c244,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-ac1e4b0a-9007-47e9-8a09-99f6dba7ad3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-0628747e-7ed1-45ff-940b-df72f2d0513d,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-5ab54552-2967-4774-99eb-c65d4c31f006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507272504-172.17.0.15-1595341993205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39874,DS-7cf030fd-b377-4294-b233-ce1941b45095,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-f73d8eaf-46e1-4a71-b3ec-69afe94ba697,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-264ad1ef-b8d1-4a20-ba49-aba7de2f438b,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-6d666660-37a0-4db8-a744-425305b03220,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-066b39d8-1dfc-4182-8d15-b863277f7484,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-240be3a1-83ac-404d-a7df-71ab932e2797,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-214726c9-3ae6-4a51-a720-42437657913c,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-dee2484e-6ed5-4c1d-9336-30524b39fdf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507272504-172.17.0.15-1595341993205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39874,DS-7cf030fd-b377-4294-b233-ce1941b45095,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-f73d8eaf-46e1-4a71-b3ec-69afe94ba697,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-264ad1ef-b8d1-4a20-ba49-aba7de2f438b,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-6d666660-37a0-4db8-a744-425305b03220,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-066b39d8-1dfc-4182-8d15-b863277f7484,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-240be3a1-83ac-404d-a7df-71ab932e2797,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-214726c9-3ae6-4a51-a720-42437657913c,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-dee2484e-6ed5-4c1d-9336-30524b39fdf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651956786-172.17.0.15-1595342039296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41975,DS-29a8341c-c74e-4f26-9248-d1075d84be22,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-7b5230ac-965a-45bd-8097-772da16a23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-5d574f6f-2ca6-4660-b23b-fc814a25b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-962348db-7ac1-4fd3-87dc-756a3bd80beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-b84de703-235c-4867-a6ae-8b35c5e57c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-1e6b75ab-02a9-438b-ae47-38135bbc7ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-d91a8a92-4772-4924-b677-fd7b852c17db,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-3edb6c78-01b9-4309-8ee1-4c3f2d804640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651956786-172.17.0.15-1595342039296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41975,DS-29a8341c-c74e-4f26-9248-d1075d84be22,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-7b5230ac-965a-45bd-8097-772da16a23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-5d574f6f-2ca6-4660-b23b-fc814a25b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-962348db-7ac1-4fd3-87dc-756a3bd80beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-b84de703-235c-4867-a6ae-8b35c5e57c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-1e6b75ab-02a9-438b-ae47-38135bbc7ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-d91a8a92-4772-4924-b677-fd7b852c17db,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-3edb6c78-01b9-4309-8ee1-4c3f2d804640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456759603-172.17.0.15-1595343005245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44388,DS-abd6f7f9-27fa-4af2-9ad8-ce84b2201d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-e9c11a9f-840d-4fd3-bb20-57f0a3733227,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-1febbd08-00de-41ec-8383-c1f69b72d606,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-b96adb16-4296-4c8f-a50a-33c82e556c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-4259fb0d-109d-429f-8ea6-a2ff15e44a56,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-9bc1875c-1463-4d5e-b090-3305fdde9c76,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-32698303-3a37-4861-a292-76578ac4c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-64ed147b-2fe6-4a12-b8cf-c11947bb3d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456759603-172.17.0.15-1595343005245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44388,DS-abd6f7f9-27fa-4af2-9ad8-ce84b2201d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-e9c11a9f-840d-4fd3-bb20-57f0a3733227,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-1febbd08-00de-41ec-8383-c1f69b72d606,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-b96adb16-4296-4c8f-a50a-33c82e556c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-4259fb0d-109d-429f-8ea6-a2ff15e44a56,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-9bc1875c-1463-4d5e-b090-3305fdde9c76,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-32698303-3a37-4861-a292-76578ac4c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-64ed147b-2fe6-4a12-b8cf-c11947bb3d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613527231-172.17.0.15-1595344343271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-7a8e062f-899c-420c-b6a0-6142f95ec4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-3368fe21-db4f-4c85-9dfc-edb970103232,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-5d0eb890-e671-4a3f-8d62-f858da358494,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-126d7675-3f38-471a-8275-88741d46bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-a60e1355-134e-407f-8ec3-9d99e01161b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-5354253d-db50-4706-8102-9683b0cb2a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-47351ec0-072b-4781-8546-4f06180d7ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-cbc733e1-beab-4419-9c3b-43d3adeefdfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613527231-172.17.0.15-1595344343271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-7a8e062f-899c-420c-b6a0-6142f95ec4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-3368fe21-db4f-4c85-9dfc-edb970103232,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-5d0eb890-e671-4a3f-8d62-f858da358494,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-126d7675-3f38-471a-8275-88741d46bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-a60e1355-134e-407f-8ec3-9d99e01161b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-5354253d-db50-4706-8102-9683b0cb2a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-47351ec0-072b-4781-8546-4f06180d7ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-cbc733e1-beab-4419-9c3b-43d3adeefdfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286435762-172.17.0.15-1595344428859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38962,DS-ccddf90d-d613-4d3f-9434-00ce0eb7eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-4a9b2391-8467-44d8-a6a6-64d20fd264bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-339b88d4-c502-4eab-92d1-8cf4601007b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-d7bf1556-cd85-42cf-bd18-c507a506e7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-0f56c591-c49c-47e5-92bf-9962e3be94d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-1a34de84-3816-426c-a87d-b75b6ddcaa32,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-d2d08437-694f-4f33-8415-d4e4a6ef986f,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-a9715e03-f2c0-4018-9ee4-b99ad10c12f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286435762-172.17.0.15-1595344428859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38962,DS-ccddf90d-d613-4d3f-9434-00ce0eb7eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-4a9b2391-8467-44d8-a6a6-64d20fd264bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-339b88d4-c502-4eab-92d1-8cf4601007b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-d7bf1556-cd85-42cf-bd18-c507a506e7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-0f56c591-c49c-47e5-92bf-9962e3be94d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-1a34de84-3816-426c-a87d-b75b6ddcaa32,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-d2d08437-694f-4f33-8415-d4e4a6ef986f,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-a9715e03-f2c0-4018-9ee4-b99ad10c12f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142787584-172.17.0.15-1595344471448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-7957e8f3-03c1-47d8-be16-22659a1529ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-8e625834-fea2-44bc-994c-6fd947263215,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-b504fc07-bd6d-42bc-9d14-7af3a72672a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-c496c8c3-437a-4ec1-a302-e801e720299f,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-543357e3-71a0-49c0-bb7b-03e521dbbcae,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-a3945c33-6e43-47d7-97de-52937b84b696,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-44b3b5a5-a9ff-45b2-bb8d-7417fafa7932,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-a782357c-022d-498c-acdf-9aa6d276f42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142787584-172.17.0.15-1595344471448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-7957e8f3-03c1-47d8-be16-22659a1529ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-8e625834-fea2-44bc-994c-6fd947263215,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-b504fc07-bd6d-42bc-9d14-7af3a72672a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-c496c8c3-437a-4ec1-a302-e801e720299f,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-543357e3-71a0-49c0-bb7b-03e521dbbcae,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-a3945c33-6e43-47d7-97de-52937b84b696,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-44b3b5a5-a9ff-45b2-bb8d-7417fafa7932,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-a782357c-022d-498c-acdf-9aa6d276f42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812474988-172.17.0.15-1595344715343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-237c8e9c-09d3-4592-bbfc-229d6293697a,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-8bfbe8e6-3e3c-4171-b9a1-8a2372a347b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-32c06228-f300-4cab-b533-8846c879ce9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-80828d12-1c42-45f0-aa05-a335ea601978,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-15477d61-a238-471b-9e80-39f682730104,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-3c4e1654-85f2-488b-b4b2-fb0e309622e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-096c05c6-2ed7-4fdd-a506-f7bdd1461426,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-27382119-c30b-4ce7-b644-704b12e28d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812474988-172.17.0.15-1595344715343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-237c8e9c-09d3-4592-bbfc-229d6293697a,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-8bfbe8e6-3e3c-4171-b9a1-8a2372a347b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-32c06228-f300-4cab-b533-8846c879ce9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-80828d12-1c42-45f0-aa05-a335ea601978,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-15477d61-a238-471b-9e80-39f682730104,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-3c4e1654-85f2-488b-b4b2-fb0e309622e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-096c05c6-2ed7-4fdd-a506-f7bdd1461426,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-27382119-c30b-4ce7-b644-704b12e28d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547702456-172.17.0.15-1595345186509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33620,DS-077dfdfc-b6d0-4d0d-834b-0747f995045f,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-cce754fc-a95b-4476-aaae-4c24ffa2e1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-68c6295a-bbc0-44dd-85d9-f366c5c7c240,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-0b703b4f-9037-4563-b93f-e57907f07b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-34e93ed1-10c5-4eef-b245-dfcd3d94e120,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-160890c4-4896-4c31-90c6-cbaf02815437,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-065d3b3d-540d-4469-9301-ffc9b0ba1593,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-37dac79d-5fcd-412e-ac68-6094388c4fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547702456-172.17.0.15-1595345186509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33620,DS-077dfdfc-b6d0-4d0d-834b-0747f995045f,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-cce754fc-a95b-4476-aaae-4c24ffa2e1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-68c6295a-bbc0-44dd-85d9-f366c5c7c240,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-0b703b4f-9037-4563-b93f-e57907f07b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-34e93ed1-10c5-4eef-b245-dfcd3d94e120,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-160890c4-4896-4c31-90c6-cbaf02815437,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-065d3b3d-540d-4469-9301-ffc9b0ba1593,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-37dac79d-5fcd-412e-ac68-6094388c4fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93106298-172.17.0.15-1595345481127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-b70317a5-3f5e-4982-9bd2-64805fc4e9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-4de90eed-b73f-49a7-bcb6-aa9bd6ec5685,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-9aa85087-b621-40d2-9651-70bd43a6bf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-a02f5148-a9c8-431b-85ba-da0c3ea28831,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-a44b3338-4979-4876-a502-f47e0100cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-b9de09f3-4481-4f4f-95b5-61fa7170c564,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-ac74189f-812f-4629-82a0-9cd564eccba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-7ef13630-3f27-4ab9-85a5-90cca68c0b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93106298-172.17.0.15-1595345481127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-b70317a5-3f5e-4982-9bd2-64805fc4e9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-4de90eed-b73f-49a7-bcb6-aa9bd6ec5685,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-9aa85087-b621-40d2-9651-70bd43a6bf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-a02f5148-a9c8-431b-85ba-da0c3ea28831,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-a44b3338-4979-4876-a502-f47e0100cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-b9de09f3-4481-4f4f-95b5-61fa7170c564,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-ac74189f-812f-4629-82a0-9cd564eccba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-7ef13630-3f27-4ab9-85a5-90cca68c0b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212060602-172.17.0.15-1595345528932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-094aff08-3729-4963-a69e-f0892e596dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-55f50c79-4963-4df3-85c6-600d7b7755ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-25714970-f3ef-4992-bb82-fc30981cb147,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-15987d4c-11e9-497b-8dfa-4728f92e4f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-530cc84f-90dd-4e82-889e-a4e6b9d25f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-46caf548-1c60-4f1e-8a6f-ce8f14a167bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-4c3b13a5-13d7-4857-bbeb-c5f8d34c387d,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-0cb621af-4a51-48bd-abe2-51b1e4d226d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212060602-172.17.0.15-1595345528932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-094aff08-3729-4963-a69e-f0892e596dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-55f50c79-4963-4df3-85c6-600d7b7755ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-25714970-f3ef-4992-bb82-fc30981cb147,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-15987d4c-11e9-497b-8dfa-4728f92e4f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-530cc84f-90dd-4e82-889e-a4e6b9d25f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-46caf548-1c60-4f1e-8a6f-ce8f14a167bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-4c3b13a5-13d7-4857-bbeb-c5f8d34c387d,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-0cb621af-4a51-48bd-abe2-51b1e4d226d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615990097-172.17.0.15-1595346060613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36959,DS-caea4ced-3aca-4205-8a0a-818e61e81692,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-5fdcbcee-98cb-4c77-8a13-193f946c0cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-83f746be-86d1-4eb1-adf0-95b211d13ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-66789c9b-3462-4839-aabc-0e1e69bfc99f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-66284147-7fad-4c34-9b38-023086c6e833,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-5b3a5cfa-8ebf-4655-b1a0-3d25d214fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-c6ea718e-cea7-44df-810f-64d1081e253c,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-c117ccca-1aca-4044-823f-196a36a2dc2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615990097-172.17.0.15-1595346060613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36959,DS-caea4ced-3aca-4205-8a0a-818e61e81692,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-5fdcbcee-98cb-4c77-8a13-193f946c0cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-83f746be-86d1-4eb1-adf0-95b211d13ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-66789c9b-3462-4839-aabc-0e1e69bfc99f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-66284147-7fad-4c34-9b38-023086c6e833,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-5b3a5cfa-8ebf-4655-b1a0-3d25d214fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-c6ea718e-cea7-44df-810f-64d1081e253c,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-c117ccca-1aca-4044-823f-196a36a2dc2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25950457-172.17.0.15-1595346108767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-5611f14a-579d-416f-965f-6a186adb0e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-5bded638-6771-40a6-a8ae-c327434327ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-e544ebc3-90af-4603-aacf-71a360db81b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-da6284d9-a11f-49f0-99af-383055256694,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-2dec6a60-f9e7-4cb5-9f16-299f58dd8d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-832a046a-8f6f-4f29-849f-7953a223fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-ba9a7efa-698c-45e0-aadf-6841c205c023,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-af731fa5-8de8-4eb6-bdc7-49b7fc8d05df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25950457-172.17.0.15-1595346108767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-5611f14a-579d-416f-965f-6a186adb0e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-5bded638-6771-40a6-a8ae-c327434327ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-e544ebc3-90af-4603-aacf-71a360db81b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-da6284d9-a11f-49f0-99af-383055256694,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-2dec6a60-f9e7-4cb5-9f16-299f58dd8d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-832a046a-8f6f-4f29-849f-7953a223fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-ba9a7efa-698c-45e0-aadf-6841c205c023,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-af731fa5-8de8-4eb6-bdc7-49b7fc8d05df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183477174-172.17.0.15-1595346674295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-c1f64b65-e07c-422a-b41c-404f7454c381,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-e4a8e8e1-5fec-46c9-8769-17f076c18df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-d8e9a202-2ab2-4b02-9e4b-8516c5052f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-0ae6e891-2ff6-4c60-b538-d57a0542f914,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-5cb28c1b-bf21-4011-8fe4-39a5487c8575,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-4ab0845f-53d8-45d0-8066-2e71d06da517,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-df722477-a31e-4697-afca-2b90a6f91280,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-5db7a284-2644-484d-9221-707435d0b34b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183477174-172.17.0.15-1595346674295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-c1f64b65-e07c-422a-b41c-404f7454c381,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-e4a8e8e1-5fec-46c9-8769-17f076c18df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-d8e9a202-2ab2-4b02-9e4b-8516c5052f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-0ae6e891-2ff6-4c60-b538-d57a0542f914,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-5cb28c1b-bf21-4011-8fe4-39a5487c8575,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-4ab0845f-53d8-45d0-8066-2e71d06da517,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-df722477-a31e-4697-afca-2b90a6f91280,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-5db7a284-2644-484d-9221-707435d0b34b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506104847-172.17.0.15-1595346846735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44775,DS-44692ae4-eabc-4308-8010-14bbdd7d63dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-ba6773de-8039-46f3-bc80-1b1487a0022f,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-7fb5fa36-9673-4802-af9e-abd209784b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-e03f102d-c38e-4b49-810f-733e883ff56b,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-7fc6b116-6e97-42ba-af65-57aaee33f994,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-1829f22c-9678-4df1-9c90-7a7bd3d08838,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-88e50bfe-58cc-4931-a55f-2b852850eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-62e08230-ac15-456d-8db1-4b6c549dddfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506104847-172.17.0.15-1595346846735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44775,DS-44692ae4-eabc-4308-8010-14bbdd7d63dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-ba6773de-8039-46f3-bc80-1b1487a0022f,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-7fb5fa36-9673-4802-af9e-abd209784b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-e03f102d-c38e-4b49-810f-733e883ff56b,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-7fc6b116-6e97-42ba-af65-57aaee33f994,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-1829f22c-9678-4df1-9c90-7a7bd3d08838,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-88e50bfe-58cc-4931-a55f-2b852850eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-62e08230-ac15-456d-8db1-4b6c549dddfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082957712-172.17.0.15-1595347198637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-bb41d9a1-23ed-4bda-8438-002fb63af359,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-a4746df3-658a-469e-8a7a-68a440f6e124,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-66e48ec4-819e-41e1-9560-efd9d600d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-0d9e1802-4d3c-4b47-9fd8-0889565d1180,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-a18e38bb-f5d7-4ff5-aece-f08a0bedd768,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-1dc9ecf0-4fd7-422b-bb02-5523f51c7900,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c61a9bf8-6647-4143-a5cb-31c62a2446b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-2b0e7ae6-8d01-4751-8fda-d2964d1a1fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082957712-172.17.0.15-1595347198637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-bb41d9a1-23ed-4bda-8438-002fb63af359,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-a4746df3-658a-469e-8a7a-68a440f6e124,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-66e48ec4-819e-41e1-9560-efd9d600d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-0d9e1802-4d3c-4b47-9fd8-0889565d1180,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-a18e38bb-f5d7-4ff5-aece-f08a0bedd768,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-1dc9ecf0-4fd7-422b-bb02-5523f51c7900,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c61a9bf8-6647-4143-a5cb-31c62a2446b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-2b0e7ae6-8d01-4751-8fda-d2964d1a1fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6797
