reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594187050-172.17.0.3-1595330804280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-1258ab1b-3640-4766-8aee-55dae614c27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-ba64951f-c87a-412e-904a-4dac194f7ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-8e85808e-b6e8-41ee-a470-bc03f6b2d960,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-3f78170e-d2d3-42de-8055-f3cb179293f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-0e3891dd-6041-4aad-9b99-691d5a1ff86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-438c1df8-36c0-43a7-81de-f1b5f193a324,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-ddc47eac-c8da-4e72-83fd-2b24642ed0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-2546cd4f-36ff-4bcc-979e-ab6394362492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594187050-172.17.0.3-1595330804280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-1258ab1b-3640-4766-8aee-55dae614c27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-ba64951f-c87a-412e-904a-4dac194f7ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-8e85808e-b6e8-41ee-a470-bc03f6b2d960,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-3f78170e-d2d3-42de-8055-f3cb179293f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-0e3891dd-6041-4aad-9b99-691d5a1ff86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-438c1df8-36c0-43a7-81de-f1b5f193a324,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-ddc47eac-c8da-4e72-83fd-2b24642ed0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-2546cd4f-36ff-4bcc-979e-ab6394362492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848844993-172.17.0.3-1595331100712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-15d30ae0-e74c-40d0-a482-c1c4f7fe3916,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-fbb4876a-0b30-4a02-9170-28c7030a64db,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-787c0935-8570-42a8-8b88-5dfaf4ecb549,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-5d6627a6-1a84-46ea-92b8-98aba20593a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-f30e490a-4777-4c0e-b313-5d0b2f7d1ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-ca30bd78-4b20-4a65-a0ed-2b56a5a0a991,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-5ff7841c-f199-4afa-b5bc-d621f005c465,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-14c4ce5d-bad7-4d45-92de-5ad40c06ac70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848844993-172.17.0.3-1595331100712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-15d30ae0-e74c-40d0-a482-c1c4f7fe3916,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-fbb4876a-0b30-4a02-9170-28c7030a64db,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-787c0935-8570-42a8-8b88-5dfaf4ecb549,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-5d6627a6-1a84-46ea-92b8-98aba20593a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-f30e490a-4777-4c0e-b313-5d0b2f7d1ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-ca30bd78-4b20-4a65-a0ed-2b56a5a0a991,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-5ff7841c-f199-4afa-b5bc-d621f005c465,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-14c4ce5d-bad7-4d45-92de-5ad40c06ac70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027752851-172.17.0.3-1595331594343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36720,DS-2cb739a6-1b73-4ac5-9fa7-8ad2acfcda59,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-264024d9-ce80-490f-8292-35a56d2c04a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-209a18a4-658f-40f3-a92c-f0ba84538e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-6135385d-c95f-4c32-9d13-36136ad6ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-9726feb2-92d1-43d5-adfe-60b6824730d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-8571c30b-bd07-4aab-a1f2-85d14a04d46c,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-648b51bb-b73d-417c-8f9b-e4e1940b0aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-8674ce2a-96d3-4f3a-a41d-fb9957708382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027752851-172.17.0.3-1595331594343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36720,DS-2cb739a6-1b73-4ac5-9fa7-8ad2acfcda59,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-264024d9-ce80-490f-8292-35a56d2c04a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-209a18a4-658f-40f3-a92c-f0ba84538e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-6135385d-c95f-4c32-9d13-36136ad6ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-9726feb2-92d1-43d5-adfe-60b6824730d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-8571c30b-bd07-4aab-a1f2-85d14a04d46c,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-648b51bb-b73d-417c-8f9b-e4e1940b0aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-8674ce2a-96d3-4f3a-a41d-fb9957708382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127994085-172.17.0.3-1595332418708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40704,DS-66ddfdd0-e495-4794-882a-80fce886d823,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-0897ef71-44df-4090-ba73-823711559d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-206a41b3-2612-4940-b4a9-4b4c30bdecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-6e4a4f49-d041-49dd-a8c7-227d37831f88,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-ca7e4e5f-eb47-4738-aa9a-9f7e62589ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-fe06c15c-8b60-45c9-900b-75096bda2802,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-c67a5fb1-9799-41c6-a707-8ce42d808135,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-f96ef30e-c54c-4f33-82ba-cbd7f8673b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127994085-172.17.0.3-1595332418708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40704,DS-66ddfdd0-e495-4794-882a-80fce886d823,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-0897ef71-44df-4090-ba73-823711559d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-206a41b3-2612-4940-b4a9-4b4c30bdecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-6e4a4f49-d041-49dd-a8c7-227d37831f88,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-ca7e4e5f-eb47-4738-aa9a-9f7e62589ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-fe06c15c-8b60-45c9-900b-75096bda2802,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-c67a5fb1-9799-41c6-a707-8ce42d808135,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-f96ef30e-c54c-4f33-82ba-cbd7f8673b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436176348-172.17.0.3-1595332656328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-4f98e9f3-b8d6-4418-badf-e8ccf7a97736,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-ce6436c6-6b05-4faa-8a78-44e4d1465a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-444653dd-b6a4-480f-826a-72813b02a58c,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-325acf1a-d886-42f3-89a3-4b5af57bdd18,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-7f9ff0ae-0557-4c43-97cd-8934930a55a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-a0389ec7-7a0b-4ef6-ac11-698693100eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-a0115aec-410b-4346-8958-96ca812ed97b,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-7a4884e6-9e1c-42d8-b37c-706639e74214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436176348-172.17.0.3-1595332656328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-4f98e9f3-b8d6-4418-badf-e8ccf7a97736,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-ce6436c6-6b05-4faa-8a78-44e4d1465a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-444653dd-b6a4-480f-826a-72813b02a58c,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-325acf1a-d886-42f3-89a3-4b5af57bdd18,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-7f9ff0ae-0557-4c43-97cd-8934930a55a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-a0389ec7-7a0b-4ef6-ac11-698693100eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-a0115aec-410b-4346-8958-96ca812ed97b,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-7a4884e6-9e1c-42d8-b37c-706639e74214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094074808-172.17.0.3-1595332729338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43429,DS-f7d58e7d-d5b1-4fa0-9dfc-aeee7a177805,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-c554d130-a84d-4803-afde-114b12a73fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-e43398d5-0ce0-481d-9975-107f40328972,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-142218ac-937b-4642-81ba-1349e927e688,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-5a1d7d09-d296-4f04-b438-179942885e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-78f59514-b68e-4fb0-8acd-87679a7cbf06,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-40788df1-e140-4613-a30a-635dfebe4516,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-d356cce9-0ed9-4058-b3f6-54d512818d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094074808-172.17.0.3-1595332729338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43429,DS-f7d58e7d-d5b1-4fa0-9dfc-aeee7a177805,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-c554d130-a84d-4803-afde-114b12a73fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-e43398d5-0ce0-481d-9975-107f40328972,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-142218ac-937b-4642-81ba-1349e927e688,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-5a1d7d09-d296-4f04-b438-179942885e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-78f59514-b68e-4fb0-8acd-87679a7cbf06,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-40788df1-e140-4613-a30a-635dfebe4516,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-d356cce9-0ed9-4058-b3f6-54d512818d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284984613-172.17.0.3-1595333213304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42515,DS-7e904c69-3728-44a2-ac90-fce65fb649a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-0fa505f5-50f8-4e73-b56c-38139b1d9837,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-c55f26e4-c376-4d59-a3ae-369da6f8111c,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-6cde10e5-7d5e-43bd-a5b9-ceb2625030f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-6b701de0-6c8f-445c-b176-2330593e3f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-ee00733f-6a5b-4e93-8395-34744cc41d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-855637ac-9416-4a04-bb61-29aaca7a8ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-ef2da216-b66f-4d21-9804-0e0cb05a7485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284984613-172.17.0.3-1595333213304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42515,DS-7e904c69-3728-44a2-ac90-fce65fb649a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-0fa505f5-50f8-4e73-b56c-38139b1d9837,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-c55f26e4-c376-4d59-a3ae-369da6f8111c,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-6cde10e5-7d5e-43bd-a5b9-ceb2625030f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-6b701de0-6c8f-445c-b176-2330593e3f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-ee00733f-6a5b-4e93-8395-34744cc41d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-855637ac-9416-4a04-bb61-29aaca7a8ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-ef2da216-b66f-4d21-9804-0e0cb05a7485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375591621-172.17.0.3-1595333496147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-0ea02777-7bce-41ac-b1c6-c9e4c3ce5572,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-e13396ff-df11-4b76-b2cb-3e2350d8d93e,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-186c279f-e442-4780-8ff0-604e96c8e55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-820524e8-c236-4eff-b589-faff2f49f419,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-0055a1a9-01e1-4c1b-8b67-da10c9044cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-ebe4c9a5-2646-4936-ba7a-0c599ac04c61,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-2c7d7647-e743-4dd8-83a5-47e30d26b8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-b2a96e62-a728-461a-8cf1-ac7893164628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375591621-172.17.0.3-1595333496147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-0ea02777-7bce-41ac-b1c6-c9e4c3ce5572,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-e13396ff-df11-4b76-b2cb-3e2350d8d93e,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-186c279f-e442-4780-8ff0-604e96c8e55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-820524e8-c236-4eff-b589-faff2f49f419,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-0055a1a9-01e1-4c1b-8b67-da10c9044cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-ebe4c9a5-2646-4936-ba7a-0c599ac04c61,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-2c7d7647-e743-4dd8-83a5-47e30d26b8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-b2a96e62-a728-461a-8cf1-ac7893164628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286037553-172.17.0.3-1595333597327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42691,DS-7cab6aff-9650-4438-a9ed-2e7a19bbd824,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-0cb6e83e-f7fb-4f23-8955-07d0c2e32bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-6dae5816-3c4b-43d6-9b09-abeffbffc627,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-ab27c1d4-e31f-4eb5-80fa-b8e48d1185f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-9d4acf67-c6cc-4cb6-ae86-bdc20dfe0ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-ba6ba6d0-7294-4856-bfa0-f794d9d0c86b,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-d6fe3e43-b5a0-4bad-94a8-b571c31a9d06,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-cb1ba72f-769b-4ba7-919c-f4225708aef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286037553-172.17.0.3-1595333597327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42691,DS-7cab6aff-9650-4438-a9ed-2e7a19bbd824,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-0cb6e83e-f7fb-4f23-8955-07d0c2e32bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-6dae5816-3c4b-43d6-9b09-abeffbffc627,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-ab27c1d4-e31f-4eb5-80fa-b8e48d1185f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-9d4acf67-c6cc-4cb6-ae86-bdc20dfe0ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-ba6ba6d0-7294-4856-bfa0-f794d9d0c86b,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-d6fe3e43-b5a0-4bad-94a8-b571c31a9d06,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-cb1ba72f-769b-4ba7-919c-f4225708aef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238396712-172.17.0.3-1595333853891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42035,DS-d8568315-b10f-41d6-ad6d-da70e02bc1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-b11b36e3-a475-48bd-ba1d-1920594d1b74,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-ba4ae240-a750-4c44-b82c-073c12a8d6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-b603b325-bee6-4073-ac2f-f9747b31733f,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-dec18653-157a-4810-8aac-f5508ce18955,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-7787f223-d07a-495b-9537-bc06e10bf5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-7e262eec-1e89-468d-a54a-a2f7be7f3a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-e8613151-37bd-4afc-8e59-3f813fa42599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238396712-172.17.0.3-1595333853891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42035,DS-d8568315-b10f-41d6-ad6d-da70e02bc1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-b11b36e3-a475-48bd-ba1d-1920594d1b74,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-ba4ae240-a750-4c44-b82c-073c12a8d6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-b603b325-bee6-4073-ac2f-f9747b31733f,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-dec18653-157a-4810-8aac-f5508ce18955,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-7787f223-d07a-495b-9537-bc06e10bf5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-7e262eec-1e89-468d-a54a-a2f7be7f3a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-e8613151-37bd-4afc-8e59-3f813fa42599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613411595-172.17.0.3-1595334191401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40493,DS-d21db049-590a-45ae-a38e-b1bdd2624d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-b0854727-13fd-429a-9b13-f6134bcf1605,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-0ed7ffbd-9298-4b0f-a15c-647b8619fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-8b6aba39-ab17-434b-9abb-289ccddf8b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-39e0817e-6e37-4754-9952-d7ab3450ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-427bfad2-7952-42bc-b536-3112cc18f8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-fc07f49e-4ebf-4ada-aca1-da1cdd0219b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-a2db8aad-b031-47dd-8399-b5a4234257bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613411595-172.17.0.3-1595334191401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40493,DS-d21db049-590a-45ae-a38e-b1bdd2624d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-b0854727-13fd-429a-9b13-f6134bcf1605,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-0ed7ffbd-9298-4b0f-a15c-647b8619fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-8b6aba39-ab17-434b-9abb-289ccddf8b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-39e0817e-6e37-4754-9952-d7ab3450ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-427bfad2-7952-42bc-b536-3112cc18f8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-fc07f49e-4ebf-4ada-aca1-da1cdd0219b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-a2db8aad-b031-47dd-8399-b5a4234257bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457172381-172.17.0.3-1595334403291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-c609f240-9595-46a6-886b-9c0aa887c5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-a35cd7bd-d75c-40b7-ab6e-6f4ed6d56fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-91c6c799-5a4b-4e16-9e6e-048bd9dcdbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-baa65fdc-6c91-468a-abcb-978997e507cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-f3b0b4d1-6378-41a9-8c85-055fe9443945,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-0dabe64a-ecd3-4a58-93d6-ceee1f7f077d,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-4978f474-fe9a-4b10-b529-3bd64a2270eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-6bf10227-8a38-4bc3-8bc3-c0c87d8c1dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457172381-172.17.0.3-1595334403291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-c609f240-9595-46a6-886b-9c0aa887c5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-a35cd7bd-d75c-40b7-ab6e-6f4ed6d56fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-91c6c799-5a4b-4e16-9e6e-048bd9dcdbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-baa65fdc-6c91-468a-abcb-978997e507cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-f3b0b4d1-6378-41a9-8c85-055fe9443945,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-0dabe64a-ecd3-4a58-93d6-ceee1f7f077d,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-4978f474-fe9a-4b10-b529-3bd64a2270eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-6bf10227-8a38-4bc3-8bc3-c0c87d8c1dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530426651-172.17.0.3-1595335583389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-47937c61-b89a-4e3c-8787-585397116c98,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-f07a246d-1e8d-408f-a621-da4c94c72464,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-c0e2beca-45c8-4a48-9340-704a0ddd63ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-58cb60ca-eef7-45f8-888d-233765b1188e,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-5d657e62-3bba-4ec3-8844-9dedf5b2a307,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-dc0bc63d-cc6f-4a67-af5d-6d8ac267a316,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-6a8b050b-d0a4-4aa2-a428-267b0b9ed77f,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-07f24a12-2175-4138-a01c-c5887c9d47ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530426651-172.17.0.3-1595335583389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-47937c61-b89a-4e3c-8787-585397116c98,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-f07a246d-1e8d-408f-a621-da4c94c72464,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-c0e2beca-45c8-4a48-9340-704a0ddd63ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-58cb60ca-eef7-45f8-888d-233765b1188e,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-5d657e62-3bba-4ec3-8844-9dedf5b2a307,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-dc0bc63d-cc6f-4a67-af5d-6d8ac267a316,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-6a8b050b-d0a4-4aa2-a428-267b0b9ed77f,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-07f24a12-2175-4138-a01c-c5887c9d47ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5396
