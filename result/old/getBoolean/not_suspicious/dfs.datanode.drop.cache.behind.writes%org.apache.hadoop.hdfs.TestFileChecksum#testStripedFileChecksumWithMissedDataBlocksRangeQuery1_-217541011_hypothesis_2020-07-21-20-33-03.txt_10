reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135840996-172.17.0.3-1595364097385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-5e33217d-ab1d-4695-b2a9-3509f7359147,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-41f2b9d2-bbb7-4833-9859-e833a946b3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-bb025ee5-fde1-431a-a46f-79e2e3d3fefb,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-3cab0369-b6a9-4eec-83c7-de492e401103,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-cecb536b-589f-46f6-96da-5819ea1ab40f,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-de6a76de-fc8a-4556-8251-64eb03d3ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7a7a610d-0b7d-4395-8199-5515cf5eaa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-23c9ba57-7e72-4b2a-9976-b01442617084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135840996-172.17.0.3-1595364097385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-5e33217d-ab1d-4695-b2a9-3509f7359147,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-41f2b9d2-bbb7-4833-9859-e833a946b3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-bb025ee5-fde1-431a-a46f-79e2e3d3fefb,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-3cab0369-b6a9-4eec-83c7-de492e401103,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-cecb536b-589f-46f6-96da-5819ea1ab40f,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-de6a76de-fc8a-4556-8251-64eb03d3ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7a7a610d-0b7d-4395-8199-5515cf5eaa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-23c9ba57-7e72-4b2a-9976-b01442617084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619058438-172.17.0.3-1595364240640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-13f36213-aba4-4e06-8399-87f46c906c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-563a7de1-5a99-490d-a51e-f69bbe0aacad,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-d8264138-a246-4538-b50a-9b342bb894ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-c0fe3318-863e-437f-a195-4c146bb58e12,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-179a2b67-e4f9-4390-a77b-b08c799d02c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-689ba9da-2e62-4819-9170-20a862e60dee,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-c2bb3bed-c1c6-4df3-ab5f-855f20bd149e,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-224869c8-1f38-4782-89b3-3467acf07df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619058438-172.17.0.3-1595364240640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-13f36213-aba4-4e06-8399-87f46c906c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-563a7de1-5a99-490d-a51e-f69bbe0aacad,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-d8264138-a246-4538-b50a-9b342bb894ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-c0fe3318-863e-437f-a195-4c146bb58e12,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-179a2b67-e4f9-4390-a77b-b08c799d02c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-689ba9da-2e62-4819-9170-20a862e60dee,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-c2bb3bed-c1c6-4df3-ab5f-855f20bd149e,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-224869c8-1f38-4782-89b3-3467acf07df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563935406-172.17.0.3-1595365434666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-343f819b-9563-4105-8ba4-94fa3e8f0b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-9562f2f1-09e6-4de4-a697-cce303802159,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-d3032443-171d-4805-8989-51eef50494c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-a919b8fa-8b86-4137-9c08-c375751b80fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-8850f1c8-067d-4fb9-a912-a691ce4dc67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-746e16a1-4252-4dcd-a265-be4e62f442bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-0e3a8b73-2b37-4548-853b-0f9363188da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-f7bcbfc0-d676-4cfe-8fa3-f40b1168d9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563935406-172.17.0.3-1595365434666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-343f819b-9563-4105-8ba4-94fa3e8f0b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-9562f2f1-09e6-4de4-a697-cce303802159,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-d3032443-171d-4805-8989-51eef50494c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-a919b8fa-8b86-4137-9c08-c375751b80fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-8850f1c8-067d-4fb9-a912-a691ce4dc67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-746e16a1-4252-4dcd-a265-be4e62f442bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-0e3a8b73-2b37-4548-853b-0f9363188da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-f7bcbfc0-d676-4cfe-8fa3-f40b1168d9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702665638-172.17.0.3-1595365459915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40520,DS-3dc61333-a46c-493e-9267-6d478a813f80,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-a381dc1d-adf5-4964-b5cf-c4420bfbc5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b8d98704-4f66-42a2-b744-1038810752ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-856c5ee8-22d2-4545-ae6d-2d09999e1df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-d78e70ab-d69a-4302-91c6-79fd798c5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-c7660b13-d0c9-470f-88ad-43a592badc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-c12fb260-0b59-4cde-85cf-cb11ddf6c962,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-df8c5cff-4ec8-44b6-86eb-f9fc5255996c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702665638-172.17.0.3-1595365459915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40520,DS-3dc61333-a46c-493e-9267-6d478a813f80,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-a381dc1d-adf5-4964-b5cf-c4420bfbc5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b8d98704-4f66-42a2-b744-1038810752ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-856c5ee8-22d2-4545-ae6d-2d09999e1df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-d78e70ab-d69a-4302-91c6-79fd798c5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-c7660b13-d0c9-470f-88ad-43a592badc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-c12fb260-0b59-4cde-85cf-cb11ddf6c962,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-df8c5cff-4ec8-44b6-86eb-f9fc5255996c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958535183-172.17.0.3-1595365721784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36007,DS-4fd19502-4df2-4124-94b2-d7dc172f3549,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-61d4c263-ccd8-4464-b524-20bab8617937,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-34d54bbb-c327-4043-bdf0-27f337422981,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-e3c95c38-625b-4da7-b8ae-22c1c3784d41,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-108776b9-fa81-4c9b-ae82-e88845474321,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-be981549-5907-4e42-a347-0b830a5fb7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-ac15809d-42fa-4d4c-bb33-42f0583f9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-680fa03d-95f7-4534-b13d-39436a42b80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958535183-172.17.0.3-1595365721784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36007,DS-4fd19502-4df2-4124-94b2-d7dc172f3549,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-61d4c263-ccd8-4464-b524-20bab8617937,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-34d54bbb-c327-4043-bdf0-27f337422981,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-e3c95c38-625b-4da7-b8ae-22c1c3784d41,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-108776b9-fa81-4c9b-ae82-e88845474321,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-be981549-5907-4e42-a347-0b830a5fb7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-ac15809d-42fa-4d4c-bb33-42f0583f9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-680fa03d-95f7-4534-b13d-39436a42b80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687933076-172.17.0.3-1595365754258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-4d82c7d7-b0b9-4ed5-a468-57a358a1847e,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-a769892d-3583-4901-b18f-763788cf8296,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-0e26482e-3893-4fdb-82b3-ca314feb9911,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-67a0062b-3b4f-4a04-b55c-f664d49308b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-55ae8ac3-21b7-4f8c-b1e3-af190d9a7b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-4d24ad5b-605e-4267-bcb5-2995d2e9402c,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a744cf52-a5d1-4ade-8370-d57a9eef54ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-8304f6ba-0155-4264-8e06-7b5d3303c1a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687933076-172.17.0.3-1595365754258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-4d82c7d7-b0b9-4ed5-a468-57a358a1847e,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-a769892d-3583-4901-b18f-763788cf8296,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-0e26482e-3893-4fdb-82b3-ca314feb9911,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-67a0062b-3b4f-4a04-b55c-f664d49308b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-55ae8ac3-21b7-4f8c-b1e3-af190d9a7b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-4d24ad5b-605e-4267-bcb5-2995d2e9402c,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a744cf52-a5d1-4ade-8370-d57a9eef54ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-8304f6ba-0155-4264-8e06-7b5d3303c1a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560986761-172.17.0.3-1595365994915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39968,DS-92fea65e-c8e2-49d7-94bd-1bd31f4e99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-2ea2d2db-937d-42ef-a11d-25e7b7258237,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-39e56956-35e8-4b36-ae12-bb7a88f0d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-c92a4a97-9f22-446e-9397-eff355446d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-99fe62d7-a2da-4c5e-baa9-d0e105e96edb,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-072e770a-c3b8-4565-b33d-ef0ff2c61dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-271008f9-939f-45eb-8a77-ac3479e18f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-0a5fc6e9-eeef-4f99-b1d1-b75bc68f006e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560986761-172.17.0.3-1595365994915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39968,DS-92fea65e-c8e2-49d7-94bd-1bd31f4e99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-2ea2d2db-937d-42ef-a11d-25e7b7258237,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-39e56956-35e8-4b36-ae12-bb7a88f0d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-c92a4a97-9f22-446e-9397-eff355446d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-99fe62d7-a2da-4c5e-baa9-d0e105e96edb,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-072e770a-c3b8-4565-b33d-ef0ff2c61dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-271008f9-939f-45eb-8a77-ac3479e18f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-0a5fc6e9-eeef-4f99-b1d1-b75bc68f006e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945168771-172.17.0.3-1595366093988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36519,DS-f9396e9c-b013-40d9-a8ce-466c126d15be,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-c8b81490-296e-42ed-b3cb-42f414ec9207,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-1237dc8e-7177-4142-b84b-729c3f387cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-bca9552a-4ae9-4cea-aa2f-e746775f0620,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-70254924-a6e8-48c4-9189-10acf5c1ca46,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-1d1311b4-0f55-472c-913e-45238e6b67ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-779c0131-090e-4960-911a-98ef8eeed371,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-3ab187cf-32d1-4d06-803b-76f9e56566ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945168771-172.17.0.3-1595366093988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36519,DS-f9396e9c-b013-40d9-a8ce-466c126d15be,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-c8b81490-296e-42ed-b3cb-42f414ec9207,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-1237dc8e-7177-4142-b84b-729c3f387cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-bca9552a-4ae9-4cea-aa2f-e746775f0620,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-70254924-a6e8-48c4-9189-10acf5c1ca46,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-1d1311b4-0f55-472c-913e-45238e6b67ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-779c0131-090e-4960-911a-98ef8eeed371,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-3ab187cf-32d1-4d06-803b-76f9e56566ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126992749-172.17.0.3-1595366213575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45846,DS-7cb1e00b-f7fe-4135-a55b-c1397df43ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-09a8a4de-cae9-4817-a1ad-4e2fe27858ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-fa81e265-c599-45ce-888c-519ce393706f,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-c264b22a-9a2f-4896-b917-31b28cc03293,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-c2d39fd0-cc0e-469f-b9a7-a44ffe8ea160,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-285784d8-e0eb-4e81-b28e-3f94a6f14a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-f3232b4d-5b1a-4fdb-b9cc-76dcbc401a00,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-3e8bea77-2685-48ff-a9fc-b2690762dd22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126992749-172.17.0.3-1595366213575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45846,DS-7cb1e00b-f7fe-4135-a55b-c1397df43ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-09a8a4de-cae9-4817-a1ad-4e2fe27858ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-fa81e265-c599-45ce-888c-519ce393706f,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-c264b22a-9a2f-4896-b917-31b28cc03293,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-c2d39fd0-cc0e-469f-b9a7-a44ffe8ea160,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-285784d8-e0eb-4e81-b28e-3f94a6f14a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-f3232b4d-5b1a-4fdb-b9cc-76dcbc401a00,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-3e8bea77-2685-48ff-a9fc-b2690762dd22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806323269-172.17.0.3-1595366424145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43172,DS-11a9a4dd-b06e-4eb8-ae60-d1834c2fbed4,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-da063337-9869-40b3-b2fd-bd828a05e901,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-6537c695-e283-4f9e-968b-f277a4c0886f,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-342b44ca-2755-4f7a-9227-47718517dd60,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-b45c73c3-86c9-48e8-8e17-14b33d39d2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-2f1f0122-d015-4a33-b4ba-10061b374959,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-98e9889a-c38f-45bd-a97a-b071896b6b03,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-6ccf0c4c-c5b9-4938-88cf-5b10afa31f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806323269-172.17.0.3-1595366424145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43172,DS-11a9a4dd-b06e-4eb8-ae60-d1834c2fbed4,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-da063337-9869-40b3-b2fd-bd828a05e901,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-6537c695-e283-4f9e-968b-f277a4c0886f,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-342b44ca-2755-4f7a-9227-47718517dd60,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-b45c73c3-86c9-48e8-8e17-14b33d39d2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-2f1f0122-d015-4a33-b4ba-10061b374959,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-98e9889a-c38f-45bd-a97a-b071896b6b03,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-6ccf0c4c-c5b9-4938-88cf-5b10afa31f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235812453-172.17.0.3-1595366794760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42402,DS-08251690-8ef4-42c8-9e3f-f4dfd0311b09,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-3224db06-0f1a-40c5-99ea-5b0cd5c83e34,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-7b9507e6-a510-49bf-9ed7-6482fb7863eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-e24524c6-8db1-48a5-b177-ebb27ade149e,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-1362a928-bce8-4e02-8a35-a935dd739091,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-c4e4420c-d1e8-40ae-b653-e36384dda639,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-c92beab9-e563-47d1-af85-d490c4aa1475,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-9de82bee-cf6a-43b5-a854-f96e0301041d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235812453-172.17.0.3-1595366794760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42402,DS-08251690-8ef4-42c8-9e3f-f4dfd0311b09,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-3224db06-0f1a-40c5-99ea-5b0cd5c83e34,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-7b9507e6-a510-49bf-9ed7-6482fb7863eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-e24524c6-8db1-48a5-b177-ebb27ade149e,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-1362a928-bce8-4e02-8a35-a935dd739091,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-c4e4420c-d1e8-40ae-b653-e36384dda639,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-c92beab9-e563-47d1-af85-d490c4aa1475,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-9de82bee-cf6a-43b5-a854-f96e0301041d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233234340-172.17.0.3-1595367117754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37558,DS-d9e1fcfd-c1c3-4c9a-9462-78577f2f18b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-4b9cadea-73c4-46b8-9233-65bfaf1009e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-00d2df2b-502c-461b-9593-8e847e9a7de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-b9057527-7ffd-4f5b-8fba-81c15b91d314,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-6673efde-d9b6-40bc-8232-b4f143103a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-4fe922a2-a859-4554-8ef1-f5d13bf4cb34,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-3e54fb32-1fd7-43d4-8d42-f251224cfd99,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-e89ce1bd-f7d6-43bb-b84b-9ae5134842cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233234340-172.17.0.3-1595367117754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37558,DS-d9e1fcfd-c1c3-4c9a-9462-78577f2f18b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-4b9cadea-73c4-46b8-9233-65bfaf1009e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-00d2df2b-502c-461b-9593-8e847e9a7de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-b9057527-7ffd-4f5b-8fba-81c15b91d314,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-6673efde-d9b6-40bc-8232-b4f143103a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-4fe922a2-a859-4554-8ef1-f5d13bf4cb34,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-3e54fb32-1fd7-43d4-8d42-f251224cfd99,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-e89ce1bd-f7d6-43bb-b84b-9ae5134842cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001456749-172.17.0.3-1595367243521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39476,DS-1b71167e-9030-4ab1-9e5f-d44eb0e6ca9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-f69ae15a-986a-496f-9ab4-2330b2dbcc38,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-4619f544-a387-4d39-8bc5-60f69671e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-16e8c638-a4d7-45dc-941a-c104114c7932,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-267485de-a1a6-4b3e-9bb1-b75e5c29ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-645d64b6-d54e-433c-add4-840a027492fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-725e71ff-c4e4-4591-a694-85709a36aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-34464ba7-962c-479b-9b32-fe0590904a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001456749-172.17.0.3-1595367243521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39476,DS-1b71167e-9030-4ab1-9e5f-d44eb0e6ca9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-f69ae15a-986a-496f-9ab4-2330b2dbcc38,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-4619f544-a387-4d39-8bc5-60f69671e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-16e8c638-a4d7-45dc-941a-c104114c7932,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-267485de-a1a6-4b3e-9bb1-b75e5c29ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-645d64b6-d54e-433c-add4-840a027492fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-725e71ff-c4e4-4591-a694-85709a36aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-34464ba7-962c-479b-9b32-fe0590904a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794782146-172.17.0.3-1595367956696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40787,DS-483ae33d-896a-47e4-a7ed-f5b9b2b411ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-adc3b0ce-2a78-441c-b5d9-e193c0dfd7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-87bc3861-5431-4146-994c-b422c6078487,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-594869e2-6ece-4d34-aa89-e3dc066ff6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-f96c3234-a4c6-4185-96ad-da6e8f214596,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-83f04caa-7252-479d-a8f5-b4f2eae7bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-e7117db7-95dc-46cd-9363-cfda07487d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-406b7cdc-8729-463a-94e1-812fd780c986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794782146-172.17.0.3-1595367956696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40787,DS-483ae33d-896a-47e4-a7ed-f5b9b2b411ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-adc3b0ce-2a78-441c-b5d9-e193c0dfd7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-87bc3861-5431-4146-994c-b422c6078487,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-594869e2-6ece-4d34-aa89-e3dc066ff6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-f96c3234-a4c6-4185-96ad-da6e8f214596,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-83f04caa-7252-479d-a8f5-b4f2eae7bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-e7117db7-95dc-46cd-9363-cfda07487d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-406b7cdc-8729-463a-94e1-812fd780c986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377934426-172.17.0.3-1595368257481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36139,DS-092abe5b-0cc3-4e19-b060-2d29694cbdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-4676f41b-40c2-496f-92bc-62f63df82f52,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-bcb39fcc-5b69-4fd5-bbbc-77723497bc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-e610aea1-7db8-4ed1-b175-30cd07523b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-d401abae-4655-45a9-a140-ae5af260599b,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-aba4d912-9f69-43ef-95ae-2fc72bf093f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-8fb63b4d-55e7-4599-b51d-58881cc34ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-a9d4ae91-e0e2-431c-87f3-0baaeefa6aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377934426-172.17.0.3-1595368257481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36139,DS-092abe5b-0cc3-4e19-b060-2d29694cbdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-4676f41b-40c2-496f-92bc-62f63df82f52,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-bcb39fcc-5b69-4fd5-bbbc-77723497bc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-e610aea1-7db8-4ed1-b175-30cd07523b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-d401abae-4655-45a9-a140-ae5af260599b,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-aba4d912-9f69-43ef-95ae-2fc72bf093f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-8fb63b4d-55e7-4599-b51d-58881cc34ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-a9d4ae91-e0e2-431c-87f3-0baaeefa6aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303833570-172.17.0.3-1595368721337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-f7a19ee5-968e-407e-b545-bedcd211e31e,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-121f3837-46f0-4378-9852-620643751ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-6c9f9f47-7c02-4167-9d37-d8bfe7282f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-805edf6d-1eec-49d5-88a8-bb55d4159dec,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-f6bdbaba-8437-4462-99dc-ad9b6adcd18a,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-9d896651-b261-4d17-a967-e1619328d558,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-8e80c674-a465-424b-9e54-6d9054c75022,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-859670ff-7581-4eaa-b2f2-c8d8ba62227b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303833570-172.17.0.3-1595368721337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-f7a19ee5-968e-407e-b545-bedcd211e31e,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-121f3837-46f0-4378-9852-620643751ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-6c9f9f47-7c02-4167-9d37-d8bfe7282f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-805edf6d-1eec-49d5-88a8-bb55d4159dec,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-f6bdbaba-8437-4462-99dc-ad9b6adcd18a,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-9d896651-b261-4d17-a967-e1619328d558,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-8e80c674-a465-424b-9e54-6d9054c75022,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-859670ff-7581-4eaa-b2f2-c8d8ba62227b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5377
