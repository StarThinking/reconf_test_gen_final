reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993632243-172.17.0.12-1595371009015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33678,DS-925e013a-5439-4532-8b89-65a242e30e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-1faea6d8-381e-4f5b-ac44-55d9e8af4184,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-89549a2f-275b-4146-9e91-4448e371afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-f4353687-d15e-4ac9-993f-aee7f3adcd60,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-b647ff1a-396a-4715-a437-506a4b16a39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-5e1b68b1-2f90-4f31-b77e-7bd8f78d3149,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-e82febed-9dba-4319-b027-38e6a3f7d0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-15d13bb4-94d9-487d-af1b-e8c68ade9b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993632243-172.17.0.12-1595371009015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33678,DS-925e013a-5439-4532-8b89-65a242e30e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-1faea6d8-381e-4f5b-ac44-55d9e8af4184,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-89549a2f-275b-4146-9e91-4448e371afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-f4353687-d15e-4ac9-993f-aee7f3adcd60,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-b647ff1a-396a-4715-a437-506a4b16a39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-5e1b68b1-2f90-4f31-b77e-7bd8f78d3149,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-e82febed-9dba-4319-b027-38e6a3f7d0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-15d13bb4-94d9-487d-af1b-e8c68ade9b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218963550-172.17.0.12-1595372248209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39859,DS-5e8bd52f-4be6-4516-b725-ff82c875c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-8994eb61-d573-4b4a-a08c-a52853f48155,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-ba08fd8d-0cef-4e02-b77b-62fa6904b057,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-97296123-8fac-4fd4-a99d-77b3d55d8d09,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-14656656-2cce-4429-af1c-88aaf5f4f313,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-9df83abd-3706-464d-a356-0cf89eb394dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-f6d8adde-a912-47ca-ba9c-d6cbab9ec5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-204b9a7f-9eef-4009-b032-30c28fffbbeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218963550-172.17.0.12-1595372248209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39859,DS-5e8bd52f-4be6-4516-b725-ff82c875c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-8994eb61-d573-4b4a-a08c-a52853f48155,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-ba08fd8d-0cef-4e02-b77b-62fa6904b057,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-97296123-8fac-4fd4-a99d-77b3d55d8d09,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-14656656-2cce-4429-af1c-88aaf5f4f313,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-9df83abd-3706-464d-a356-0cf89eb394dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-f6d8adde-a912-47ca-ba9c-d6cbab9ec5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-204b9a7f-9eef-4009-b032-30c28fffbbeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775155599-172.17.0.12-1595372372346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33169,DS-68085b02-342e-4d37-9de8-5c576e9ef1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-d3855095-5fea-471c-8681-dc445c6dc91f,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-ca029f63-2d63-47dd-9aea-d8676fc7626f,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-4da2e905-9aef-4c44-9fc2-aded5086821f,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-a5c6c37d-b590-434a-881c-ac31f6a8ee87,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-7987bbde-f7da-4ac9-90fa-73ea5c51c10d,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-ccb74f6a-7d1a-4a6b-8d99-bde6279d2172,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-1eaba14e-5726-42f4-827b-8f7d63c85e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775155599-172.17.0.12-1595372372346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33169,DS-68085b02-342e-4d37-9de8-5c576e9ef1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-d3855095-5fea-471c-8681-dc445c6dc91f,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-ca029f63-2d63-47dd-9aea-d8676fc7626f,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-4da2e905-9aef-4c44-9fc2-aded5086821f,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-a5c6c37d-b590-434a-881c-ac31f6a8ee87,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-7987bbde-f7da-4ac9-90fa-73ea5c51c10d,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-ccb74f6a-7d1a-4a6b-8d99-bde6279d2172,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-1eaba14e-5726-42f4-827b-8f7d63c85e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830947466-172.17.0.12-1595372523115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-164c46d0-353a-401c-a293-4beda1152f10,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-12fb743d-3623-4031-8228-0b07643a41b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-61c4af07-ed2a-4999-b32e-399902493887,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-cb2e9a6f-d8f1-4cf3-8ef8-945f3ede6e16,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-01be5448-b8a2-4117-872b-ccb3e038d7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-09cabea5-fb27-41d8-8175-46ffccd58466,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-d687088b-806b-4e14-8724-0555a41863b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-57457a04-f42d-4510-b4ef-b4c652b2459a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830947466-172.17.0.12-1595372523115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-164c46d0-353a-401c-a293-4beda1152f10,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-12fb743d-3623-4031-8228-0b07643a41b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-61c4af07-ed2a-4999-b32e-399902493887,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-cb2e9a6f-d8f1-4cf3-8ef8-945f3ede6e16,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-01be5448-b8a2-4117-872b-ccb3e038d7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-09cabea5-fb27-41d8-8175-46ffccd58466,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-d687088b-806b-4e14-8724-0555a41863b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-57457a04-f42d-4510-b4ef-b4c652b2459a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131110397-172.17.0.12-1595372907256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42084,DS-423c9547-64c3-4268-a576-00bc403d3d15,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-052bbbb9-634f-4f48-af22-e6d26adaae15,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-454d0df3-080b-4bbf-ab07-287bf2089397,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-d032d102-5bed-48d9-baf2-cdfbf63049ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-a80811aa-1f31-4acc-a05f-2ed92314ac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-d1636b2c-3ed8-4685-9d03-1560386da466,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-fc1eddcb-6f0e-4eeb-a5d2-673f20d2458f,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-0c79cf85-c80d-4db5-8bdf-c8950006f9ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131110397-172.17.0.12-1595372907256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42084,DS-423c9547-64c3-4268-a576-00bc403d3d15,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-052bbbb9-634f-4f48-af22-e6d26adaae15,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-454d0df3-080b-4bbf-ab07-287bf2089397,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-d032d102-5bed-48d9-baf2-cdfbf63049ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-a80811aa-1f31-4acc-a05f-2ed92314ac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-d1636b2c-3ed8-4685-9d03-1560386da466,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-fc1eddcb-6f0e-4eeb-a5d2-673f20d2458f,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-0c79cf85-c80d-4db5-8bdf-c8950006f9ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423150928-172.17.0.12-1595372940956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41044,DS-03099e66-c601-459f-a660-9fa433c2c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-1901b26c-ad65-4eb4-9974-71deb3d6efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-d6d6ffce-c810-4b5f-89ed-7dcfb535e771,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-26096c62-e8a6-4e5b-9874-6655a7bf6fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-1bf75768-9268-4331-a707-dc7fc76a88b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-45dfe143-321e-4565-8060-bf85cc647513,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-e486a8c4-f5c0-41eb-8930-1d8021e972cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-233a2157-4733-44ab-8ea4-d26d7c0c2837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423150928-172.17.0.12-1595372940956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41044,DS-03099e66-c601-459f-a660-9fa433c2c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-1901b26c-ad65-4eb4-9974-71deb3d6efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-d6d6ffce-c810-4b5f-89ed-7dcfb535e771,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-26096c62-e8a6-4e5b-9874-6655a7bf6fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-1bf75768-9268-4331-a707-dc7fc76a88b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-45dfe143-321e-4565-8060-bf85cc647513,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-e486a8c4-f5c0-41eb-8930-1d8021e972cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-233a2157-4733-44ab-8ea4-d26d7c0c2837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980624059-172.17.0.12-1595373269490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-c1596509-d7bd-4cea-bb11-bbdd0aaa5e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-f3a87d2d-97ae-41e8-b37c-e240e128c651,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-57b4dfd8-25bb-4a6c-a35f-cda28e2f16c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-f197d820-ff62-46d6-b0bf-6714b66063d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-dcbe75d0-8a93-4b9a-8dd8-24079d2e413f,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-2878a510-ee25-424d-9e47-8373694e56f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-4b62e720-bb54-48a6-afde-64526722eb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-9094e7e1-9f1b-4206-8898-11857aadc109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980624059-172.17.0.12-1595373269490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-c1596509-d7bd-4cea-bb11-bbdd0aaa5e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-f3a87d2d-97ae-41e8-b37c-e240e128c651,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-57b4dfd8-25bb-4a6c-a35f-cda28e2f16c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-f197d820-ff62-46d6-b0bf-6714b66063d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-dcbe75d0-8a93-4b9a-8dd8-24079d2e413f,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-2878a510-ee25-424d-9e47-8373694e56f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-4b62e720-bb54-48a6-afde-64526722eb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-9094e7e1-9f1b-4206-8898-11857aadc109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417507141-172.17.0.12-1595373853675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37470,DS-28f238f5-09ea-4d75-a448-a76bff939cca,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-dd7f49a0-cbf5-448d-8a74-9406b3c0efb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-e2c047d0-8067-458f-aee3-985ea87aa16b,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-2b170bae-1abd-4000-ba6e-5f43c85f51e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-100212bc-4fbe-430c-aeed-10f2e9524c69,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-7f9f6580-3044-4185-8936-426c81725764,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-5e5730af-526d-4f5f-8933-c113571c1591,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-a9d9683a-ae8e-4238-bc44-f8052e940994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417507141-172.17.0.12-1595373853675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37470,DS-28f238f5-09ea-4d75-a448-a76bff939cca,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-dd7f49a0-cbf5-448d-8a74-9406b3c0efb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-e2c047d0-8067-458f-aee3-985ea87aa16b,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-2b170bae-1abd-4000-ba6e-5f43c85f51e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-100212bc-4fbe-430c-aeed-10f2e9524c69,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-7f9f6580-3044-4185-8936-426c81725764,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-5e5730af-526d-4f5f-8933-c113571c1591,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-a9d9683a-ae8e-4238-bc44-f8052e940994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193478425-172.17.0.12-1595374012073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-3cfbfec7-397e-4c40-ae90-9b7282a4bf72,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-cacc6ba4-7710-498c-afd4-53b73cfb39af,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-edbec542-db2a-454d-be75-965473661b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-d180aa54-6295-4335-bfb8-bf7769569408,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-a934167b-cbc8-41f2-ad7e-b684d0adbb35,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-0d6d24d3-efcc-4f93-aada-e7d49c01d281,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-15139ad1-c5c8-4666-a2d7-9af08fbf5a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-812f51e9-24df-4aab-b830-e56320114a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193478425-172.17.0.12-1595374012073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-3cfbfec7-397e-4c40-ae90-9b7282a4bf72,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-cacc6ba4-7710-498c-afd4-53b73cfb39af,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-edbec542-db2a-454d-be75-965473661b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-d180aa54-6295-4335-bfb8-bf7769569408,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-a934167b-cbc8-41f2-ad7e-b684d0adbb35,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-0d6d24d3-efcc-4f93-aada-e7d49c01d281,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-15139ad1-c5c8-4666-a2d7-9af08fbf5a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-812f51e9-24df-4aab-b830-e56320114a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603049598-172.17.0.12-1595374490305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37154,DS-416deb3b-425e-44f7-8a2d-033424697c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-471c174d-ddca-4c6e-bd78-ce59ee50af71,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-41ee0b53-0968-45bf-9b05-6b8463a84a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-370a628e-f06d-411d-b300-99d5672ddbea,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-55d9d896-a610-4cfc-baa5-3f0bdcbcfad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-211c638c-3760-454b-b7ed-9b66a996541a,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-28a16fc1-69fa-4f04-99bc-16ceec9ef69d,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-c92e452e-6ea0-4575-8586-c84ca108abf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603049598-172.17.0.12-1595374490305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37154,DS-416deb3b-425e-44f7-8a2d-033424697c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-471c174d-ddca-4c6e-bd78-ce59ee50af71,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-41ee0b53-0968-45bf-9b05-6b8463a84a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-370a628e-f06d-411d-b300-99d5672ddbea,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-55d9d896-a610-4cfc-baa5-3f0bdcbcfad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-211c638c-3760-454b-b7ed-9b66a996541a,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-28a16fc1-69fa-4f04-99bc-16ceec9ef69d,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-c92e452e-6ea0-4575-8586-c84ca108abf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945247427-172.17.0.12-1595374526193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-89da09b1-34c2-4476-952c-0c56adfc737d,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-1ecba103-ce91-4514-986f-57358ddf7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-12f9c4b8-76e5-4fb7-9aa3-841943d32acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-9a209eb3-6ee7-4f8f-afa1-86a8680305bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-c92b9545-a8d9-4018-b181-a4e4cd36ba3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-3845dcee-1f15-4133-81de-2b17b1c6e09a,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-4eda829d-f5fe-4f52-8dfa-8e2d571c1f15,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-fafaedc1-e530-46fe-b23d-51dbc0dd3bb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945247427-172.17.0.12-1595374526193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-89da09b1-34c2-4476-952c-0c56adfc737d,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-1ecba103-ce91-4514-986f-57358ddf7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-12f9c4b8-76e5-4fb7-9aa3-841943d32acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-9a209eb3-6ee7-4f8f-afa1-86a8680305bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-c92b9545-a8d9-4018-b181-a4e4cd36ba3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-3845dcee-1f15-4133-81de-2b17b1c6e09a,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-4eda829d-f5fe-4f52-8dfa-8e2d571c1f15,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-fafaedc1-e530-46fe-b23d-51dbc0dd3bb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621482074-172.17.0.12-1595374716859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-7aebae42-0588-48a3-a9df-8bf4af43eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-f3ca7f8f-3566-4813-930b-d3f22d606287,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-6a239651-f480-4e76-a846-9948219612fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-a4b37478-90de-4e86-acf8-d410564bf588,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-2682302c-83ff-4fd2-bad4-95ae696d8ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-6b83e1da-4592-4ea8-82c9-f35ca264722d,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-2ca9c40a-400d-4de3-a468-37519abf2992,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-9811887d-d14c-4e41-bd69-a4e96d757f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621482074-172.17.0.12-1595374716859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-7aebae42-0588-48a3-a9df-8bf4af43eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-f3ca7f8f-3566-4813-930b-d3f22d606287,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-6a239651-f480-4e76-a846-9948219612fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-a4b37478-90de-4e86-acf8-d410564bf588,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-2682302c-83ff-4fd2-bad4-95ae696d8ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-6b83e1da-4592-4ea8-82c9-f35ca264722d,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-2ca9c40a-400d-4de3-a468-37519abf2992,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-9811887d-d14c-4e41-bd69-a4e96d757f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045965892-172.17.0.12-1595375964913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-45f126cc-5a50-43f8-84eb-621c4b2deb99,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-4bf6c974-a543-4a72-b5d1-288be41dcfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-574774b0-45fa-44e4-9839-9d94ccc96a61,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-248836bb-6b8e-4e6d-8b17-f1052a543f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-37c20de7-a3d1-4f5d-8227-95c5ace7e807,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-ae228548-f0c6-4ebb-b168-25021a2413ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-5651a117-3003-4be7-86bd-d9a830d31f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-71705142-fe73-4f4f-aef3-c9fb570a21d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045965892-172.17.0.12-1595375964913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-45f126cc-5a50-43f8-84eb-621c4b2deb99,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-4bf6c974-a543-4a72-b5d1-288be41dcfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-574774b0-45fa-44e4-9839-9d94ccc96a61,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-248836bb-6b8e-4e6d-8b17-f1052a543f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-37c20de7-a3d1-4f5d-8227-95c5ace7e807,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-ae228548-f0c6-4ebb-b168-25021a2413ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-5651a117-3003-4be7-86bd-d9a830d31f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-71705142-fe73-4f4f-aef3-c9fb570a21d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5494
