reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129956874-172.17.0.6-1595289423634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36398,DS-df6d2fe9-c08a-480e-b135-e25a5ba44a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-4cec8c5b-3be7-480e-8d44-32ddef319e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-2aafdc39-7805-42a6-a25e-1d9b7d4eecd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-d962e3ee-e73f-4808-8351-c7f3aa8684bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-403214c3-b4e8-42de-9737-38b2ea09bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-14895415-d914-4453-b0d3-333dbcf4bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-aeb53a42-368c-42c6-ae07-dd578e529bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-58d8ef4e-fb83-46bc-b7bf-64c77498e8e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129956874-172.17.0.6-1595289423634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36398,DS-df6d2fe9-c08a-480e-b135-e25a5ba44a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-4cec8c5b-3be7-480e-8d44-32ddef319e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-2aafdc39-7805-42a6-a25e-1d9b7d4eecd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-d962e3ee-e73f-4808-8351-c7f3aa8684bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-403214c3-b4e8-42de-9737-38b2ea09bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-14895415-d914-4453-b0d3-333dbcf4bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-aeb53a42-368c-42c6-ae07-dd578e529bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-58d8ef4e-fb83-46bc-b7bf-64c77498e8e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247433380-172.17.0.6-1595289456492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37431,DS-0ff83c20-e081-4a94-825d-1e3c07a54892,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-9baa16a1-fb59-4130-ba7d-d73124514e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-b50f87f9-8485-406d-8d2e-434544151341,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-2446c96f-401d-432e-b19b-2f06ecfbbe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-9c19724d-2e9e-4731-9555-e2647b91c573,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-b836b1fe-00ad-4a04-b071-42c641956085,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-0f5608c2-0ed4-404c-82b0-44d274f8cac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-08f85d5d-7a66-4f08-b204-0e89dd7c8a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247433380-172.17.0.6-1595289456492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37431,DS-0ff83c20-e081-4a94-825d-1e3c07a54892,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-9baa16a1-fb59-4130-ba7d-d73124514e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-b50f87f9-8485-406d-8d2e-434544151341,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-2446c96f-401d-432e-b19b-2f06ecfbbe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-9c19724d-2e9e-4731-9555-e2647b91c573,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-b836b1fe-00ad-4a04-b071-42c641956085,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-0f5608c2-0ed4-404c-82b0-44d274f8cac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-08f85d5d-7a66-4f08-b204-0e89dd7c8a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40915181-172.17.0.6-1595289487255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-5e834438-efb9-4c41-9a10-4f7302944432,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-dabe5312-2bea-475c-9335-4b15b59d4adc,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-6f5f03eb-e5a1-45ec-9d2a-c039922ac89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-719fa6e7-cbee-4dfb-ad65-f810f9861cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-ad893aa8-2753-403d-9eca-7749dc11e328,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-5a96d4ea-c09e-4959-be37-5e291e9a485f,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-eb1f9bcc-1388-4f29-bdea-9f5515f9aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-3750d408-a47d-49f8-8140-3f5bef957a86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40915181-172.17.0.6-1595289487255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-5e834438-efb9-4c41-9a10-4f7302944432,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-dabe5312-2bea-475c-9335-4b15b59d4adc,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-6f5f03eb-e5a1-45ec-9d2a-c039922ac89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-719fa6e7-cbee-4dfb-ad65-f810f9861cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-ad893aa8-2753-403d-9eca-7749dc11e328,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-5a96d4ea-c09e-4959-be37-5e291e9a485f,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-eb1f9bcc-1388-4f29-bdea-9f5515f9aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-3750d408-a47d-49f8-8140-3f5bef957a86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870196152-172.17.0.6-1595289589972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38128,DS-47afbb62-5c66-434e-985e-994663d9247e,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-d9ec6712-eff4-4903-806e-5759e21a94e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-430d9884-c642-48d5-9a55-da577041135a,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-8cd496a3-1920-4fa5-ab25-af2f5470c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-0f04113e-8bc5-4c12-8fe8-6d70502ab076,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-d839a099-a12b-4c33-8335-010cf1924caa,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-b05fa60c-ed12-4bbd-8217-fe9a1fdf8b41,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-0639d648-efdb-4ba0-81e4-004923b6d4b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870196152-172.17.0.6-1595289589972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38128,DS-47afbb62-5c66-434e-985e-994663d9247e,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-d9ec6712-eff4-4903-806e-5759e21a94e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-430d9884-c642-48d5-9a55-da577041135a,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-8cd496a3-1920-4fa5-ab25-af2f5470c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-0f04113e-8bc5-4c12-8fe8-6d70502ab076,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-d839a099-a12b-4c33-8335-010cf1924caa,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-b05fa60c-ed12-4bbd-8217-fe9a1fdf8b41,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-0639d648-efdb-4ba0-81e4-004923b6d4b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993728101-172.17.0.6-1595289702450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-85a09082-297b-4f16-a5fd-01710836eee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-98133c18-e72c-4f83-83a3-f33433865fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-e983c996-e004-4ff5-9438-76bad9a4278f,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-c1dbcf0c-2941-4478-adfe-cb35e1c4ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-8049cd64-9bb8-4584-b502-8b9c9c2559e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-250507d7-9a2c-423c-ae06-41abb28b2d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-b2df2670-9966-4572-aa71-6b3934029b11,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-f54ecfff-ba7a-45e5-a43e-e8621bc28c3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993728101-172.17.0.6-1595289702450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-85a09082-297b-4f16-a5fd-01710836eee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-98133c18-e72c-4f83-83a3-f33433865fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-e983c996-e004-4ff5-9438-76bad9a4278f,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-c1dbcf0c-2941-4478-adfe-cb35e1c4ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-8049cd64-9bb8-4584-b502-8b9c9c2559e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-250507d7-9a2c-423c-ae06-41abb28b2d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-b2df2670-9966-4572-aa71-6b3934029b11,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-f54ecfff-ba7a-45e5-a43e-e8621bc28c3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347099383-172.17.0.6-1595289740768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39065,DS-da872b39-367a-4bd8-b575-fc718ea6d685,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-fbdfdf58-185f-4f22-a198-06c581890606,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-83000130-04f6-41a4-9dd3-474aa742bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-4c22f0be-e3f0-439f-a1a4-4ccdb7004af1,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-910bb53b-0e82-463c-9348-f1ef3a3c0e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-8c536bc4-117d-4ebb-a5fc-70648ba32d72,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-8963b8bd-669e-48df-a702-32ac3ab55dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-fc6bd102-6181-477e-b66e-5dc14eea93ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347099383-172.17.0.6-1595289740768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39065,DS-da872b39-367a-4bd8-b575-fc718ea6d685,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-fbdfdf58-185f-4f22-a198-06c581890606,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-83000130-04f6-41a4-9dd3-474aa742bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-4c22f0be-e3f0-439f-a1a4-4ccdb7004af1,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-910bb53b-0e82-463c-9348-f1ef3a3c0e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-8c536bc4-117d-4ebb-a5fc-70648ba32d72,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-8963b8bd-669e-48df-a702-32ac3ab55dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-fc6bd102-6181-477e-b66e-5dc14eea93ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675381835-172.17.0.6-1595289787368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45027,DS-3e55007a-d000-4fda-90be-97b290dee812,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-104d5773-7dee-4c3b-b94a-75d3ac408fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-0ab495fd-446a-486d-9992-e818835558ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-8334219e-abce-47ec-b71e-4a20b6e91748,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-b2461f78-0fa6-49c5-95f2-45c5d248c660,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-1b59258e-7153-4bda-ba36-3b65e11cec21,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-cbcd035b-8bd3-45fb-883b-711851f13225,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-c072daf5-ab56-4b41-8837-e80e4e268b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675381835-172.17.0.6-1595289787368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45027,DS-3e55007a-d000-4fda-90be-97b290dee812,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-104d5773-7dee-4c3b-b94a-75d3ac408fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-0ab495fd-446a-486d-9992-e818835558ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-8334219e-abce-47ec-b71e-4a20b6e91748,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-b2461f78-0fa6-49c5-95f2-45c5d248c660,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-1b59258e-7153-4bda-ba36-3b65e11cec21,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-cbcd035b-8bd3-45fb-883b-711851f13225,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-c072daf5-ab56-4b41-8837-e80e4e268b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2604380-172.17.0.6-1595289855752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-6b5cbc82-e76b-40ac-ad0b-3274440c40e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-a6739fdb-7481-4767-bd6e-fdee35cf087d,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-d6e2377c-0127-4ef4-a1ed-5a570bc6a04c,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-247bc890-b478-43b7-9b86-6d610c24b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-070cca63-a143-448b-a1f2-4ed5c82fdf97,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-958cdb00-29ca-4571-8b2f-3583795a49fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-7428667c-1285-4848-a00c-6cc4677b23f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-de65cc6c-36f4-44df-88d0-fe43a192bfd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2604380-172.17.0.6-1595289855752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-6b5cbc82-e76b-40ac-ad0b-3274440c40e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-a6739fdb-7481-4767-bd6e-fdee35cf087d,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-d6e2377c-0127-4ef4-a1ed-5a570bc6a04c,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-247bc890-b478-43b7-9b86-6d610c24b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-070cca63-a143-448b-a1f2-4ed5c82fdf97,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-958cdb00-29ca-4571-8b2f-3583795a49fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-7428667c-1285-4848-a00c-6cc4677b23f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-de65cc6c-36f4-44df-88d0-fe43a192bfd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949439747-172.17.0.6-1595289885467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-7469f469-ccc5-46d7-8a2a-02e0a208b3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-0b1353e5-52ac-4c36-9f12-94df00a97126,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-5b4ae246-c80f-445e-8f61-dbb750a63fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-98e97408-be04-4787-b7ef-3c906b0c9d13,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-0fd16be0-1c57-4709-a713-9f62357b3e71,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-9f08d7a8-f08f-43fc-ba66-1d86dae3f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-627595bf-1bba-419d-93ee-93082ba133a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-b097b26b-bfe9-483f-9c6b-d1cec79cbaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949439747-172.17.0.6-1595289885467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-7469f469-ccc5-46d7-8a2a-02e0a208b3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-0b1353e5-52ac-4c36-9f12-94df00a97126,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-5b4ae246-c80f-445e-8f61-dbb750a63fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-98e97408-be04-4787-b7ef-3c906b0c9d13,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-0fd16be0-1c57-4709-a713-9f62357b3e71,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-9f08d7a8-f08f-43fc-ba66-1d86dae3f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-627595bf-1bba-419d-93ee-93082ba133a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-b097b26b-bfe9-483f-9c6b-d1cec79cbaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351788450-172.17.0.6-1595289922832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-e2a621ab-ae3d-4a42-8a11-7d81d17381a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-672c3b2f-2394-4e3e-b007-5bbc68acedee,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-73cb080b-0536-4180-a90c-c9afb20d2b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-8963c615-d782-47e3-b138-3941f344352e,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-83123c84-c0e2-47e8-a547-9afe8a382d12,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-36dd98b4-f17f-4631-8098-e072e594ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-9a7cb508-5e3b-4f41-9d78-3bbe74c8af62,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-d79d7451-2676-46bf-9fbe-7daa0ebbbe5a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351788450-172.17.0.6-1595289922832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-e2a621ab-ae3d-4a42-8a11-7d81d17381a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-672c3b2f-2394-4e3e-b007-5bbc68acedee,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-73cb080b-0536-4180-a90c-c9afb20d2b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-8963c615-d782-47e3-b138-3941f344352e,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-83123c84-c0e2-47e8-a547-9afe8a382d12,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-36dd98b4-f17f-4631-8098-e072e594ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-9a7cb508-5e3b-4f41-9d78-3bbe74c8af62,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-d79d7451-2676-46bf-9fbe-7daa0ebbbe5a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214596545-172.17.0.6-1595290243740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-668e4dec-bcd2-41d9-8d20-c64e3f7fec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-bf60f5d1-ff5d-47f0-b7cd-66aeb7526c42,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-4d4e8191-28a3-488e-8cfa-680404f1075c,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-377723ad-4378-4485-b9f1-c57ee985fad7,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-c8555351-ffd4-4d1c-bc50-328c0862d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-b14e9b8b-ce3d-458d-8d86-469f60c94750,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-5dc0467b-8868-4af3-ba5a-15b82c03d016,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-6b677247-62dc-4e95-9b8b-399c34131ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214596545-172.17.0.6-1595290243740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-668e4dec-bcd2-41d9-8d20-c64e3f7fec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-bf60f5d1-ff5d-47f0-b7cd-66aeb7526c42,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-4d4e8191-28a3-488e-8cfa-680404f1075c,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-377723ad-4378-4485-b9f1-c57ee985fad7,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-c8555351-ffd4-4d1c-bc50-328c0862d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-b14e9b8b-ce3d-458d-8d86-469f60c94750,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-5dc0467b-8868-4af3-ba5a-15b82c03d016,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-6b677247-62dc-4e95-9b8b-399c34131ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415590710-172.17.0.6-1595290307821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34192,DS-2e9af626-4a94-42d0-86fa-536866305c21,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-5de65f2a-05be-44c9-aecb-1b32edec2c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-4c95e3b3-9734-4b74-80bc-333965a80a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-68cfd13e-0c19-4a26-b868-b13e4d587f03,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-2781ad8a-c7c4-400d-8568-64c7ffc17a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-4569dd9a-829e-438d-aced-1db91992ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-e327a723-91bf-44e4-9834-2ce35a7345de,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-ca3e985d-c21a-4a11-9459-65e6fbbc0dd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415590710-172.17.0.6-1595290307821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34192,DS-2e9af626-4a94-42d0-86fa-536866305c21,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-5de65f2a-05be-44c9-aecb-1b32edec2c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-4c95e3b3-9734-4b74-80bc-333965a80a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-68cfd13e-0c19-4a26-b868-b13e4d587f03,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-2781ad8a-c7c4-400d-8568-64c7ffc17a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-4569dd9a-829e-438d-aced-1db91992ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-e327a723-91bf-44e4-9834-2ce35a7345de,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-ca3e985d-c21a-4a11-9459-65e6fbbc0dd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251271481-172.17.0.6-1595290861018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36785,DS-6bfef685-889e-4fe0-b638-cea90fd94160,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-ce7390fb-20d7-4ece-906a-35641c97f70c,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-f325cc72-df58-46c6-b9ae-dfacbb14cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-4f9f85c2-550e-4309-8637-2c58345bda06,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-faa1972f-2c51-4118-adef-0e774af3fd84,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-413ee929-7803-4141-b695-2346e4ebd4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-de62b771-3ef7-4659-949d-5a03a87afeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-252a73fe-e03d-4678-a01b-a3bbf4e7fb84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251271481-172.17.0.6-1595290861018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36785,DS-6bfef685-889e-4fe0-b638-cea90fd94160,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-ce7390fb-20d7-4ece-906a-35641c97f70c,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-f325cc72-df58-46c6-b9ae-dfacbb14cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-4f9f85c2-550e-4309-8637-2c58345bda06,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-faa1972f-2c51-4118-adef-0e774af3fd84,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-413ee929-7803-4141-b695-2346e4ebd4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-de62b771-3ef7-4659-949d-5a03a87afeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-252a73fe-e03d-4678-a01b-a3bbf4e7fb84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097624315-172.17.0.6-1595290906693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-7d9c8db7-e9fa-46d4-972b-e8e72e1cc916,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-bde11e28-0029-4796-930f-390c401056f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cd19b39e-923c-4bbc-a4ea-760086c5f0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-4904f5eb-94e0-4e49-bc94-0cbadb070bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-6c1b397e-ae1d-4bdd-bf07-57b29c9239d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-e08f8155-e1ca-49c6-8de7-67b3ebc673d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-7614d17e-1947-4787-881d-3b55c8baca33,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-21e69c6e-1373-45b0-883e-2892c17a92e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097624315-172.17.0.6-1595290906693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-7d9c8db7-e9fa-46d4-972b-e8e72e1cc916,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-bde11e28-0029-4796-930f-390c401056f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cd19b39e-923c-4bbc-a4ea-760086c5f0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-4904f5eb-94e0-4e49-bc94-0cbadb070bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-6c1b397e-ae1d-4bdd-bf07-57b29c9239d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-e08f8155-e1ca-49c6-8de7-67b3ebc673d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-7614d17e-1947-4787-881d-3b55c8baca33,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-21e69c6e-1373-45b0-883e-2892c17a92e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645490769-172.17.0.6-1595290993350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-5b02be32-e57d-4b07-8a00-53c8508b167c,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-0c0f67e6-4ea1-4fbe-892a-6b7a1ba36727,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-73df997e-7ccc-439d-af7a-dff36dc68d93,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-700ee33b-2a6c-4f4b-a47f-fc0845bc3f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-a93a5680-11d6-4b79-80dd-4b071885a629,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-90e79f40-2372-4ba4-9d61-7bea6c713b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-436fa8a0-922e-4657-ae86-9317de28c005,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-6dd0a5a9-e0e9-4e2c-9f2d-0a9be2ad23e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645490769-172.17.0.6-1595290993350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-5b02be32-e57d-4b07-8a00-53c8508b167c,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-0c0f67e6-4ea1-4fbe-892a-6b7a1ba36727,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-73df997e-7ccc-439d-af7a-dff36dc68d93,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-700ee33b-2a6c-4f4b-a47f-fc0845bc3f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-a93a5680-11d6-4b79-80dd-4b071885a629,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-90e79f40-2372-4ba4-9d61-7bea6c713b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-436fa8a0-922e-4657-ae86-9317de28c005,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-6dd0a5a9-e0e9-4e2c-9f2d-0a9be2ad23e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791434704-172.17.0.6-1595291064177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-6ed8fd00-9ea9-4046-ad9b-56daf94f4781,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-07dca470-11b8-4423-906b-7ccb6bd89fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-f1dca1ad-a5ac-49cc-8e53-4b8db3434b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-dea749b5-d750-4201-a02b-682b75d2910c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d405eb2e-295b-4b8f-8966-b57f1be2c615,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-5ee43103-a03c-4c39-94ed-45253f21de57,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-d380e36b-ed9a-4be4-a34c-37fd55d423bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-12d9f77a-5753-40f1-b187-9d5661edfff3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791434704-172.17.0.6-1595291064177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-6ed8fd00-9ea9-4046-ad9b-56daf94f4781,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-07dca470-11b8-4423-906b-7ccb6bd89fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-f1dca1ad-a5ac-49cc-8e53-4b8db3434b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-dea749b5-d750-4201-a02b-682b75d2910c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d405eb2e-295b-4b8f-8966-b57f1be2c615,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-5ee43103-a03c-4c39-94ed-45253f21de57,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-d380e36b-ed9a-4be4-a34c-37fd55d423bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-12d9f77a-5753-40f1-b187-9d5661edfff3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31676641-172.17.0.6-1595291104741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-a8f2a50e-f7b6-423e-ad29-8c2bafe4e255,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-e3072336-6f13-4978-8fe2-2b06eb3c9f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-70434f59-b56d-47f9-9932-d7ec365525d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-80dcf46e-b53a-4461-9452-b0738dd8ae55,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-31a2082e-6b41-44b4-9c02-d3c418978df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-c8e2d605-f3e7-4df4-b776-0e6d30d6b723,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-216d995c-e2d7-44bb-b5be-ae3ce17c4eca,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-2e3b72dd-5344-4bcb-9f13-dee7fca5024a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31676641-172.17.0.6-1595291104741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-a8f2a50e-f7b6-423e-ad29-8c2bafe4e255,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-e3072336-6f13-4978-8fe2-2b06eb3c9f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-70434f59-b56d-47f9-9932-d7ec365525d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-80dcf46e-b53a-4461-9452-b0738dd8ae55,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-31a2082e-6b41-44b4-9c02-d3c418978df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-c8e2d605-f3e7-4df4-b776-0e6d30d6b723,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-216d995c-e2d7-44bb-b5be-ae3ce17c4eca,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-2e3b72dd-5344-4bcb-9f13-dee7fca5024a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997732216-172.17.0.6-1595291168527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37227,DS-7c3de44f-ff44-4b36-8ada-aeee18458a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-ab52681e-8c04-4b50-be28-12bd90ab0239,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-8245a6cf-29ef-49d9-9d72-bb7f9c6a75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-dc75771e-8b8e-4934-af24-573b6412f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-4b626161-ac0c-4b61-8ab1-8ddec2cdf52f,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-8e70c7ba-6a8b-46a2-af65-93cc5e0d86ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-6d8ef6eb-d3a2-4f9f-9d34-a67ecf0cbbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-6bb8c447-8169-4a30-a862-546677b2ab1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997732216-172.17.0.6-1595291168527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37227,DS-7c3de44f-ff44-4b36-8ada-aeee18458a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-ab52681e-8c04-4b50-be28-12bd90ab0239,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-8245a6cf-29ef-49d9-9d72-bb7f9c6a75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-dc75771e-8b8e-4934-af24-573b6412f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-4b626161-ac0c-4b61-8ab1-8ddec2cdf52f,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-8e70c7ba-6a8b-46a2-af65-93cc5e0d86ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-6d8ef6eb-d3a2-4f9f-9d34-a67ecf0cbbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-6bb8c447-8169-4a30-a862-546677b2ab1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762004623-172.17.0.6-1595291354189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-660688f0-8457-4024-9834-be555d7f9e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-d20d8d1f-b9f7-4111-8466-9de613fa395b,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-545fe7b3-fbd6-4767-a0d0-79fc3e8a77e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-526a4325-4f21-40e8-bdfc-c194a6239886,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-c65a6798-3267-4d6d-9175-5b0c26f41746,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-f57d758c-ec21-4a7a-806c-cf99bd0a58b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-3283b03f-1ca7-45c8-8f30-0f65ee23f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-89f3c871-6dad-445b-9161-5175cafb8957,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762004623-172.17.0.6-1595291354189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-660688f0-8457-4024-9834-be555d7f9e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-d20d8d1f-b9f7-4111-8466-9de613fa395b,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-545fe7b3-fbd6-4767-a0d0-79fc3e8a77e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-526a4325-4f21-40e8-bdfc-c194a6239886,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-c65a6798-3267-4d6d-9175-5b0c26f41746,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-f57d758c-ec21-4a7a-806c-cf99bd0a58b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-3283b03f-1ca7-45c8-8f30-0f65ee23f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-89f3c871-6dad-445b-9161-5175cafb8957,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033186708-172.17.0.6-1595291532137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-7f1c4723-2f52-4c9f-8ec0-acdc4ab5d2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-bd1f2a28-4abd-4c94-a56c-3c453dfe815f,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-862e881b-13d9-46b3-8f5f-10b524f83cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-ba1a45b6-2fe3-4d3e-8030-2889a49080c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-7ac3af64-9f0f-45dd-9241-d980aed16f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-14456e5f-1f80-4278-9c53-2f111e82f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-f1e7a193-054c-4b30-8fe7-81c4f983dac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-ffbfecb0-cdcc-4410-ad3f-35939b24c1e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033186708-172.17.0.6-1595291532137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44470,DS-7f1c4723-2f52-4c9f-8ec0-acdc4ab5d2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-bd1f2a28-4abd-4c94-a56c-3c453dfe815f,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-862e881b-13d9-46b3-8f5f-10b524f83cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-ba1a45b6-2fe3-4d3e-8030-2889a49080c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-7ac3af64-9f0f-45dd-9241-d980aed16f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-14456e5f-1f80-4278-9c53-2f111e82f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-f1e7a193-054c-4b30-8fe7-81c4f983dac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-ffbfecb0-cdcc-4410-ad3f-35939b24c1e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20839347-172.17.0.6-1595291899753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-f321048c-4ec5-4ab0-8bc0-fbbc29804420,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-3dbf1341-a366-4fd7-a5b8-e25a8f977c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-8ca1ce98-5c8d-44a6-9b3e-7bf71d7315c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-81825921-12fd-4885-99f2-239254c19047,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-cac98ebd-b69d-4a92-859e-003dc06419df,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-0399446a-6827-469d-994f-7e6af97940c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-3f5adfec-13fd-4465-8615-b443a0a7146d,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-8314ee44-ca0e-4f4b-985c-aa59f16e08fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20839347-172.17.0.6-1595291899753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-f321048c-4ec5-4ab0-8bc0-fbbc29804420,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-3dbf1341-a366-4fd7-a5b8-e25a8f977c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-8ca1ce98-5c8d-44a6-9b3e-7bf71d7315c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-81825921-12fd-4885-99f2-239254c19047,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-cac98ebd-b69d-4a92-859e-003dc06419df,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-0399446a-6827-469d-994f-7e6af97940c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-3f5adfec-13fd-4465-8615-b443a0a7146d,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-8314ee44-ca0e-4f4b-985c-aa59f16e08fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109045858-172.17.0.6-1595291969940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-bdf311c4-3b40-4278-a8b5-13822c4ebfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-24a201f7-95b4-4d24-89ed-133e8fb98abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-e2d4eac6-a447-43f6-aa34-59f09d726413,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-f772b358-038b-4499-a182-7f87f323a8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-a4a67c21-c098-4124-b9d1-99201854e83f,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-b03b0534-5032-44a1-af86-a34be5b3a0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-afff98ed-fb5b-49e3-9fae-4a10185e2d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-eb0139e8-e9f2-4385-ae9b-d24285040f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109045858-172.17.0.6-1595291969940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-bdf311c4-3b40-4278-a8b5-13822c4ebfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-24a201f7-95b4-4d24-89ed-133e8fb98abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-e2d4eac6-a447-43f6-aa34-59f09d726413,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-f772b358-038b-4499-a182-7f87f323a8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-a4a67c21-c098-4124-b9d1-99201854e83f,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-b03b0534-5032-44a1-af86-a34be5b3a0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-afff98ed-fb5b-49e3-9fae-4a10185e2d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-eb0139e8-e9f2-4385-ae9b-d24285040f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411866749-172.17.0.6-1595292005408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34477,DS-52860913-af69-45d9-8200-bd92a3c3eb02,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-47440f7b-2fae-4e95-8ce2-c5cf3aeacb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-f022e535-a154-45ba-89b3-5d95fc4117b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-19748e3f-7afb-4a47-9d2c-7e71d8ae4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-c0690086-6fac-4a71-8260-1cad7bd31e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-f46c41ae-933a-4b1f-b62f-491bd65f41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-de0d8baf-a1d1-4556-a114-6eb09122b284,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-f5e97d80-4a70-41d8-ba35-99b9ff60cb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411866749-172.17.0.6-1595292005408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34477,DS-52860913-af69-45d9-8200-bd92a3c3eb02,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-47440f7b-2fae-4e95-8ce2-c5cf3aeacb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-f022e535-a154-45ba-89b3-5d95fc4117b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-19748e3f-7afb-4a47-9d2c-7e71d8ae4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-c0690086-6fac-4a71-8260-1cad7bd31e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-f46c41ae-933a-4b1f-b62f-491bd65f41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-de0d8baf-a1d1-4556-a114-6eb09122b284,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-f5e97d80-4a70-41d8-ba35-99b9ff60cb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381925399-172.17.0.6-1595292285831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-9310680c-3e1d-4229-99ee-607b479bc4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-3d022b5c-f43a-428e-ad80-58f31c61745c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-937e3b9a-1dcc-4e5c-9a5b-078867c2419d,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-51841129-b046-464c-ad26-97743dccf34f,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-2b61b940-68f8-4acd-9bd7-0f922153db72,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-9c6cb478-a9a9-4011-9353-31d5cc6a4647,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-3777c7e5-af7f-49e4-92f0-fc055fe73afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-8de3f633-8c60-42b1-a8b1-015c591e92d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381925399-172.17.0.6-1595292285831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-9310680c-3e1d-4229-99ee-607b479bc4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-3d022b5c-f43a-428e-ad80-58f31c61745c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-937e3b9a-1dcc-4e5c-9a5b-078867c2419d,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-51841129-b046-464c-ad26-97743dccf34f,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-2b61b940-68f8-4acd-9bd7-0f922153db72,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-9c6cb478-a9a9-4011-9353-31d5cc6a4647,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-3777c7e5-af7f-49e4-92f0-fc055fe73afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-8de3f633-8c60-42b1-a8b1-015c591e92d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127319290-172.17.0.6-1595292319833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36562,DS-1f2db44f-53d2-47ec-88f0-81aabd4e95b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-ee0f8b82-9137-4ca5-8804-d26829a48122,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-2443cd7a-65db-442b-8890-67185e830252,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-1417cea7-a8c5-4e73-8ba3-2cf45f39317e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-83213b74-c65c-4960-a24b-4a1bb4fcc9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-6e7601fa-9dd8-4fa1-a5cd-654ea85e838b,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-fce96a21-8631-44e4-afa0-5c31e2d16bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-388e4c0c-a094-4716-a52a-44d9d6c515af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127319290-172.17.0.6-1595292319833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36562,DS-1f2db44f-53d2-47ec-88f0-81aabd4e95b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-ee0f8b82-9137-4ca5-8804-d26829a48122,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-2443cd7a-65db-442b-8890-67185e830252,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-1417cea7-a8c5-4e73-8ba3-2cf45f39317e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-83213b74-c65c-4960-a24b-4a1bb4fcc9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-6e7601fa-9dd8-4fa1-a5cd-654ea85e838b,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-fce96a21-8631-44e4-afa0-5c31e2d16bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-388e4c0c-a094-4716-a52a-44d9d6c515af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873919242-172.17.0.6-1595292349073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46230,DS-308ac491-8cf0-4967-b2e0-5e73c303e651,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-de1067f0-5180-4c7b-9f11-f2ad0cecd414,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-bd33ba9b-02d0-4efb-ab14-552f6cfb831b,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-d5f1d4ff-4bee-4c34-a5e5-bb3bbc80f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-4dbc704e-d71a-462e-b78c-a611737d4dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-ba4dff0a-62c6-48d0-9690-cde4427d2713,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-2e773d38-f15f-438b-bd77-8114fcabc65b,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-54ef8274-c2f9-40ca-83b3-5f9d3502f42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873919242-172.17.0.6-1595292349073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46230,DS-308ac491-8cf0-4967-b2e0-5e73c303e651,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-de1067f0-5180-4c7b-9f11-f2ad0cecd414,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-bd33ba9b-02d0-4efb-ab14-552f6cfb831b,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-d5f1d4ff-4bee-4c34-a5e5-bb3bbc80f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-4dbc704e-d71a-462e-b78c-a611737d4dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-ba4dff0a-62c6-48d0-9690-cde4427d2713,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-2e773d38-f15f-438b-bd77-8114fcabc65b,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-54ef8274-c2f9-40ca-83b3-5f9d3502f42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190921364-172.17.0.6-1595292468548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44698,DS-598a8a60-cb60-40f4-bf13-89720ee981bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-e4a6e556-5508-4017-b3ec-03e6563a4bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-d9d8218d-d883-4bf5-9249-24b7c12ac15a,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-e487f15e-0fe4-43d3-bead-e4071b23fdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-8e93e186-bff9-4ce2-acf8-59c416db627a,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-e5b878cb-f2a4-48c6-8a95-3105fc98bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-25e46602-717b-470c-82f1-38c180ee1dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-3989fd6f-8c34-41a7-9645-71d2e19bc780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190921364-172.17.0.6-1595292468548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44698,DS-598a8a60-cb60-40f4-bf13-89720ee981bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-e4a6e556-5508-4017-b3ec-03e6563a4bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-d9d8218d-d883-4bf5-9249-24b7c12ac15a,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-e487f15e-0fe4-43d3-bead-e4071b23fdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-8e93e186-bff9-4ce2-acf8-59c416db627a,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-e5b878cb-f2a4-48c6-8a95-3105fc98bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-25e46602-717b-470c-82f1-38c180ee1dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-3989fd6f-8c34-41a7-9645-71d2e19bc780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484983377-172.17.0.6-1595292503573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34256,DS-897c413a-9a2e-40dc-977d-341f098e0f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-b2c1c201-e9cc-4555-af1d-a6b59a42acc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-50b1e9cf-bbf0-4634-aeea-19cfb4b3c150,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-fe0e9442-d69d-444e-9ceb-d6e74fbba68f,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-7a43e712-7ffd-4bc9-92b3-ad6364df4997,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-899052d9-c523-4278-8cea-9224a95cefcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-d3e2d337-2ee4-4762-91b6-e1fbcdf46b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-bc7da598-254b-440c-a2d1-fd63acc2b24b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484983377-172.17.0.6-1595292503573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34256,DS-897c413a-9a2e-40dc-977d-341f098e0f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-b2c1c201-e9cc-4555-af1d-a6b59a42acc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-50b1e9cf-bbf0-4634-aeea-19cfb4b3c150,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-fe0e9442-d69d-444e-9ceb-d6e74fbba68f,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-7a43e712-7ffd-4bc9-92b3-ad6364df4997,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-899052d9-c523-4278-8cea-9224a95cefcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-d3e2d337-2ee4-4762-91b6-e1fbcdf46b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-bc7da598-254b-440c-a2d1-fd63acc2b24b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589135926-172.17.0.6-1595292620423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-b6c188e5-2a93-4ca2-934e-d91d28c500de,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-4e3daca4-0208-4dad-9360-d9dadb16a1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-555712fa-74de-4ebd-a419-e0ae4d511185,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-c0375fcd-83c9-489e-996c-919a3e830cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-fc8e3df5-91e3-4bcb-ac77-2dd0d89976d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-df27f23d-dee0-4378-bdbf-b2595e0e6080,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-29fe5c79-4c66-434b-8a15-474b2ad8c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-903ef43f-4f09-474e-b9b6-ff1f60152309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589135926-172.17.0.6-1595292620423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-b6c188e5-2a93-4ca2-934e-d91d28c500de,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-4e3daca4-0208-4dad-9360-d9dadb16a1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-555712fa-74de-4ebd-a419-e0ae4d511185,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-c0375fcd-83c9-489e-996c-919a3e830cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-fc8e3df5-91e3-4bcb-ac77-2dd0d89976d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-df27f23d-dee0-4378-bdbf-b2595e0e6080,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-29fe5c79-4c66-434b-8a15-474b2ad8c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-903ef43f-4f09-474e-b9b6-ff1f60152309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016443114-172.17.0.6-1595292659699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-77f4af1e-ba87-499f-bf60-13b3ea7dcbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-d896ee41-b6dc-4985-a7a8-ea213d449067,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-61e31131-83ca-409e-80c2-5f48b087ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-48ab0faa-7ca1-4ef7-a5af-40bc74709ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-0ba5bec2-f494-410c-9425-33ea9877ae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-57f67d8b-bdd9-4b8b-9dc9-1be440d88205,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-80e4618c-5fd2-4879-9785-73ca9fe41385,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-316d0eff-55c6-4af8-8ee5-7ced7f42101f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016443114-172.17.0.6-1595292659699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-77f4af1e-ba87-499f-bf60-13b3ea7dcbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-d896ee41-b6dc-4985-a7a8-ea213d449067,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-61e31131-83ca-409e-80c2-5f48b087ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-48ab0faa-7ca1-4ef7-a5af-40bc74709ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-0ba5bec2-f494-410c-9425-33ea9877ae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-57f67d8b-bdd9-4b8b-9dc9-1be440d88205,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-80e4618c-5fd2-4879-9785-73ca9fe41385,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-316d0eff-55c6-4af8-8ee5-7ced7f42101f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227312023-172.17.0.6-1595292727005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41950,DS-e28a2528-79b9-449d-af51-dc6530b25c23,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-8d6c3b73-6d7d-4c4b-ac19-65c11dc07149,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-d2c5fbad-9fe0-4a44-b1b6-a2e1d2964772,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-92d0b610-b997-44ef-aa30-3361229cd828,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-7133cfe5-e875-47da-9cd4-7c606682280b,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-8f9c0bb4-9f0e-489a-8cae-b266f13e6151,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-9e2d1b25-1854-40a3-bab9-7b20f8d8aabb,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-4d36fa1c-8d15-417e-bfe0-4c101563b135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227312023-172.17.0.6-1595292727005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41950,DS-e28a2528-79b9-449d-af51-dc6530b25c23,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-8d6c3b73-6d7d-4c4b-ac19-65c11dc07149,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-d2c5fbad-9fe0-4a44-b1b6-a2e1d2964772,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-92d0b610-b997-44ef-aa30-3361229cd828,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-7133cfe5-e875-47da-9cd4-7c606682280b,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-8f9c0bb4-9f0e-489a-8cae-b266f13e6151,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-9e2d1b25-1854-40a3-bab9-7b20f8d8aabb,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-4d36fa1c-8d15-417e-bfe0-4c101563b135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715065603-172.17.0.6-1595292761781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-b9c431f3-3de6-4834-a453-18b63d8bd475,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-35b582a9-4f78-4a29-8c41-62fc2ad280dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-630dbfe6-8749-459e-9a17-51cd307c9aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4dadda0e-6af5-489f-bfe1-fb31801a4bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-449bfdf5-33f3-436f-9753-378dbf138dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-46e67546-193f-4fc5-ad21-842e0093cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-870f1c7f-989e-49fa-a8b9-213e12662212,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-6c359221-5edd-4a9b-a206-df5995442aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715065603-172.17.0.6-1595292761781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-b9c431f3-3de6-4834-a453-18b63d8bd475,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-35b582a9-4f78-4a29-8c41-62fc2ad280dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-630dbfe6-8749-459e-9a17-51cd307c9aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4dadda0e-6af5-489f-bfe1-fb31801a4bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-449bfdf5-33f3-436f-9753-378dbf138dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-46e67546-193f-4fc5-ad21-842e0093cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-870f1c7f-989e-49fa-a8b9-213e12662212,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-6c359221-5edd-4a9b-a206-df5995442aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969597675-172.17.0.6-1595292945939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44852,DS-5202a1c8-1fa8-480a-add3-5ba17e846686,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-189e5cdf-c007-4cb6-af31-10099416a414,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-c41f7da6-a50c-4daf-bc10-9d159f30a266,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-82479506-68df-4ee0-9b60-aefb393eb347,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-6351c5d5-784c-4068-b3fd-301812752e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-b5b8e618-17b7-4881-a983-70baf9b2714f,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-f1c0af45-bd84-47dd-b994-3f57f22f83c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-5a77f07e-cfdb-423a-856a-eea807b1e4d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969597675-172.17.0.6-1595292945939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44852,DS-5202a1c8-1fa8-480a-add3-5ba17e846686,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-189e5cdf-c007-4cb6-af31-10099416a414,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-c41f7da6-a50c-4daf-bc10-9d159f30a266,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-82479506-68df-4ee0-9b60-aefb393eb347,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-6351c5d5-784c-4068-b3fd-301812752e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-b5b8e618-17b7-4881-a983-70baf9b2714f,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-f1c0af45-bd84-47dd-b994-3f57f22f83c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-5a77f07e-cfdb-423a-856a-eea807b1e4d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493529298-172.17.0.6-1595293100687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-a8ee5648-9807-4e30-9fca-9f5e03dea663,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-9b6fa1f0-bfe3-4283-99f1-ec54c3b7d722,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-089df660-17ae-45e8-8125-1a3c6aa8037c,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-f1be6be6-5b11-4e6e-b969-b5d087f682f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-f5217674-2ae6-4de2-acc2-e3f92b8d63f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-bb0f0e6b-00a9-43d1-828b-98f1241ebb81,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-b938b933-5464-4e78-a2b5-37d47bc386cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-36d9db9e-9b45-4c41-9cea-6739cb02dd9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493529298-172.17.0.6-1595293100687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-a8ee5648-9807-4e30-9fca-9f5e03dea663,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-9b6fa1f0-bfe3-4283-99f1-ec54c3b7d722,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-089df660-17ae-45e8-8125-1a3c6aa8037c,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-f1be6be6-5b11-4e6e-b969-b5d087f682f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-f5217674-2ae6-4de2-acc2-e3f92b8d63f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-bb0f0e6b-00a9-43d1-828b-98f1241ebb81,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-b938b933-5464-4e78-a2b5-37d47bc386cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-36d9db9e-9b45-4c41-9cea-6739cb02dd9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756207947-172.17.0.6-1595293445421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-7fbd35c5-4980-4f68-86d6-801aead9354a,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-a2e9274f-d7d8-4c0c-a791-2d1d8db0e24a,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-a5263f0a-46b6-4e5f-bf5e-8d47d6f69f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-9a589d9e-4f90-45dc-8dd5-ebc9a84758d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-8a905400-5f99-4a70-b62d-e1fb4033ab11,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-cb4fd6ba-0696-4351-b8e0-63c551c8df57,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-02630084-e5ca-4b41-85d8-c7f6a1df38c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-c1c31b7d-b183-486e-8e00-d2c0d59c56df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756207947-172.17.0.6-1595293445421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-7fbd35c5-4980-4f68-86d6-801aead9354a,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-a2e9274f-d7d8-4c0c-a791-2d1d8db0e24a,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-a5263f0a-46b6-4e5f-bf5e-8d47d6f69f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-9a589d9e-4f90-45dc-8dd5-ebc9a84758d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-8a905400-5f99-4a70-b62d-e1fb4033ab11,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-cb4fd6ba-0696-4351-b8e0-63c551c8df57,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-02630084-e5ca-4b41-85d8-c7f6a1df38c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-c1c31b7d-b183-486e-8e00-d2c0d59c56df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780135272-172.17.0.6-1595293500330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35349,DS-32af5a9f-0842-4f7a-8c76-9213bd0650e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-f7a803e6-a98d-4cb2-bad4-24f4fc517472,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-ad7d5e63-eff7-42b1-bacb-5c6fe1512edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-b4c35e72-a426-4069-b5bc-22cbb04022ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-26549395-19e1-4179-88e6-68cbd6753c17,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-3bea1d1f-16d8-493c-83e2-52a64c24ef20,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-8d10d609-f53c-45d3-a148-1d211a6a28f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-884972af-04f1-40f2-b686-fefc0bf9ff05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780135272-172.17.0.6-1595293500330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35349,DS-32af5a9f-0842-4f7a-8c76-9213bd0650e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-f7a803e6-a98d-4cb2-bad4-24f4fc517472,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-ad7d5e63-eff7-42b1-bacb-5c6fe1512edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-b4c35e72-a426-4069-b5bc-22cbb04022ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-26549395-19e1-4179-88e6-68cbd6753c17,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-3bea1d1f-16d8-493c-83e2-52a64c24ef20,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-8d10d609-f53c-45d3-a148-1d211a6a28f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-884972af-04f1-40f2-b686-fefc0bf9ff05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863884934-172.17.0.6-1595293575827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33674,DS-9bc4a492-d8d3-401d-a3bf-93c2a3fecb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-0fb0cd97-397e-4379-bfb3-f9c77ccf0977,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-7f51faa1-47ec-4022-9cec-88631674a501,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-c9d8fdf7-29cb-4ea7-9dd7-a54a35eede80,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-e5b9029e-e73c-4eac-9c10-80c4bfeb726e,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-ec87d8d7-29b9-4c77-a102-4f6a02a438b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-75c4c8a8-48a5-425f-9b4d-e151196c8cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-6c405580-6307-417c-b214-cdf24447411f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863884934-172.17.0.6-1595293575827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33674,DS-9bc4a492-d8d3-401d-a3bf-93c2a3fecb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-0fb0cd97-397e-4379-bfb3-f9c77ccf0977,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-7f51faa1-47ec-4022-9cec-88631674a501,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-c9d8fdf7-29cb-4ea7-9dd7-a54a35eede80,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-e5b9029e-e73c-4eac-9c10-80c4bfeb726e,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-ec87d8d7-29b9-4c77-a102-4f6a02a438b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-75c4c8a8-48a5-425f-9b4d-e151196c8cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-6c405580-6307-417c-b214-cdf24447411f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145959802-172.17.0.6-1595293697766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44329,DS-ef5fe1b8-0649-417e-b10c-e7133fbd0ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-bf0209e3-0ea3-4c36-b8d2-dcedd43c6bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-7a8a2593-8273-4a67-b867-b83e38cb9b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-a84e006e-a7ec-4325-855c-3f1821955dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-be1a7c96-2fa6-4d77-bd76-590c0b58e5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-7a2ce586-82ce-4548-b75d-f5f39be3d249,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-311dc358-e6e3-4cd8-a145-7b7ca4c42748,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-abea1c75-2e04-4171-b1f9-280c8057a0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145959802-172.17.0.6-1595293697766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44329,DS-ef5fe1b8-0649-417e-b10c-e7133fbd0ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-bf0209e3-0ea3-4c36-b8d2-dcedd43c6bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-7a8a2593-8273-4a67-b867-b83e38cb9b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-a84e006e-a7ec-4325-855c-3f1821955dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-be1a7c96-2fa6-4d77-bd76-590c0b58e5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-7a2ce586-82ce-4548-b75d-f5f39be3d249,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-311dc358-e6e3-4cd8-a145-7b7ca4c42748,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-abea1c75-2e04-4171-b1f9-280c8057a0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906816549-172.17.0.6-1595293844100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-13f3da7b-1d77-47f2-9a41-5cd1d9da79c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-f190e4fc-751e-41d8-912a-5ef831ca2ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-90a0ec99-8d6c-4a0d-a286-d6a8dde8be01,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-3396efaf-0f02-407d-a369-0d17e07cf062,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-adb00970-bec3-495f-9ccd-065897fa396a,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-585bb78e-6b0c-42ad-bc33-478833ef6a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-7b8ecd9f-7805-414c-8a61-957d9b679b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-7a553edb-dc25-4650-9ffa-4f9f2a89f10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906816549-172.17.0.6-1595293844100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-13f3da7b-1d77-47f2-9a41-5cd1d9da79c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-f190e4fc-751e-41d8-912a-5ef831ca2ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-90a0ec99-8d6c-4a0d-a286-d6a8dde8be01,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-3396efaf-0f02-407d-a369-0d17e07cf062,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-adb00970-bec3-495f-9ccd-065897fa396a,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-585bb78e-6b0c-42ad-bc33-478833ef6a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-7b8ecd9f-7805-414c-8a61-957d9b679b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-7a553edb-dc25-4650-9ffa-4f9f2a89f10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851422079-172.17.0.6-1595293976873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40217,DS-a35266d9-74a5-4a0c-997b-d3f7a0610fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-fb4c7532-1821-4adb-b8ad-214b976be917,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-1ee9d9fc-506c-4ed4-b830-76f74ab809bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-7692e91f-5f0e-4373-90a6-79f5165697f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-1d246f15-2c73-4e76-9c6a-890384fc813e,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-0cb439d7-7c37-4543-8b19-bd62a90a1dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-e6666180-a353-481f-bf3e-1b8338470cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-6f19bfca-7da8-4a60-8e48-427c3459d380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851422079-172.17.0.6-1595293976873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40217,DS-a35266d9-74a5-4a0c-997b-d3f7a0610fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-fb4c7532-1821-4adb-b8ad-214b976be917,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-1ee9d9fc-506c-4ed4-b830-76f74ab809bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-7692e91f-5f0e-4373-90a6-79f5165697f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-1d246f15-2c73-4e76-9c6a-890384fc813e,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-0cb439d7-7c37-4543-8b19-bd62a90a1dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-e6666180-a353-481f-bf3e-1b8338470cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-6f19bfca-7da8-4a60-8e48-427c3459d380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835903624-172.17.0.6-1595294151081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43654,DS-e20a4555-bc0f-4a21-a7b0-858a401c56de,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-414acbdd-e67f-4385-8c76-26f2acc08656,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-4572d2ea-4bb6-456b-8afc-daa2e930f8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-e7a79d06-3f2d-413f-8394-b616d64d7018,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-876d16e7-e791-4d05-90b6-73638a37d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-5b74de5e-52f4-4e51-8bc8-7249b4b7230d,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-af44181d-7551-433c-b231-167909281780,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-449ce88f-93a2-4591-bb11-e1a1a1e76e1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835903624-172.17.0.6-1595294151081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43654,DS-e20a4555-bc0f-4a21-a7b0-858a401c56de,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-414acbdd-e67f-4385-8c76-26f2acc08656,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-4572d2ea-4bb6-456b-8afc-daa2e930f8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-e7a79d06-3f2d-413f-8394-b616d64d7018,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-876d16e7-e791-4d05-90b6-73638a37d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-5b74de5e-52f4-4e51-8bc8-7249b4b7230d,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-af44181d-7551-433c-b231-167909281780,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-449ce88f-93a2-4591-bb11-e1a1a1e76e1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251957173-172.17.0.6-1595294421826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-53b4c335-ff30-43d3-8b12-e4aa02680739,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-5d47d86d-87cc-4044-a152-33d982aea24a,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-43eeebe9-6132-4fe3-8b25-d57e92bf8745,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-1afd5c0e-622f-4583-9878-d62211b40009,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-6abd3b2e-f641-403f-85d7-d1cc74f3243b,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-14834cca-5529-4490-9c15-eb3b3a940498,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-93a942ea-60e6-46ce-9469-5a1eefa4a618,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-d653d4f5-67bb-4470-b40c-d9a3fb30a1be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251957173-172.17.0.6-1595294421826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-53b4c335-ff30-43d3-8b12-e4aa02680739,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-5d47d86d-87cc-4044-a152-33d982aea24a,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-43eeebe9-6132-4fe3-8b25-d57e92bf8745,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-1afd5c0e-622f-4583-9878-d62211b40009,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-6abd3b2e-f641-403f-85d7-d1cc74f3243b,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-14834cca-5529-4490-9c15-eb3b3a940498,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-93a942ea-60e6-46ce-9469-5a1eefa4a618,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-d653d4f5-67bb-4470-b40c-d9a3fb30a1be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55061158-172.17.0.6-1595294640954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33054,DS-80317eab-f37d-4654-81ad-9f52a7d40099,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-9688066d-f6bb-421e-8872-658352b46ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-3d82a03c-7f4d-4492-a75b-e0bce606299e,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-f06f5b83-5ee4-4ecf-a355-f23b9bbc3666,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-3ec04cd7-6679-4331-b09f-7d11b91673ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-4de0bd18-70e9-4bf9-a34f-5d2cbe3dceef,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-a2674e4c-f907-4f35-8cb9-4e230c07acd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-e40b1267-624c-4894-be35-a73639cbc71e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55061158-172.17.0.6-1595294640954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33054,DS-80317eab-f37d-4654-81ad-9f52a7d40099,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-9688066d-f6bb-421e-8872-658352b46ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-3d82a03c-7f4d-4492-a75b-e0bce606299e,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-f06f5b83-5ee4-4ecf-a355-f23b9bbc3666,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-3ec04cd7-6679-4331-b09f-7d11b91673ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-4de0bd18-70e9-4bf9-a34f-5d2cbe3dceef,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-a2674e4c-f907-4f35-8cb9-4e230c07acd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-e40b1267-624c-4894-be35-a73639cbc71e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030477782-172.17.0.6-1595294723350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41041,DS-264555bc-214a-4aec-b6f0-54e9f06e0101,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-010249f5-b0db-4531-9136-e09e4356ead5,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-b4329e1e-0653-4a1f-8166-2a48f49f36a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-ad23c627-229d-4e90-a039-243122dab675,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-62ca3c67-f817-4099-86b0-0f64550cd2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-662eacd8-a366-40c5-9727-4a43ef8ae796,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-fc98b433-ccf8-498d-a973-d55904078657,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-738c39f5-9eef-44f3-b0b0-1ebdf516c2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030477782-172.17.0.6-1595294723350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41041,DS-264555bc-214a-4aec-b6f0-54e9f06e0101,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-010249f5-b0db-4531-9136-e09e4356ead5,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-b4329e1e-0653-4a1f-8166-2a48f49f36a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-ad23c627-229d-4e90-a039-243122dab675,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-62ca3c67-f817-4099-86b0-0f64550cd2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-662eacd8-a366-40c5-9727-4a43ef8ae796,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-fc98b433-ccf8-498d-a973-d55904078657,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-738c39f5-9eef-44f3-b0b0-1ebdf516c2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689486217-172.17.0.6-1595294831009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-d4fbd2cf-f09d-4624-b32d-41041d310f94,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-713d1d4b-4e92-4ee1-b9c2-f6582257de42,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-d7f9cd84-056c-4ea3-ab38-70b5639f9029,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-df888bc4-83d1-4388-ae2d-25ccc123142d,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-69ce0353-3c63-4512-9427-26df01c8a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-b839fca4-c52d-47a6-94a6-9ba83b01e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-dcd3f5a7-9f3e-4248-b642-82c4894e24f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-0c21c1b3-dcc9-4db5-87b7-d14daf3539fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689486217-172.17.0.6-1595294831009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-d4fbd2cf-f09d-4624-b32d-41041d310f94,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-713d1d4b-4e92-4ee1-b9c2-f6582257de42,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-d7f9cd84-056c-4ea3-ab38-70b5639f9029,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-df888bc4-83d1-4388-ae2d-25ccc123142d,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-69ce0353-3c63-4512-9427-26df01c8a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-b839fca4-c52d-47a6-94a6-9ba83b01e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-dcd3f5a7-9f3e-4248-b642-82c4894e24f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-0c21c1b3-dcc9-4db5-87b7-d14daf3539fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 5547
