reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204436905-172.17.0.13-1595959929748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43608,DS-277a83eb-7c56-4075-9816-40242d40e424,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-cbc29bbe-d9a4-458d-8d49-3cb829053e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-44179dae-660a-438e-8955-046845de8837,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-8f4b02f1-977f-4ca5-bb16-0b6329bc7ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-af855ebc-df73-45fe-a15c-d762c1150ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-711a890d-804d-40c5-b6a4-4d48d9353955,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-90640d19-c2c7-48a7-91e4-b9035d0318a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-af474d51-227b-4850-8601-218581b4150f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204436905-172.17.0.13-1595959929748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43608,DS-277a83eb-7c56-4075-9816-40242d40e424,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-cbc29bbe-d9a4-458d-8d49-3cb829053e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-44179dae-660a-438e-8955-046845de8837,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-8f4b02f1-977f-4ca5-bb16-0b6329bc7ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-af855ebc-df73-45fe-a15c-d762c1150ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-711a890d-804d-40c5-b6a4-4d48d9353955,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-90640d19-c2c7-48a7-91e4-b9035d0318a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-af474d51-227b-4850-8601-218581b4150f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741821842-172.17.0.13-1595960405207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41324,DS-55825019-b3ab-4a8c-bd0c-a25b9b0345f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-5ef3b81b-8425-4d68-9e87-817af42feecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-9284d3d0-1956-48a6-88d3-720a34d91ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-10af7d7c-6361-457f-b0d4-6635b12bc3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-37eee17b-b3d9-4323-b332-457b21c49a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-108fa513-8b8e-4fdf-8d56-df13d2067507,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-2104ef27-29e7-44c6-9621-ac3668ef4ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-e03b721f-b245-470c-8b1a-89385d45bbf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741821842-172.17.0.13-1595960405207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41324,DS-55825019-b3ab-4a8c-bd0c-a25b9b0345f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-5ef3b81b-8425-4d68-9e87-817af42feecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-9284d3d0-1956-48a6-88d3-720a34d91ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-10af7d7c-6361-457f-b0d4-6635b12bc3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-37eee17b-b3d9-4323-b332-457b21c49a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-108fa513-8b8e-4fdf-8d56-df13d2067507,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-2104ef27-29e7-44c6-9621-ac3668ef4ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-e03b721f-b245-470c-8b1a-89385d45bbf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734650786-172.17.0.13-1595960702185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45394,DS-8e201299-df0d-4bc1-81f5-8b591a3d0be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-7939e16f-d870-4b6e-b5f3-3d05d1596b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-db29bd95-56de-4ad8-9db2-d98e7e3a98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-71387170-1adc-48e9-9aed-8533809e9725,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-51028d9c-b234-4fa4-9883-1c174644c392,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-0083a7c3-db92-404d-8793-ea5953b9860b,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-0d60c081-b53c-489e-813e-6e6af842d300,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-2c41a7c5-c797-4c43-b510-d1809b7dcb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734650786-172.17.0.13-1595960702185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45394,DS-8e201299-df0d-4bc1-81f5-8b591a3d0be4,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-7939e16f-d870-4b6e-b5f3-3d05d1596b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-db29bd95-56de-4ad8-9db2-d98e7e3a98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-71387170-1adc-48e9-9aed-8533809e9725,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-51028d9c-b234-4fa4-9883-1c174644c392,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-0083a7c3-db92-404d-8793-ea5953b9860b,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-0d60c081-b53c-489e-813e-6e6af842d300,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-2c41a7c5-c797-4c43-b510-d1809b7dcb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239305655-172.17.0.13-1595961089375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37505,DS-2aa81f38-2fb9-4d56-89c8-919b5efc0051,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-a9d273b1-dd51-4d2e-a591-ca5b4dd0b70f,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-595438d8-a395-4fe7-b109-750a942fb5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-ee7b9001-266c-42ea-b81a-80b570f386e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-c8a97075-41ac-44d7-b8f4-4bba26084f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-2d23a209-7875-4813-91f6-8a478178fdec,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-079342d5-0a58-44b8-b121-bdc086466a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-3446c412-be67-47cc-8ba2-4e107d24cd6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239305655-172.17.0.13-1595961089375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37505,DS-2aa81f38-2fb9-4d56-89c8-919b5efc0051,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-a9d273b1-dd51-4d2e-a591-ca5b4dd0b70f,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-595438d8-a395-4fe7-b109-750a942fb5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-ee7b9001-266c-42ea-b81a-80b570f386e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-c8a97075-41ac-44d7-b8f4-4bba26084f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-2d23a209-7875-4813-91f6-8a478178fdec,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-079342d5-0a58-44b8-b121-bdc086466a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-3446c412-be67-47cc-8ba2-4e107d24cd6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169152995-172.17.0.13-1595961557651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-66e71359-e064-40ec-88f5-70462fdbe194,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-d5ed597f-8af2-466b-80cb-af1c5f7c207d,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-09e8d88b-419e-438e-9301-74e5950ed348,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-0157f37f-8c21-4c35-8de8-865e252750bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-84c97a65-e2bf-498f-8d1d-9f399bc5fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-eed1cd28-c435-4ea1-8b5a-e6b45d7feca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-d0fd41b1-f970-44af-8e58-1aa2fb2850de,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-a655d287-5360-40f5-84eb-60907b1f0487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169152995-172.17.0.13-1595961557651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-66e71359-e064-40ec-88f5-70462fdbe194,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-d5ed597f-8af2-466b-80cb-af1c5f7c207d,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-09e8d88b-419e-438e-9301-74e5950ed348,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-0157f37f-8c21-4c35-8de8-865e252750bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-84c97a65-e2bf-498f-8d1d-9f399bc5fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-eed1cd28-c435-4ea1-8b5a-e6b45d7feca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-d0fd41b1-f970-44af-8e58-1aa2fb2850de,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-a655d287-5360-40f5-84eb-60907b1f0487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840735872-172.17.0.13-1595962133772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-7f618101-8f6e-445a-abfa-ce82cd14b931,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-c52041d1-1769-4103-a6be-28c52bdd11f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-f1ca4ee1-ec6a-409b-9a6e-53aaba001882,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-fbf965ed-33b4-4dd8-b8d6-76764134c377,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-653b50d0-0a41-45b7-9aea-9365bd2bfe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-b960e124-30bc-4c84-bd83-5454c8acc7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-5b8248d3-fb12-4cc5-8833-b265371d3a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-8c8caab5-44ee-478f-9751-d1525195e10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840735872-172.17.0.13-1595962133772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-7f618101-8f6e-445a-abfa-ce82cd14b931,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-c52041d1-1769-4103-a6be-28c52bdd11f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-f1ca4ee1-ec6a-409b-9a6e-53aaba001882,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-fbf965ed-33b4-4dd8-b8d6-76764134c377,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-653b50d0-0a41-45b7-9aea-9365bd2bfe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-b960e124-30bc-4c84-bd83-5454c8acc7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-5b8248d3-fb12-4cc5-8833-b265371d3a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-8c8caab5-44ee-478f-9751-d1525195e10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696745056-172.17.0.13-1595962167700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42486,DS-35c9e2e4-a131-4a7e-817f-42bb262cfa45,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-82920909-b084-4fc7-9215-35c4a116903f,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-664c9ed6-a5c7-4b0a-bb0c-9464c9c63ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-37131fe8-0b5d-4d87-be51-1c3b299553b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-15ac2dda-3716-490a-934f-f835296dd45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-2f706bed-0b8e-4aaa-aae1-59b5cdea45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-5014f4b8-26ee-4b17-bee4-b43c6ef14194,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-45e7cf79-2868-4be8-84a1-c14a01a9f988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696745056-172.17.0.13-1595962167700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42486,DS-35c9e2e4-a131-4a7e-817f-42bb262cfa45,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-82920909-b084-4fc7-9215-35c4a116903f,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-664c9ed6-a5c7-4b0a-bb0c-9464c9c63ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-37131fe8-0b5d-4d87-be51-1c3b299553b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-15ac2dda-3716-490a-934f-f835296dd45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-2f706bed-0b8e-4aaa-aae1-59b5cdea45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-5014f4b8-26ee-4b17-bee4-b43c6ef14194,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-45e7cf79-2868-4be8-84a1-c14a01a9f988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371928408-172.17.0.13-1595962201251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44706,DS-f1d5dbac-dd76-4623-946e-85cffa7f1f28,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-642c5fbb-56de-46bb-aeaf-91769f399285,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-43c06e56-dfb0-4fee-9f05-9c223cbbf210,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-96836cf9-9653-4b97-b2f1-6bba44943514,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-c22743c4-890f-418c-b8fe-152644fc2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-07c916bc-e5ed-43da-9c36-222b42b4feae,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-bc2b002a-0af1-4729-bed7-8435501c04e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-7fcec7ba-0bcc-4ce6-8e75-49e369b80b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371928408-172.17.0.13-1595962201251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44706,DS-f1d5dbac-dd76-4623-946e-85cffa7f1f28,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-642c5fbb-56de-46bb-aeaf-91769f399285,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-43c06e56-dfb0-4fee-9f05-9c223cbbf210,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-96836cf9-9653-4b97-b2f1-6bba44943514,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-c22743c4-890f-418c-b8fe-152644fc2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-07c916bc-e5ed-43da-9c36-222b42b4feae,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-bc2b002a-0af1-4729-bed7-8435501c04e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-7fcec7ba-0bcc-4ce6-8e75-49e369b80b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321945204-172.17.0.13-1595962268080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44944,DS-23f92c2c-e0fc-4b2a-a526-38035bf511a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-5623a447-5345-4528-af2a-5c7bd33702d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-04452239-a26e-40d9-93d6-e5bf50718745,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-4ff8e3be-309a-44c0-a92a-9bcda1059632,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-841d43cd-d32e-4686-ba9a-7209ab910623,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-808e1c42-c425-480b-9465-15c2c623deb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-94ff0210-432a-4967-97bb-abe55c881910,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-5a6b0b76-d181-407a-aa45-63715322c1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321945204-172.17.0.13-1595962268080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44944,DS-23f92c2c-e0fc-4b2a-a526-38035bf511a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-5623a447-5345-4528-af2a-5c7bd33702d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-04452239-a26e-40d9-93d6-e5bf50718745,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-4ff8e3be-309a-44c0-a92a-9bcda1059632,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-841d43cd-d32e-4686-ba9a-7209ab910623,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-808e1c42-c425-480b-9465-15c2c623deb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-94ff0210-432a-4967-97bb-abe55c881910,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-5a6b0b76-d181-407a-aa45-63715322c1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083113525-172.17.0.13-1595962302349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41354,DS-cd506c34-45ed-412b-8bae-35214b103919,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-5bddb984-6f80-46c8-ac5c-f8b23d0e0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-eb4d77b5-0b48-4486-9d94-dbbe1a8d375b,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-d350be6b-ecd6-4e50-9f6b-1fa486659fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-cad9d943-7535-4c44-8770-57b34231db01,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-d40f1fd7-ebc4-4012-88c3-2051d3545054,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-c9904762-db76-4ee8-b41d-a594990b2cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-b712e5b3-136d-439a-b35a-b9728b3ebc0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083113525-172.17.0.13-1595962302349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41354,DS-cd506c34-45ed-412b-8bae-35214b103919,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-5bddb984-6f80-46c8-ac5c-f8b23d0e0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-eb4d77b5-0b48-4486-9d94-dbbe1a8d375b,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-d350be6b-ecd6-4e50-9f6b-1fa486659fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-cad9d943-7535-4c44-8770-57b34231db01,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-d40f1fd7-ebc4-4012-88c3-2051d3545054,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-c9904762-db76-4ee8-b41d-a594990b2cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-b712e5b3-136d-439a-b35a-b9728b3ebc0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554742811-172.17.0.13-1595962374780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46057,DS-a92255c9-2c10-480a-833b-eb6df954c090,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-4885189d-f2c2-4d5a-b151-4df50618d704,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-5365a39b-0124-4dcb-95d2-35101748faf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-44cf9dc2-1b33-4e74-8433-814fc2c94b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-038cbfff-e71e-43fc-a087-75467a3a457a,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-0b766d14-0bce-4117-8ce2-09fe5dbafbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-d8bc02a9-2a2f-4361-9528-a9839c4bfb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-6888f06a-5c14-4741-9548-fb85e673a2db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554742811-172.17.0.13-1595962374780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46057,DS-a92255c9-2c10-480a-833b-eb6df954c090,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-4885189d-f2c2-4d5a-b151-4df50618d704,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-5365a39b-0124-4dcb-95d2-35101748faf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-44cf9dc2-1b33-4e74-8433-814fc2c94b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-038cbfff-e71e-43fc-a087-75467a3a457a,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-0b766d14-0bce-4117-8ce2-09fe5dbafbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-d8bc02a9-2a2f-4361-9528-a9839c4bfb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-6888f06a-5c14-4741-9548-fb85e673a2db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557037421-172.17.0.13-1595962878605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-52d60c6a-1baf-4036-94bd-f023d32707d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-b12f527e-0583-402c-9071-bad7cfd0f298,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-25a8660e-b362-4856-911d-b71eded55a54,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-1828ff41-5c86-49c7-a049-3a2a4b2d2954,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-12435f67-00d1-496e-86d4-9c29425a00ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-3bdf47c4-df9e-43af-a25c-1e77f50ff0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-52fa3e5c-186e-4786-beaf-1a9e9a619dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-e8a930d1-f05b-4dd1-8a77-a983e6efa06d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557037421-172.17.0.13-1595962878605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-52d60c6a-1baf-4036-94bd-f023d32707d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-b12f527e-0583-402c-9071-bad7cfd0f298,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-25a8660e-b362-4856-911d-b71eded55a54,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-1828ff41-5c86-49c7-a049-3a2a4b2d2954,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-12435f67-00d1-496e-86d4-9c29425a00ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-3bdf47c4-df9e-43af-a25c-1e77f50ff0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-52fa3e5c-186e-4786-beaf-1a9e9a619dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-e8a930d1-f05b-4dd1-8a77-a983e6efa06d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349711401-172.17.0.13-1595963797324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-e299245c-aa6b-49a5-bdb2-dd89828e8b17,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-7ba7edce-6f44-4eda-bac5-72102d7f330b,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-913988b8-4d70-408b-9a49-88a96980ecd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-5acc9a9e-1296-4440-8eb5-84b08d4e8d81,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-32f9b4de-c867-4d92-a107-09f66e6ec0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-b2c88106-a6bc-41f4-8a67-0728710bd7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-6b0130fe-05f7-4386-9de6-352757242cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-ce3b8621-df42-4f02-862b-49b7f0e0567d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349711401-172.17.0.13-1595963797324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-e299245c-aa6b-49a5-bdb2-dd89828e8b17,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-7ba7edce-6f44-4eda-bac5-72102d7f330b,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-913988b8-4d70-408b-9a49-88a96980ecd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-5acc9a9e-1296-4440-8eb5-84b08d4e8d81,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-32f9b4de-c867-4d92-a107-09f66e6ec0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-b2c88106-a6bc-41f4-8a67-0728710bd7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-6b0130fe-05f7-4386-9de6-352757242cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-ce3b8621-df42-4f02-862b-49b7f0e0567d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238156125-172.17.0.13-1595963825845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-9797f0f5-05aa-4acf-be18-0d7d14c4f335,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-4d594302-8075-4a49-b1c2-2dcaa12591f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-a70ee9f3-21b6-4223-8aae-8849c7bf5db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-26abddbb-44bb-4b63-9fec-04a22bfb33a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-012ba449-e0ae-4725-9195-d1067a4a7aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-6e73a0fb-684d-438f-a1bb-7c6fde32a77f,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-3da2aca4-1015-436f-ba65-b179ff39e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-e6207b87-1273-4b47-9e43-baf23cf6fc96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238156125-172.17.0.13-1595963825845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-9797f0f5-05aa-4acf-be18-0d7d14c4f335,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-4d594302-8075-4a49-b1c2-2dcaa12591f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-a70ee9f3-21b6-4223-8aae-8849c7bf5db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-26abddbb-44bb-4b63-9fec-04a22bfb33a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-012ba449-e0ae-4725-9195-d1067a4a7aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-6e73a0fb-684d-438f-a1bb-7c6fde32a77f,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-3da2aca4-1015-436f-ba65-b179ff39e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-e6207b87-1273-4b47-9e43-baf23cf6fc96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582618026-172.17.0.13-1595964267711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46404,DS-9fb4e78f-77ac-47ef-91a9-30c0ad0afcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-9a8a47f7-b59c-409f-bf45-0660779a8545,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-009bfd6d-c212-40d9-896a-b7888610419c,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-6cbe8285-b61c-4010-9072-4169810c3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-12ab8f9f-0605-4972-bbe8-006bbbd132ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-be5ff95c-ee78-460c-b78c-663bddc4450d,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-dd6aaadc-d368-4f0d-be52-db227069cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-4e53c284-20ad-4c8d-9b26-8122611ce846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582618026-172.17.0.13-1595964267711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46404,DS-9fb4e78f-77ac-47ef-91a9-30c0ad0afcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-9a8a47f7-b59c-409f-bf45-0660779a8545,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-009bfd6d-c212-40d9-896a-b7888610419c,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-6cbe8285-b61c-4010-9072-4169810c3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-12ab8f9f-0605-4972-bbe8-006bbbd132ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-be5ff95c-ee78-460c-b78c-663bddc4450d,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-dd6aaadc-d368-4f0d-be52-db227069cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-4e53c284-20ad-4c8d-9b26-8122611ce846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155832521-172.17.0.13-1595964669268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-5b2a5431-6904-44a2-be56-ebc0298f01db,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-b923d166-3075-4ec2-9a20-2f22b58f14c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-7f90a796-4d71-416b-a187-60279afb2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-832f8896-646a-4c43-83b6-14fc91f0cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-79125f04-57ca-449c-aabf-6966dd710255,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-2f27c418-e6e0-4cde-b599-5e472f28abf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-12a774fa-7ce0-4674-9b32-8fd01e000341,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-10a39741-1928-4959-b275-4dee6445de80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155832521-172.17.0.13-1595964669268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-5b2a5431-6904-44a2-be56-ebc0298f01db,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-b923d166-3075-4ec2-9a20-2f22b58f14c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-7f90a796-4d71-416b-a187-60279afb2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-832f8896-646a-4c43-83b6-14fc91f0cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-79125f04-57ca-449c-aabf-6966dd710255,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-2f27c418-e6e0-4cde-b599-5e472f28abf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-12a774fa-7ce0-4674-9b32-8fd01e000341,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-10a39741-1928-4959-b275-4dee6445de80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121112309-172.17.0.13-1595964706321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38491,DS-9dd02f22-f365-4f95-81c5-c3a92ff6cede,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-e484b07e-5c53-4c8b-b25d-8a4560b7fb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-62c36d2e-eb2a-4cfd-b50a-c23f4b07f2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-bf304396-e88e-4886-8284-df026198b33a,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-deee5aa3-c5d0-4751-8008-048f446ef5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-08150d2d-93e7-4e73-9216-9d72c530b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-4598f18c-18aa-4026-9730-c6b673022fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-57b03418-3432-49e7-ae65-0e1508a0c78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121112309-172.17.0.13-1595964706321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38491,DS-9dd02f22-f365-4f95-81c5-c3a92ff6cede,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-e484b07e-5c53-4c8b-b25d-8a4560b7fb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-62c36d2e-eb2a-4cfd-b50a-c23f4b07f2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-bf304396-e88e-4886-8284-df026198b33a,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-deee5aa3-c5d0-4751-8008-048f446ef5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-08150d2d-93e7-4e73-9216-9d72c530b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-4598f18c-18aa-4026-9730-c6b673022fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-57b03418-3432-49e7-ae65-0e1508a0c78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45839854-172.17.0.13-1595964766577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-dfa4612f-b589-45b5-8a40-672873228b15,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-fcca4510-01e9-4ea9-97b6-21aae7ac28b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-679d2781-e84e-42dc-85f5-a2173d301682,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-07d8fb84-4d73-4f5c-9610-51ee5cd4e483,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-849de936-c971-490c-b4f3-5bdf6fba8193,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-07b051e2-3fc8-492a-a983-9b16dd4d345c,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-14d3df16-74d8-4742-af68-7318222cc7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-598d78b4-d72e-4cb9-abbc-620fd75d9997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45839854-172.17.0.13-1595964766577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-dfa4612f-b589-45b5-8a40-672873228b15,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-fcca4510-01e9-4ea9-97b6-21aae7ac28b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-679d2781-e84e-42dc-85f5-a2173d301682,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-07d8fb84-4d73-4f5c-9610-51ee5cd4e483,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-849de936-c971-490c-b4f3-5bdf6fba8193,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-07b051e2-3fc8-492a-a983-9b16dd4d345c,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-14d3df16-74d8-4742-af68-7318222cc7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-598d78b4-d72e-4cb9-abbc-620fd75d9997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5405
