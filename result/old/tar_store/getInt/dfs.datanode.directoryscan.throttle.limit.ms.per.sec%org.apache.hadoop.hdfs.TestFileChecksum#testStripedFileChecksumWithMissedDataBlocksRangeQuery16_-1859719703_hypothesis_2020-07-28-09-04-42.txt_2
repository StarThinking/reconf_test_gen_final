reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378828535-172.17.0.13-1595927808615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40290,DS-7711b83b-5a07-49bb-8d8a-d409d659370d,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-d6e99fea-3e99-4f0e-8c59-a22910d3ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-823d15ee-9642-4439-b654-cb408a7c74b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-177fe1a3-e437-4fb8-9cf7-9517390998b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-54e02c6c-4c4f-4842-83c1-3a8dc5724c61,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-84aa1828-baa6-4cca-aa6d-4ab67d37d631,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-0fb2802d-f15d-49bb-8abf-ac50b5da5986,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-9bfd9cb3-204d-4066-ac0c-d1e1adbb2340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378828535-172.17.0.13-1595927808615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40290,DS-7711b83b-5a07-49bb-8d8a-d409d659370d,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-d6e99fea-3e99-4f0e-8c59-a22910d3ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-823d15ee-9642-4439-b654-cb408a7c74b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-177fe1a3-e437-4fb8-9cf7-9517390998b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-54e02c6c-4c4f-4842-83c1-3a8dc5724c61,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-84aa1828-baa6-4cca-aa6d-4ab67d37d631,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-0fb2802d-f15d-49bb-8abf-ac50b5da5986,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-9bfd9cb3-204d-4066-ac0c-d1e1adbb2340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016049725-172.17.0.13-1595927944066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-abd6b75a-ba5b-4477-bee9-c0c87494450b,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-12ba237b-bff6-45d7-9b64-578819cdc431,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-febe61e4-a385-455b-bdbd-1eabb76b89c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-3b1fc53d-4850-4ae2-b2f1-922380b91109,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-a000c6dd-e338-4a0d-bf45-0613236aea52,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-e05f5dfc-3e04-490e-83be-eefb09614a45,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-d24f7d30-cb2b-426a-a25e-4c57773ce332,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-2f158116-6f21-4e25-b085-1c20d4391178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016049725-172.17.0.13-1595927944066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-abd6b75a-ba5b-4477-bee9-c0c87494450b,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-12ba237b-bff6-45d7-9b64-578819cdc431,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-febe61e4-a385-455b-bdbd-1eabb76b89c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-3b1fc53d-4850-4ae2-b2f1-922380b91109,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-a000c6dd-e338-4a0d-bf45-0613236aea52,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-e05f5dfc-3e04-490e-83be-eefb09614a45,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-d24f7d30-cb2b-426a-a25e-4c57773ce332,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-2f158116-6f21-4e25-b085-1c20d4391178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561188883-172.17.0.13-1595927975968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-2c3865fb-80be-449e-90da-59b4f07bc0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-f584b0c2-0fc4-49a6-be52-ce5caf52f468,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-be2374ac-7736-47ba-bf6c-33a9bce68515,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-d99d6496-eba4-4f45-a67b-95fb059ae81d,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-ea718633-d6cf-445a-a654-16b44d06cc16,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-99938e8f-72cd-4d94-b560-e8e1448a421c,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-58431120-a66a-492c-b803-5fdaf5f06248,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-7bc546b4-c611-4acf-a3ce-eeae8e51d336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561188883-172.17.0.13-1595927975968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-2c3865fb-80be-449e-90da-59b4f07bc0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-f584b0c2-0fc4-49a6-be52-ce5caf52f468,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-be2374ac-7736-47ba-bf6c-33a9bce68515,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-d99d6496-eba4-4f45-a67b-95fb059ae81d,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-ea718633-d6cf-445a-a654-16b44d06cc16,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-99938e8f-72cd-4d94-b560-e8e1448a421c,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-58431120-a66a-492c-b803-5fdaf5f06248,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-7bc546b4-c611-4acf-a3ce-eeae8e51d336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209426527-172.17.0.13-1595928244274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43016,DS-4022bfa5-cc4b-4e47-8317-7037d224bfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-53c3489e-7843-4063-b1f0-5b8ca6723607,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-c1d6f1a6-480d-4561-bf5b-47387e69876e,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-0c238f7e-7634-4e14-8f9d-49a726f70be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-ffd4b12f-9217-4ee5-9a72-3300a589b153,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-8b860ac8-5ded-4747-aef6-6e1f5d6c8da0,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-ca65ac15-6faf-4f1b-bc54-e64e27e5687e,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-6cad2969-5338-4bf6-85be-b05da868edc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209426527-172.17.0.13-1595928244274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43016,DS-4022bfa5-cc4b-4e47-8317-7037d224bfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-53c3489e-7843-4063-b1f0-5b8ca6723607,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-c1d6f1a6-480d-4561-bf5b-47387e69876e,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-0c238f7e-7634-4e14-8f9d-49a726f70be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-ffd4b12f-9217-4ee5-9a72-3300a589b153,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-8b860ac8-5ded-4747-aef6-6e1f5d6c8da0,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-ca65ac15-6faf-4f1b-bc54-e64e27e5687e,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-6cad2969-5338-4bf6-85be-b05da868edc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055827627-172.17.0.13-1595929064370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-c497b958-3c33-49ac-845d-66fb26bd69a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-e96d49ee-3696-4995-b41b-8f6aec770892,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-6ae69f68-e4cc-454b-bf1a-4882b77c1c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-f72d52af-6845-47f3-bae0-fd34229b5611,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-3faf6547-4fdd-4387-8546-7fda296a6ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-a8827a6a-d6b0-4230-b851-01501855ec7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-72ce7870-c678-4169-a3ad-bbccc89d8251,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-3d48e5d4-46a1-488b-9691-21006c27f566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055827627-172.17.0.13-1595929064370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-c497b958-3c33-49ac-845d-66fb26bd69a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-e96d49ee-3696-4995-b41b-8f6aec770892,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-6ae69f68-e4cc-454b-bf1a-4882b77c1c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-f72d52af-6845-47f3-bae0-fd34229b5611,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-3faf6547-4fdd-4387-8546-7fda296a6ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-a8827a6a-d6b0-4230-b851-01501855ec7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-72ce7870-c678-4169-a3ad-bbccc89d8251,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-3d48e5d4-46a1-488b-9691-21006c27f566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181218705-172.17.0.13-1595929423798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41159,DS-75d37be9-bbf7-4e0c-acee-0a0e33d8adec,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-4bcf94df-5b88-4791-bf8d-6d9081cdf12b,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-0e11c56e-214f-4bd0-b567-a8244290fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-77cc60e5-66dd-4608-8436-238eae5fdc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-7a2fc422-5362-4daa-80ab-1acdce7c1853,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-dccb1321-ce8d-459b-a84a-4e6085fc9534,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-94e25d1a-bbf5-4c2b-9f39-a45c35103d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-c2059ad3-8fdd-4baa-b961-7e187bbe070c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181218705-172.17.0.13-1595929423798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41159,DS-75d37be9-bbf7-4e0c-acee-0a0e33d8adec,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-4bcf94df-5b88-4791-bf8d-6d9081cdf12b,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-0e11c56e-214f-4bd0-b567-a8244290fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-77cc60e5-66dd-4608-8436-238eae5fdc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-7a2fc422-5362-4daa-80ab-1acdce7c1853,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-dccb1321-ce8d-459b-a84a-4e6085fc9534,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-94e25d1a-bbf5-4c2b-9f39-a45c35103d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-c2059ad3-8fdd-4baa-b961-7e187bbe070c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940831492-172.17.0.13-1595929856266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43462,DS-84222908-12de-4cc2-96bc-c687b93dff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-0641b49b-947a-41c7-af07-b3ec04188bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-e3f58b51-e591-4bb9-9b4c-b66451209de3,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-ef3e3d9d-93f6-494a-8ae6-a389ec79ee65,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-e03db86e-14da-4402-a9b2-0f58d1c7a692,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-dbc6e0a3-606b-4a7a-8533-7f8acda3e0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-44692bcf-d3ad-4a0f-9380-1b4faf543fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-262c333e-532d-46c2-a286-38dc66b1293f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940831492-172.17.0.13-1595929856266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43462,DS-84222908-12de-4cc2-96bc-c687b93dff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-0641b49b-947a-41c7-af07-b3ec04188bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-e3f58b51-e591-4bb9-9b4c-b66451209de3,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-ef3e3d9d-93f6-494a-8ae6-a389ec79ee65,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-e03db86e-14da-4402-a9b2-0f58d1c7a692,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-dbc6e0a3-606b-4a7a-8533-7f8acda3e0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-44692bcf-d3ad-4a0f-9380-1b4faf543fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-262c333e-532d-46c2-a286-38dc66b1293f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378678489-172.17.0.13-1595929889654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35326,DS-18f02772-0cb5-4491-8a04-86d1cffe7503,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-313b8d56-a73f-4884-be5a-c242b310ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-f03406cb-b36e-4125-bda7-d9dcdc16a271,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-cd3163fd-fc8c-4d48-9df9-4bdad4e8fc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-a35e0dd4-7bd9-4b17-a872-26e6910d76e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-04b782bc-15c6-45dd-baf4-43e53f071475,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-c9ea8814-78f6-43c3-815e-1f6b214627bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-9c0ca7d8-3de6-4044-ba2a-5b2ca6a8b362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378678489-172.17.0.13-1595929889654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35326,DS-18f02772-0cb5-4491-8a04-86d1cffe7503,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-313b8d56-a73f-4884-be5a-c242b310ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-f03406cb-b36e-4125-bda7-d9dcdc16a271,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-cd3163fd-fc8c-4d48-9df9-4bdad4e8fc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-a35e0dd4-7bd9-4b17-a872-26e6910d76e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-04b782bc-15c6-45dd-baf4-43e53f071475,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-c9ea8814-78f6-43c3-815e-1f6b214627bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-9c0ca7d8-3de6-4044-ba2a-5b2ca6a8b362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960576744-172.17.0.13-1595930339759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37994,DS-d15fe8e0-9ba1-4c8b-a965-ad0c9ac8224e,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-0a022d1f-de21-4619-94eb-5db17c8a87b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-f686f361-efa3-4615-a625-2c318debc1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-dcbf5e27-d719-471b-8994-8ac80e4ceb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-7fd35159-0e23-4e73-a24b-826d69144047,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-837d9419-6551-40cd-b357-24e25e775438,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-e74ec4d1-90f6-4a17-bb08-3f94f7d24cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-fe531bf2-0230-42db-bd28-a344e012deb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960576744-172.17.0.13-1595930339759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37994,DS-d15fe8e0-9ba1-4c8b-a965-ad0c9ac8224e,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-0a022d1f-de21-4619-94eb-5db17c8a87b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-f686f361-efa3-4615-a625-2c318debc1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-dcbf5e27-d719-471b-8994-8ac80e4ceb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-7fd35159-0e23-4e73-a24b-826d69144047,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-837d9419-6551-40cd-b357-24e25e775438,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-e74ec4d1-90f6-4a17-bb08-3f94f7d24cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-fe531bf2-0230-42db-bd28-a344e012deb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465532611-172.17.0.13-1595930423799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40648,DS-1c57a7e3-fcf4-415f-900c-1a905427ec0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-2e373530-bfec-4733-a3c2-17cd3455847a,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-c5c8ce89-38b0-4fa9-af21-8a88dfd96a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-796af3c2-6552-41a9-ace4-3963fd1d0662,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-1631f5d1-b740-4fe0-abd9-422e57d9e221,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-f49d8a7e-5e22-44b0-addc-f21bd4c93300,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-dadc493d-37b2-4826-b770-85b806c61073,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-fcc4f215-e529-4e17-9728-6ea45cb26558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465532611-172.17.0.13-1595930423799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40648,DS-1c57a7e3-fcf4-415f-900c-1a905427ec0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-2e373530-bfec-4733-a3c2-17cd3455847a,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-c5c8ce89-38b0-4fa9-af21-8a88dfd96a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-796af3c2-6552-41a9-ace4-3963fd1d0662,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-1631f5d1-b740-4fe0-abd9-422e57d9e221,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-f49d8a7e-5e22-44b0-addc-f21bd4c93300,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-dadc493d-37b2-4826-b770-85b806c61073,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-fcc4f215-e529-4e17-9728-6ea45cb26558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551784383-172.17.0.13-1595931106042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-4246d127-a0dc-4932-bfab-eee5d6c086b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-c9ca4cee-1e6b-4d3a-91be-5f8e8a3e3806,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-66cde86e-b851-48fd-8221-983a10a8f746,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-7ab02269-8973-48d4-9fb3-2df0596119d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-d15341ac-0243-41ad-9c5b-d6e47e56f1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-2f50b97c-96e3-470f-b8f8-6d3932727971,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-239765ad-fad5-4721-bf24-405f7c139e97,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-f3c0cb4b-f712-497e-a738-b80061b79afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551784383-172.17.0.13-1595931106042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-4246d127-a0dc-4932-bfab-eee5d6c086b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-c9ca4cee-1e6b-4d3a-91be-5f8e8a3e3806,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-66cde86e-b851-48fd-8221-983a10a8f746,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-7ab02269-8973-48d4-9fb3-2df0596119d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-d15341ac-0243-41ad-9c5b-d6e47e56f1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-2f50b97c-96e3-470f-b8f8-6d3932727971,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-239765ad-fad5-4721-bf24-405f7c139e97,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-f3c0cb4b-f712-497e-a738-b80061b79afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003371817-172.17.0.13-1595931376331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38969,DS-69aa9bb1-0e0b-4fbf-8320-3a5b1cc17a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-ffa6bff0-df53-4406-a057-dbad37d488fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-b33614bc-ea28-418b-bbc3-188103708c70,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-7315a69a-5a4c-4108-a874-c55dbc46d1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-0449b926-d9ef-4f8f-8d3d-37c6553fd0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-cdeb0435-5574-4fab-9d47-4fff6f78c652,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-90071253-299c-4353-9d75-e6a25ae82835,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-c8ba6ab7-e18f-4ee6-838c-9b63dcc04bcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003371817-172.17.0.13-1595931376331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38969,DS-69aa9bb1-0e0b-4fbf-8320-3a5b1cc17a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-ffa6bff0-df53-4406-a057-dbad37d488fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-b33614bc-ea28-418b-bbc3-188103708c70,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-7315a69a-5a4c-4108-a874-c55dbc46d1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-0449b926-d9ef-4f8f-8d3d-37c6553fd0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-cdeb0435-5574-4fab-9d47-4fff6f78c652,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-90071253-299c-4353-9d75-e6a25ae82835,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-c8ba6ab7-e18f-4ee6-838c-9b63dcc04bcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606344681-172.17.0.13-1595931415801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45862,DS-34395d58-9bc4-41fd-a2dc-6a639819db64,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-fcb004da-53ae-484d-babb-fbb69a0c100e,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-697f3e40-1a99-4b4c-bc5a-1f3e997642cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-122d281a-6627-454a-b38b-ec72c21b04b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-9017cf3d-c473-496b-b43a-cf93ce8c428e,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-f0f2ce18-db62-45b7-ad5a-4b58ca7d3e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-9917e2f3-e414-414c-9d41-8fa329d44d15,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-79aebe54-a98c-40da-a6e1-42dc2a738f4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606344681-172.17.0.13-1595931415801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45862,DS-34395d58-9bc4-41fd-a2dc-6a639819db64,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-fcb004da-53ae-484d-babb-fbb69a0c100e,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-697f3e40-1a99-4b4c-bc5a-1f3e997642cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-122d281a-6627-454a-b38b-ec72c21b04b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-9017cf3d-c473-496b-b43a-cf93ce8c428e,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-f0f2ce18-db62-45b7-ad5a-4b58ca7d3e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-9917e2f3-e414-414c-9d41-8fa329d44d15,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-79aebe54-a98c-40da-a6e1-42dc2a738f4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907523489-172.17.0.13-1595931458110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35829,DS-49b9f3ed-2d1d-4df2-8436-4367798258a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-7c1c93c7-56ec-4001-ae70-af7dd303d697,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-8ed2630b-4ba7-4e4d-bc21-1f06fcb99ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-a3e2d959-38fe-43f5-a8bf-d57c934754f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-de957e73-909c-4208-8f0f-4f7d1ba40b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-fbc9bcde-01a7-473a-91b4-ec1d7c419669,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-6f21489b-60a5-4376-8081-c9f0aed5641e,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-0f549475-eef1-47a0-9b4f-59f0549bda38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907523489-172.17.0.13-1595931458110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35829,DS-49b9f3ed-2d1d-4df2-8436-4367798258a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-7c1c93c7-56ec-4001-ae70-af7dd303d697,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-8ed2630b-4ba7-4e4d-bc21-1f06fcb99ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-a3e2d959-38fe-43f5-a8bf-d57c934754f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-de957e73-909c-4208-8f0f-4f7d1ba40b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-fbc9bcde-01a7-473a-91b4-ec1d7c419669,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-6f21489b-60a5-4376-8081-c9f0aed5641e,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-0f549475-eef1-47a0-9b4f-59f0549bda38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091965151-172.17.0.13-1595931908362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-9c7d41b8-3100-4cb7-81b6-b1119a4265fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b5d8030d-1c4e-431a-835b-69af7bd5c781,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-303ccda5-f18a-46ca-88e0-457ebc2136b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-d6f1dcdf-3391-4db5-8091-400b58dd6ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-1cdf8443-8cf7-4d45-bd75-8d3f13bd55ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-deb7ee31-f93d-4b81-8669-5081d0c8f647,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-69c3011d-99f4-4d7e-a6db-d44fb6b3b728,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-f779fab0-0097-414f-95a8-3f6626f51718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091965151-172.17.0.13-1595931908362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-9c7d41b8-3100-4cb7-81b6-b1119a4265fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b5d8030d-1c4e-431a-835b-69af7bd5c781,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-303ccda5-f18a-46ca-88e0-457ebc2136b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-d6f1dcdf-3391-4db5-8091-400b58dd6ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-1cdf8443-8cf7-4d45-bd75-8d3f13bd55ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-deb7ee31-f93d-4b81-8669-5081d0c8f647,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-69c3011d-99f4-4d7e-a6db-d44fb6b3b728,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-f779fab0-0097-414f-95a8-3f6626f51718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834004148-172.17.0.13-1595931973078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44527,DS-b00b5d4d-33e0-4845-ba73-1f94449a8e51,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-98349978-fd5d-4afc-b77f-7e7de3788ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-a64a96c5-ce88-42ee-9872-cbf62da3b6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-d2ac9661-1c95-4d96-925d-74cc75c32db0,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-7862e12c-bc57-4c2e-8750-06373964527c,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-012f634e-2870-42ca-ab92-1e51c17cc5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-dbf54b58-a9e8-463b-8acd-c869a4f45ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-92ad1602-c731-44af-ae77-585ea8402670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834004148-172.17.0.13-1595931973078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44527,DS-b00b5d4d-33e0-4845-ba73-1f94449a8e51,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-98349978-fd5d-4afc-b77f-7e7de3788ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-a64a96c5-ce88-42ee-9872-cbf62da3b6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-d2ac9661-1c95-4d96-925d-74cc75c32db0,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-7862e12c-bc57-4c2e-8750-06373964527c,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-012f634e-2870-42ca-ab92-1e51c17cc5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-dbf54b58-a9e8-463b-8acd-c869a4f45ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-92ad1602-c731-44af-ae77-585ea8402670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5305
