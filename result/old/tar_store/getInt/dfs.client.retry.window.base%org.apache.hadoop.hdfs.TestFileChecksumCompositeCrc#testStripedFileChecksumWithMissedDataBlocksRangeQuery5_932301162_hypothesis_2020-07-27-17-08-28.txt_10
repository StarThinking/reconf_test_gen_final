reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443782670-172.17.0.7-1595870449185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-96e7a234-a344-4637-b5b8-ed8ed1d8731c,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-d11b5f6a-ba4d-4278-9a39-c51b71cbb681,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-b5d98fb3-2fe6-4e10-b805-b99ac25768c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-8f75afa2-3a76-445e-9d45-a70f80cfc288,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-d2b6562f-fc9a-4c0f-a99a-32b6ce6c1e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-6495bc23-b96f-4e35-a9d4-c93e4b880b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-fd706250-2249-4915-a07b-beec8cb29a59,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-bf2ce1de-22ec-4eb6-a3f1-8f68ad0c20a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443782670-172.17.0.7-1595870449185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-96e7a234-a344-4637-b5b8-ed8ed1d8731c,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-d11b5f6a-ba4d-4278-9a39-c51b71cbb681,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-b5d98fb3-2fe6-4e10-b805-b99ac25768c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-8f75afa2-3a76-445e-9d45-a70f80cfc288,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-d2b6562f-fc9a-4c0f-a99a-32b6ce6c1e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-6495bc23-b96f-4e35-a9d4-c93e4b880b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-fd706250-2249-4915-a07b-beec8cb29a59,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-bf2ce1de-22ec-4eb6-a3f1-8f68ad0c20a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470036615-172.17.0.7-1595870739719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-93f55482-e5e1-4d62-8315-b725399e6fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-25d3cf3a-a611-4ec8-bfcc-906b7971d923,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-d07ea203-288b-43fe-8f37-a25f417551c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-ebf0b629-639f-4072-a70c-f3813ea2ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-6ace97a5-a3ad-4e8f-8ee2-aa0c3066a44d,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-6221e6c4-7b04-4203-875a-dccf46863074,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-e52f595d-be78-4724-aef6-fbfb00449213,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-97bec199-8d8b-40b3-b416-d3c13890ec7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470036615-172.17.0.7-1595870739719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-93f55482-e5e1-4d62-8315-b725399e6fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-25d3cf3a-a611-4ec8-bfcc-906b7971d923,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-d07ea203-288b-43fe-8f37-a25f417551c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-ebf0b629-639f-4072-a70c-f3813ea2ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-6ace97a5-a3ad-4e8f-8ee2-aa0c3066a44d,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-6221e6c4-7b04-4203-875a-dccf46863074,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-e52f595d-be78-4724-aef6-fbfb00449213,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-97bec199-8d8b-40b3-b416-d3c13890ec7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671522075-172.17.0.7-1595870845774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43480,DS-33fbd288-24c0-425e-b5f5-b35f05f1accf,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-a367a433-97f6-445f-9c73-213dff2b25a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-3260fbcb-e6c7-4aec-8771-16450ab4c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-6570da4d-37d1-403c-aaac-5f2896ab7c87,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-c823a7bb-7f45-43a9-a41e-74b885431845,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-2fb5a75a-b855-4d30-9481-7a71d80025d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ae2db052-5fe1-4d4e-9332-6eca833ba841,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-d288b6c3-b3a2-4aef-b654-fedac1358be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671522075-172.17.0.7-1595870845774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43480,DS-33fbd288-24c0-425e-b5f5-b35f05f1accf,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-a367a433-97f6-445f-9c73-213dff2b25a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-3260fbcb-e6c7-4aec-8771-16450ab4c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-6570da4d-37d1-403c-aaac-5f2896ab7c87,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-c823a7bb-7f45-43a9-a41e-74b885431845,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-2fb5a75a-b855-4d30-9481-7a71d80025d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ae2db052-5fe1-4d4e-9332-6eca833ba841,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-d288b6c3-b3a2-4aef-b654-fedac1358be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69356117-172.17.0.7-1595871031100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-6f060155-3999-4b94-bd1a-4c3463f7b490,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-125b1e43-103f-4c9b-9e9f-1cf3c1ad321c,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-39704086-64e1-4758-9b16-68aa82a74ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-c75f1e42-fc7a-4256-8c48-06a00778d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-7707e70e-5dcb-4b0a-9149-aa839ae4ec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-26354066-65f4-49d9-bcad-16b5008e86a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-83534437-0112-40cc-870b-754ba09fa852,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-d5bacd45-b12c-4c4b-b5b4-1e8c9d4b7f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69356117-172.17.0.7-1595871031100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-6f060155-3999-4b94-bd1a-4c3463f7b490,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-125b1e43-103f-4c9b-9e9f-1cf3c1ad321c,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-39704086-64e1-4758-9b16-68aa82a74ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-c75f1e42-fc7a-4256-8c48-06a00778d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-7707e70e-5dcb-4b0a-9149-aa839ae4ec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-26354066-65f4-49d9-bcad-16b5008e86a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-83534437-0112-40cc-870b-754ba09fa852,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-d5bacd45-b12c-4c4b-b5b4-1e8c9d4b7f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577196839-172.17.0.7-1595871312155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38926,DS-5e309371-b78f-4fc4-9539-afecb357459b,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-73000db5-7bfc-4def-bef4-19d1b95be827,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-3e78bb77-33d2-4698-a11c-5a024d752b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-6185c808-e666-47ca-9ba8-11c92a4fbc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-c1d4ef5f-ac2b-439b-886a-c4576151d931,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-7af3168b-6425-403a-ad56-16a868d7b60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-8fb4a7e9-e25c-412e-85bc-8131368aeefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-c252b9f5-f9ed-44cf-b150-681bbd39d866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577196839-172.17.0.7-1595871312155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38926,DS-5e309371-b78f-4fc4-9539-afecb357459b,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-73000db5-7bfc-4def-bef4-19d1b95be827,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-3e78bb77-33d2-4698-a11c-5a024d752b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-6185c808-e666-47ca-9ba8-11c92a4fbc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-c1d4ef5f-ac2b-439b-886a-c4576151d931,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-7af3168b-6425-403a-ad56-16a868d7b60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-8fb4a7e9-e25c-412e-85bc-8131368aeefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-c252b9f5-f9ed-44cf-b150-681bbd39d866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216752335-172.17.0.7-1595871455854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36769,DS-66994b69-d14d-4ef4-82ba-6d14d77ad4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-17f1934f-251b-4b96-9c90-d913dd76933a,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-6054920d-d4f6-4763-87ad-02fc9aabd846,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-5e98a210-3bbd-468c-b37b-82888de7c25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-df195d16-bbc7-4b69-960e-bf86fd8f97d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-2793a22d-4d54-49f3-9b34-91d65238e993,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-904fb516-b7ef-4d72-ad61-5d8a3128552d,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-ffb8fd75-87e5-4c9c-ac72-06b9eca82706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216752335-172.17.0.7-1595871455854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36769,DS-66994b69-d14d-4ef4-82ba-6d14d77ad4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-17f1934f-251b-4b96-9c90-d913dd76933a,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-6054920d-d4f6-4763-87ad-02fc9aabd846,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-5e98a210-3bbd-468c-b37b-82888de7c25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-df195d16-bbc7-4b69-960e-bf86fd8f97d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-2793a22d-4d54-49f3-9b34-91d65238e993,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-904fb516-b7ef-4d72-ad61-5d8a3128552d,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-ffb8fd75-87e5-4c9c-ac72-06b9eca82706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334003624-172.17.0.7-1595871846975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37997,DS-2c45ec4a-3b3a-41db-88bd-8596b5f71530,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-23cc2186-315e-48eb-965a-33fd4dad0289,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-f808f51a-5166-4b4a-ae1f-9ac2d6a31247,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-e54e6817-cd0f-40c6-8044-d5b94adfe440,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-7fb9a818-d83d-422f-8709-83b7f9fec1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-eb65c484-a7b5-49a6-b195-b05bfd302b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-d960d92d-f2f7-4bd6-ab65-37faa730ae60,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-8a4a037c-5fb6-4753-80d5-9068abe11ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334003624-172.17.0.7-1595871846975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37997,DS-2c45ec4a-3b3a-41db-88bd-8596b5f71530,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-23cc2186-315e-48eb-965a-33fd4dad0289,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-f808f51a-5166-4b4a-ae1f-9ac2d6a31247,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-e54e6817-cd0f-40c6-8044-d5b94adfe440,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-7fb9a818-d83d-422f-8709-83b7f9fec1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-eb65c484-a7b5-49a6-b195-b05bfd302b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-d960d92d-f2f7-4bd6-ab65-37faa730ae60,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-8a4a037c-5fb6-4753-80d5-9068abe11ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355144782-172.17.0.7-1595871912400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44240,DS-a387f7e2-38ac-4539-ba0c-4872e26877bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-2a026a80-be85-4ce6-b1c1-8c131010fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-03419b29-7ff5-448b-bcd9-2183093e36fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-2766f49c-9a9f-439d-8d21-4521a7c9c876,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-f396a7fb-453f-43bc-b150-a668c3c5d8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-01167c9c-372d-4125-9819-f58642e90e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-cd94b63e-4a4c-4d18-81d6-1cdbe2769aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-978b2daf-2726-4b31-8c28-98fb308842d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355144782-172.17.0.7-1595871912400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44240,DS-a387f7e2-38ac-4539-ba0c-4872e26877bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-2a026a80-be85-4ce6-b1c1-8c131010fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-03419b29-7ff5-448b-bcd9-2183093e36fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-2766f49c-9a9f-439d-8d21-4521a7c9c876,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-f396a7fb-453f-43bc-b150-a668c3c5d8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-01167c9c-372d-4125-9819-f58642e90e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-cd94b63e-4a4c-4d18-81d6-1cdbe2769aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-978b2daf-2726-4b31-8c28-98fb308842d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596140210-172.17.0.7-1595872878084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-f7dc5680-f48b-4a65-90d0-d196919d9b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-274b67aa-e651-4578-9ceb-3880ab2c8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-a3dadb36-7e69-414d-98cc-2b099e5b480f,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-94873287-3018-4b21-b407-06b3389661e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-016945c1-29ea-4257-9687-7da5f56ed8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-8c407330-a34f-4bf3-974b-4d8989e38fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-b6aca770-040d-476d-9da9-90cc2e9a4558,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-8ace77d4-4f88-411d-88e9-2f9122ddb755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596140210-172.17.0.7-1595872878084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-f7dc5680-f48b-4a65-90d0-d196919d9b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-274b67aa-e651-4578-9ceb-3880ab2c8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-a3dadb36-7e69-414d-98cc-2b099e5b480f,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-94873287-3018-4b21-b407-06b3389661e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-016945c1-29ea-4257-9687-7da5f56ed8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-8c407330-a34f-4bf3-974b-4d8989e38fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-b6aca770-040d-476d-9da9-90cc2e9a4558,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-8ace77d4-4f88-411d-88e9-2f9122ddb755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512559227-172.17.0.7-1595873172056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42537,DS-445930cc-7984-452a-a111-c2b73ff45d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-10c59424-858f-4a33-a2c3-ebbaf2812df4,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-9cbeeb00-7602-4fe4-9b17-fd37656ad914,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-76794595-0743-4072-a878-af0b4a544db9,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-1b7d3902-6ddf-4ba2-afec-55e4684221b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-390a88e1-8e2e-4051-a70d-aafb4f941882,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-63c30d9a-ee42-421f-a8fd-9963a359650f,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-82ccb914-10a9-46b2-8ced-369238f4e9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512559227-172.17.0.7-1595873172056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42537,DS-445930cc-7984-452a-a111-c2b73ff45d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-10c59424-858f-4a33-a2c3-ebbaf2812df4,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-9cbeeb00-7602-4fe4-9b17-fd37656ad914,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-76794595-0743-4072-a878-af0b4a544db9,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-1b7d3902-6ddf-4ba2-afec-55e4684221b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-390a88e1-8e2e-4051-a70d-aafb4f941882,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-63c30d9a-ee42-421f-a8fd-9963a359650f,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-82ccb914-10a9-46b2-8ced-369238f4e9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227258137-172.17.0.7-1595873246543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42140,DS-6d1a6e95-f2c7-4904-81ea-88b3cdf266b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-ff684c30-21bf-41d5-9e30-cd4e21eb3118,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-dab2d501-e8bb-4d0e-bf84-f84df63ca7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-6e4aaa52-e441-4f5c-8107-c789258f4b88,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-04c46f35-45d1-487c-9dad-a2757b26da77,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-a615f757-943b-454f-982a-a2cfa4f48901,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-8944be00-1909-4338-82c3-c29419835cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-7eb34a19-bf4f-45fe-a553-ce1a76a2cdc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227258137-172.17.0.7-1595873246543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42140,DS-6d1a6e95-f2c7-4904-81ea-88b3cdf266b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-ff684c30-21bf-41d5-9e30-cd4e21eb3118,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-dab2d501-e8bb-4d0e-bf84-f84df63ca7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-6e4aaa52-e441-4f5c-8107-c789258f4b88,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-04c46f35-45d1-487c-9dad-a2757b26da77,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-a615f757-943b-454f-982a-a2cfa4f48901,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-8944be00-1909-4338-82c3-c29419835cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-7eb34a19-bf4f-45fe-a553-ce1a76a2cdc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910932965-172.17.0.7-1595873623092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46426,DS-9524ecc0-0375-4970-aed4-00912f52f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-b3ca5743-4946-4ca7-bc78-9a20006d63d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-e27a546b-c961-4aca-a329-b74a5c599323,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-27a22b1e-9a95-4cb0-8236-2a3719c4f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-2ce062b6-b05c-44e5-a78a-910bcfd8749a,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-59ec6705-689b-4381-b885-e9cf6cf17ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-0f100c27-71be-4265-a652-bd9a44596e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-451f55a5-83ba-4fc0-b7b3-c1b92ecfa19e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910932965-172.17.0.7-1595873623092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46426,DS-9524ecc0-0375-4970-aed4-00912f52f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-b3ca5743-4946-4ca7-bc78-9a20006d63d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-e27a546b-c961-4aca-a329-b74a5c599323,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-27a22b1e-9a95-4cb0-8236-2a3719c4f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-2ce062b6-b05c-44e5-a78a-910bcfd8749a,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-59ec6705-689b-4381-b885-e9cf6cf17ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-0f100c27-71be-4265-a652-bd9a44596e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-451f55a5-83ba-4fc0-b7b3-c1b92ecfa19e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813479445-172.17.0.7-1595874164248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40984,DS-990a06e8-62ce-416a-b033-8fb0b91f2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-6cbe677e-338d-46b4-a593-19281f8870b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-daa6be25-879b-423b-ad74-df01897958d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0f9afce2-56d7-418a-8fd9-bc738bddfbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-6fd60934-742f-4986-8c94-b216d0bfa373,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-d1486e60-f385-47c3-930d-6effe0c8c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-a923079d-f4f7-4e55-b358-8b2255b723fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-05857d60-9d77-43be-aece-9892a814c946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813479445-172.17.0.7-1595874164248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40984,DS-990a06e8-62ce-416a-b033-8fb0b91f2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-6cbe677e-338d-46b4-a593-19281f8870b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-daa6be25-879b-423b-ad74-df01897958d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0f9afce2-56d7-418a-8fd9-bc738bddfbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-6fd60934-742f-4986-8c94-b216d0bfa373,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-d1486e60-f385-47c3-930d-6effe0c8c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-a923079d-f4f7-4e55-b358-8b2255b723fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-05857d60-9d77-43be-aece-9892a814c946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040582444-172.17.0.7-1595874312825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-dda9ebf1-585e-481d-b814-e339905d0ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-cd0b8621-e2cd-45f6-9b52-3139425f5d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-600e7b2f-29b5-4eb8-8c6f-6e5e4510ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-102f5ce7-a2ef-410d-926c-70811c1c2e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-e37ed6be-542d-45f9-86c0-ab4d169ba664,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-5bbf6a1b-ab6d-40fb-9642-167bdd9a4c00,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-622c7625-8a95-490a-8c90-21d0a59d2fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-40f2e6e3-f4e0-460f-ba0c-99bd9087c317,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040582444-172.17.0.7-1595874312825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-dda9ebf1-585e-481d-b814-e339905d0ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-cd0b8621-e2cd-45f6-9b52-3139425f5d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-600e7b2f-29b5-4eb8-8c6f-6e5e4510ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-102f5ce7-a2ef-410d-926c-70811c1c2e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-e37ed6be-542d-45f9-86c0-ab4d169ba664,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-5bbf6a1b-ab6d-40fb-9642-167bdd9a4c00,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-622c7625-8a95-490a-8c90-21d0a59d2fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-40f2e6e3-f4e0-460f-ba0c-99bd9087c317,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891196768-172.17.0.7-1595874341281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44288,DS-f1b46920-81c6-4c98-a617-0d13a831e8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-fa6401b5-8599-424f-b52a-2aedd835dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-17727970-0141-4ad6-abf9-5095a774d87f,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-3e1be8e6-755c-4ec1-8494-898856494601,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-8d76cb26-7f92-434d-b354-acc2a3da1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-eefa980a-091f-4a99-9c88-18ccf39090b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-670795c3-4002-42e9-8e29-58fc0c36f815,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-805a4a38-897a-49c2-8f09-7ecb7c75e015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891196768-172.17.0.7-1595874341281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44288,DS-f1b46920-81c6-4c98-a617-0d13a831e8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-fa6401b5-8599-424f-b52a-2aedd835dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-17727970-0141-4ad6-abf9-5095a774d87f,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-3e1be8e6-755c-4ec1-8494-898856494601,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-8d76cb26-7f92-434d-b354-acc2a3da1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-eefa980a-091f-4a99-9c88-18ccf39090b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-670795c3-4002-42e9-8e29-58fc0c36f815,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-805a4a38-897a-49c2-8f09-7ecb7c75e015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321854309-172.17.0.7-1595874440892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-919ade0e-ce41-408d-bd2c-efa0b7f01a97,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-e99f47dc-9f4c-4947-924c-9812cd52c0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9a7940f9-4bda-4d77-ae38-14b30d7ecf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-b3da61b5-6c50-4141-aa1c-0fc3077fcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-c8e2085a-b537-4823-8ee6-f1d6a53a6f27,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-38fabc03-512d-487b-b28c-e3f4924b01a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-5c3f9276-baf3-4667-8086-6fb708d0f962,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-762a8079-0e06-4c67-944f-7948abaf6c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321854309-172.17.0.7-1595874440892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-919ade0e-ce41-408d-bd2c-efa0b7f01a97,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-e99f47dc-9f4c-4947-924c-9812cd52c0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9a7940f9-4bda-4d77-ae38-14b30d7ecf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-b3da61b5-6c50-4141-aa1c-0fc3077fcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-c8e2085a-b537-4823-8ee6-f1d6a53a6f27,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-38fabc03-512d-487b-b28c-e3f4924b01a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-5c3f9276-baf3-4667-8086-6fb708d0f962,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-762a8079-0e06-4c67-944f-7948abaf6c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12570499-172.17.0.7-1595874571811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-c5ed6a6b-66dc-47f4-80fd-bb8b449cd967,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-a07f7f4b-1d78-4595-8368-3ea85c8ea52b,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-bd2dccd0-6f71-4a1a-9249-c2388b980835,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-6482178d-5602-4097-869e-90957aad81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-cb681370-839e-4387-87f5-ac785feed7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-55c3f835-4bc1-484b-9565-39df252ef3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-cce11e2a-934e-4868-91be-2cf8c01dce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-6d82107d-6cec-4691-a108-266b44a6d769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12570499-172.17.0.7-1595874571811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-c5ed6a6b-66dc-47f4-80fd-bb8b449cd967,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-a07f7f4b-1d78-4595-8368-3ea85c8ea52b,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-bd2dccd0-6f71-4a1a-9249-c2388b980835,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-6482178d-5602-4097-869e-90957aad81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-cb681370-839e-4387-87f5-ac785feed7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-55c3f835-4bc1-484b-9565-39df252ef3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-cce11e2a-934e-4868-91be-2cf8c01dce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-6d82107d-6cec-4691-a108-266b44a6d769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 6000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448224173-172.17.0.7-1595874720445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38959,DS-cba0f6b7-6add-4bf3-b880-de24694c108c,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-1672e516-09a3-438b-a505-56e4dfdfd5db,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-9a9a3dc9-4633-4594-af5f-2ac6b8c24bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-ff09dc31-9411-428a-bcce-3d18c4f59198,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-d25e9214-1e14-4017-9eba-e558510a84c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-5a88617d-5019-4d03-88da-de81114fbfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-d380a48b-dc38-41aa-add6-38cd297d6f89,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-1b1a3724-d555-4701-9eab-9fad668c592a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448224173-172.17.0.7-1595874720445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38959,DS-cba0f6b7-6add-4bf3-b880-de24694c108c,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-1672e516-09a3-438b-a505-56e4dfdfd5db,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-9a9a3dc9-4633-4594-af5f-2ac6b8c24bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-ff09dc31-9411-428a-bcce-3d18c4f59198,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-d25e9214-1e14-4017-9eba-e558510a84c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-5a88617d-5019-4d03-88da-de81114fbfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-d380a48b-dc38-41aa-add6-38cd297d6f89,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-1b1a3724-d555-4701-9eab-9fad668c592a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5211
