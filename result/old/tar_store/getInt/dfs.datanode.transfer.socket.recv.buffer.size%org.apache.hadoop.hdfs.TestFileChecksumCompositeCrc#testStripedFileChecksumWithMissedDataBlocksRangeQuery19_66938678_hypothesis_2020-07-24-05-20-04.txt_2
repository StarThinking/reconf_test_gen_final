reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177955339-172.17.0.4-1595568576841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-bcbdf2d3-ab58-4576-a2ec-de97ab8a2993,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-addf003f-a22b-4f49-9311-81d93474118d,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-9b170306-ad4f-4b38-a02f-7cea9b9d74dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-64df7ddf-d027-4585-b67a-4367878458df,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-044f8524-d3db-45ca-bedc-1fd174cdf038,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-a8af0b77-9250-431e-a2c6-8ae0c3280002,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-c366175f-7eb4-4896-acb2-ded793657266,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-d2ea2939-e573-4247-a642-ae644f7cefb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177955339-172.17.0.4-1595568576841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-bcbdf2d3-ab58-4576-a2ec-de97ab8a2993,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-addf003f-a22b-4f49-9311-81d93474118d,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-9b170306-ad4f-4b38-a02f-7cea9b9d74dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-64df7ddf-d027-4585-b67a-4367878458df,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-044f8524-d3db-45ca-bedc-1fd174cdf038,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-a8af0b77-9250-431e-a2c6-8ae0c3280002,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-c366175f-7eb4-4896-acb2-ded793657266,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-d2ea2939-e573-4247-a642-ae644f7cefb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990012439-172.17.0.4-1595569090604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43030,DS-9f80a64f-bc50-4781-808c-17fb4468fcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-8f0c364e-3551-4d1f-8666-a0a03b145e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-6d08dbc0-ce24-40b0-97e7-b01116cab4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-3cc0b908-6146-46b1-9fc0-36cdcd7e2144,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-b367eb78-0a7a-4a43-965b-a27d87800f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-a12bdb50-f512-4d90-ab9f-e066f9c1a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-c189d0a1-ca48-49fc-9d25-60d8e19f0f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-88a5e46a-5bcd-4f68-bab2-7e14e9079c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990012439-172.17.0.4-1595569090604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43030,DS-9f80a64f-bc50-4781-808c-17fb4468fcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-8f0c364e-3551-4d1f-8666-a0a03b145e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-6d08dbc0-ce24-40b0-97e7-b01116cab4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-3cc0b908-6146-46b1-9fc0-36cdcd7e2144,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-b367eb78-0a7a-4a43-965b-a27d87800f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-a12bdb50-f512-4d90-ab9f-e066f9c1a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-c189d0a1-ca48-49fc-9d25-60d8e19f0f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-88a5e46a-5bcd-4f68-bab2-7e14e9079c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322854981-172.17.0.4-1595569578849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-d5adf2f5-fe91-46cb-b2d8-72235de1fd81,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-4c537c65-722e-4562-af9c-5b68f117ffaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-e8460bf1-fb4e-45bb-96cb-2e771f58c0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-ad7f9108-87df-4fa4-8e0e-e0a0a34ba7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-631b97be-7f99-40cf-921b-d3c528497403,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-5f348061-0f58-4652-8263-c2dfcc074cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-7c053fb0-b5af-4732-8986-eb383968211b,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-5b645ab0-edaa-4f12-a315-ba7a161ded66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322854981-172.17.0.4-1595569578849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-d5adf2f5-fe91-46cb-b2d8-72235de1fd81,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-4c537c65-722e-4562-af9c-5b68f117ffaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-e8460bf1-fb4e-45bb-96cb-2e771f58c0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-ad7f9108-87df-4fa4-8e0e-e0a0a34ba7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-631b97be-7f99-40cf-921b-d3c528497403,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-5f348061-0f58-4652-8263-c2dfcc074cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-7c053fb0-b5af-4732-8986-eb383968211b,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-5b645ab0-edaa-4f12-a315-ba7a161ded66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806662529-172.17.0.4-1595570304485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-e37f8ca1-6a6b-44b1-b2ae-9d6d91a594c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-0f89f59d-5544-4b0a-aec1-4ca152a1cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-5295f2d2-c8f1-4794-b584-51cc91731b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-43ec1874-3b7a-488a-8372-3efb3d75fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-317b8f85-4283-4192-8ee0-c30bb448701f,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-8be157c0-7e45-4586-b1fd-fc8be3bcaeac,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-59a81572-fd66-425d-af32-3dd58d30ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-74a07974-9440-4bb7-89b3-555a57b03841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806662529-172.17.0.4-1595570304485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-e37f8ca1-6a6b-44b1-b2ae-9d6d91a594c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-0f89f59d-5544-4b0a-aec1-4ca152a1cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-5295f2d2-c8f1-4794-b584-51cc91731b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-43ec1874-3b7a-488a-8372-3efb3d75fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-317b8f85-4283-4192-8ee0-c30bb448701f,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-8be157c0-7e45-4586-b1fd-fc8be3bcaeac,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-59a81572-fd66-425d-af32-3dd58d30ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-74a07974-9440-4bb7-89b3-555a57b03841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717681309-172.17.0.4-1595570419313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-8360b3d2-4c09-429f-9cd0-b15537ca84f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-f45207ac-acde-45d4-9a95-9d587d3a8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-6201f25c-903b-4e2f-8ab6-197ea4206173,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-a72d6da9-412e-4e7c-9451-09500debea29,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-fe396540-4acf-44d6-8439-6c36dd14d0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-1a64c223-3595-45b6-a120-1ff7b3f079b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-a78cbe26-ca18-4581-846d-f85392b1697c,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-641bd202-1845-42a6-8ef5-0fc75bc726ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717681309-172.17.0.4-1595570419313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-8360b3d2-4c09-429f-9cd0-b15537ca84f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-f45207ac-acde-45d4-9a95-9d587d3a8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-6201f25c-903b-4e2f-8ab6-197ea4206173,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-a72d6da9-412e-4e7c-9451-09500debea29,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-fe396540-4acf-44d6-8439-6c36dd14d0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-1a64c223-3595-45b6-a120-1ff7b3f079b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-a78cbe26-ca18-4581-846d-f85392b1697c,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-641bd202-1845-42a6-8ef5-0fc75bc726ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122387197-172.17.0.4-1595571404413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-7eb3f5bb-3b16-4fdc-8757-218574c0a61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-f9c23774-9012-45d7-b198-0bad10da13e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-4faea25b-f3ec-44b4-9d49-2f087e2ebe4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-d58f3480-cfcb-42cb-950a-292bf009850f,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-75d59e27-49ef-427e-a360-87ffb43ba5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-a1acbe77-fd02-4974-86b2-c27bcb79ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-83c4af85-e1a3-4f41-b757-b60062f7e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-f6a44fff-f7fa-4ad2-ab2b-5fe826306046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122387197-172.17.0.4-1595571404413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-7eb3f5bb-3b16-4fdc-8757-218574c0a61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-f9c23774-9012-45d7-b198-0bad10da13e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-4faea25b-f3ec-44b4-9d49-2f087e2ebe4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-d58f3480-cfcb-42cb-950a-292bf009850f,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-75d59e27-49ef-427e-a360-87ffb43ba5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-a1acbe77-fd02-4974-86b2-c27bcb79ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-83c4af85-e1a3-4f41-b757-b60062f7e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-f6a44fff-f7fa-4ad2-ab2b-5fe826306046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375239064-172.17.0.4-1595572090624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37041,DS-21c4781d-611a-42f1-96df-ce1dc68f4073,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-d99c9bd9-d952-4b19-8a4d-e8ac021e210b,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-ea8c2fbd-d352-4cef-8270-8f2843733824,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-86483477-5289-4059-9310-46a5eb435d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-cea5b4db-763a-4a37-a124-ee00566cad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-7dfb35ab-8cc3-44a1-a45d-9f9aabefd758,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-7644058b-e8cf-47a1-8cdd-a4fac6feeb15,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-c298d06d-5504-426f-8905-17d320949818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375239064-172.17.0.4-1595572090624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37041,DS-21c4781d-611a-42f1-96df-ce1dc68f4073,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-d99c9bd9-d952-4b19-8a4d-e8ac021e210b,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-ea8c2fbd-d352-4cef-8270-8f2843733824,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-86483477-5289-4059-9310-46a5eb435d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-cea5b4db-763a-4a37-a124-ee00566cad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-7dfb35ab-8cc3-44a1-a45d-9f9aabefd758,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-7644058b-e8cf-47a1-8cdd-a4fac6feeb15,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-c298d06d-5504-426f-8905-17d320949818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520121051-172.17.0.4-1595572161300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45274,DS-98383fde-6a5b-4afc-bceb-e29a03b9661e,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-4626e4b3-57a2-428f-a035-7a4c4877def8,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-b9902e7c-69d6-4e56-ab96-2512e737e40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-2ec9c4b1-5f00-473e-a377-d1b60dccef92,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-5caf15c5-38f4-4bff-a6c3-625119d8626e,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-73e186db-6716-4aac-9863-0281a6df8744,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-2dc192f7-41db-4c1d-969c-79234eb705b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-74674487-2b78-4631-9a49-087ec5546c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520121051-172.17.0.4-1595572161300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45274,DS-98383fde-6a5b-4afc-bceb-e29a03b9661e,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-4626e4b3-57a2-428f-a035-7a4c4877def8,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-b9902e7c-69d6-4e56-ab96-2512e737e40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-2ec9c4b1-5f00-473e-a377-d1b60dccef92,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-5caf15c5-38f4-4bff-a6c3-625119d8626e,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-73e186db-6716-4aac-9863-0281a6df8744,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-2dc192f7-41db-4c1d-969c-79234eb705b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-74674487-2b78-4631-9a49-087ec5546c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921476165-172.17.0.4-1595572417206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35555,DS-247fc634-1321-4866-ad02-36dd37252b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-d62cc7c0-bcfb-4d33-aa36-f02708ecae08,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-61c733a9-82bd-48fc-8ed2-9ad724eb7884,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-728d9cf5-3f6e-43f1-805d-b3c8143d0833,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-a4d05da4-c84d-4b7b-b82b-492332ed3c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-68203929-57ae-489f-966d-71797e8a6c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-c0f9c3e8-1c6d-485e-affb-1a4dddb8b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-ac7816a1-5074-4f1f-8ca1-d73ef49f04c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921476165-172.17.0.4-1595572417206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35555,DS-247fc634-1321-4866-ad02-36dd37252b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-d62cc7c0-bcfb-4d33-aa36-f02708ecae08,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-61c733a9-82bd-48fc-8ed2-9ad724eb7884,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-728d9cf5-3f6e-43f1-805d-b3c8143d0833,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-a4d05da4-c84d-4b7b-b82b-492332ed3c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-68203929-57ae-489f-966d-71797e8a6c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-c0f9c3e8-1c6d-485e-affb-1a4dddb8b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-ac7816a1-5074-4f1f-8ca1-d73ef49f04c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157388667-172.17.0.4-1595572533372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-1624880a-8667-4ab4-ba40-a8abe408507c,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-e95fb956-155e-4fd1-9f27-2033da0547e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-24649356-8c19-4932-acab-213acd1ce2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-c7a8086a-b2eb-42a0-a020-3823ae38d623,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-b008b04f-3be2-477d-a4c1-a194b33d0f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-d7cfec14-bd8a-44df-b102-96b835e23040,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-2d4b89e9-561f-4348-a3cb-75302be4cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-0b48fcd4-449e-4741-b2e7-ac60900cb8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157388667-172.17.0.4-1595572533372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-1624880a-8667-4ab4-ba40-a8abe408507c,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-e95fb956-155e-4fd1-9f27-2033da0547e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-24649356-8c19-4932-acab-213acd1ce2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-c7a8086a-b2eb-42a0-a020-3823ae38d623,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-b008b04f-3be2-477d-a4c1-a194b33d0f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-d7cfec14-bd8a-44df-b102-96b835e23040,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-2d4b89e9-561f-4348-a3cb-75302be4cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-0b48fcd4-449e-4741-b2e7-ac60900cb8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 128
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188724711-172.17.0.4-1595572883194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34248,DS-3cb3c0df-b6ca-4261-94a6-54df92cebc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-7769594f-d117-4e04-a3e2-4cd7b6fdb5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-a8da25e3-01a1-4ac3-be89-a4835f585c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-1e1af60b-0b0d-4a1a-bbf0-8b86628e1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-8d58405c-7b88-49ec-9396-590bf537ea15,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-117bfcf3-2bed-4924-8b0d-e6ee216f73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-1928dd61-c9e9-4040-8d7f-7fa71e2a75ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-d8458651-15fd-4f7d-9184-b5207bc43995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188724711-172.17.0.4-1595572883194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34248,DS-3cb3c0df-b6ca-4261-94a6-54df92cebc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-7769594f-d117-4e04-a3e2-4cd7b6fdb5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-a8da25e3-01a1-4ac3-be89-a4835f585c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-1e1af60b-0b0d-4a1a-bbf0-8b86628e1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-8d58405c-7b88-49ec-9396-590bf537ea15,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-117bfcf3-2bed-4924-8b0d-e6ee216f73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-1928dd61-c9e9-4040-8d7f-7fa71e2a75ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-d8458651-15fd-4f7d-9184-b5207bc43995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5463
