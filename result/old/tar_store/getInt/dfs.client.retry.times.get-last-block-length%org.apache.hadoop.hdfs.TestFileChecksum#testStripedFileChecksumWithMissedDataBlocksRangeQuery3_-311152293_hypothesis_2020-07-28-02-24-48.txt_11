reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581521945-172.17.0.17-1595903536388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37415,DS-569950e6-44ee-433a-9fec-0f33c0a76f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-8182ed40-7751-49b8-80fa-8d6f92f0c580,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-b8030de9-2128-4ee9-9d34-d94f6b1e9442,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-75a6361d-29c0-4e78-8c72-6c2fd1bfdc84,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-962569e3-978c-415e-83b0-7564b7508bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-6ac4a07f-6ba0-46e2-8d69-92db5e79d92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-ee402311-5c5b-456d-81ca-5e4c9bdc9d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-cd4e5bf7-a1e7-4158-a61a-eaaae352427b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581521945-172.17.0.17-1595903536388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37415,DS-569950e6-44ee-433a-9fec-0f33c0a76f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-8182ed40-7751-49b8-80fa-8d6f92f0c580,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-b8030de9-2128-4ee9-9d34-d94f6b1e9442,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-75a6361d-29c0-4e78-8c72-6c2fd1bfdc84,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-962569e3-978c-415e-83b0-7564b7508bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-6ac4a07f-6ba0-46e2-8d69-92db5e79d92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-ee402311-5c5b-456d-81ca-5e4c9bdc9d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-cd4e5bf7-a1e7-4158-a61a-eaaae352427b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872536801-172.17.0.17-1595903981745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-d9c19e01-3b79-4bb1-acb3-02eadd174614,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-26441d39-32ad-4631-891c-1e91827b6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-fe819392-1ff2-4b01-a214-830545eab106,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-4b53d345-b522-423e-99ed-af50365d4980,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-849354f6-7d73-46e1-a08e-f89dae2e7e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-21bdef5f-835b-4705-bfc4-a414204d67d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-d56faa87-cf07-4805-9c19-1ec4b39b9bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-236fe600-8d24-42fb-a91b-02c4ade57ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872536801-172.17.0.17-1595903981745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-d9c19e01-3b79-4bb1-acb3-02eadd174614,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-26441d39-32ad-4631-891c-1e91827b6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-fe819392-1ff2-4b01-a214-830545eab106,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-4b53d345-b522-423e-99ed-af50365d4980,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-849354f6-7d73-46e1-a08e-f89dae2e7e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-21bdef5f-835b-4705-bfc4-a414204d67d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-d56faa87-cf07-4805-9c19-1ec4b39b9bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-236fe600-8d24-42fb-a91b-02c4ade57ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022246223-172.17.0.17-1595904116713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-45a01105-e042-4d10-a36d-55436ef8a449,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-c4a5465b-33d0-4d7e-9318-6c0f23fd070c,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-f28f6fea-8ba4-4d9e-9a9a-6d8f9dcc3f08,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-e7d35d95-fce8-44b3-9ff8-f2f44dcfb358,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-538e7ecd-5a76-43b2-b7af-370d8a5d7b84,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-370dae9e-d658-4aa6-9209-ad80eff69678,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-fd0d966c-fb25-41b6-8e7c-5d93506586ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-6272ae0b-7ae7-4c05-9ee5-fef2f5fbb643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022246223-172.17.0.17-1595904116713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-45a01105-e042-4d10-a36d-55436ef8a449,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-c4a5465b-33d0-4d7e-9318-6c0f23fd070c,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-f28f6fea-8ba4-4d9e-9a9a-6d8f9dcc3f08,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-e7d35d95-fce8-44b3-9ff8-f2f44dcfb358,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-538e7ecd-5a76-43b2-b7af-370d8a5d7b84,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-370dae9e-d658-4aa6-9209-ad80eff69678,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-fd0d966c-fb25-41b6-8e7c-5d93506586ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-6272ae0b-7ae7-4c05-9ee5-fef2f5fbb643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044903650-172.17.0.17-1595904320063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-93282d06-3f8a-4172-8d5a-d3ce004260a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-88ff0929-4014-41bd-822b-47004168ce94,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-801f26ac-41e4-4228-a659-3c24079b72ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-06a00315-e3cf-442c-8156-a1910be61dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-05854c6b-e925-4e2e-a0f2-1b986dacac33,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-b87cdd6a-c5c6-48c3-b1cd-0af083cb32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-be4e9d27-1505-4f33-b340-afd6125ad7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-70337fc8-65a6-4058-a44c-6c555d2c6094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044903650-172.17.0.17-1595904320063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-93282d06-3f8a-4172-8d5a-d3ce004260a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-88ff0929-4014-41bd-822b-47004168ce94,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-801f26ac-41e4-4228-a659-3c24079b72ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-06a00315-e3cf-442c-8156-a1910be61dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-05854c6b-e925-4e2e-a0f2-1b986dacac33,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-b87cdd6a-c5c6-48c3-b1cd-0af083cb32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-be4e9d27-1505-4f33-b340-afd6125ad7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-70337fc8-65a6-4058-a44c-6c555d2c6094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752520507-172.17.0.17-1595904463007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36374,DS-85b24d52-b912-4517-aff6-2954a7dab949,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-7d77aa5c-dba3-49bb-82f7-991a9f86283b,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-b14789c4-421c-438d-a41c-49d5ca611b87,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-dfa62821-d304-4b60-87e5-80cd8e29f20b,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-201d5485-e8d9-4abe-9ea2-4dd28ff69df4,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-37381e49-f772-4129-8b3d-fb9a79160cce,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-37ed17ff-f1f4-4297-b574-da41d9a306e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-62ba352b-e83f-4995-b339-b0c4ee98d8c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752520507-172.17.0.17-1595904463007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36374,DS-85b24d52-b912-4517-aff6-2954a7dab949,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-7d77aa5c-dba3-49bb-82f7-991a9f86283b,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-b14789c4-421c-438d-a41c-49d5ca611b87,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-dfa62821-d304-4b60-87e5-80cd8e29f20b,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-201d5485-e8d9-4abe-9ea2-4dd28ff69df4,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-37381e49-f772-4129-8b3d-fb9a79160cce,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-37ed17ff-f1f4-4297-b574-da41d9a306e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-62ba352b-e83f-4995-b339-b0c4ee98d8c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402392534-172.17.0.17-1595904503233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-be15aba8-d823-42a9-9838-4246bcb4bb24,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-183570b4-c90b-4032-943b-54b886da2180,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-1d1d38d0-fc90-4aa1-b760-c2e0beaf1b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-5d632771-bd9b-46f1-bf83-753819c417fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-39dccc72-bb4b-4dfc-a5c7-2f047aa3d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-23a21779-983e-4f5b-94e5-4055929fdc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-9f78b5e1-53ce-4855-ae59-7215ff03d912,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-286a204f-4949-4a83-9cc7-912cd88e7ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402392534-172.17.0.17-1595904503233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-be15aba8-d823-42a9-9838-4246bcb4bb24,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-183570b4-c90b-4032-943b-54b886da2180,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-1d1d38d0-fc90-4aa1-b760-c2e0beaf1b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-5d632771-bd9b-46f1-bf83-753819c417fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-39dccc72-bb4b-4dfc-a5c7-2f047aa3d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-23a21779-983e-4f5b-94e5-4055929fdc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-9f78b5e1-53ce-4855-ae59-7215ff03d912,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-286a204f-4949-4a83-9cc7-912cd88e7ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720179143-172.17.0.17-1595904736952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-1623e034-4956-4ad7-95a2-ae3a004556c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-7ee1b9e2-cc0f-4af7-8f5c-531c881ab905,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-0c9b6d8e-b8a5-4d14-aee1-f23be735b5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-d3bfefa9-13b6-403a-a629-3cbdae128065,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-53d664e5-383e-4c03-9856-a3e5f38cf631,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-11ffbc49-3be8-4d15-8353-67860c5ddcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-bb53e413-446b-49c0-93fe-0759e39ca78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-b32d3233-4ca6-4582-a629-e28f3b367762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720179143-172.17.0.17-1595904736952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-1623e034-4956-4ad7-95a2-ae3a004556c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-7ee1b9e2-cc0f-4af7-8f5c-531c881ab905,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-0c9b6d8e-b8a5-4d14-aee1-f23be735b5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-d3bfefa9-13b6-403a-a629-3cbdae128065,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-53d664e5-383e-4c03-9856-a3e5f38cf631,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-11ffbc49-3be8-4d15-8353-67860c5ddcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-bb53e413-446b-49c0-93fe-0759e39ca78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-b32d3233-4ca6-4582-a629-e28f3b367762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910306917-172.17.0.17-1595905284355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39798,DS-53c16fa7-6cc4-40dc-8364-b05110c0b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-2b2e6a55-8622-4beb-ab92-315a4ff08212,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-0d655066-da9e-45e1-b784-95c59d8112c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-8ba8676e-6aa0-46ce-8de3-9fdb3db24fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-63af4a64-95dd-41b2-8278-3d0a869963fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-ae59582a-f319-4296-921e-9ba42f7a1092,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-0052d1f4-f394-4c27-908b-4ea78d84d048,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-4a4494c3-461d-4ec7-a4c6-775d833aac80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910306917-172.17.0.17-1595905284355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39798,DS-53c16fa7-6cc4-40dc-8364-b05110c0b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-2b2e6a55-8622-4beb-ab92-315a4ff08212,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-0d655066-da9e-45e1-b784-95c59d8112c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-8ba8676e-6aa0-46ce-8de3-9fdb3db24fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-63af4a64-95dd-41b2-8278-3d0a869963fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-ae59582a-f319-4296-921e-9ba42f7a1092,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-0052d1f4-f394-4c27-908b-4ea78d84d048,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-4a4494c3-461d-4ec7-a4c6-775d833aac80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772899261-172.17.0.17-1595905331062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-ab938e2a-7221-4b51-851d-66151853f5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-6a0a8a3f-a6bf-4000-83d7-734868a1f412,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-47c66832-7d2c-42c7-a9d6-98e57f710cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-8cf94bb4-d88c-49aa-a9ae-bb1707688ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-65a43334-3b2d-4337-b3bd-438e67a35905,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-55ffd1ac-a5dd-4bd7-b158-9ac91ddeded2,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-95a3defa-d1b0-4d31-8563-0ee239aeb5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-3b39af14-0357-4289-8123-6b86f51e13a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772899261-172.17.0.17-1595905331062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-ab938e2a-7221-4b51-851d-66151853f5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-6a0a8a3f-a6bf-4000-83d7-734868a1f412,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-47c66832-7d2c-42c7-a9d6-98e57f710cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-8cf94bb4-d88c-49aa-a9ae-bb1707688ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-65a43334-3b2d-4337-b3bd-438e67a35905,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-55ffd1ac-a5dd-4bd7-b158-9ac91ddeded2,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-95a3defa-d1b0-4d31-8563-0ee239aeb5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-3b39af14-0357-4289-8123-6b86f51e13a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486030634-172.17.0.17-1595905369170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-e2e1175d-5ac9-4dd1-8f03-a59623df76bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-290ec922-5be1-4bfe-b460-d9239e87c386,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-53701bf0-7c0e-423d-aa0b-9167cc37f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-31667818-8892-478b-afa7-4a2b330a9835,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-b77070ad-ed9a-4b4e-a810-a1816c03ebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-ac48d3ad-1fb5-4459-bea6-f06d2be85548,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-019d20ed-cfbe-46b6-a203-ebba3c4df1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-88a06d14-a35d-4fc7-a3f2-f436423456c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486030634-172.17.0.17-1595905369170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-e2e1175d-5ac9-4dd1-8f03-a59623df76bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-290ec922-5be1-4bfe-b460-d9239e87c386,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-53701bf0-7c0e-423d-aa0b-9167cc37f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-31667818-8892-478b-afa7-4a2b330a9835,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-b77070ad-ed9a-4b4e-a810-a1816c03ebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-ac48d3ad-1fb5-4459-bea6-f06d2be85548,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-019d20ed-cfbe-46b6-a203-ebba3c4df1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-88a06d14-a35d-4fc7-a3f2-f436423456c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905392495-172.17.0.17-1595905599301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42525,DS-3c3a3e38-78fd-40ca-8f0a-7300832ec1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-890358fd-0eac-454f-a427-6e4f04913097,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-14950654-4295-451d-90a1-59db6278bbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-83736624-2dce-4b29-a752-1f981309e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-572a6796-0d3c-4bb5-a485-d9b4849ec3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-65259c39-6e11-462b-9b40-764938e9ff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-261b4b73-e448-414e-8b1d-f1f7c12d3c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-ba7d05c4-2479-4220-98d3-d75f5b84ae55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905392495-172.17.0.17-1595905599301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42525,DS-3c3a3e38-78fd-40ca-8f0a-7300832ec1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-890358fd-0eac-454f-a427-6e4f04913097,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-14950654-4295-451d-90a1-59db6278bbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-83736624-2dce-4b29-a752-1f981309e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-572a6796-0d3c-4bb5-a485-d9b4849ec3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-65259c39-6e11-462b-9b40-764938e9ff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-261b4b73-e448-414e-8b1d-f1f7c12d3c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-ba7d05c4-2479-4220-98d3-d75f5b84ae55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029954177-172.17.0.17-1595905745118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35618,DS-f0d4ccdc-f557-49b7-a124-1cd36d2725ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-6c789bb3-010d-45ff-981d-c9b287f2f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-dffb99b2-cda5-4e58-b588-cae462cca3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-c722acb3-be76-4fe9-9c5c-a46c2be97047,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-3ab17460-f4ca-4a72-80c1-d92cba966d66,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-8a8d6cd1-f17a-4e8c-9018-36e2386a8bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-af4a6426-acc2-4ec8-abf4-59ead065ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-d36bc3ea-7918-44f8-a3ed-4f631ea2f2d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029954177-172.17.0.17-1595905745118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35618,DS-f0d4ccdc-f557-49b7-a124-1cd36d2725ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-6c789bb3-010d-45ff-981d-c9b287f2f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-dffb99b2-cda5-4e58-b588-cae462cca3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-c722acb3-be76-4fe9-9c5c-a46c2be97047,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-3ab17460-f4ca-4a72-80c1-d92cba966d66,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-8a8d6cd1-f17a-4e8c-9018-36e2386a8bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-af4a6426-acc2-4ec8-abf4-59ead065ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-d36bc3ea-7918-44f8-a3ed-4f631ea2f2d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268117246-172.17.0.17-1595905959723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38346,DS-7e61c635-81f8-41d4-97ba-82e808b2f474,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-9189bc74-f78f-4a24-bb47-7f659888e412,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-03e104b8-333e-41fa-b665-5c14cd763d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-74d49b15-af6e-4f40-b1ae-441bff52fd49,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-bdd955fd-80be-4aaf-8f0d-4c9b525ea8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-862057a0-16d0-4f4c-ae41-cfb4b609b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-ff494453-35c4-4640-8c97-610d446cb1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-98d97729-9432-4041-9662-32d3478452c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268117246-172.17.0.17-1595905959723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38346,DS-7e61c635-81f8-41d4-97ba-82e808b2f474,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-9189bc74-f78f-4a24-bb47-7f659888e412,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-03e104b8-333e-41fa-b665-5c14cd763d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-74d49b15-af6e-4f40-b1ae-441bff52fd49,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-bdd955fd-80be-4aaf-8f0d-4c9b525ea8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-862057a0-16d0-4f4c-ae41-cfb4b609b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-ff494453-35c4-4640-8c97-610d446cb1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-98d97729-9432-4041-9662-32d3478452c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875254863-172.17.0.17-1595906180609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33171,DS-67228421-9f87-4357-bbea-f63805d7947b,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-c734ad5c-b50f-4408-a56d-ab8bb06a3036,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-e182b2e3-014b-4f39-b125-b91002a2eefe,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-83dfb3c5-3e93-4062-9bf1-eed560a62374,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-49193d34-0729-4580-b496-32d71eeb7923,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-763bcc2d-e6d6-4067-9878-6947e6217060,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-68f5e1d1-9756-4a83-b797-5f1354b4fd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-c3106765-201c-4e67-b4d7-6c68ca6b4866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875254863-172.17.0.17-1595906180609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33171,DS-67228421-9f87-4357-bbea-f63805d7947b,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-c734ad5c-b50f-4408-a56d-ab8bb06a3036,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-e182b2e3-014b-4f39-b125-b91002a2eefe,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-83dfb3c5-3e93-4062-9bf1-eed560a62374,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-49193d34-0729-4580-b496-32d71eeb7923,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-763bcc2d-e6d6-4067-9878-6947e6217060,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-68f5e1d1-9756-4a83-b797-5f1354b4fd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-c3106765-201c-4e67-b4d7-6c68ca6b4866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218227556-172.17.0.17-1595907437432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-77d2fe17-8dd8-403c-aee6-e12b2af457d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-6c8e9443-28b2-4506-8832-718a0aadbd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-805a6260-f55d-4c7c-8b84-c899f597dea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-af7bab86-97df-470a-964e-906930f7505f,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-4fcf422b-a42a-4611-9355-3af01fe7a416,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-947471d5-0846-4bb2-95d8-cc43c5ec993f,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-d9f98bc4-62cf-455f-8978-b99a6dd35b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-c3eda387-5098-4892-bc22-5f3dfffdd6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218227556-172.17.0.17-1595907437432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-77d2fe17-8dd8-403c-aee6-e12b2af457d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-6c8e9443-28b2-4506-8832-718a0aadbd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-805a6260-f55d-4c7c-8b84-c899f597dea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-af7bab86-97df-470a-964e-906930f7505f,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-4fcf422b-a42a-4611-9355-3af01fe7a416,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-947471d5-0846-4bb2-95d8-cc43c5ec993f,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-d9f98bc4-62cf-455f-8978-b99a6dd35b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-c3eda387-5098-4892-bc22-5f3dfffdd6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622472342-172.17.0.17-1595908047428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-4904d102-37c9-4bd2-a5f4-a2492874ac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-7b959876-5321-4538-bc56-a615563b6fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-8223a53d-e242-4617-b30b-67c8763d92f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-133ce577-ab6d-49a8-946f-d99391efe565,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-bfa60542-9d93-431c-b7aa-7ff5c229a1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-a54855cb-4cf2-4b66-a771-245665672987,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-4c63b6c5-1fb4-439c-ad5d-f92c583b1b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-44c32d2c-3ce5-4711-aad5-9df7c5b81090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622472342-172.17.0.17-1595908047428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-4904d102-37c9-4bd2-a5f4-a2492874ac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-7b959876-5321-4538-bc56-a615563b6fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-8223a53d-e242-4617-b30b-67c8763d92f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-133ce577-ab6d-49a8-946f-d99391efe565,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-bfa60542-9d93-431c-b7aa-7ff5c229a1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-a54855cb-4cf2-4b66-a771-245665672987,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-4c63b6c5-1fb4-439c-ad5d-f92c583b1b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-44c32d2c-3ce5-4711-aad5-9df7c5b81090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600767229-172.17.0.17-1595908621319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38706,DS-e0cc4d40-f4a7-433d-882c-2cc920b62d58,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-ed68e76a-c0a6-48e2-bb3c-c3aa0f8114d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-83b9d0a0-3b18-4a56-995e-89452ea87427,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-25e05826-cd3f-4162-9ed7-8f4c30bbb9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-23379ca3-84de-491f-bc1a-0756fbcd278e,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-6eab51bd-e71d-4920-add8-61b4cf350ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-51f34337-d807-4f0b-ba45-b97f1984a228,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-f5697f29-e8be-4ed8-a3d1-30af4afa64e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600767229-172.17.0.17-1595908621319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38706,DS-e0cc4d40-f4a7-433d-882c-2cc920b62d58,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-ed68e76a-c0a6-48e2-bb3c-c3aa0f8114d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-83b9d0a0-3b18-4a56-995e-89452ea87427,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-25e05826-cd3f-4162-9ed7-8f4c30bbb9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-23379ca3-84de-491f-bc1a-0756fbcd278e,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-6eab51bd-e71d-4920-add8-61b4cf350ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-51f34337-d807-4f0b-ba45-b97f1984a228,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-f5697f29-e8be-4ed8-a3d1-30af4afa64e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517948997-172.17.0.17-1595908950816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34906,DS-d0fddd7d-e3ad-411c-a7cb-461010eb2778,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-6165016f-b695-44eb-9707-c66cb5014b12,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-f2008bfd-97fe-43ee-9aac-3984681419df,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-0bbde49b-6f43-4131-a50d-13199fd4c093,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-cf0e032b-7d17-49e4-89ee-7d18ea258918,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-11adac32-e9ce-4641-90aa-5bcc5a44e8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-16d2a916-fca3-4c41-a1a6-1a8100b19237,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-c0a9d923-8285-4e21-ba9e-320687da3863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517948997-172.17.0.17-1595908950816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34906,DS-d0fddd7d-e3ad-411c-a7cb-461010eb2778,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-6165016f-b695-44eb-9707-c66cb5014b12,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-f2008bfd-97fe-43ee-9aac-3984681419df,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-0bbde49b-6f43-4131-a50d-13199fd4c093,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-cf0e032b-7d17-49e4-89ee-7d18ea258918,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-11adac32-e9ce-4641-90aa-5bcc5a44e8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-16d2a916-fca3-4c41-a1a6-1a8100b19237,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-c0a9d923-8285-4e21-ba9e-320687da3863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069371528-172.17.0.17-1595909518898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-5dd049c4-c5b4-48f3-aa6b-865110ef3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-b442eb06-d432-4a28-b69b-31d6c878e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c09d6290-0842-42b8-9285-4c4716726a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-1e8120d0-cc62-4aaf-ab8f-6dbe532a52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-2bb1c470-67d3-451f-ba3f-0040c478d9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-5fc4c094-5c2c-4a1f-9cf7-cb9d70c407e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-d6cc8c1a-1014-4ece-b105-d11805f11f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-ca208d23-adf5-4101-94a5-4867e9f16fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069371528-172.17.0.17-1595909518898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-5dd049c4-c5b4-48f3-aa6b-865110ef3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-b442eb06-d432-4a28-b69b-31d6c878e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c09d6290-0842-42b8-9285-4c4716726a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-1e8120d0-cc62-4aaf-ab8f-6dbe532a52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-2bb1c470-67d3-451f-ba3f-0040c478d9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-5fc4c094-5c2c-4a1f-9cf7-cb9d70c407e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-d6cc8c1a-1014-4ece-b105-d11805f11f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-ca208d23-adf5-4101-94a5-4867e9f16fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6770
