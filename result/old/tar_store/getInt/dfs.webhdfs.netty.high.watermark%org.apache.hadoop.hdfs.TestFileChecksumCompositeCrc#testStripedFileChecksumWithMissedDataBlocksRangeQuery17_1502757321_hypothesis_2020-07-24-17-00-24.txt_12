reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869058347-172.17.0.21-1595610486325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-bf8a1c07-ce1d-46ed-996c-c0067b17418c,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-cd4cd1bc-667b-4fba-ad94-b970689df8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-0c0995bf-c468-4239-bd10-4afdd72b2135,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-68e2b21c-4ff2-459c-b212-4afc5ed45d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-2aac3424-948a-44b8-8dcc-a146368b4992,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-f1a9249a-d9cb-4ef8-9445-1ba6dd8b5226,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-a38c2760-0deb-4190-a747-b4e5a9fb7d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-8ba4ab3f-119f-4afe-a2c5-793f3e6b8ee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869058347-172.17.0.21-1595610486325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-bf8a1c07-ce1d-46ed-996c-c0067b17418c,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-cd4cd1bc-667b-4fba-ad94-b970689df8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-0c0995bf-c468-4239-bd10-4afdd72b2135,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-68e2b21c-4ff2-459c-b212-4afc5ed45d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-2aac3424-948a-44b8-8dcc-a146368b4992,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-f1a9249a-d9cb-4ef8-9445-1ba6dd8b5226,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-a38c2760-0deb-4190-a747-b4e5a9fb7d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-8ba4ab3f-119f-4afe-a2c5-793f3e6b8ee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670780756-172.17.0.21-1595610808638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34192,DS-211dcc4f-6ce8-4482-920b-c8f4ea9bf4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-fd2a69fe-e618-473c-ae3d-c4e5808a5b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-56870f53-6e73-44b9-b08b-0a2ce99c2ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-a76af128-7636-45c5-afcc-5124da8fbebe,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-8011cb7f-d17c-474f-a90d-85018c4eae41,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-51215768-7761-4eed-95ee-9ff328581ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-f7da490f-92c8-4c7f-a30b-ba20b4262e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-c8899d94-6443-4227-92c7-e5bdee825e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670780756-172.17.0.21-1595610808638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34192,DS-211dcc4f-6ce8-4482-920b-c8f4ea9bf4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-fd2a69fe-e618-473c-ae3d-c4e5808a5b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-56870f53-6e73-44b9-b08b-0a2ce99c2ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-a76af128-7636-45c5-afcc-5124da8fbebe,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-8011cb7f-d17c-474f-a90d-85018c4eae41,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-51215768-7761-4eed-95ee-9ff328581ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-f7da490f-92c8-4c7f-a30b-ba20b4262e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-c8899d94-6443-4227-92c7-e5bdee825e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338507429-172.17.0.21-1595610911003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42259,DS-b70e89d1-394d-4f3e-a11e-99a23b84c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-cf1fccd4-36ed-4d59-8403-5cb3c2dd50c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-39abaebc-58a4-46be-bf11-da13465dc9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-f138ed5b-ee96-47e0-adde-0638531c7891,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-30d27c13-6117-4819-a3c8-349b622def4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-7244cdc9-0602-434a-92bd-94485b933ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-6f5ace9c-eb02-4775-b9c0-ab8386dafc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-6167442c-f10c-405d-8b05-3eec290f2875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338507429-172.17.0.21-1595610911003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42259,DS-b70e89d1-394d-4f3e-a11e-99a23b84c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-cf1fccd4-36ed-4d59-8403-5cb3c2dd50c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-39abaebc-58a4-46be-bf11-da13465dc9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-f138ed5b-ee96-47e0-adde-0638531c7891,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-30d27c13-6117-4819-a3c8-349b622def4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-7244cdc9-0602-434a-92bd-94485b933ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-6f5ace9c-eb02-4775-b9c0-ab8386dafc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-6167442c-f10c-405d-8b05-3eec290f2875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758078415-172.17.0.21-1595610974802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-329d986e-5423-4f82-8081-8a8dac438d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-24711bad-b9af-4f8a-8257-2cbe5e08143f,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-08302071-733c-4e09-aa50-0a083f422c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-378e5619-dcca-4c7a-be34-294cf41b080d,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-46b25c93-7a4c-4cad-b434-85e56d618010,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-dce1c4c8-ae34-4ef9-ae98-ccb81a37a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-e672f819-5000-4f30-827b-5799acaf44e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-998c3f8d-9237-42a0-b771-b8494c24d041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758078415-172.17.0.21-1595610974802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-329d986e-5423-4f82-8081-8a8dac438d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-24711bad-b9af-4f8a-8257-2cbe5e08143f,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-08302071-733c-4e09-aa50-0a083f422c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-378e5619-dcca-4c7a-be34-294cf41b080d,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-46b25c93-7a4c-4cad-b434-85e56d618010,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-dce1c4c8-ae34-4ef9-ae98-ccb81a37a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-e672f819-5000-4f30-827b-5799acaf44e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-998c3f8d-9237-42a0-b771-b8494c24d041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697589393-172.17.0.21-1595611305495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-e55be0b3-47a5-493e-91b2-46d332eb2744,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-c6f0bd61-34dc-4b40-8a68-e57efffaf3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-59bada6c-1b11-48cd-8544-e578c7630330,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-6d7b145e-fe51-4e6a-aede-7a8701224121,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-288a7434-a52f-4805-8ccb-8b89887dc2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-b34eb163-1139-4f30-992e-bbebabaae62f,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-9dab08fa-e182-4ff6-9a7f-eb19110cda93,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-5081ce72-f5fe-4120-ab31-57a94725ca46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697589393-172.17.0.21-1595611305495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-e55be0b3-47a5-493e-91b2-46d332eb2744,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-c6f0bd61-34dc-4b40-8a68-e57efffaf3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-59bada6c-1b11-48cd-8544-e578c7630330,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-6d7b145e-fe51-4e6a-aede-7a8701224121,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-288a7434-a52f-4805-8ccb-8b89887dc2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-b34eb163-1139-4f30-992e-bbebabaae62f,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-9dab08fa-e182-4ff6-9a7f-eb19110cda93,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-5081ce72-f5fe-4120-ab31-57a94725ca46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46750467-172.17.0.21-1595611513340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-0fdca75e-a2f8-4626-b1be-aacf3501fdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-2f2e546b-f26b-4e47-b28b-ed0ebade105c,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-8640d6be-a981-4ae4-a1ec-d9e6f507f98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-004395e9-6708-4912-8182-e13139dcf13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-6228fef2-e2ce-494d-b0af-adbbc97ded3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-84c640e7-80f0-46eb-a403-5b29d050f41f,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-8fbac5b5-c0cb-4da9-a6a7-e1b186019bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-8ec6ce7d-cf77-490f-b0e5-8caee1c9cc68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46750467-172.17.0.21-1595611513340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-0fdca75e-a2f8-4626-b1be-aacf3501fdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-2f2e546b-f26b-4e47-b28b-ed0ebade105c,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-8640d6be-a981-4ae4-a1ec-d9e6f507f98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-004395e9-6708-4912-8182-e13139dcf13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-6228fef2-e2ce-494d-b0af-adbbc97ded3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-84c640e7-80f0-46eb-a403-5b29d050f41f,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-8fbac5b5-c0cb-4da9-a6a7-e1b186019bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-8ec6ce7d-cf77-490f-b0e5-8caee1c9cc68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58098695-172.17.0.21-1595612806537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-1c0bb6bc-b7d7-4e3e-9b71-27c0987fe647,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-81284806-ab3f-42d0-8479-6099876ee001,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-a59766ec-6b71-4655-884c-b8c9ec00a3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-3e5a228c-0fa0-4bc1-b3ec-57fc6db546c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-f916177b-40ee-4c96-831e-d2377f76be66,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-5239f76a-5bd1-4fdb-a7b3-f1c745e04e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-b769b49c-18d5-4548-b6b6-716c44a5c0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-afb8f8cb-7957-4697-8871-5593dd6f29ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58098695-172.17.0.21-1595612806537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-1c0bb6bc-b7d7-4e3e-9b71-27c0987fe647,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-81284806-ab3f-42d0-8479-6099876ee001,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-a59766ec-6b71-4655-884c-b8c9ec00a3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-3e5a228c-0fa0-4bc1-b3ec-57fc6db546c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-f916177b-40ee-4c96-831e-d2377f76be66,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-5239f76a-5bd1-4fdb-a7b3-f1c745e04e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-b769b49c-18d5-4548-b6b6-716c44a5c0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-afb8f8cb-7957-4697-8871-5593dd6f29ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427387105-172.17.0.21-1595613070649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37325,DS-69925ec9-a99f-4a2f-b2dc-df2925b30129,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-c917bc0a-c1ab-490a-87d5-9059637ecfea,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-6a3759be-b164-4ddc-821f-bff6ce90d877,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-b780bc6f-2b75-4c13-bab6-f0ddc345bdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-7c3af3cd-2e35-436f-a7fe-10419999c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-cbe10d4c-aa84-42b0-9b61-5d5d897f5b86,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-9eb449ac-e950-4538-a08d-146414744ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-d3203abd-ad80-4c06-a7e7-a48b367bc07c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427387105-172.17.0.21-1595613070649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37325,DS-69925ec9-a99f-4a2f-b2dc-df2925b30129,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-c917bc0a-c1ab-490a-87d5-9059637ecfea,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-6a3759be-b164-4ddc-821f-bff6ce90d877,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-b780bc6f-2b75-4c13-bab6-f0ddc345bdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-7c3af3cd-2e35-436f-a7fe-10419999c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-cbe10d4c-aa84-42b0-9b61-5d5d897f5b86,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-9eb449ac-e950-4538-a08d-146414744ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-d3203abd-ad80-4c06-a7e7-a48b367bc07c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370539596-172.17.0.21-1595613811617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-033fb582-8c5d-419c-b08e-c9b80d53b0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-7b8b614f-3795-4721-961a-7dd9249d42a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-7b0574f5-9a45-415a-a29e-466d90f06ced,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-0d811298-1fad-4801-b686-c5ec3ae312ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-b65dfd46-1c4c-4cb5-bbf2-9a9531012194,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-77ee25e3-966c-4433-ad7c-ba8ea52e90e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-b4ee1755-c5e7-431c-944c-8bd6615bc10b,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-09539a09-8d38-40a7-8aa9-208ccd5bdce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370539596-172.17.0.21-1595613811617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-033fb582-8c5d-419c-b08e-c9b80d53b0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-7b8b614f-3795-4721-961a-7dd9249d42a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-7b0574f5-9a45-415a-a29e-466d90f06ced,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-0d811298-1fad-4801-b686-c5ec3ae312ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-b65dfd46-1c4c-4cb5-bbf2-9a9531012194,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-77ee25e3-966c-4433-ad7c-ba8ea52e90e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-b4ee1755-c5e7-431c-944c-8bd6615bc10b,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-09539a09-8d38-40a7-8aa9-208ccd5bdce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571142321-172.17.0.21-1595614521056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40005,DS-6a8c16ed-a51e-4448-b006-b79e1396d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-b1c7c09d-f001-4a5f-b22a-3da158ab0626,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-d0508db7-1c32-4c76-ae29-99c13105e82e,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-2689b715-e695-4ecd-9a70-6f411af5acfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-900f9a80-985b-41ff-9065-2f905ac5a360,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-3837b5d2-c506-40df-9c14-9a4661a66522,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-a86e98cf-6954-4320-8e47-f33b42db7dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-ab38c665-fbd5-4ed9-a04e-979da988b611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571142321-172.17.0.21-1595614521056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40005,DS-6a8c16ed-a51e-4448-b006-b79e1396d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-b1c7c09d-f001-4a5f-b22a-3da158ab0626,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-d0508db7-1c32-4c76-ae29-99c13105e82e,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-2689b715-e695-4ecd-9a70-6f411af5acfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-900f9a80-985b-41ff-9065-2f905ac5a360,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-3837b5d2-c506-40df-9c14-9a4661a66522,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-a86e98cf-6954-4320-8e47-f33b42db7dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-ab38c665-fbd5-4ed9-a04e-979da988b611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760095294-172.17.0.21-1595614856096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-32d9a7d6-9e6f-4be0-aa68-0739a9a00879,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-99ed3eb9-3db2-417b-bb8a-4836982b9cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-8517256d-265a-43f3-a14f-c96928c9abc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-e5d263a7-ace0-4e29-af0e-9a86af53d7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-53d04fc2-8581-444e-9059-a9c12a6cb6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-998b0a94-6e8f-4368-97e1-ccc7ccf8dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-e440a80c-d76c-47bf-a4ca-2e7a45c62a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-e80831d2-a356-4c8f-b001-58fb5537a0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760095294-172.17.0.21-1595614856096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-32d9a7d6-9e6f-4be0-aa68-0739a9a00879,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-99ed3eb9-3db2-417b-bb8a-4836982b9cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-8517256d-265a-43f3-a14f-c96928c9abc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-e5d263a7-ace0-4e29-af0e-9a86af53d7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-53d04fc2-8581-444e-9059-a9c12a6cb6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-998b0a94-6e8f-4368-97e1-ccc7ccf8dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-e440a80c-d76c-47bf-a4ca-2e7a45c62a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-e80831d2-a356-4c8f-b001-58fb5537a0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5334
