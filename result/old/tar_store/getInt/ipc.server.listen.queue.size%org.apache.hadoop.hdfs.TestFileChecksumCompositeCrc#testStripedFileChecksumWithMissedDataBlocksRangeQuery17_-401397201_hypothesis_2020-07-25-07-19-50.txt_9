reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1314546153-172.17.0.6-1595661760992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38826,DS-d7285d3a-776e-4e86-993c-052b79306c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-402fa195-c1a4-4ebd-a921-68bf2f2351c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-f1554f63-ec56-40c6-80a0-b8ee6692d7af,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-5a34b159-f3fc-4644-b955-ad9e415c8217,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-2e563af9-7897-4d26-9b6a-f3ab4b98a284,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-67cdc39f-af37-4243-93fa-11cb40cb5802,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-195563d2-9462-4b6e-8945-8b68efe42a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-d58cbcb3-b10e-4478-9558-2291e822f594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1314546153-172.17.0.6-1595661760992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38826,DS-d7285d3a-776e-4e86-993c-052b79306c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-402fa195-c1a4-4ebd-a921-68bf2f2351c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-f1554f63-ec56-40c6-80a0-b8ee6692d7af,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-5a34b159-f3fc-4644-b955-ad9e415c8217,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-2e563af9-7897-4d26-9b6a-f3ab4b98a284,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-67cdc39f-af37-4243-93fa-11cb40cb5802,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-195563d2-9462-4b6e-8945-8b68efe42a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-d58cbcb3-b10e-4478-9558-2291e822f594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830933654-172.17.0.6-1595663124733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40697,DS-47089815-8ad1-430b-b297-94810c6f2477,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-68ab0948-f70b-47be-9316-d7ad44345baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-6863f340-03f1-430f-8fa7-1b66db2d101e,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-bd3fdfa5-141f-4b5a-bab9-34ede4f36cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-07d67fba-6292-4357-ab79-b87651edbdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-32b33950-c4f6-4256-819d-04e0ce938b51,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-febe318e-a491-42f9-a3ed-c727c99e4c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-cab2ce8f-93e7-4a4b-80f1-e0c975d3adb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830933654-172.17.0.6-1595663124733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40697,DS-47089815-8ad1-430b-b297-94810c6f2477,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-68ab0948-f70b-47be-9316-d7ad44345baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-6863f340-03f1-430f-8fa7-1b66db2d101e,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-bd3fdfa5-141f-4b5a-bab9-34ede4f36cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-07d67fba-6292-4357-ab79-b87651edbdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-32b33950-c4f6-4256-819d-04e0ce938b51,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-febe318e-a491-42f9-a3ed-c727c99e4c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-cab2ce8f-93e7-4a4b-80f1-e0c975d3adb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697858326-172.17.0.6-1595663737409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-8aab3913-beb3-48e4-9c21-b5760cddf6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-103e4049-2496-4eb5-9b2f-d6eb6020ad12,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-4582dabc-2dd2-4ffa-bc4c-87d12e857562,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-bc237b11-ab0c-4ce4-980e-b31b537bd099,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-09325960-a8b6-4495-9369-756876454f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-4138f1bd-734c-4e05-9d32-16af0f2ac31e,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-9902f99f-b3c6-446a-bb4a-b891d3579c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-a2235dd1-434f-4b4e-aa05-63d34f77c6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697858326-172.17.0.6-1595663737409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-8aab3913-beb3-48e4-9c21-b5760cddf6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-103e4049-2496-4eb5-9b2f-d6eb6020ad12,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-4582dabc-2dd2-4ffa-bc4c-87d12e857562,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-bc237b11-ab0c-4ce4-980e-b31b537bd099,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-09325960-a8b6-4495-9369-756876454f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-4138f1bd-734c-4e05-9d32-16af0f2ac31e,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-9902f99f-b3c6-446a-bb4a-b891d3579c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-a2235dd1-434f-4b4e-aa05-63d34f77c6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686049057-172.17.0.6-1595663928378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38661,DS-f7cd44d9-2145-4429-ba93-ec9edfc4fa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-6d335c72-3ca4-4555-bb37-70ca743f3461,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-836b7c21-44c0-4cb2-8cc9-3c5285398bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-6142ca9c-d056-440f-9b88-cba6856737bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-f3f5df98-2527-4000-acd4-d77026b66035,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-578dd8cd-8a36-4b55-80ef-74b66a1d9a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-77361e0e-04d6-49de-80c1-3df6f1bf0753,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-62f8898b-e0a2-4bd9-b413-4fb945502242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686049057-172.17.0.6-1595663928378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38661,DS-f7cd44d9-2145-4429-ba93-ec9edfc4fa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-6d335c72-3ca4-4555-bb37-70ca743f3461,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-836b7c21-44c0-4cb2-8cc9-3c5285398bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-6142ca9c-d056-440f-9b88-cba6856737bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-f3f5df98-2527-4000-acd4-d77026b66035,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-578dd8cd-8a36-4b55-80ef-74b66a1d9a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-77361e0e-04d6-49de-80c1-3df6f1bf0753,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-62f8898b-e0a2-4bd9-b413-4fb945502242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883114596-172.17.0.6-1595664013127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41084,DS-10b2daf0-9007-440b-ae72-d9cbeef72171,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-b8787b2a-96a7-493c-95b1-09bd165e05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-56132dcc-9a35-4336-a965-700c101caf07,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-e8bb200b-0b6f-43dc-a7ea-95092a8db4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-1a688e9d-1b5b-49b9-b597-c64256f92317,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-19631a5d-96dc-460a-88bb-6d26b5a27ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d9b073d3-790d-4adf-9c71-0a661019da2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-6e7100ed-0d69-4373-b89d-54645181a079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883114596-172.17.0.6-1595664013127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41084,DS-10b2daf0-9007-440b-ae72-d9cbeef72171,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-b8787b2a-96a7-493c-95b1-09bd165e05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-56132dcc-9a35-4336-a965-700c101caf07,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-e8bb200b-0b6f-43dc-a7ea-95092a8db4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-1a688e9d-1b5b-49b9-b597-c64256f92317,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-19631a5d-96dc-460a-88bb-6d26b5a27ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d9b073d3-790d-4adf-9c71-0a661019da2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-6e7100ed-0d69-4373-b89d-54645181a079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213854086-172.17.0.6-1595664900092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-857b3b53-37cb-422e-89e7-92d4ee4758ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-d2fa2765-7abf-4b27-8ae3-290f2b7d562f,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-c11ca697-5631-4f3a-bf65-104aa98be94d,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-3042948d-4d7a-4013-a611-4e53572e1586,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-28e31802-557b-4d5a-aa63-482ced266257,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-5eae291a-c6cb-4646-9bf7-70ee454d6d68,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-6beb3b5a-31d6-48fc-8fb4-5f65440c9844,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-1e3e1638-be72-4652-913f-fe2501990118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213854086-172.17.0.6-1595664900092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-857b3b53-37cb-422e-89e7-92d4ee4758ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-d2fa2765-7abf-4b27-8ae3-290f2b7d562f,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-c11ca697-5631-4f3a-bf65-104aa98be94d,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-3042948d-4d7a-4013-a611-4e53572e1586,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-28e31802-557b-4d5a-aa63-482ced266257,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-5eae291a-c6cb-4646-9bf7-70ee454d6d68,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-6beb3b5a-31d6-48fc-8fb4-5f65440c9844,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-1e3e1638-be72-4652-913f-fe2501990118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712892609-172.17.0.6-1595664936970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45368,DS-0b3d132a-7e7b-413b-b25b-37e37092ff45,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-af9611bb-1dd2-41ab-a774-6614df61d4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-6c6b8b8a-10f7-4fb1-b13b-80ed0e81ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-d8b4bac8-0a3e-4d42-8cf5-74fe8972679f,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-ca285ba6-34f7-4fb8-8619-7674336395ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-4a00018c-d5fb-4d00-b63f-f86425f9936f,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-45edfced-be3b-443f-b383-c554937a396d,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-c1004cd9-7bba-42fc-802e-18390fb09e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712892609-172.17.0.6-1595664936970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45368,DS-0b3d132a-7e7b-413b-b25b-37e37092ff45,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-af9611bb-1dd2-41ab-a774-6614df61d4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-6c6b8b8a-10f7-4fb1-b13b-80ed0e81ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-d8b4bac8-0a3e-4d42-8cf5-74fe8972679f,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-ca285ba6-34f7-4fb8-8619-7674336395ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-4a00018c-d5fb-4d00-b63f-f86425f9936f,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-45edfced-be3b-443f-b383-c554937a396d,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-c1004cd9-7bba-42fc-802e-18390fb09e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535512415-172.17.0.6-1595665178653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43914,DS-eed91e16-5abc-4f6e-af0b-1b4035dc4344,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-32b40f29-984a-421e-bcc7-26ae1d28714a,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-5ed03ad6-0fd4-4cc6-a616-078e3d4a79d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-6a5aeabf-b4b5-465b-b3b7-a66697100cae,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-ae5836db-6833-47e8-9120-1524a125a494,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-13e7f56f-d3f0-4b32-b070-4057047ea619,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-1074294d-771e-4f70-815d-8aecf92938ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-82a71c85-0d21-4232-811e-1e14f8105fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535512415-172.17.0.6-1595665178653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43914,DS-eed91e16-5abc-4f6e-af0b-1b4035dc4344,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-32b40f29-984a-421e-bcc7-26ae1d28714a,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-5ed03ad6-0fd4-4cc6-a616-078e3d4a79d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-6a5aeabf-b4b5-465b-b3b7-a66697100cae,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-ae5836db-6833-47e8-9120-1524a125a494,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-13e7f56f-d3f0-4b32-b070-4057047ea619,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-1074294d-771e-4f70-815d-8aecf92938ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-82a71c85-0d21-4232-811e-1e14f8105fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-674849767-172.17.0.6-1595665484986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45053,DS-3b0ce6ca-3122-4462-a91d-95a237d87ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-353459f8-66b2-4df7-ba07-e025cdb34846,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-0e771672-7683-40e9-ab9a-2ee11dd54614,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-96cefb5c-df1a-4fd3-be5a-318fbe28660a,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-73cfc684-6447-44eb-83dc-cdd6235ac278,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-5a9d4d28-1c3c-4644-a1ab-38c31ca7077e,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-f1757874-fdbd-4bd7-8f53-3e64a9e69416,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-b4a81ea5-9592-4121-b8c6-3e064af334ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-674849767-172.17.0.6-1595665484986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45053,DS-3b0ce6ca-3122-4462-a91d-95a237d87ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-353459f8-66b2-4df7-ba07-e025cdb34846,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-0e771672-7683-40e9-ab9a-2ee11dd54614,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-96cefb5c-df1a-4fd3-be5a-318fbe28660a,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-73cfc684-6447-44eb-83dc-cdd6235ac278,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-5a9d4d28-1c3c-4644-a1ab-38c31ca7077e,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-f1757874-fdbd-4bd7-8f53-3e64a9e69416,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-b4a81ea5-9592-4121-b8c6-3e064af334ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279425427-172.17.0.6-1595665757861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-3096467c-6ac0-41e9-b908-b68ce86524ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-8e9920a3-05e1-4e43-8d76-3653e1d5c882,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-cac1ddb9-e4ef-4c7d-82a7-644d682d3f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-bc4ad76c-7ac9-44d4-bd4c-3489e239bc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-bb8601b0-8761-47fc-bd73-fd77826d97e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-9845aedb-6699-4660-9e7d-12e34b4729bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-147c01a6-8f91-4d1c-9c4f-41e2733d1add,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-5a3273cd-22c7-4d27-b325-01e2fd122d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279425427-172.17.0.6-1595665757861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-3096467c-6ac0-41e9-b908-b68ce86524ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-8e9920a3-05e1-4e43-8d76-3653e1d5c882,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-cac1ddb9-e4ef-4c7d-82a7-644d682d3f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-bc4ad76c-7ac9-44d4-bd4c-3489e239bc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-bb8601b0-8761-47fc-bd73-fd77826d97e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-9845aedb-6699-4660-9e7d-12e34b4729bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-147c01a6-8f91-4d1c-9c4f-41e2733d1add,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-5a3273cd-22c7-4d27-b325-01e2fd122d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310263431-172.17.0.6-1595666419263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35091,DS-59b2e68d-6fc4-4994-8caa-bf3f10b7bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-161f4801-d1b6-4a25-8a8d-ecbc8f6e79be,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-59e817dd-4c6e-440a-8a3c-6c1b32b828b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-be521f68-e200-4897-af79-9f5c293d97ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-8666126e-507f-4881-97fe-9c591055654c,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-63bbb952-8967-4a02-87f5-d8f5c29b03e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-d32ae8bb-6798-4501-bc18-8bfd2cba8331,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-0e8909fb-6253-4150-89de-8ccdeb33dbf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310263431-172.17.0.6-1595666419263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35091,DS-59b2e68d-6fc4-4994-8caa-bf3f10b7bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-161f4801-d1b6-4a25-8a8d-ecbc8f6e79be,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-59e817dd-4c6e-440a-8a3c-6c1b32b828b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-be521f68-e200-4897-af79-9f5c293d97ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-8666126e-507f-4881-97fe-9c591055654c,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-63bbb952-8967-4a02-87f5-d8f5c29b03e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-d32ae8bb-6798-4501-bc18-8bfd2cba8331,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-0e8909fb-6253-4150-89de-8ccdeb33dbf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866288948-172.17.0.6-1595666608183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-665d0e11-643d-4a20-8b37-c14956f318ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-91ff8bdf-44d5-41f8-a8d3-1d6713c2c3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-f553bd4d-90db-4d01-92b1-a1b4aec1b764,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-4a1aae30-dcf3-4b22-81ce-9d3086cd4b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-d90c77d0-e3d7-49c6-ab6c-eab0932dad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-92d6dd88-37ff-440c-901a-4795f2c46751,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-63a010e2-580f-482a-ab6e-bee406c7cc81,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-b8854f0f-1465-4447-9896-0e78e066c733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866288948-172.17.0.6-1595666608183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-665d0e11-643d-4a20-8b37-c14956f318ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-91ff8bdf-44d5-41f8-a8d3-1d6713c2c3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-f553bd4d-90db-4d01-92b1-a1b4aec1b764,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-4a1aae30-dcf3-4b22-81ce-9d3086cd4b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-d90c77d0-e3d7-49c6-ab6c-eab0932dad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-92d6dd88-37ff-440c-901a-4795f2c46751,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-63a010e2-580f-482a-ab6e-bee406c7cc81,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-b8854f0f-1465-4447-9896-0e78e066c733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057765741-172.17.0.6-1595666997686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46056,DS-aafec2af-56e7-424f-8fa7-b711dd6cc636,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-13b639ba-7fe4-4ee6-afaf-c1f1dcfd52be,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-b7df20f0-d662-4603-815c-1c01fe650925,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-5cfa28a2-c7c1-4ffb-8601-f3faa260ee62,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-430f0fa0-5b3d-471f-8896-a363ea6d6015,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-7f20da41-b2f7-4eda-92ca-1662937fd451,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-65ed4598-4140-4c65-afcf-0a95498cd0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-24fb9f17-ca9d-4586-844f-58f5c8bf15f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057765741-172.17.0.6-1595666997686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46056,DS-aafec2af-56e7-424f-8fa7-b711dd6cc636,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-13b639ba-7fe4-4ee6-afaf-c1f1dcfd52be,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-b7df20f0-d662-4603-815c-1c01fe650925,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-5cfa28a2-c7c1-4ffb-8601-f3faa260ee62,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-430f0fa0-5b3d-471f-8896-a363ea6d6015,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-7f20da41-b2f7-4eda-92ca-1662937fd451,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-65ed4598-4140-4c65-afcf-0a95498cd0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-24fb9f17-ca9d-4586-844f-58f5c8bf15f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5897
