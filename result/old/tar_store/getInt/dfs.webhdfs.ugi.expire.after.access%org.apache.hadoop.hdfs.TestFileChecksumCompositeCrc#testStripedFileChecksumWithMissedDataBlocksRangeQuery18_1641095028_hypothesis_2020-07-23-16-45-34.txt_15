reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229221764-172.17.0.12-1595522820788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36186,DS-3badd053-e48f-4c6e-922a-6685f02f65be,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-accbf913-7a63-49bb-a861-a80d1237f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-1a0887f5-fb5f-4991-bb64-f1fd3f0c2ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-5770f64f-5eb1-4b4f-a642-4ef06787bfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-3c7d8c0b-fbae-4ac5-a6e7-78ad2b9b6c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-f6472d8d-8637-4ac6-a0e5-d155a35b4857,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-bd8dcf3d-64e5-472e-a979-bb04157f2812,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-adf482d2-07fc-4c07-87fb-60917c1457ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229221764-172.17.0.12-1595522820788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36186,DS-3badd053-e48f-4c6e-922a-6685f02f65be,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-accbf913-7a63-49bb-a861-a80d1237f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-1a0887f5-fb5f-4991-bb64-f1fd3f0c2ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-5770f64f-5eb1-4b4f-a642-4ef06787bfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-3c7d8c0b-fbae-4ac5-a6e7-78ad2b9b6c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-f6472d8d-8637-4ac6-a0e5-d155a35b4857,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-bd8dcf3d-64e5-472e-a979-bb04157f2812,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-adf482d2-07fc-4c07-87fb-60917c1457ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183333056-172.17.0.12-1595523046021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39207,DS-8966cb59-dfea-4e01-90d8-00a1f2eff73c,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-238e7003-eddb-4469-b229-879e29c4e9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-10f1c4fe-dda5-4096-bf90-3880d316604e,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-9b4c1261-0d60-44aa-9386-6da7f5266c94,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-38237576-89d8-42d9-ab8f-4c197e57af63,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-20ec2502-82ca-4bdc-994d-ced85d9b4642,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-f0d8ebf6-6aa6-4631-b131-c7ebb493013a,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-1cc2f2a4-4399-473e-9cae-66a5f2f7324c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183333056-172.17.0.12-1595523046021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39207,DS-8966cb59-dfea-4e01-90d8-00a1f2eff73c,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-238e7003-eddb-4469-b229-879e29c4e9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-10f1c4fe-dda5-4096-bf90-3880d316604e,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-9b4c1261-0d60-44aa-9386-6da7f5266c94,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-38237576-89d8-42d9-ab8f-4c197e57af63,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-20ec2502-82ca-4bdc-994d-ced85d9b4642,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-f0d8ebf6-6aa6-4631-b131-c7ebb493013a,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-1cc2f2a4-4399-473e-9cae-66a5f2f7324c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129607012-172.17.0.12-1595523389800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44802,DS-4f85cfbe-b052-4619-b197-5455b11d1107,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-cbcccd5d-d081-4639-8a3e-7b1748075bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-1eb6dcd3-7934-4b7d-91a3-3350c441bb72,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-6e91d326-6261-4a08-ac9e-52a98fe1163e,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-116970ad-f980-49b5-b355-86cbb28db839,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-c94169c2-8ac3-4036-a5dc-7eb3d13f0fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-cb8b443d-6a6e-4109-94ec-48fa25f24350,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-f4a5b6a4-d84c-4ac3-85db-7441399dc4bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129607012-172.17.0.12-1595523389800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44802,DS-4f85cfbe-b052-4619-b197-5455b11d1107,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-cbcccd5d-d081-4639-8a3e-7b1748075bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-1eb6dcd3-7934-4b7d-91a3-3350c441bb72,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-6e91d326-6261-4a08-ac9e-52a98fe1163e,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-116970ad-f980-49b5-b355-86cbb28db839,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-c94169c2-8ac3-4036-a5dc-7eb3d13f0fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-cb8b443d-6a6e-4109-94ec-48fa25f24350,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-f4a5b6a4-d84c-4ac3-85db-7441399dc4bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737957636-172.17.0.12-1595523682765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36301,DS-53345d23-fcaf-4636-9955-e786340cabcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-5ce16c3b-1fb8-48c8-a074-a63aeec06e48,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-12d9bba6-4785-4ad9-88eb-0fb0aff41481,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-88a206ad-343b-4900-bc22-1090f7a3508a,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-c3d4fd46-0e2f-4d2c-abbb-2ff58952f1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-a7be81ed-2381-4beb-a540-ab57a8afde1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-c6a8e6d3-21d1-4646-80aa-1d6dbdee4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-dca300f4-4f99-480c-9efa-7014d240e185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737957636-172.17.0.12-1595523682765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36301,DS-53345d23-fcaf-4636-9955-e786340cabcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-5ce16c3b-1fb8-48c8-a074-a63aeec06e48,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-12d9bba6-4785-4ad9-88eb-0fb0aff41481,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-88a206ad-343b-4900-bc22-1090f7a3508a,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-c3d4fd46-0e2f-4d2c-abbb-2ff58952f1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-a7be81ed-2381-4beb-a540-ab57a8afde1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-c6a8e6d3-21d1-4646-80aa-1d6dbdee4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-dca300f4-4f99-480c-9efa-7014d240e185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501711024-172.17.0.12-1595524246893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37943,DS-defefe95-9979-44be-9e25-95a800c36197,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-718a9f7d-bbdf-4ee6-ae80-4f840b1b3ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-1945c945-1b9d-4d0a-b1a8-ced01362c72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-83407cef-a71f-45ca-b8dd-eb3389941ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-a8850a86-30cf-4aa2-8fcb-b2419517ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-0117b1b3-7ed6-4470-aafb-7ece433c8624,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-af9ff1e8-0be7-4592-a78c-d0481adddcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-50ab9149-4f53-453e-acfc-d52a6d72c96f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501711024-172.17.0.12-1595524246893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37943,DS-defefe95-9979-44be-9e25-95a800c36197,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-718a9f7d-bbdf-4ee6-ae80-4f840b1b3ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-1945c945-1b9d-4d0a-b1a8-ced01362c72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-83407cef-a71f-45ca-b8dd-eb3389941ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-a8850a86-30cf-4aa2-8fcb-b2419517ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-0117b1b3-7ed6-4470-aafb-7ece433c8624,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-af9ff1e8-0be7-4592-a78c-d0481adddcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-50ab9149-4f53-453e-acfc-d52a6d72c96f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693277166-172.17.0.12-1595524576395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-b416f860-f1d7-42fa-bae9-833e32154630,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-61833e97-f523-4db4-b852-9d64b6cf18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-03a3ca3a-e005-4552-83fa-c5aa4715c81d,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-b9803de0-ecdf-42aa-852b-8543bd93494c,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-0cceac1a-66a3-49b2-838c-92c676a3ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-f06485c7-bd1c-4683-8fcd-a3d71a18deae,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-a40596c3-2f96-49cd-ac73-9ca5f84c470e,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-99e72e6d-67e8-49e2-ad8c-7cdc8de0989a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693277166-172.17.0.12-1595524576395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-b416f860-f1d7-42fa-bae9-833e32154630,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-61833e97-f523-4db4-b852-9d64b6cf18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-03a3ca3a-e005-4552-83fa-c5aa4715c81d,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-b9803de0-ecdf-42aa-852b-8543bd93494c,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-0cceac1a-66a3-49b2-838c-92c676a3ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-f06485c7-bd1c-4683-8fcd-a3d71a18deae,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-a40596c3-2f96-49cd-ac73-9ca5f84c470e,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-99e72e6d-67e8-49e2-ad8c-7cdc8de0989a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132724045-172.17.0.12-1595524965151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-cb840bfa-6ab8-44fd-8df1-aab3e78969da,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-850afb8a-7697-48a1-ae27-29ef82612ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-22ee2d4e-4f94-43ba-a7d0-91df521e10a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0e4b7c70-e6de-442d-b130-29ee1b765300,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-e0f333be-aa2e-46a7-bc9a-c83ab4a5ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-b0abc8f6-157d-4264-95d3-dc835ead916f,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-0554918b-177a-47de-b29f-0042f5eda103,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-19ae1792-5fd2-4b62-b2df-f0f5d2d767c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132724045-172.17.0.12-1595524965151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-cb840bfa-6ab8-44fd-8df1-aab3e78969da,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-850afb8a-7697-48a1-ae27-29ef82612ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-22ee2d4e-4f94-43ba-a7d0-91df521e10a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0e4b7c70-e6de-442d-b130-29ee1b765300,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-e0f333be-aa2e-46a7-bc9a-c83ab4a5ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-b0abc8f6-157d-4264-95d3-dc835ead916f,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-0554918b-177a-47de-b29f-0042f5eda103,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-19ae1792-5fd2-4b62-b2df-f0f5d2d767c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808461271-172.17.0.12-1595525411214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33442,DS-f981f812-c0bd-4a42-bfbf-27942421dd92,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-65876623-6ffe-4e51-b8c2-1e984c475490,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-8696d85b-7de9-4e62-a57e-b76e4cfa1fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-ee3a3469-c704-479e-86e6-ff64f3be1ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-228de251-469c-4fe2-9410-7535bb19b286,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-6f90ae12-dee0-4edd-a487-210741f79e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-0c943a1f-431c-4593-8b57-81a5c66524bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-09f661a3-bd85-493e-a38e-ec18ff7d8c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808461271-172.17.0.12-1595525411214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33442,DS-f981f812-c0bd-4a42-bfbf-27942421dd92,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-65876623-6ffe-4e51-b8c2-1e984c475490,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-8696d85b-7de9-4e62-a57e-b76e4cfa1fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-ee3a3469-c704-479e-86e6-ff64f3be1ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-228de251-469c-4fe2-9410-7535bb19b286,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-6f90ae12-dee0-4edd-a487-210741f79e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-0c943a1f-431c-4593-8b57-81a5c66524bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-09f661a3-bd85-493e-a38e-ec18ff7d8c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271442162-172.17.0.12-1595525683227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-fbf55431-5cff-417d-afb9-4b7083c4aca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-6a368e77-8802-4214-8b62-1824b04086fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-a2fafa6c-b38f-44b1-91c2-9f8e5734458e,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-12299a60-5236-4d90-9467-0c631b44a819,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-49101372-6f5d-4a25-bb25-6ed423059f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-5b0a1b9c-2130-4c7d-9d9c-02ea3983a717,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-c83a1e0d-2106-40a6-a4fd-6d7fdfbcce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-a4446b84-746a-48ef-8e1d-4b3132d01c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271442162-172.17.0.12-1595525683227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-fbf55431-5cff-417d-afb9-4b7083c4aca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-6a368e77-8802-4214-8b62-1824b04086fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-a2fafa6c-b38f-44b1-91c2-9f8e5734458e,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-12299a60-5236-4d90-9467-0c631b44a819,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-49101372-6f5d-4a25-bb25-6ed423059f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-5b0a1b9c-2130-4c7d-9d9c-02ea3983a717,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-c83a1e0d-2106-40a6-a4fd-6d7fdfbcce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-a4446b84-746a-48ef-8e1d-4b3132d01c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672335492-172.17.0.12-1595526844173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40886,DS-86f5b427-f3f0-484b-90b3-d4bf00197b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-b0ac9ec4-f9b8-47a7-b1f1-fc67148eb0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-5b1e5443-4092-4ddf-8397-40d6f73761ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-4d636ec1-464f-44c2-bbad-062817a80541,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-4af336dd-1c52-4236-a790-1e253206e481,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-92212025-7a26-4144-85b7-7b419adea791,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-74b58f98-0f22-4784-b503-977ebfea6d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-d82e41a2-4eec-43f9-be63-7d5b63a3664d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672335492-172.17.0.12-1595526844173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40886,DS-86f5b427-f3f0-484b-90b3-d4bf00197b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-b0ac9ec4-f9b8-47a7-b1f1-fc67148eb0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-5b1e5443-4092-4ddf-8397-40d6f73761ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-4d636ec1-464f-44c2-bbad-062817a80541,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-4af336dd-1c52-4236-a790-1e253206e481,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-92212025-7a26-4144-85b7-7b419adea791,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-74b58f98-0f22-4784-b503-977ebfea6d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-d82e41a2-4eec-43f9-be63-7d5b63a3664d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401893669-172.17.0.12-1595526875841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37413,DS-60fe56a8-5168-4f79-b252-25b9ad2cb174,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-ad0ebc11-27a9-4795-85fa-8dd476b0182c,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-4a4655e0-4dd0-40df-8189-465b88f3ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-0db8124c-2b4f-4cdf-85a7-c5605ffbf2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-cfd8cddc-166c-44cb-96b4-f36110b0290d,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-cf972f95-b155-4f00-87b6-be932a9cd730,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-ef7f0be7-3746-44fa-a883-441076755ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-b72cb553-f910-4fd9-a216-bfade83ae82c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401893669-172.17.0.12-1595526875841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37413,DS-60fe56a8-5168-4f79-b252-25b9ad2cb174,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-ad0ebc11-27a9-4795-85fa-8dd476b0182c,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-4a4655e0-4dd0-40df-8189-465b88f3ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-0db8124c-2b4f-4cdf-85a7-c5605ffbf2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-cfd8cddc-166c-44cb-96b4-f36110b0290d,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-cf972f95-b155-4f00-87b6-be932a9cd730,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-ef7f0be7-3746-44fa-a883-441076755ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-b72cb553-f910-4fd9-a216-bfade83ae82c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5054
