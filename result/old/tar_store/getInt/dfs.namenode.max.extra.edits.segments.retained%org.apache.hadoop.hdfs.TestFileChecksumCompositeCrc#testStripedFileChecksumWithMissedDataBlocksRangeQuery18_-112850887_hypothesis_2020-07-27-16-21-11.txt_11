reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497339843-172.17.0.9-1595867241177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33769,DS-dd99027b-8e98-4929-8545-508d84f5d9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-9e2f474f-e727-4f4d-852c-5fa7986de37a,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-d8a81e3d-529b-4029-9f61-34b41b7eca9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-3abaeae1-36ec-4eb2-a15e-e60d74174fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-be7f52de-3142-4642-b426-e5183a70fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-f10b0944-b85c-4cd9-83a0-a68a2053f762,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-c225c378-ea81-4fcd-acfc-35272a8cd228,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-3bef9c7d-994f-4ea3-b207-bb5554fdfe5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497339843-172.17.0.9-1595867241177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33769,DS-dd99027b-8e98-4929-8545-508d84f5d9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-9e2f474f-e727-4f4d-852c-5fa7986de37a,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-d8a81e3d-529b-4029-9f61-34b41b7eca9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-3abaeae1-36ec-4eb2-a15e-e60d74174fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-be7f52de-3142-4642-b426-e5183a70fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-f10b0944-b85c-4cd9-83a0-a68a2053f762,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-c225c378-ea81-4fcd-acfc-35272a8cd228,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-3bef9c7d-994f-4ea3-b207-bb5554fdfe5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973664155-172.17.0.9-1595867648210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-baca6c1b-0bcb-4625-9a4a-c2f03a12b302,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-7eda6664-501a-4f8c-8ceb-e0b50a58a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-5999de56-4a54-41db-aae7-b3c5ead21d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-52875b4e-c39c-4db7-95b5-28974ee81d14,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-097a7a93-be8e-4a95-bb4b-bab0bfd1c318,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-dc833a3f-385f-4b66-8a1c-fa6904b5e483,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-3f13e951-5cef-4d2a-8fbd-66aeb9d56df4,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-07bd1de5-f81c-468b-ad9b-e134c55d0ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973664155-172.17.0.9-1595867648210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-baca6c1b-0bcb-4625-9a4a-c2f03a12b302,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-7eda6664-501a-4f8c-8ceb-e0b50a58a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-5999de56-4a54-41db-aae7-b3c5ead21d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-52875b4e-c39c-4db7-95b5-28974ee81d14,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-097a7a93-be8e-4a95-bb4b-bab0bfd1c318,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-dc833a3f-385f-4b66-8a1c-fa6904b5e483,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-3f13e951-5cef-4d2a-8fbd-66aeb9d56df4,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-07bd1de5-f81c-468b-ad9b-e134c55d0ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117428075-172.17.0.9-1595867982785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-7683889d-d19f-4a4a-86a8-8e6dbdbf9889,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-064b3018-a363-411b-9b53-01c2b3e7338d,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-ecda42c7-9dce-420f-98e4-0c6010c80859,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-f8318de8-1219-4143-bd20-628333f3f36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-3d3271dd-80a6-4922-b681-d1130ae55cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-b2d5df9c-5704-46dc-940c-1acc3e112034,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-4ac19756-c0a9-4e33-b776-8aaaac3ceb43,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-dfb5ccd4-bace-441a-88d2-48d1c22bcfbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117428075-172.17.0.9-1595867982785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-7683889d-d19f-4a4a-86a8-8e6dbdbf9889,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-064b3018-a363-411b-9b53-01c2b3e7338d,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-ecda42c7-9dce-420f-98e4-0c6010c80859,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-f8318de8-1219-4143-bd20-628333f3f36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-3d3271dd-80a6-4922-b681-d1130ae55cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-b2d5df9c-5704-46dc-940c-1acc3e112034,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-4ac19756-c0a9-4e33-b776-8aaaac3ceb43,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-dfb5ccd4-bace-441a-88d2-48d1c22bcfbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971461421-172.17.0.9-1595868262643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42676,DS-f42a62b8-ada3-43b8-8ca8-0fcd50a4a3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-09cb8a73-08f5-4c35-bb01-67a8587d45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-4f23584e-4ea3-4cd2-b01b-962742ff09fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-861e7aa4-3af1-4169-a3e7-433d187254be,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-79ef764d-bc3b-4909-8341-b9482e259766,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4db6ecae-bbe7-4af0-b10b-36ccadb6cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-45d85693-1343-4cc8-aa9e-70bfb5e47fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-7ad99926-e618-4219-8ba8-33329f631b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971461421-172.17.0.9-1595868262643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42676,DS-f42a62b8-ada3-43b8-8ca8-0fcd50a4a3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-09cb8a73-08f5-4c35-bb01-67a8587d45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-4f23584e-4ea3-4cd2-b01b-962742ff09fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-861e7aa4-3af1-4169-a3e7-433d187254be,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-79ef764d-bc3b-4909-8341-b9482e259766,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4db6ecae-bbe7-4af0-b10b-36ccadb6cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-45d85693-1343-4cc8-aa9e-70bfb5e47fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-7ad99926-e618-4219-8ba8-33329f631b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101731707-172.17.0.9-1595868366815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37511,DS-007d715f-7b93-4fa8-a057-058a5948e2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-51aa7c1d-abe4-407f-adb4-2df519bc871d,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-9158fccf-f182-4c59-9932-651ea4e07ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-42e9b380-3db7-43cb-887a-1f2aafeb9342,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-da94bfb0-6428-4170-9060-6a4cdf2f938f,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-2cc7e5dd-1ce9-4983-80f5-0bb6b1e2afef,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-055b9ab4-8607-451a-9154-7fdcc8ea8f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-00eef24f-6cd6-42d2-b8a9-b8cdfbb842b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101731707-172.17.0.9-1595868366815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37511,DS-007d715f-7b93-4fa8-a057-058a5948e2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-51aa7c1d-abe4-407f-adb4-2df519bc871d,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-9158fccf-f182-4c59-9932-651ea4e07ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-42e9b380-3db7-43cb-887a-1f2aafeb9342,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-da94bfb0-6428-4170-9060-6a4cdf2f938f,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-2cc7e5dd-1ce9-4983-80f5-0bb6b1e2afef,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-055b9ab4-8607-451a-9154-7fdcc8ea8f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-00eef24f-6cd6-42d2-b8a9-b8cdfbb842b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267852234-172.17.0.9-1595868680944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42965,DS-5d32e806-45f9-409b-a311-5bfc85bff02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-8151b256-c84f-4585-8f9d-add8000bcf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-a2c8c400-5543-4c2a-bab4-300527ed5286,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-fcada942-b51e-4a4b-afbd-ecf70ff2e2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-9802100f-5527-432e-9771-09a8da5ba1db,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-f51005b7-3bb1-4daa-8828-f0caae3d0042,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-c9d52823-4c7b-482e-994e-4a5c5b343ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-489db487-8480-4262-8f3f-a5bbf574a00a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267852234-172.17.0.9-1595868680944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42965,DS-5d32e806-45f9-409b-a311-5bfc85bff02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-8151b256-c84f-4585-8f9d-add8000bcf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-a2c8c400-5543-4c2a-bab4-300527ed5286,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-fcada942-b51e-4a4b-afbd-ecf70ff2e2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-9802100f-5527-432e-9771-09a8da5ba1db,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-f51005b7-3bb1-4daa-8828-f0caae3d0042,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-c9d52823-4c7b-482e-994e-4a5c5b343ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-489db487-8480-4262-8f3f-a5bbf574a00a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355318647-172.17.0.9-1595868747088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36363,DS-47e1e068-929e-4ad4-8e64-ccc6ec45fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-89a96a04-8279-4880-9d3a-5e0f52c7017d,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-ddb5b399-803a-49ac-9c27-88d56f82ab8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-dd6871b0-aa49-4d75-a078-689759486e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-9899a77d-d5a5-459a-843a-083a0b472434,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-6e30be56-e589-490d-9cec-32a3f7e58cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-97805854-0eeb-4b33-9d08-b168312c5ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-f9c7a2cd-4fd7-4f44-9d47-84c2230cd9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355318647-172.17.0.9-1595868747088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36363,DS-47e1e068-929e-4ad4-8e64-ccc6ec45fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-89a96a04-8279-4880-9d3a-5e0f52c7017d,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-ddb5b399-803a-49ac-9c27-88d56f82ab8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-dd6871b0-aa49-4d75-a078-689759486e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-9899a77d-d5a5-459a-843a-083a0b472434,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-6e30be56-e589-490d-9cec-32a3f7e58cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-97805854-0eeb-4b33-9d08-b168312c5ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-f9c7a2cd-4fd7-4f44-9d47-84c2230cd9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773784418-172.17.0.9-1595868906883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-1ee38d0a-7f68-40a8-922f-aace3ff0ff0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-439d0772-156a-4631-86fd-7fd4ce5c860d,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-6ce18a47-e6c9-4478-b86b-6ed1a0df6443,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-e0a08018-57e4-4344-8a70-de96244ffb52,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-197affbb-0764-4959-9462-0e537203445c,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-8c58569f-3fa1-4a8c-88a8-354251f2875b,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-65c40fb6-c9f2-4d40-ae55-05d14d955f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-394f8672-94df-42db-af6c-7094d83eba72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773784418-172.17.0.9-1595868906883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-1ee38d0a-7f68-40a8-922f-aace3ff0ff0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-439d0772-156a-4631-86fd-7fd4ce5c860d,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-6ce18a47-e6c9-4478-b86b-6ed1a0df6443,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-e0a08018-57e4-4344-8a70-de96244ffb52,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-197affbb-0764-4959-9462-0e537203445c,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-8c58569f-3fa1-4a8c-88a8-354251f2875b,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-65c40fb6-c9f2-4d40-ae55-05d14d955f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-394f8672-94df-42db-af6c-7094d83eba72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206596579-172.17.0.9-1595869582025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-52dc04c1-f5b1-4286-8563-381655a717ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-0a8d33b2-f103-4c76-9ca0-934a928a1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-307ca6cf-9337-46f2-82a7-a63c4f4800a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-ffc1ed97-c254-417c-8339-e23981b02077,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-1e05636f-8977-4985-a4f4-aebc031ad66a,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-7243d1ff-15ce-4ce7-9614-163c65b8e221,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-b860e765-4eaf-4da6-bace-f57d75f9cd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-2ab9007a-9da6-4f04-96a8-b625c7aad01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206596579-172.17.0.9-1595869582025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-52dc04c1-f5b1-4286-8563-381655a717ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-0a8d33b2-f103-4c76-9ca0-934a928a1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-307ca6cf-9337-46f2-82a7-a63c4f4800a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-ffc1ed97-c254-417c-8339-e23981b02077,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-1e05636f-8977-4985-a4f4-aebc031ad66a,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-7243d1ff-15ce-4ce7-9614-163c65b8e221,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-b860e765-4eaf-4da6-bace-f57d75f9cd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-2ab9007a-9da6-4f04-96a8-b625c7aad01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711059578-172.17.0.9-1595869687663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-c9e4e2a5-c187-48db-800c-848f68f58100,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-5ff267e7-0fd1-44ca-be12-d8508e062bda,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-ad4b59d9-37e6-4361-805c-1f7484a93b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-7f4b916a-1a7c-4562-af69-04873500e30e,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-3517edc1-7efb-4a2a-9521-3b4046f18507,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-8b71dd89-e751-4436-8093-d5bbfb5c16d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-5b62139b-1405-41b6-a4ad-2c0f5149c846,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-60a01712-560b-49d6-a77c-be32c990259b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711059578-172.17.0.9-1595869687663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-c9e4e2a5-c187-48db-800c-848f68f58100,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-5ff267e7-0fd1-44ca-be12-d8508e062bda,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-ad4b59d9-37e6-4361-805c-1f7484a93b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-7f4b916a-1a7c-4562-af69-04873500e30e,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-3517edc1-7efb-4a2a-9521-3b4046f18507,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-8b71dd89-e751-4436-8093-d5bbfb5c16d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-5b62139b-1405-41b6-a4ad-2c0f5149c846,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-60a01712-560b-49d6-a77c-be32c990259b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708019782-172.17.0.9-1595869898971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35826,DS-648bfb0e-8aea-417d-8f0b-b0bed593b938,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-138a6872-f40d-4275-8e23-d490d07d98b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-7fcb219d-84f5-4f73-a9c9-520519769e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-b7f5a8ef-b5bb-45e6-8f28-3742dd2d2a55,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-d12bda8f-27ea-44f5-a2ef-0881ee177636,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-abd8038b-a5e7-4a5b-871c-0d090434436a,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-87246bcb-ae48-4515-92df-088282b99f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-7b30bc85-f8d4-4e17-b1ea-f1782379471b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708019782-172.17.0.9-1595869898971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35826,DS-648bfb0e-8aea-417d-8f0b-b0bed593b938,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-138a6872-f40d-4275-8e23-d490d07d98b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-7fcb219d-84f5-4f73-a9c9-520519769e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-b7f5a8ef-b5bb-45e6-8f28-3742dd2d2a55,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-d12bda8f-27ea-44f5-a2ef-0881ee177636,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-abd8038b-a5e7-4a5b-871c-0d090434436a,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-87246bcb-ae48-4515-92df-088282b99f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-7b30bc85-f8d4-4e17-b1ea-f1782379471b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958533260-172.17.0.9-1595870016957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33386,DS-803fab04-34f0-468d-9d15-03de9e59db36,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-8eec0e70-cfd4-48ef-b3b9-78032edcf239,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-72d01aad-3706-4508-bad4-012f18f58131,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-29e3c04f-953f-4b20-a883-4ec678dc77a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-1c4cd57a-2372-4c5c-9a18-cd027247a83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-858840fc-0e67-4bab-a2d4-5e3d04042080,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-b60b5ce0-56c3-4021-9bfa-7e9b4595f245,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-447cf841-6a2f-42d5-9779-d259a295252a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958533260-172.17.0.9-1595870016957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33386,DS-803fab04-34f0-468d-9d15-03de9e59db36,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-8eec0e70-cfd4-48ef-b3b9-78032edcf239,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-72d01aad-3706-4508-bad4-012f18f58131,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-29e3c04f-953f-4b20-a883-4ec678dc77a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-1c4cd57a-2372-4c5c-9a18-cd027247a83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-858840fc-0e67-4bab-a2d4-5e3d04042080,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-b60b5ce0-56c3-4021-9bfa-7e9b4595f245,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-447cf841-6a2f-42d5-9779-d259a295252a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733391388-172.17.0.9-1595870988806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38526,DS-b8d651ba-656b-4981-9eab-1a089c617030,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-c7e98a96-b34d-469b-8b7c-dc475edf84c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-247256d3-17e0-4a55-be39-50ab6780a10f,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-d79b5c8b-ed01-484c-a611-04d58eb9b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-55f4951d-ecda-4c42-acfd-adca356f09e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-6f12e1cb-21d4-41bd-9121-5383ab8a4542,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-c0d273db-9c47-4cd8-918d-a9000455cdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-21e67059-09e0-4ba4-a968-02f35f7b56ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733391388-172.17.0.9-1595870988806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38526,DS-b8d651ba-656b-4981-9eab-1a089c617030,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-c7e98a96-b34d-469b-8b7c-dc475edf84c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-247256d3-17e0-4a55-be39-50ab6780a10f,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-d79b5c8b-ed01-484c-a611-04d58eb9b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-55f4951d-ecda-4c42-acfd-adca356f09e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-6f12e1cb-21d4-41bd-9121-5383ab8a4542,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-c0d273db-9c47-4cd8-918d-a9000455cdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-21e67059-09e0-4ba4-a968-02f35f7b56ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644127154-172.17.0.9-1595871930670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43739,DS-fad618d4-8f1f-4965-a8a0-56dde2bada34,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-005c010e-f0a9-4b6e-a1f3-e7d749d40ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-cdcc62fd-4fab-4e30-a354-2cac58c041ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-046057f6-a13f-4b5f-90d3-66e93fb8cd01,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-e347ef13-b2a6-4cdf-ad6d-25cca03539a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-fc51d735-c7c9-4382-bb44-e92baf51742e,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-88bb2daf-f518-4352-8eea-f2a7ed71f3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-d0eebe68-b17b-4c7b-9fe9-bcbb9a7d126b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644127154-172.17.0.9-1595871930670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43739,DS-fad618d4-8f1f-4965-a8a0-56dde2bada34,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-005c010e-f0a9-4b6e-a1f3-e7d749d40ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-cdcc62fd-4fab-4e30-a354-2cac58c041ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-046057f6-a13f-4b5f-90d3-66e93fb8cd01,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-e347ef13-b2a6-4cdf-ad6d-25cca03539a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-fc51d735-c7c9-4382-bb44-e92baf51742e,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-88bb2daf-f518-4352-8eea-f2a7ed71f3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-d0eebe68-b17b-4c7b-9fe9-bcbb9a7d126b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635281700-172.17.0.9-1595871963895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35256,DS-7f346a0c-a9ee-4f6d-8edc-4d51da151a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-1742e18e-b845-46cb-b54f-4e15bdc64f99,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-4b1285fe-2b75-4a39-9af2-12bd27fbe484,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-c2d026c1-a2d9-4ef8-8f3d-e92f1c76c883,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-f2870ae6-38c3-4d30-991f-cb4a6d990f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-6451dd24-7d05-4128-8307-e5f6ead3e867,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-ad909356-30fe-44e5-8aea-16a654be1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-a22292c1-2ba4-4fd9-a239-65d51708a154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635281700-172.17.0.9-1595871963895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35256,DS-7f346a0c-a9ee-4f6d-8edc-4d51da151a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-1742e18e-b845-46cb-b54f-4e15bdc64f99,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-4b1285fe-2b75-4a39-9af2-12bd27fbe484,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-c2d026c1-a2d9-4ef8-8f3d-e92f1c76c883,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-f2870ae6-38c3-4d30-991f-cb4a6d990f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-6451dd24-7d05-4128-8307-e5f6ead3e867,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-ad909356-30fe-44e5-8aea-16a654be1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-a22292c1-2ba4-4fd9-a239-65d51708a154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5253
