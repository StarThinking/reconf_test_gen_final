reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374839009-172.17.0.18-1595600655198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44032,DS-a438c2d7-de07-461e-8295-ecc83b44d612,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-c7f0033a-2f02-4b70-b9b8-15579e62a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-371983ed-6672-475e-8d69-a1a57fd83677,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-67bb9f03-b72a-4626-98db-a457621d64ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-5db70a2e-f68b-41f5-a5fb-385530a72e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-cf237af8-4ca9-4e70-a950-131fc00d4725,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-84dc3f65-bb2e-4a79-8e40-c50a5ae22681,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-b89ee34b-0b32-43cc-b5af-09731a4aaa06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374839009-172.17.0.18-1595600655198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44032,DS-a438c2d7-de07-461e-8295-ecc83b44d612,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-c7f0033a-2f02-4b70-b9b8-15579e62a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-371983ed-6672-475e-8d69-a1a57fd83677,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-67bb9f03-b72a-4626-98db-a457621d64ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-5db70a2e-f68b-41f5-a5fb-385530a72e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-cf237af8-4ca9-4e70-a950-131fc00d4725,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-84dc3f65-bb2e-4a79-8e40-c50a5ae22681,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-b89ee34b-0b32-43cc-b5af-09731a4aaa06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096255043-172.17.0.18-1595600692707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34169,DS-1ded330f-ef46-41d0-be6f-52059871cced,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-6f0d3046-0a55-4e3b-9f5b-b5a21df4c130,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-a9311ccf-85af-4717-a202-7a911783ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-610b7830-8428-41de-9624-0e053c2c1de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-d919d138-cefa-40d2-9196-6d4bc03fff24,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-574fe1e9-7bc1-4fad-9fcd-77d027319758,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-5659e569-6162-4c1d-81b8-f851d8aa0952,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-21a2e3db-cbb2-4739-bc6d-d89aeddc6964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096255043-172.17.0.18-1595600692707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34169,DS-1ded330f-ef46-41d0-be6f-52059871cced,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-6f0d3046-0a55-4e3b-9f5b-b5a21df4c130,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-a9311ccf-85af-4717-a202-7a911783ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-610b7830-8428-41de-9624-0e053c2c1de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-d919d138-cefa-40d2-9196-6d4bc03fff24,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-574fe1e9-7bc1-4fad-9fcd-77d027319758,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-5659e569-6162-4c1d-81b8-f851d8aa0952,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-21a2e3db-cbb2-4739-bc6d-d89aeddc6964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015341787-172.17.0.18-1595600972287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41240,DS-7b77fe5b-4068-4bbc-86b4-e383eb28fc58,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-e6de27d7-5aa2-4a4b-b56c-eba339e6cdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-99f64a38-1f5d-4525-a5eb-2d143e3206f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-6baffb1e-7cd6-44c9-8f00-4fdc36a70d52,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-e627adab-65e0-45ef-a3ff-c5ade14e4faf,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-7cdfc40d-40aa-4129-859f-87e53bde22cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-4718a75d-9693-4b80-9d4c-e36b17467762,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-3d09aea9-ee0f-46df-986c-73f34d715449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015341787-172.17.0.18-1595600972287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41240,DS-7b77fe5b-4068-4bbc-86b4-e383eb28fc58,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-e6de27d7-5aa2-4a4b-b56c-eba339e6cdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-99f64a38-1f5d-4525-a5eb-2d143e3206f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-6baffb1e-7cd6-44c9-8f00-4fdc36a70d52,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-e627adab-65e0-45ef-a3ff-c5ade14e4faf,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-7cdfc40d-40aa-4129-859f-87e53bde22cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-4718a75d-9693-4b80-9d4c-e36b17467762,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-3d09aea9-ee0f-46df-986c-73f34d715449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069116691-172.17.0.18-1595601503031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-d2111045-2cdf-485c-8f98-5a50ae7e31a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-db6a795e-811d-4a4d-a421-aa89e3578f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-483af0be-ff27-4a6c-b294-3eaf6dbb75e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-fefeaae8-90d4-4f89-b4d7-aeb03b988423,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d3df4281-c6c5-439a-beff-24598516d356,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-fdb78684-980b-4621-9bff-ca1f658e4a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-fc24096a-405b-4d4b-8994-91abf7dab09a,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-5b3263c4-e164-4b99-b08b-72c7fd24f801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069116691-172.17.0.18-1595601503031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-d2111045-2cdf-485c-8f98-5a50ae7e31a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-db6a795e-811d-4a4d-a421-aa89e3578f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-483af0be-ff27-4a6c-b294-3eaf6dbb75e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-fefeaae8-90d4-4f89-b4d7-aeb03b988423,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d3df4281-c6c5-439a-beff-24598516d356,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-fdb78684-980b-4621-9bff-ca1f658e4a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-fc24096a-405b-4d4b-8994-91abf7dab09a,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-5b3263c4-e164-4b99-b08b-72c7fd24f801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498376629-172.17.0.18-1595601768107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-062ba977-394a-487c-a8af-12d3c1baec05,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-7c86658f-1a0a-4c79-bfd1-f7be803d9a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-30c6d3cb-4e24-4327-bbd5-4908c578a123,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-18653f33-55d2-4a0a-8e76-7a45c746b335,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-05e2d3b8-b525-4d58-88e7-ccff4746f33c,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-fd5a347c-b1df-42f4-a333-104df4946769,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-8039b6a7-e7b9-4eba-a61a-f95068b04b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-01f66860-5193-4096-8373-004559b6422b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498376629-172.17.0.18-1595601768107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-062ba977-394a-487c-a8af-12d3c1baec05,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-7c86658f-1a0a-4c79-bfd1-f7be803d9a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-30c6d3cb-4e24-4327-bbd5-4908c578a123,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-18653f33-55d2-4a0a-8e76-7a45c746b335,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-05e2d3b8-b525-4d58-88e7-ccff4746f33c,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-fd5a347c-b1df-42f4-a333-104df4946769,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-8039b6a7-e7b9-4eba-a61a-f95068b04b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-01f66860-5193-4096-8373-004559b6422b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312102578-172.17.0.18-1595602209967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-c3f1ab0f-9876-41c6-aa67-4da647185269,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-730e781d-4009-4cf5-90b5-287803239030,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-f0835e7a-3950-47fc-ac95-c3de035ab081,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-81837044-ecf4-48e9-96f6-62e57c1910e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d167bab5-0e15-47bc-b29f-0549c1e00006,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-4637f3b1-411f-429c-89aa-5c4e792abcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-8259c4f7-fd0f-44a5-a35b-2c57b3a32a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-7926ad55-8982-4c7f-9598-eec35085b838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312102578-172.17.0.18-1595602209967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-c3f1ab0f-9876-41c6-aa67-4da647185269,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-730e781d-4009-4cf5-90b5-287803239030,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-f0835e7a-3950-47fc-ac95-c3de035ab081,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-81837044-ecf4-48e9-96f6-62e57c1910e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d167bab5-0e15-47bc-b29f-0549c1e00006,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-4637f3b1-411f-429c-89aa-5c4e792abcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-8259c4f7-fd0f-44a5-a35b-2c57b3a32a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-7926ad55-8982-4c7f-9598-eec35085b838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122171663-172.17.0.18-1595602471575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-0032818d-c518-46f6-8c36-819d9b4ba454,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-914a628c-a78b-48f3-ba52-2f655aeca79b,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-288bda78-7861-47ee-9dbd-6c2dcdbf6d98,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-237d39e8-f09b-4b90-bcf4-4440e82d4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-84791f55-b4b9-4b25-be58-fe480febc072,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-67f9ef72-9cd2-42c8-8e62-4d755fb37d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-60241b6f-294b-44b2-a258-5cb9b44b64e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-1aa2f4ad-92d3-4eeb-b7ec-8bbe12da71a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122171663-172.17.0.18-1595602471575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-0032818d-c518-46f6-8c36-819d9b4ba454,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-914a628c-a78b-48f3-ba52-2f655aeca79b,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-288bda78-7861-47ee-9dbd-6c2dcdbf6d98,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-237d39e8-f09b-4b90-bcf4-4440e82d4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-84791f55-b4b9-4b25-be58-fe480febc072,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-67f9ef72-9cd2-42c8-8e62-4d755fb37d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-60241b6f-294b-44b2-a258-5cb9b44b64e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-1aa2f4ad-92d3-4eeb-b7ec-8bbe12da71a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248761901-172.17.0.18-1595602552279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43382,DS-1f34408b-fa56-4351-b51d-cbc0cd2527dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-543a58fa-8f57-4587-90d0-54521f1bf7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-69d8b115-67fe-41cb-9a05-201cdc69a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-25e29410-7203-4e3b-8806-904c8d801203,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-c008ac1b-8e66-4058-aac3-5eb0c8a620ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-fabadf18-58f7-465d-b063-4430581fc9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-4edbb3d3-5144-44ac-a7c4-dc353bac5828,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-831ed586-64b8-41aa-9b34-e430d966de4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248761901-172.17.0.18-1595602552279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43382,DS-1f34408b-fa56-4351-b51d-cbc0cd2527dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-543a58fa-8f57-4587-90d0-54521f1bf7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-69d8b115-67fe-41cb-9a05-201cdc69a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-25e29410-7203-4e3b-8806-904c8d801203,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-c008ac1b-8e66-4058-aac3-5eb0c8a620ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-fabadf18-58f7-465d-b063-4430581fc9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-4edbb3d3-5144-44ac-a7c4-dc353bac5828,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-831ed586-64b8-41aa-9b34-e430d966de4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835610554-172.17.0.18-1595603325623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-acfdc1d8-5072-49a7-a66c-4f1baba50c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-806b78f8-a8cc-462c-b875-7d09f39d9224,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d8d5438c-8b37-463a-9c29-763baae8183f,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-17d1b5ae-aa96-411c-bdcb-8bbc9dc09985,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-ca7ea460-3f7a-4a0f-99c9-376b116e8a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-af533915-4fe3-44e3-a8f5-a15c5e2f2fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-0adbb345-4eb0-47d0-8814-cc1397aa2b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-4fbf0b19-a380-45ea-820d-b6d3647215ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835610554-172.17.0.18-1595603325623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-acfdc1d8-5072-49a7-a66c-4f1baba50c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-806b78f8-a8cc-462c-b875-7d09f39d9224,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d8d5438c-8b37-463a-9c29-763baae8183f,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-17d1b5ae-aa96-411c-bdcb-8bbc9dc09985,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-ca7ea460-3f7a-4a0f-99c9-376b116e8a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-af533915-4fe3-44e3-a8f5-a15c5e2f2fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-0adbb345-4eb0-47d0-8814-cc1397aa2b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-4fbf0b19-a380-45ea-820d-b6d3647215ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983594889-172.17.0.18-1595603582029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40893,DS-12a8df75-0490-4824-9f69-60414e27ea11,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-e2a7b1af-52e9-4002-9d46-30afea9095ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-104eeaed-d7e7-4d3f-9396-478f878c2b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-c9acb78d-87ca-4680-af31-483ca8debbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-e57bf9a1-0e8a-49b5-98d1-c7f3e7483710,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-dc0bf145-3b3e-49b7-a26e-958eac8e0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-ab25b300-18dd-45a7-a2ef-cee2d88c0854,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-37f11e35-379f-4143-94df-ff9728f57cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983594889-172.17.0.18-1595603582029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40893,DS-12a8df75-0490-4824-9f69-60414e27ea11,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-e2a7b1af-52e9-4002-9d46-30afea9095ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-104eeaed-d7e7-4d3f-9396-478f878c2b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-c9acb78d-87ca-4680-af31-483ca8debbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-e57bf9a1-0e8a-49b5-98d1-c7f3e7483710,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-dc0bf145-3b3e-49b7-a26e-958eac8e0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-ab25b300-18dd-45a7-a2ef-cee2d88c0854,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-37f11e35-379f-4143-94df-ff9728f57cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838984757-172.17.0.18-1595603956162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-25bf8783-bcb4-4fcd-8be1-8a425b6db028,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-0bd9f7ca-c38b-4dc6-ae12-f55ce91790b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-e494bab4-db52-4a02-bbd9-90b72a820159,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-60d18f5f-6381-4f0e-9a3e-800ef6575679,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-ff9a9824-0a3d-420c-8370-ecbd9f6c0c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-603343ff-0b35-4651-8b56-6cd0dec53ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-c3ede8c5-dca5-4f89-b7a6-2b88d0b75f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-a7a707ed-e513-4809-a031-d96b46449682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838984757-172.17.0.18-1595603956162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-25bf8783-bcb4-4fcd-8be1-8a425b6db028,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-0bd9f7ca-c38b-4dc6-ae12-f55ce91790b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-e494bab4-db52-4a02-bbd9-90b72a820159,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-60d18f5f-6381-4f0e-9a3e-800ef6575679,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-ff9a9824-0a3d-420c-8370-ecbd9f6c0c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-603343ff-0b35-4651-8b56-6cd0dec53ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-c3ede8c5-dca5-4f89-b7a6-2b88d0b75f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-a7a707ed-e513-4809-a031-d96b46449682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026893142-172.17.0.18-1595604388355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-c8127f06-9a8b-4b42-bc7c-3344136f5d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-31d81a67-d273-4acb-8ba0-f8880533547a,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-93234124-d41f-4b06-a206-9810e4e7651a,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-0b15ed32-be83-4977-94bf-b14f8602e43d,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-802c4048-c1ad-42eb-ad8b-3a31024947de,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-c0be297c-5d8c-4fe6-9d13-29302b5867f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-b1f16d6a-9b81-4163-9d30-c1ea153fa919,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-9d048bf0-70d2-402c-b4f5-6e2d87c240ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026893142-172.17.0.18-1595604388355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-c8127f06-9a8b-4b42-bc7c-3344136f5d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-31d81a67-d273-4acb-8ba0-f8880533547a,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-93234124-d41f-4b06-a206-9810e4e7651a,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-0b15ed32-be83-4977-94bf-b14f8602e43d,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-802c4048-c1ad-42eb-ad8b-3a31024947de,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-c0be297c-5d8c-4fe6-9d13-29302b5867f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-b1f16d6a-9b81-4163-9d30-c1ea153fa919,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-9d048bf0-70d2-402c-b4f5-6e2d87c240ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750233530-172.17.0.18-1595605154402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37427,DS-e931ba89-ab37-46f5-a7d5-c79fb2bc8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-04f029fa-21d0-4c47-98e5-1303c1727ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-86d9c29c-b1e5-48ec-b978-f940b84d9a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-c2d5e47b-0a4e-4375-9b36-944e3113d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-067e9ea7-7e6d-475c-8606-6b1f239fb652,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-0c06edd1-0c13-4bd6-8283-8ccae939867b,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-916025a3-13f2-43c5-b02b-22e42cbe1700,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-dfd0f827-bfb4-46f4-9450-9a1ad340a7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750233530-172.17.0.18-1595605154402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37427,DS-e931ba89-ab37-46f5-a7d5-c79fb2bc8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-04f029fa-21d0-4c47-98e5-1303c1727ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-86d9c29c-b1e5-48ec-b978-f940b84d9a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-c2d5e47b-0a4e-4375-9b36-944e3113d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-067e9ea7-7e6d-475c-8606-6b1f239fb652,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-0c06edd1-0c13-4bd6-8283-8ccae939867b,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-916025a3-13f2-43c5-b02b-22e42cbe1700,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-dfd0f827-bfb4-46f4-9450-9a1ad340a7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867203075-172.17.0.18-1595605579698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46133,DS-e4a422e2-6483-4a13-80f9-43c55dfe5106,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-a21e8111-2f70-4c30-b0ac-0fa73d4fec1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-061f22cc-f195-434f-bc54-6cb25f184484,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-6d4c2c5a-305c-4862-8930-662ee4379cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-f1c42227-cd4b-482a-9750-34a05b90df06,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-04cb9ad0-d083-4bee-8891-45c9e8a764da,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-ded74c60-e099-4506-80c8-ba784a7dfa57,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-8689c48a-ed69-4f37-9ec9-2c1f67111e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867203075-172.17.0.18-1595605579698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46133,DS-e4a422e2-6483-4a13-80f9-43c55dfe5106,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-a21e8111-2f70-4c30-b0ac-0fa73d4fec1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-061f22cc-f195-434f-bc54-6cb25f184484,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-6d4c2c5a-305c-4862-8930-662ee4379cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-f1c42227-cd4b-482a-9750-34a05b90df06,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-04cb9ad0-d083-4bee-8891-45c9e8a764da,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-ded74c60-e099-4506-80c8-ba784a7dfa57,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-8689c48a-ed69-4f37-9ec9-2c1f67111e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5670
