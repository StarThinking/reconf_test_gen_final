reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912199228-172.17.0.11-1595578478701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41050,DS-d6cc5999-54c8-40fd-bd1b-dddac3ef1375,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-f6fc62ab-7b02-44c1-8ce5-8371d1235437,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-f9acec6f-00d8-4f2f-b300-150da64fb192,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-f8bacc4a-f00a-4f6a-8647-b2d79243a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-36ad6019-872e-4c8a-9930-e49ccf831652,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-338567c0-5c32-40d8-a2b5-4de5d14a9dde,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-9f609c3b-af32-4914-91a9-e52583671755,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-dc042bf8-42a3-445e-a7ff-09c8c5d5020d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912199228-172.17.0.11-1595578478701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41050,DS-d6cc5999-54c8-40fd-bd1b-dddac3ef1375,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-f6fc62ab-7b02-44c1-8ce5-8371d1235437,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-f9acec6f-00d8-4f2f-b300-150da64fb192,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-f8bacc4a-f00a-4f6a-8647-b2d79243a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-36ad6019-872e-4c8a-9930-e49ccf831652,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-338567c0-5c32-40d8-a2b5-4de5d14a9dde,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-9f609c3b-af32-4914-91a9-e52583671755,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-dc042bf8-42a3-445e-a7ff-09c8c5d5020d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567638490-172.17.0.11-1595578552586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34726,DS-b4589bb1-3cd7-438a-a371-5a99f182da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-ff073515-e25d-428d-9405-73a2ca1d33b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-56658626-07ac-42a8-86a6-e3cda06c9e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-64242751-5d7c-40a7-a53b-c460bf5487d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-1f7b13b2-7f41-490b-a137-e300392d407b,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-0fedeef0-9553-469a-848a-df23692e4862,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-57a522c5-7a61-4f3a-84a9-a4fb349eaa50,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-48bb2b42-a520-4d1b-96a1-b2c4b8fa2efc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567638490-172.17.0.11-1595578552586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34726,DS-b4589bb1-3cd7-438a-a371-5a99f182da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-ff073515-e25d-428d-9405-73a2ca1d33b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-56658626-07ac-42a8-86a6-e3cda06c9e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-64242751-5d7c-40a7-a53b-c460bf5487d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-1f7b13b2-7f41-490b-a137-e300392d407b,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-0fedeef0-9553-469a-848a-df23692e4862,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-57a522c5-7a61-4f3a-84a9-a4fb349eaa50,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-48bb2b42-a520-4d1b-96a1-b2c4b8fa2efc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289231967-172.17.0.11-1595578591122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33078,DS-cf67573f-d9cf-4086-9774-5988207d179a,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-974ab7c8-3b02-4a1c-9439-3847afc91478,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-fef06c31-c72a-4f2f-aff7-56de7739dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-f6e7b783-eef9-4ee9-82d8-d859b1da745b,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-47bcd90b-3ef5-4847-863b-673b673216f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-ee7b86e2-7854-4c90-be20-6a57ce1c6016,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-05ae6beb-2cdb-4fb5-b501-8f6453e32afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-3c21344e-af6e-49aa-ad70-fc7085af5ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289231967-172.17.0.11-1595578591122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33078,DS-cf67573f-d9cf-4086-9774-5988207d179a,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-974ab7c8-3b02-4a1c-9439-3847afc91478,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-fef06c31-c72a-4f2f-aff7-56de7739dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-f6e7b783-eef9-4ee9-82d8-d859b1da745b,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-47bcd90b-3ef5-4847-863b-673b673216f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-ee7b86e2-7854-4c90-be20-6a57ce1c6016,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-05ae6beb-2cdb-4fb5-b501-8f6453e32afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-3c21344e-af6e-49aa-ad70-fc7085af5ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664264283-172.17.0.11-1595578711546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43614,DS-cdd516a3-3087-4e1f-a5d1-c81d7bce74e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-788dd642-b331-4190-aa05-161b3d974c51,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-5ccc1f53-685b-49b8-b07c-b650b647633f,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-a35d81bb-e84c-4211-8741-7777c55bd1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-7034a5d9-0f30-42ec-a8f6-365c4b5113d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-a4d9ae0d-da49-4c48-9ba3-a0786eabc328,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-bdbfd277-1f92-48c4-a6e1-f7c116492c24,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-5ca5897f-bcd7-47e3-9aa7-0309069622df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664264283-172.17.0.11-1595578711546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43614,DS-cdd516a3-3087-4e1f-a5d1-c81d7bce74e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-788dd642-b331-4190-aa05-161b3d974c51,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-5ccc1f53-685b-49b8-b07c-b650b647633f,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-a35d81bb-e84c-4211-8741-7777c55bd1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-7034a5d9-0f30-42ec-a8f6-365c4b5113d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-a4d9ae0d-da49-4c48-9ba3-a0786eabc328,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-bdbfd277-1f92-48c4-a6e1-f7c116492c24,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-5ca5897f-bcd7-47e3-9aa7-0309069622df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143845425-172.17.0.11-1595579170997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-98b53890-4a7f-45c8-bfc9-8738043a9753,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-ab7ae496-4b4b-46b7-8874-48f0bca733e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-33c48fa2-7a7e-4c7b-a273-ff57d6556f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-4cde95f6-f256-488f-9356-5a9ae1ee66fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-1a1c22b2-c1d2-41d2-8a00-571c4b906732,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-fffd460c-81c1-42f3-85d3-cb8cec38bf74,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-8f2c3e59-0cd8-4f93-aff6-5930fa508b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-4ca4fcbf-9aa8-4130-96bf-c6f9c131a37c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143845425-172.17.0.11-1595579170997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-98b53890-4a7f-45c8-bfc9-8738043a9753,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-ab7ae496-4b4b-46b7-8874-48f0bca733e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-33c48fa2-7a7e-4c7b-a273-ff57d6556f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-4cde95f6-f256-488f-9356-5a9ae1ee66fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-1a1c22b2-c1d2-41d2-8a00-571c4b906732,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-fffd460c-81c1-42f3-85d3-cb8cec38bf74,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-8f2c3e59-0cd8-4f93-aff6-5930fa508b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-4ca4fcbf-9aa8-4130-96bf-c6f9c131a37c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287245612-172.17.0.11-1595579215452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39040,DS-83880125-2a73-4058-a3a2-d4294bfd092a,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-1a189992-7512-4075-8374-b19cedda26af,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-de9958ac-3a17-4287-b3a1-5edfe2aabb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-99930770-be57-4603-867c-8e47ceefa2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-c1b5da35-9424-44c5-9d40-27aa290496a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-4d6dc06a-1a41-44f7-a780-acb91621ec88,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-d702e645-ecc2-4d5f-aba8-c5383025deea,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-b2d94b0f-2bc4-42c2-bb4b-097b3e4ee1ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287245612-172.17.0.11-1595579215452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39040,DS-83880125-2a73-4058-a3a2-d4294bfd092a,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-1a189992-7512-4075-8374-b19cedda26af,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-de9958ac-3a17-4287-b3a1-5edfe2aabb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-99930770-be57-4603-867c-8e47ceefa2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-c1b5da35-9424-44c5-9d40-27aa290496a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-4d6dc06a-1a41-44f7-a780-acb91621ec88,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-d702e645-ecc2-4d5f-aba8-c5383025deea,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-b2d94b0f-2bc4-42c2-bb4b-097b3e4ee1ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823269845-172.17.0.11-1595579523798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-85987ef6-cdcb-4309-81d6-ad85913bdb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-948342c1-aa0f-4c90-8de0-96242f55e739,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-4aeb49fb-8bf1-43e2-ba3f-ac6a74437479,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-5c718172-e154-4b3b-8933-16846c569723,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-e526ccda-ba54-4fa7-ba72-bf2a74c61ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-5beddb42-bb8d-408f-b64d-fe4cec98b860,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-e2ba1ac2-3b61-4b69-abaa-14190af59038,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-5c08a832-d1e6-4731-a661-c47d691191bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823269845-172.17.0.11-1595579523798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-85987ef6-cdcb-4309-81d6-ad85913bdb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-948342c1-aa0f-4c90-8de0-96242f55e739,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-4aeb49fb-8bf1-43e2-ba3f-ac6a74437479,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-5c718172-e154-4b3b-8933-16846c569723,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-e526ccda-ba54-4fa7-ba72-bf2a74c61ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-5beddb42-bb8d-408f-b64d-fe4cec98b860,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-e2ba1ac2-3b61-4b69-abaa-14190af59038,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-5c08a832-d1e6-4731-a661-c47d691191bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279384789-172.17.0.11-1595579708856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-d613c995-36ef-45f8-80ce-2e288693ecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-289b75c6-ceb1-4b65-9c03-9aede8736141,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-4f0c5fb5-753e-4974-a71f-94faddd89bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-32799f9c-1f5f-4e60-8f51-fa26b12a6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-eaf17544-6f8c-4bad-a4c3-a80001b7a957,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-be1d909d-5eed-4bf4-90ce-f2645db4c21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-aca6bc31-6547-4f96-8d1e-80faff81fbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-75e68e19-9e55-42b4-8363-ce494ab983a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279384789-172.17.0.11-1595579708856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-d613c995-36ef-45f8-80ce-2e288693ecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-289b75c6-ceb1-4b65-9c03-9aede8736141,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-4f0c5fb5-753e-4974-a71f-94faddd89bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-32799f9c-1f5f-4e60-8f51-fa26b12a6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-eaf17544-6f8c-4bad-a4c3-a80001b7a957,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-be1d909d-5eed-4bf4-90ce-f2645db4c21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-aca6bc31-6547-4f96-8d1e-80faff81fbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-75e68e19-9e55-42b4-8363-ce494ab983a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97500869-172.17.0.11-1595580148782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-ac6f1cda-f195-4881-97ba-9f039d9ad5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-b04a762c-b12c-49ca-a00d-2e64c6d519e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-3bd2cc45-27d1-4d5e-a397-5b99c10ebfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-1eca70bd-b32b-4012-9bf2-e27d7a9edbff,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-2a559d6b-e99f-4df7-ad40-00fbeea867a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-cc7791a0-9cfb-44c2-9915-95bd486bd3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-26e3b34d-e545-482e-9d4b-48251815f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-030d9bc9-e879-4732-a698-f1ace18c85f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97500869-172.17.0.11-1595580148782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-ac6f1cda-f195-4881-97ba-9f039d9ad5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-b04a762c-b12c-49ca-a00d-2e64c6d519e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-3bd2cc45-27d1-4d5e-a397-5b99c10ebfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-1eca70bd-b32b-4012-9bf2-e27d7a9edbff,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-2a559d6b-e99f-4df7-ad40-00fbeea867a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-cc7791a0-9cfb-44c2-9915-95bd486bd3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-26e3b34d-e545-482e-9d4b-48251815f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-030d9bc9-e879-4732-a698-f1ace18c85f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182741365-172.17.0.11-1595580222005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33578,DS-6d3b95d4-1379-46a1-ac20-c1d6889e0548,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-3a977026-4bef-471f-9caa-8258abeea947,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-3e7fe968-aa28-4476-bf05-82d488384a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-f432d150-5ffe-423c-a426-703bf84737b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-78fd952a-53f5-4211-b662-967b5d847422,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-9fec56bb-1552-45a8-8aba-091b6abdd656,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-1a0fcd6d-faec-4fa8-aed2-b32acbc5c834,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-a9faebf8-2ffd-4f3e-b0ce-89f472b65504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182741365-172.17.0.11-1595580222005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33578,DS-6d3b95d4-1379-46a1-ac20-c1d6889e0548,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-3a977026-4bef-471f-9caa-8258abeea947,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-3e7fe968-aa28-4476-bf05-82d488384a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-f432d150-5ffe-423c-a426-703bf84737b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-78fd952a-53f5-4211-b662-967b5d847422,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-9fec56bb-1552-45a8-8aba-091b6abdd656,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-1a0fcd6d-faec-4fa8-aed2-b32acbc5c834,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-a9faebf8-2ffd-4f3e-b0ce-89f472b65504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198236222-172.17.0.11-1595580293406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36330,DS-a6f4b4ca-f0e1-4402-892c-1f0b5f20b0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-4e7bbda7-118c-4d05-bda2-43e388c241ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-7e984655-4d72-4ba0-8cbd-f6f83495524f,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-70d69123-b6fd-4680-8be3-b360830b2c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-399535bb-8aa2-4a53-b503-49e144a9792d,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-50f077c0-9cdd-475b-9630-35fe20d0a54d,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-777f22d3-b750-445d-8d82-278c25d642b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-199b5af1-9b43-4925-b4d4-d6b3d38a820b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198236222-172.17.0.11-1595580293406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36330,DS-a6f4b4ca-f0e1-4402-892c-1f0b5f20b0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-4e7bbda7-118c-4d05-bda2-43e388c241ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-7e984655-4d72-4ba0-8cbd-f6f83495524f,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-70d69123-b6fd-4680-8be3-b360830b2c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-399535bb-8aa2-4a53-b503-49e144a9792d,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-50f077c0-9cdd-475b-9630-35fe20d0a54d,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-777f22d3-b750-445d-8d82-278c25d642b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-199b5af1-9b43-4925-b4d4-d6b3d38a820b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563680400-172.17.0.11-1595580409298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45802,DS-6020ab76-8c37-4624-ae51-d4f261a92aad,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-13ce832e-7243-464d-880f-f085568bc506,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-ba14e36a-dfff-4e12-ba75-ff240b5f5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-fde02b08-2e8a-4dd3-8b4c-99ff29d9bb42,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-5102174a-bee0-4a5e-a32a-48eaeb2b2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-712dcdbc-1ef3-4f57-a4af-ab8687eaf046,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-0808f7ed-0ec1-45e5-9207-83dec172817f,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-b416798b-f87f-442c-b6b7-6e1503109213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563680400-172.17.0.11-1595580409298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45802,DS-6020ab76-8c37-4624-ae51-d4f261a92aad,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-13ce832e-7243-464d-880f-f085568bc506,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-ba14e36a-dfff-4e12-ba75-ff240b5f5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-fde02b08-2e8a-4dd3-8b4c-99ff29d9bb42,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-5102174a-bee0-4a5e-a32a-48eaeb2b2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-712dcdbc-1ef3-4f57-a4af-ab8687eaf046,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-0808f7ed-0ec1-45e5-9207-83dec172817f,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-b416798b-f87f-442c-b6b7-6e1503109213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868761088-172.17.0.11-1595580629400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-74651de9-5b26-47f3-8733-f5276dacf56f,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-d7b0f325-e6f2-4678-bbbd-007160f1fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-1ddcd216-25b2-4714-9439-70b0beadd74d,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-f770b71e-1f36-421e-ab62-4767a5818e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-bf8ac5e1-2df0-4d2b-8db4-85c1dcad5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-4b7af811-ca0a-4bf4-ae9b-9de8d2bef2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-b97e29ea-f3d1-4458-987d-2d0245674516,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-826b33d8-6c45-429c-9b68-1af5b1970bcf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868761088-172.17.0.11-1595580629400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-74651de9-5b26-47f3-8733-f5276dacf56f,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-d7b0f325-e6f2-4678-bbbd-007160f1fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-1ddcd216-25b2-4714-9439-70b0beadd74d,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-f770b71e-1f36-421e-ab62-4767a5818e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-bf8ac5e1-2df0-4d2b-8db4-85c1dcad5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-4b7af811-ca0a-4bf4-ae9b-9de8d2bef2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-b97e29ea-f3d1-4458-987d-2d0245674516,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-826b33d8-6c45-429c-9b68-1af5b1970bcf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983673970-172.17.0.11-1595580815905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-e072a6a8-afd0-48f1-ac1c-0913178aebda,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-4f340a70-cb59-4876-b075-0159cd535f51,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-87947790-2171-4d59-adae-c23ed77dfcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-93df05e6-c12b-4a10-ae95-b59754a2f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-5e8c1f98-7252-4033-bd2b-b2ae1af69e67,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-9b5d550a-9ab6-42fb-9fb6-d9ec7ba4a1db,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-e3707ebb-e8e2-4a18-84d0-ed2b75346f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-f975fb12-22cc-4190-8b8e-5f0a0a526037,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983673970-172.17.0.11-1595580815905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-e072a6a8-afd0-48f1-ac1c-0913178aebda,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-4f340a70-cb59-4876-b075-0159cd535f51,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-87947790-2171-4d59-adae-c23ed77dfcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-93df05e6-c12b-4a10-ae95-b59754a2f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-5e8c1f98-7252-4033-bd2b-b2ae1af69e67,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-9b5d550a-9ab6-42fb-9fb6-d9ec7ba4a1db,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-e3707ebb-e8e2-4a18-84d0-ed2b75346f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-f975fb12-22cc-4190-8b8e-5f0a0a526037,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130664391-172.17.0.11-1595581070828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-6b03f00f-557d-488f-ad6b-426ed32e8b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-7394d78d-f887-42e6-9142-1b2f96563364,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-0e0642c0-d8f8-4724-af71-e26f6743911b,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-1d5548f1-1b57-4472-89c9-7b9bf6230bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-36d00bd8-217e-4175-bba0-e410cc3d893d,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-08e9fdd2-a37e-4563-8089-2c5f1432e96e,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-73a00fb6-3948-47bc-a4bf-c9c651ba26ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-b4062450-e47c-432d-8ee9-9e88ca7892a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130664391-172.17.0.11-1595581070828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-6b03f00f-557d-488f-ad6b-426ed32e8b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-7394d78d-f887-42e6-9142-1b2f96563364,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-0e0642c0-d8f8-4724-af71-e26f6743911b,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-1d5548f1-1b57-4472-89c9-7b9bf6230bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-36d00bd8-217e-4175-bba0-e410cc3d893d,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-08e9fdd2-a37e-4563-8089-2c5f1432e96e,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-73a00fb6-3948-47bc-a4bf-c9c651ba26ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-b4062450-e47c-432d-8ee9-9e88ca7892a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892171640-172.17.0.11-1595581422686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44662,DS-6722dd99-1683-4cf0-963b-c83a49ef0f64,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-84595aab-b58b-450b-ae79-ec9569ac1508,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-f6d24c79-dae7-49c4-b862-54fe628895ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-70b5fdb4-c0b2-451e-a9ab-803581dbe21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-5d638725-89b5-4a85-b409-2d7423023eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-b74633e5-532e-49aa-84d7-745b912e9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-5f3c94e8-517f-4cf4-949d-b8f18b7e9f03,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-c9d5ae75-abe6-4454-baba-65faff7abc87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892171640-172.17.0.11-1595581422686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44662,DS-6722dd99-1683-4cf0-963b-c83a49ef0f64,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-84595aab-b58b-450b-ae79-ec9569ac1508,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-f6d24c79-dae7-49c4-b862-54fe628895ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-70b5fdb4-c0b2-451e-a9ab-803581dbe21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-5d638725-89b5-4a85-b409-2d7423023eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-b74633e5-532e-49aa-84d7-745b912e9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-5f3c94e8-517f-4cf4-949d-b8f18b7e9f03,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-c9d5ae75-abe6-4454-baba-65faff7abc87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058570221-172.17.0.11-1595581453575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-06cacc46-9aff-4978-b89f-511a6e6028dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-be071e5a-5115-4845-876a-d75bdd67eac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-d438fd23-5e21-4b18-b472-5b9df019b353,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-63058e7f-c1d3-4b55-ab7f-660fe72fdbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-80c3c0c5-f148-40d8-bee6-71512b79944c,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-c3364dc1-c91e-437b-8baf-b76161ac7809,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-9cf5c41d-21bd-45ec-a171-fdedddc7e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-2269aad6-f99d-4b88-8639-586287e5343f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058570221-172.17.0.11-1595581453575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-06cacc46-9aff-4978-b89f-511a6e6028dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-be071e5a-5115-4845-876a-d75bdd67eac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-d438fd23-5e21-4b18-b472-5b9df019b353,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-63058e7f-c1d3-4b55-ab7f-660fe72fdbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-80c3c0c5-f148-40d8-bee6-71512b79944c,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-c3364dc1-c91e-437b-8baf-b76161ac7809,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-9cf5c41d-21bd-45ec-a171-fdedddc7e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-2269aad6-f99d-4b88-8639-586287e5343f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891885771-172.17.0.11-1595581529029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-19c6c8b6-67fa-47f8-8854-9a5510f88fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-35dd25f5-6c85-4098-b51a-3db44089110e,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-fabc2b62-6d2a-4ce3-acad-5b71729a0ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-8ce0090a-6610-4be9-ab7a-a8dd96905c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-26f539d9-6b04-4064-89b7-c25a3a5057b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-7f5b9091-bfe0-4c93-a7b3-6acfa98f0e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-e3de201c-1d6e-4312-a884-4320c6d5e751,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-4e3a51eb-3649-4f4a-830c-c470573f374c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891885771-172.17.0.11-1595581529029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-19c6c8b6-67fa-47f8-8854-9a5510f88fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-35dd25f5-6c85-4098-b51a-3db44089110e,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-fabc2b62-6d2a-4ce3-acad-5b71729a0ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-8ce0090a-6610-4be9-ab7a-a8dd96905c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-26f539d9-6b04-4064-89b7-c25a3a5057b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-7f5b9091-bfe0-4c93-a7b3-6acfa98f0e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-e3de201c-1d6e-4312-a884-4320c6d5e751,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-4e3a51eb-3649-4f4a-830c-c470573f374c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145481630-172.17.0.11-1595581720015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-32f165e0-1ca5-4c2b-993b-2a92eb6b6700,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-d550045c-fca4-4c91-ba36-87d22544bff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-3a3d2602-d951-46eb-8ae5-cd87c74d283c,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-8932932e-8549-441d-a6e4-dd4b8dd2feb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-52fe18db-7a7d-49bf-b756-0b3afc1c31cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-02b3107f-9234-4ac6-b026-16fb71045470,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-acb44445-6808-44c9-9f1a-ed13df1d68b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-4fa75b49-79cf-48f4-bcbc-b02a47e5aad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145481630-172.17.0.11-1595581720015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-32f165e0-1ca5-4c2b-993b-2a92eb6b6700,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-d550045c-fca4-4c91-ba36-87d22544bff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-3a3d2602-d951-46eb-8ae5-cd87c74d283c,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-8932932e-8549-441d-a6e4-dd4b8dd2feb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-52fe18db-7a7d-49bf-b756-0b3afc1c31cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-02b3107f-9234-4ac6-b026-16fb71045470,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-acb44445-6808-44c9-9f1a-ed13df1d68b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-4fa75b49-79cf-48f4-bcbc-b02a47e5aad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838122039-172.17.0.11-1595581907231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-e687b9fc-c2f6-4890-a112-97a54d69fa75,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-38a2e836-651d-45c4-93a2-7ec7c96d2cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-9dd4d838-64be-4ecc-9bf5-a5c94ce17cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-8bf1c735-9b1a-491d-90f5-72f0e58daf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-70296865-cd82-42bd-ab6d-df0c354436da,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-a69d2e94-6de3-4359-a9ba-45806e24557b,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-40f58524-460b-4656-bd5d-5705e3a5e9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-29a5834c-afa2-4cac-8cea-49a175f9ece7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838122039-172.17.0.11-1595581907231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-e687b9fc-c2f6-4890-a112-97a54d69fa75,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-38a2e836-651d-45c4-93a2-7ec7c96d2cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-9dd4d838-64be-4ecc-9bf5-a5c94ce17cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-8bf1c735-9b1a-491d-90f5-72f0e58daf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-70296865-cd82-42bd-ab6d-df0c354436da,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-a69d2e94-6de3-4359-a9ba-45806e24557b,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-40f58524-460b-4656-bd5d-5705e3a5e9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-29a5834c-afa2-4cac-8cea-49a175f9ece7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884252829-172.17.0.11-1595581982729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-6ea452b6-7c26-4c99-9983-101fc449eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-456ba88e-576b-4425-bcea-92f70a90807e,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-3783aa5f-c8e0-4572-9c58-7c27f71467ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-c042c9cd-599f-4f40-9f73-b494d6f629aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-ef34c424-e606-4fcd-8b34-ef2f8268bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-f91e4463-3cac-47aa-9517-f3e636979d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-e44cc3ee-f768-401e-b33d-25aef7a8f854,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-9ced0d90-2ed8-42e2-be25-f26d2b8ed9ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884252829-172.17.0.11-1595581982729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-6ea452b6-7c26-4c99-9983-101fc449eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-456ba88e-576b-4425-bcea-92f70a90807e,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-3783aa5f-c8e0-4572-9c58-7c27f71467ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-c042c9cd-599f-4f40-9f73-b494d6f629aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-ef34c424-e606-4fcd-8b34-ef2f8268bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-f91e4463-3cac-47aa-9517-f3e636979d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-e44cc3ee-f768-401e-b33d-25aef7a8f854,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-9ced0d90-2ed8-42e2-be25-f26d2b8ed9ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218198330-172.17.0.11-1595582178894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-83d8b2a1-0d95-4117-85fe-e8542bd53256,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-ce102f12-a41f-471a-b8bb-de93925f723e,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-4dbbf79f-1cd0-443b-b522-31bd182b3d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-55b360bd-1364-4856-9f9e-6ba4a94b56b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-57b57c85-4455-40dd-a1c6-05827acd9f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-27d97b2e-5de8-4d0a-8bdd-5b00412e2b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-9cf78107-2e45-48ae-a6c0-ed354a53d107,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-de73e923-e588-439b-a03a-691fbf459d49,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218198330-172.17.0.11-1595582178894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-83d8b2a1-0d95-4117-85fe-e8542bd53256,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-ce102f12-a41f-471a-b8bb-de93925f723e,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-4dbbf79f-1cd0-443b-b522-31bd182b3d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-55b360bd-1364-4856-9f9e-6ba4a94b56b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-57b57c85-4455-40dd-a1c6-05827acd9f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-27d97b2e-5de8-4d0a-8bdd-5b00412e2b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-9cf78107-2e45-48ae-a6c0-ed354a53d107,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-de73e923-e588-439b-a03a-691fbf459d49,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058457796-172.17.0.11-1595582302756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-88e767af-8af4-405e-8560-382b307efec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-06191e43-6624-4342-aaa4-d4f1c7d4d7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-37e30137-d567-43c7-935b-f7efb4f61f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-861c0f48-e1de-4efc-bcf7-071317c0bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-86124d1e-503a-4f19-8aca-d670713c2615,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-3782ddcb-4583-48b9-9ce4-58bee881a156,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-25a6d1bb-ef84-42c3-b386-49a3845c0ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-f3471a61-521c-422e-be05-c96aded2b19e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058457796-172.17.0.11-1595582302756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-88e767af-8af4-405e-8560-382b307efec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-06191e43-6624-4342-aaa4-d4f1c7d4d7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-37e30137-d567-43c7-935b-f7efb4f61f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-861c0f48-e1de-4efc-bcf7-071317c0bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-86124d1e-503a-4f19-8aca-d670713c2615,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-3782ddcb-4583-48b9-9ce4-58bee881a156,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-25a6d1bb-ef84-42c3-b386-49a3845c0ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-f3471a61-521c-422e-be05-c96aded2b19e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127215196-172.17.0.11-1595582524588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-adccfd0c-8bed-4afb-911b-8b2e5fc9f991,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-d2ade116-5425-4c74-b89b-affada521e41,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-72c49137-34be-42c0-a416-39b889ca3135,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-d1433e86-0548-4c0c-a207-a9e138b24456,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-64239d01-613c-4f05-8eee-3d52268c7d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-1686618b-ba75-4ce0-bca3-8a4a4f79ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-c19f9817-4422-4675-9aad-910bad3cae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-18a80e58-d581-434e-8883-b8006ee69310,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127215196-172.17.0.11-1595582524588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-adccfd0c-8bed-4afb-911b-8b2e5fc9f991,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-d2ade116-5425-4c74-b89b-affada521e41,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-72c49137-34be-42c0-a416-39b889ca3135,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-d1433e86-0548-4c0c-a207-a9e138b24456,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-64239d01-613c-4f05-8eee-3d52268c7d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-1686618b-ba75-4ce0-bca3-8a4a4f79ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-c19f9817-4422-4675-9aad-910bad3cae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-18a80e58-d581-434e-8883-b8006ee69310,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072871307-172.17.0.11-1595582563689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37077,DS-30847153-3939-46c7-a280-527e0717f382,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-13088211-cfe8-4a9d-a71d-ea5a7339ec90,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-b979cdb5-18c4-4acd-ac48-1bee0a77b1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-40e02e41-779e-4200-9e59-043fb55bf89b,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-84a21116-fb65-4358-ab30-2d3a4404363e,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-ae69a8ce-f7d0-4787-8763-21e71df3d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-ec66bede-4fdd-45f3-b58d-48f149f6b971,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-32d122a0-bd72-426f-b13a-caf63155c72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072871307-172.17.0.11-1595582563689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37077,DS-30847153-3939-46c7-a280-527e0717f382,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-13088211-cfe8-4a9d-a71d-ea5a7339ec90,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-b979cdb5-18c4-4acd-ac48-1bee0a77b1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-40e02e41-779e-4200-9e59-043fb55bf89b,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-84a21116-fb65-4358-ab30-2d3a4404363e,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-ae69a8ce-f7d0-4787-8763-21e71df3d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-ec66bede-4fdd-45f3-b58d-48f149f6b971,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-32d122a0-bd72-426f-b13a-caf63155c72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084539098-172.17.0.11-1595582632551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38867,DS-48a6de7c-5c72-452f-9af2-b5baafbee463,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-ac44cb39-3c78-4c09-9fcb-a2c71bee60bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-fe993df4-3f75-4fb4-b990-222b7339db99,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-fa3bb4bd-0966-4574-a533-2d8b3185e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-c2e49a76-9134-4dae-bb31-5144c65be7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-fdec2b2d-8335-4c97-b14e-1a47fa6ce18b,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-8dd07c14-f94f-40ac-ac39-695866aeeedf,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-8d11663c-7e81-4378-a26b-652c56415195,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084539098-172.17.0.11-1595582632551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38867,DS-48a6de7c-5c72-452f-9af2-b5baafbee463,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-ac44cb39-3c78-4c09-9fcb-a2c71bee60bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-fe993df4-3f75-4fb4-b990-222b7339db99,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-fa3bb4bd-0966-4574-a533-2d8b3185e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-c2e49a76-9134-4dae-bb31-5144c65be7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-fdec2b2d-8335-4c97-b14e-1a47fa6ce18b,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-8dd07c14-f94f-40ac-ac39-695866aeeedf,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-8d11663c-7e81-4378-a26b-652c56415195,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940730075-172.17.0.11-1595582667236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-837acc74-5b23-4417-a687-87d8be7c5e95,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-67d61935-7f46-4283-923e-b2c9840858ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-0fcdc7df-bf56-449c-9831-25c9fbfea5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-8ebe01d2-9b52-4916-b176-1d265620c69a,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-cbf721e1-87de-4c23-ac59-655b0f7f72cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-c34cc7b9-f9e9-483b-8fe6-eb83dd9e77ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-a1045cd0-ee6d-4a16-9c13-2c4f3ebdb6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-a720c5aa-82d0-406b-b114-b0069e7bca4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940730075-172.17.0.11-1595582667236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-837acc74-5b23-4417-a687-87d8be7c5e95,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-67d61935-7f46-4283-923e-b2c9840858ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-0fcdc7df-bf56-449c-9831-25c9fbfea5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-8ebe01d2-9b52-4916-b176-1d265620c69a,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-cbf721e1-87de-4c23-ac59-655b0f7f72cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-c34cc7b9-f9e9-483b-8fe6-eb83dd9e77ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-a1045cd0-ee6d-4a16-9c13-2c4f3ebdb6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-a720c5aa-82d0-406b-b114-b0069e7bca4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753600663-172.17.0.11-1595582748797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35161,DS-ff885efc-3aa3-4f6b-b4ab-963b37ef7dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-a75e4862-9ec5-461c-b10e-f1b5a2cd090c,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-5fa1574e-241a-4529-8293-3a458fd5ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-6e7fc546-7a0f-4da4-a12b-0e325b42ce89,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-d764fec3-8df8-4c64-9def-9895fccad96b,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-7a5351ee-4489-4b0f-bc4b-f96056398cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-4bc1c781-320d-41a9-80bb-253b9ff1844d,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-2a3fbb02-b777-4e09-bdec-a94bf2f3189c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753600663-172.17.0.11-1595582748797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35161,DS-ff885efc-3aa3-4f6b-b4ab-963b37ef7dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-a75e4862-9ec5-461c-b10e-f1b5a2cd090c,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-5fa1574e-241a-4529-8293-3a458fd5ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-6e7fc546-7a0f-4da4-a12b-0e325b42ce89,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-d764fec3-8df8-4c64-9def-9895fccad96b,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-7a5351ee-4489-4b0f-bc4b-f96056398cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-4bc1c781-320d-41a9-80bb-253b9ff1844d,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-2a3fbb02-b777-4e09-bdec-a94bf2f3189c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166839637-172.17.0.11-1595583137613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37252,DS-d1cf1fd1-91be-4746-8e40-215799c9481b,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-ccc3e397-2688-482e-a5b8-2caa8233491c,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-a639dd9e-1634-42f5-ae4d-38d794fb611d,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-32c612ff-df96-4ee0-9cea-46c0c51c2de1,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-7f2c84fa-479e-459a-9aa8-75a383c15ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-1760da18-69b9-4389-822e-3a1bb0555ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-7f0f8f23-3a55-4e7e-b728-54612686852a,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-506e93e1-33e1-4d02-a5dc-7aa0a6d52136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166839637-172.17.0.11-1595583137613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37252,DS-d1cf1fd1-91be-4746-8e40-215799c9481b,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-ccc3e397-2688-482e-a5b8-2caa8233491c,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-a639dd9e-1634-42f5-ae4d-38d794fb611d,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-32c612ff-df96-4ee0-9cea-46c0c51c2de1,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-7f2c84fa-479e-459a-9aa8-75a383c15ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-1760da18-69b9-4389-822e-3a1bb0555ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-7f0f8f23-3a55-4e7e-b728-54612686852a,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-506e93e1-33e1-4d02-a5dc-7aa0a6d52136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085561458-172.17.0.11-1595583366498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41966,DS-038f6393-041e-4ac7-8e29-cbf57ccbc468,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-37eb9842-13a6-48d9-a826-81974320c345,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-3c40f200-d06f-455a-9ee8-ceeb85dcc1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-b99c194b-a553-4d19-a6ad-0df19a27ae70,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-e717a4e5-a391-494a-9e66-8e3dee6f98a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-31a9e204-44b5-4e47-aa0f-da03c6444db2,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-e18efd3c-caf2-4d99-8446-df852365550f,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-c09fde05-9d6b-4afd-9db8-6e849fde3803,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085561458-172.17.0.11-1595583366498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41966,DS-038f6393-041e-4ac7-8e29-cbf57ccbc468,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-37eb9842-13a6-48d9-a826-81974320c345,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-3c40f200-d06f-455a-9ee8-ceeb85dcc1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-b99c194b-a553-4d19-a6ad-0df19a27ae70,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-e717a4e5-a391-494a-9e66-8e3dee6f98a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-31a9e204-44b5-4e47-aa0f-da03c6444db2,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-e18efd3c-caf2-4d99-8446-df852365550f,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-c09fde05-9d6b-4afd-9db8-6e849fde3803,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146508815-172.17.0.11-1595583402834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45839,DS-50159112-523f-4ef8-a1b8-3332f94007c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-37e7e29f-5056-4b56-b02b-6a99ae3a6327,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-3441be5d-1d29-4f68-888b-6b1c525b9ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-51f1933c-6ae3-438c-8773-d486cc4ba131,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-69df5c73-4ba6-49b9-ae03-6271448ac4be,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-f13eb059-892a-4300-9ba3-4e2e77ccadc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-6cd8818c-a3c5-4f27-b4bb-f887e112ba46,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-75172be1-c1dc-4e3a-9612-615e63e6271f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146508815-172.17.0.11-1595583402834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45839,DS-50159112-523f-4ef8-a1b8-3332f94007c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-37e7e29f-5056-4b56-b02b-6a99ae3a6327,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-3441be5d-1d29-4f68-888b-6b1c525b9ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-51f1933c-6ae3-438c-8773-d486cc4ba131,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-69df5c73-4ba6-49b9-ae03-6271448ac4be,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-f13eb059-892a-4300-9ba3-4e2e77ccadc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-6cd8818c-a3c5-4f27-b4bb-f887e112ba46,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-75172be1-c1dc-4e3a-9612-615e63e6271f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901833058-172.17.0.11-1595583700800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-2ed2ae78-ac88-43c0-8695-13c4d7a33745,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-ffdc44d2-78eb-48a3-b112-1f70bcee2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-3f8ef462-330d-4f37-9d3f-5286c2a932f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-f3a5a55d-841b-4612-9c10-3ef8c9b05852,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-9e2a06f6-4e78-4dcb-8048-175776caa2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-9d4b636c-559b-48a2-b9be-33806c4724f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-4b54baca-f5d7-4990-8cff-f86920249630,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-5622baff-7107-47a7-ac95-c8b65cc17e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901833058-172.17.0.11-1595583700800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-2ed2ae78-ac88-43c0-8695-13c4d7a33745,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-ffdc44d2-78eb-48a3-b112-1f70bcee2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-3f8ef462-330d-4f37-9d3f-5286c2a932f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-f3a5a55d-841b-4612-9c10-3ef8c9b05852,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-9e2a06f6-4e78-4dcb-8048-175776caa2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-9d4b636c-559b-48a2-b9be-33806c4724f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-4b54baca-f5d7-4990-8cff-f86920249630,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-5622baff-7107-47a7-ac95-c8b65cc17e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145547412-172.17.0.11-1595583780296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-3a0a42b2-7ff6-4b28-9e88-e9b799199aef,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-ce12679b-0c55-43f5-9bb7-dd5437027764,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-c6d285a8-94bc-4e90-8f9b-db23418011c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-ca8f4d4e-ea71-42ef-bd15-e5099fbf1e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-6effb1d9-d220-47f2-8de7-82e9e4153f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-bf0da9c1-f46e-4635-842a-6ffe5312a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-225ca3b2-a8a0-48ce-9754-63ec34245d15,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-dbcfbc5a-12d1-4653-b8cf-3845adf73561,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145547412-172.17.0.11-1595583780296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-3a0a42b2-7ff6-4b28-9e88-e9b799199aef,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-ce12679b-0c55-43f5-9bb7-dd5437027764,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-c6d285a8-94bc-4e90-8f9b-db23418011c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-ca8f4d4e-ea71-42ef-bd15-e5099fbf1e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-6effb1d9-d220-47f2-8de7-82e9e4153f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-bf0da9c1-f46e-4635-842a-6ffe5312a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-225ca3b2-a8a0-48ce-9754-63ec34245d15,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-dbcfbc5a-12d1-4653-b8cf-3845adf73561,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869947159-172.17.0.11-1595583858785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35765,DS-49ccbda6-d21c-4fcb-a495-ce509076f717,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-8732ede0-2efe-4781-881f-669a9fd48395,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-a735e012-2d5c-42c6-9a2b-495d4ddfc9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-5ae1b8b5-b403-43d7-8ee0-01336df74cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-b387d3f9-19ae-47f6-a9b7-ab7f54b24cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-4d996979-3bbd-41f0-a040-f3509983e7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-94dbc711-6c84-435b-9aa1-272bb7ea2d62,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-d07b8947-710d-4844-a117-e63807363f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869947159-172.17.0.11-1595583858785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35765,DS-49ccbda6-d21c-4fcb-a495-ce509076f717,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-8732ede0-2efe-4781-881f-669a9fd48395,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-a735e012-2d5c-42c6-9a2b-495d4ddfc9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-5ae1b8b5-b403-43d7-8ee0-01336df74cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-b387d3f9-19ae-47f6-a9b7-ab7f54b24cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-4d996979-3bbd-41f0-a040-f3509983e7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-94dbc711-6c84-435b-9aa1-272bb7ea2d62,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-d07b8947-710d-4844-a117-e63807363f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321627562-172.17.0.11-1595583896476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40121,DS-edf47bcf-e84d-4dbb-ab02-96c959115623,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-b9e78776-cdc2-4604-bced-d1638a6b2edc,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-fd2b4d21-a138-4a71-876a-8e772112cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-2e698927-98b8-45e9-9052-e65050d2283d,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-546dcf6a-1e0c-48e2-a3a5-9c22429c6694,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-4c71bf2b-5f1a-4896-bcc7-dea0f239d94b,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-86e5d46c-80e9-4453-b154-a5766875f497,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-cce0ced2-4866-4f72-974a-3095c9140df5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321627562-172.17.0.11-1595583896476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40121,DS-edf47bcf-e84d-4dbb-ab02-96c959115623,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-b9e78776-cdc2-4604-bced-d1638a6b2edc,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-fd2b4d21-a138-4a71-876a-8e772112cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-2e698927-98b8-45e9-9052-e65050d2283d,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-546dcf6a-1e0c-48e2-a3a5-9c22429c6694,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-4c71bf2b-5f1a-4896-bcc7-dea0f239d94b,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-86e5d46c-80e9-4453-b154-a5766875f497,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-cce0ced2-4866-4f72-974a-3095c9140df5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085690758-172.17.0.11-1595583982404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36325,DS-23fccc2d-29e3-47c3-95db-eab8513e8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-2f61bb03-c2f3-4023-af8c-6c0aad870024,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-64784764-fdfb-4afd-88f2-2ab475660592,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-cadbd604-ba8a-413b-8b69-f924f92a097f,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-39b725c7-4311-47bf-a555-5e8ea6f9b320,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-de641b4f-898e-424b-a79c-dc91a4009db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-9db9a38d-4747-4557-8462-cd9003553861,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-6082da57-a6b0-419a-bc00-4c6b2cda3290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085690758-172.17.0.11-1595583982404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36325,DS-23fccc2d-29e3-47c3-95db-eab8513e8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-2f61bb03-c2f3-4023-af8c-6c0aad870024,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-64784764-fdfb-4afd-88f2-2ab475660592,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-cadbd604-ba8a-413b-8b69-f924f92a097f,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-39b725c7-4311-47bf-a555-5e8ea6f9b320,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-de641b4f-898e-424b-a79c-dc91a4009db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-9db9a38d-4747-4557-8462-cd9003553861,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-6082da57-a6b0-419a-bc00-4c6b2cda3290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424811209-172.17.0.11-1595584014892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32863,DS-dbfd37c8-4cc0-4415-aafb-ea3d228cd305,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-01116a56-08bc-408b-8e4d-b19d71b84390,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-15004b73-f9cd-4352-9caa-481379565031,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-ecbdae4e-9db9-4ad1-bacf-e8370a292a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-ea47749b-9d99-423c-a621-400642978bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-3a1286a3-48e0-4fce-bd64-81e8b888e556,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-f705ba18-1787-47fa-a8b8-3cc9949aba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-afb21d36-28d7-497a-8421-8fdf262f04c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424811209-172.17.0.11-1595584014892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32863,DS-dbfd37c8-4cc0-4415-aafb-ea3d228cd305,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-01116a56-08bc-408b-8e4d-b19d71b84390,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-15004b73-f9cd-4352-9caa-481379565031,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-ecbdae4e-9db9-4ad1-bacf-e8370a292a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-ea47749b-9d99-423c-a621-400642978bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-3a1286a3-48e0-4fce-bd64-81e8b888e556,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-f705ba18-1787-47fa-a8b8-3cc9949aba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-afb21d36-28d7-497a-8421-8fdf262f04c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5763
