reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417009199-172.17.0.14-1595828976769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-816ac966-1b2d-4f25-b639-cfe2a79135a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-f91fa5ba-416a-49a7-b788-65b03fe71d43,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-bc1694b4-7fb9-4b9b-bc0c-86bc8c264dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-49b08560-1f0f-49bc-ad2f-0c12b7369227,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-4ffd9698-4cce-49db-b236-fd57299701bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-1a5d124f-31fe-4a6f-a221-5957c7ecc3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-619f3d8f-0969-4f36-95ab-357651b5c900,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-2949648e-ab9b-4ffb-a52a-7d10744300ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417009199-172.17.0.14-1595828976769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-816ac966-1b2d-4f25-b639-cfe2a79135a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-f91fa5ba-416a-49a7-b788-65b03fe71d43,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-bc1694b4-7fb9-4b9b-bc0c-86bc8c264dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-49b08560-1f0f-49bc-ad2f-0c12b7369227,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-4ffd9698-4cce-49db-b236-fd57299701bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-1a5d124f-31fe-4a6f-a221-5957c7ecc3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-619f3d8f-0969-4f36-95ab-357651b5c900,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-2949648e-ab9b-4ffb-a52a-7d10744300ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81358675-172.17.0.14-1595829173307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44660,DS-e65affbb-7e2d-4741-aa1c-080e8f59834f,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-4efc3684-fda2-4d62-a43e-aa0b7d4d9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-a9368a42-d74c-4eab-ad33-049c165b4dda,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-555bce89-e2fd-4646-994f-2438aa3bf01c,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-f117e241-054b-4c9e-b520-2bb36e8367a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-cee185eb-9615-4ac7-af46-54ceb18e398a,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-ef484a9f-db23-4658-8260-2432fc1ec471,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-4939b147-b511-4041-bc39-9f79189eb7c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81358675-172.17.0.14-1595829173307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44660,DS-e65affbb-7e2d-4741-aa1c-080e8f59834f,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-4efc3684-fda2-4d62-a43e-aa0b7d4d9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-a9368a42-d74c-4eab-ad33-049c165b4dda,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-555bce89-e2fd-4646-994f-2438aa3bf01c,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-f117e241-054b-4c9e-b520-2bb36e8367a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-cee185eb-9615-4ac7-af46-54ceb18e398a,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-ef484a9f-db23-4658-8260-2432fc1ec471,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-4939b147-b511-4041-bc39-9f79189eb7c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447275966-172.17.0.14-1595829206064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-865086d7-71d6-4855-8920-749474b650a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-4d6004c0-9da9-47cf-b33f-5cd065249f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-c234ede1-983b-429b-b74b-a60c82e2c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-47011b78-a057-4cf5-881b-861283e0e937,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-5f0798ed-73a6-4f4a-a794-d98bed82d622,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-d3b8fb75-bf2b-45ec-98e1-4311d88f6182,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-5515e14e-1e72-4c80-947b-e22e536ccfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-6541cbec-2601-432b-a5d4-6a8fbccae7b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447275966-172.17.0.14-1595829206064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-865086d7-71d6-4855-8920-749474b650a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-4d6004c0-9da9-47cf-b33f-5cd065249f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-c234ede1-983b-429b-b74b-a60c82e2c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-47011b78-a057-4cf5-881b-861283e0e937,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-5f0798ed-73a6-4f4a-a794-d98bed82d622,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-d3b8fb75-bf2b-45ec-98e1-4311d88f6182,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-5515e14e-1e72-4c80-947b-e22e536ccfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-6541cbec-2601-432b-a5d4-6a8fbccae7b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462734598-172.17.0.14-1595829454841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-3daafa0f-a670-4cb6-868d-67cba2ec1b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-bde42c4e-8764-444f-bfb8-720f7b040163,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-373872c5-ee24-44df-880c-4f96047e8cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-73ac0a66-fdd7-42cb-92c4-6f03e77129e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-25ec0d9e-42e5-4c18-b831-00c55494e71a,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-44fb6de3-30a5-4f99-8ef2-1ba4df1eb958,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-f6d530df-9016-4427-aa28-42616654fc57,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-2da684cc-df2b-484b-96d7-32dd9adea922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462734598-172.17.0.14-1595829454841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-3daafa0f-a670-4cb6-868d-67cba2ec1b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-bde42c4e-8764-444f-bfb8-720f7b040163,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-373872c5-ee24-44df-880c-4f96047e8cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-73ac0a66-fdd7-42cb-92c4-6f03e77129e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-25ec0d9e-42e5-4c18-b831-00c55494e71a,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-44fb6de3-30a5-4f99-8ef2-1ba4df1eb958,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-f6d530df-9016-4427-aa28-42616654fc57,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-2da684cc-df2b-484b-96d7-32dd9adea922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877820192-172.17.0.14-1595829665681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-6ef29090-5be5-4581-9e55-308199aee322,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-dd589580-8aa3-4532-a61a-b220868ca11f,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-6c576023-8783-4bb6-a133-19ab57a28cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-a7b20301-a24c-4aa5-8f74-89269d7e02f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a7678ce8-1066-4a08-95da-1d2b6b40e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-84577e51-32b2-40c4-819e-c5ec5b98d980,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-ebc5c086-3488-40d7-b607-5f48c7be2eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-8b65f188-f628-4242-85ae-94ab21e31483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877820192-172.17.0.14-1595829665681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-6ef29090-5be5-4581-9e55-308199aee322,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-dd589580-8aa3-4532-a61a-b220868ca11f,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-6c576023-8783-4bb6-a133-19ab57a28cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-a7b20301-a24c-4aa5-8f74-89269d7e02f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a7678ce8-1066-4a08-95da-1d2b6b40e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-84577e51-32b2-40c4-819e-c5ec5b98d980,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-ebc5c086-3488-40d7-b607-5f48c7be2eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-8b65f188-f628-4242-85ae-94ab21e31483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929141388-172.17.0.14-1595829780672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-00601611-e157-473a-874b-ebfb7f0a4860,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-445c7ad6-10d5-4e93-bd83-8facaa887f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-266fe3dd-dc92-4a07-840f-81fa0af3da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-cebfb78d-a26e-48f4-8051-99d22a6d21f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-b639d8e5-25d9-463a-9191-ddf3be40ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-48a2f1f2-7d00-4eab-ad51-720df362c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-59a71691-0f0e-4883-9fd2-7ac3a0dcbee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-30972d38-7d2a-42bc-85e7-4fee16d9d1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929141388-172.17.0.14-1595829780672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-00601611-e157-473a-874b-ebfb7f0a4860,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-445c7ad6-10d5-4e93-bd83-8facaa887f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-266fe3dd-dc92-4a07-840f-81fa0af3da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-cebfb78d-a26e-48f4-8051-99d22a6d21f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-b639d8e5-25d9-463a-9191-ddf3be40ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-48a2f1f2-7d00-4eab-ad51-720df362c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-59a71691-0f0e-4883-9fd2-7ac3a0dcbee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-30972d38-7d2a-42bc-85e7-4fee16d9d1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395983216-172.17.0.14-1595829862061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-22659176-0da1-42be-b2bd-3b07eb82ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-81b4b767-fdcf-418c-b53b-b2958d877442,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-fef7d9c4-871f-4c4b-a698-68413b4af064,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-67b25e77-eff5-4480-b297-018d2d7348e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-13dc2a0a-f8c3-4889-9258-f17506960578,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-851d6277-a279-4fe4-a4bb-dde726859de2,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-9c3104c9-a048-4cb8-9061-c391a22d0df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-5b7d991e-957e-4c52-a8e0-53f0d45c917c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395983216-172.17.0.14-1595829862061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-22659176-0da1-42be-b2bd-3b07eb82ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-81b4b767-fdcf-418c-b53b-b2958d877442,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-fef7d9c4-871f-4c4b-a698-68413b4af064,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-67b25e77-eff5-4480-b297-018d2d7348e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-13dc2a0a-f8c3-4889-9258-f17506960578,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-851d6277-a279-4fe4-a4bb-dde726859de2,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-9c3104c9-a048-4cb8-9061-c391a22d0df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-5b7d991e-957e-4c52-a8e0-53f0d45c917c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529109004-172.17.0.14-1595830194375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42997,DS-a59929d5-cef6-42c3-b447-e064308e993f,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-1d3974c7-f2b8-486f-9857-06b24354ad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-180782be-c6b6-44e8-8c88-816c737d0510,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-e0e0bac2-ca9d-4305-a68a-292daeb2b869,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-ce6dd49d-21d4-4d58-aca8-eb4ce10d5315,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-cd95ab2a-8024-4149-babb-edd861959f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-a51b3372-617d-4cd0-b0d9-aaf36c81a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-5efeb4b4-eda2-4bf6-ba99-bc2916eee2c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529109004-172.17.0.14-1595830194375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42997,DS-a59929d5-cef6-42c3-b447-e064308e993f,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-1d3974c7-f2b8-486f-9857-06b24354ad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-180782be-c6b6-44e8-8c88-816c737d0510,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-e0e0bac2-ca9d-4305-a68a-292daeb2b869,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-ce6dd49d-21d4-4d58-aca8-eb4ce10d5315,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-cd95ab2a-8024-4149-babb-edd861959f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-a51b3372-617d-4cd0-b0d9-aaf36c81a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-5efeb4b4-eda2-4bf6-ba99-bc2916eee2c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710899564-172.17.0.14-1595830272753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39642,DS-c1289d32-71d8-4895-bb4f-ee921650aa99,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-bbc1c489-a678-438e-ae9d-5f6f57a79216,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-1f9ea9bf-faa4-4bbc-a00a-1f3be3ed5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-0797c6b0-bdfd-4fe4-8774-f4f07073bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-3b767b05-1b60-4fc8-878b-9aaf67a6b4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-356ff1ac-bfe9-47ab-a047-5e3f57a4d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-58b01edd-6974-4172-9a1b-bdb80631eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-d0a95d7d-5e2c-4f44-b426-b38f6f6ad94b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710899564-172.17.0.14-1595830272753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39642,DS-c1289d32-71d8-4895-bb4f-ee921650aa99,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-bbc1c489-a678-438e-ae9d-5f6f57a79216,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-1f9ea9bf-faa4-4bbc-a00a-1f3be3ed5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-0797c6b0-bdfd-4fe4-8774-f4f07073bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-3b767b05-1b60-4fc8-878b-9aaf67a6b4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-356ff1ac-bfe9-47ab-a047-5e3f57a4d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-58b01edd-6974-4172-9a1b-bdb80631eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-d0a95d7d-5e2c-4f44-b426-b38f6f6ad94b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177810107-172.17.0.14-1595830314077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38621,DS-a9ab2d35-9505-43d8-a15d-0fe0f805dd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-141f83d4-fc83-496e-891c-1b1e72f4ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-d97e528b-56ce-4fb3-86f0-f5d99c3e1224,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-3d01570d-8952-45e3-8e4c-427e5956c1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-72bce7a8-d23a-4f89-90f0-87e3a1d8022f,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-cff813a1-1783-4690-ba27-3a1b802864b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-bb4626f4-f104-482f-8462-87158c29e7da,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-c827e3e1-d29d-49d1-b2a6-2e357f14b79f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177810107-172.17.0.14-1595830314077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38621,DS-a9ab2d35-9505-43d8-a15d-0fe0f805dd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-141f83d4-fc83-496e-891c-1b1e72f4ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-d97e528b-56ce-4fb3-86f0-f5d99c3e1224,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-3d01570d-8952-45e3-8e4c-427e5956c1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-72bce7a8-d23a-4f89-90f0-87e3a1d8022f,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-cff813a1-1783-4690-ba27-3a1b802864b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-bb4626f4-f104-482f-8462-87158c29e7da,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-c827e3e1-d29d-49d1-b2a6-2e357f14b79f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558256317-172.17.0.14-1595830383636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-53545198-c2e6-4a5c-ad9c-260772e2d9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-c07f8d49-7ef8-44b4-97f9-97294e6d9c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-bda503f0-4ab4-4057-b75c-415674b08e83,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-c565c774-82ad-4380-92dc-450095f19ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-9f1fe0fc-f84c-447a-8969-f30359b53e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-ca1f4c13-0982-4363-97d0-4782e49ffaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-e6695c8d-376a-480c-b4ce-012f8164ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-c29cd0f3-43bc-4dd9-b827-eb3ae4a3381a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558256317-172.17.0.14-1595830383636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-53545198-c2e6-4a5c-ad9c-260772e2d9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-c07f8d49-7ef8-44b4-97f9-97294e6d9c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-bda503f0-4ab4-4057-b75c-415674b08e83,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-c565c774-82ad-4380-92dc-450095f19ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-9f1fe0fc-f84c-447a-8969-f30359b53e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-ca1f4c13-0982-4363-97d0-4782e49ffaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-e6695c8d-376a-480c-b4ce-012f8164ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-c29cd0f3-43bc-4dd9-b827-eb3ae4a3381a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410770917-172.17.0.14-1595830524376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-eedc93d2-fb10-41eb-b75a-d883324b1c19,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-54f215ce-b4e8-4e78-946e-659667eacd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-39288460-59a0-481b-857a-2a841465d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-d190b8de-28fd-4487-b1e6-b3f30be4f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-7f90ec01-16cc-4ed3-beca-c7fb31f28166,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-b57ce85c-df8f-4377-adc9-c3628d9a8549,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-0f8063f0-4627-4efd-b138-42aca59b015f,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-b17e2a34-682e-4e6e-8fb0-1f164eafc706,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410770917-172.17.0.14-1595830524376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-eedc93d2-fb10-41eb-b75a-d883324b1c19,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-54f215ce-b4e8-4e78-946e-659667eacd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-39288460-59a0-481b-857a-2a841465d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-d190b8de-28fd-4487-b1e6-b3f30be4f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-7f90ec01-16cc-4ed3-beca-c7fb31f28166,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-b57ce85c-df8f-4377-adc9-c3628d9a8549,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-0f8063f0-4627-4efd-b138-42aca59b015f,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-b17e2a34-682e-4e6e-8fb0-1f164eafc706,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482825131-172.17.0.14-1595830666190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35262,DS-4ac62395-329c-4505-ae03-210619f95dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-9e52f61d-2c96-4631-bf29-5bd1e22b215d,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-4e600e51-e5db-448d-a506-39e8176bc0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-19ce7cf1-3b24-4f23-b090-ff9056195db6,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-cffec70a-917e-414a-8f3b-edeed2ffe397,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-13275318-b4d1-402e-99ef-bc4934b89211,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-d4b3690f-35bf-40f0-b133-8a9a52b25fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-dce0d6c9-aaea-4fca-98a5-7a99b7c98798,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482825131-172.17.0.14-1595830666190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35262,DS-4ac62395-329c-4505-ae03-210619f95dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-9e52f61d-2c96-4631-bf29-5bd1e22b215d,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-4e600e51-e5db-448d-a506-39e8176bc0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-19ce7cf1-3b24-4f23-b090-ff9056195db6,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-cffec70a-917e-414a-8f3b-edeed2ffe397,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-13275318-b4d1-402e-99ef-bc4934b89211,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-d4b3690f-35bf-40f0-b133-8a9a52b25fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-dce0d6c9-aaea-4fca-98a5-7a99b7c98798,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005613310-172.17.0.14-1595830804311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42199,DS-96c4cc8f-ad32-4602-84a5-adcfece35de4,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-fce6abac-b550-49ad-bf31-6b514925c069,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-385b8643-a357-43de-83bf-6e5688c10d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-84fffe9a-d9c5-4e0f-aa3c-a20224930e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-81e3d0b8-c98a-47e7-80f6-24b105422497,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-34a80142-f95c-423f-a614-cfa3a9a769ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-4c848f9b-3809-42ae-9f4e-e26c9cd53955,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-4cccaafe-86cd-4b1f-9a4c-48f5fd111329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005613310-172.17.0.14-1595830804311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42199,DS-96c4cc8f-ad32-4602-84a5-adcfece35de4,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-fce6abac-b550-49ad-bf31-6b514925c069,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-385b8643-a357-43de-83bf-6e5688c10d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-84fffe9a-d9c5-4e0f-aa3c-a20224930e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-81e3d0b8-c98a-47e7-80f6-24b105422497,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-34a80142-f95c-423f-a614-cfa3a9a769ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-4c848f9b-3809-42ae-9f4e-e26c9cd53955,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-4cccaafe-86cd-4b1f-9a4c-48f5fd111329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344306232-172.17.0.14-1595830873735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-56d7ec78-e207-47d2-b266-e1d0ecbe28c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-d422926d-4290-45d4-b481-d3ec14cc0191,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-20bbda36-832d-402b-9e8b-615a724f4901,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-35a52c40-b07b-49eb-bc7e-b01c2b8850fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-e7f945ac-2cb3-488f-b6ce-bd47980f0986,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-50aae477-15b7-4085-b85a-14b6b08c3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-7c404b2d-8062-4aac-be10-a5eacab6ffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-1685d8af-b7f9-40b9-8c0f-37fee2570c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344306232-172.17.0.14-1595830873735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-56d7ec78-e207-47d2-b266-e1d0ecbe28c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-d422926d-4290-45d4-b481-d3ec14cc0191,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-20bbda36-832d-402b-9e8b-615a724f4901,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-35a52c40-b07b-49eb-bc7e-b01c2b8850fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-e7f945ac-2cb3-488f-b6ce-bd47980f0986,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-50aae477-15b7-4085-b85a-14b6b08c3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-7c404b2d-8062-4aac-be10-a5eacab6ffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-1685d8af-b7f9-40b9-8c0f-37fee2570c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896993389-172.17.0.14-1595830985995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33281,DS-aad571fb-b32b-4193-8e2f-b2eed07f4872,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-39c3edaf-4c0a-410e-bacb-e9bdd3fd856c,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-20fec52b-b555-47af-ae42-d586ffb7b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-cac197fc-a962-487f-a681-fa27bba08b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-d48018c6-5f1a-405f-a2b9-b29d2f425fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-78cda36c-5a21-4d87-8e8a-576d0e7bc532,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-7e75aa89-55c7-450f-92d5-8f75f49dfd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-8537c044-f579-4d4c-95fd-9169e2f04418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896993389-172.17.0.14-1595830985995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33281,DS-aad571fb-b32b-4193-8e2f-b2eed07f4872,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-39c3edaf-4c0a-410e-bacb-e9bdd3fd856c,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-20fec52b-b555-47af-ae42-d586ffb7b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-cac197fc-a962-487f-a681-fa27bba08b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-d48018c6-5f1a-405f-a2b9-b29d2f425fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-78cda36c-5a21-4d87-8e8a-576d0e7bc532,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-7e75aa89-55c7-450f-92d5-8f75f49dfd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-8537c044-f579-4d4c-95fd-9169e2f04418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053563067-172.17.0.14-1595831088899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-d3a63546-4885-4f12-909a-e321b3336411,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-3874877d-2eda-44d3-a46d-96a9efd22128,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-edc63920-c177-48a6-bdca-28368e77f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-67194bd5-52eb-4632-992a-bf9b34ba9028,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-a66dfcf1-a82c-48b0-aa28-815ccee1ac62,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-92149269-4d02-4ce4-ba56-5d1773536f11,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-3f1772a4-f59e-4337-bc3f-1d52a390e187,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-3cea1eee-2e48-4e46-8677-0131e73c5dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053563067-172.17.0.14-1595831088899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-d3a63546-4885-4f12-909a-e321b3336411,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-3874877d-2eda-44d3-a46d-96a9efd22128,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-edc63920-c177-48a6-bdca-28368e77f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-67194bd5-52eb-4632-992a-bf9b34ba9028,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-a66dfcf1-a82c-48b0-aa28-815ccee1ac62,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-92149269-4d02-4ce4-ba56-5d1773536f11,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-3f1772a4-f59e-4337-bc3f-1d52a390e187,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-3cea1eee-2e48-4e46-8677-0131e73c5dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005357612-172.17.0.14-1595831168129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-278b49a9-65b6-42e8-ad50-e1d4459e28ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-642441a6-c429-4909-9eff-eb306225702c,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-2085cbbd-c884-4c3f-a631-2ce39ccf50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-78fde11c-a537-4020-a993-6e5c102858c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-9581735e-497e-44fc-812f-21bd5d1fa479,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-01eeca19-12c6-44e1-84db-7e95815e830b,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-56b6f161-f4b0-48fa-acbd-6051ed23d78d,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-c924bca8-5248-4cd8-8c0f-c2e250f9e10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005357612-172.17.0.14-1595831168129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-278b49a9-65b6-42e8-ad50-e1d4459e28ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-642441a6-c429-4909-9eff-eb306225702c,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-2085cbbd-c884-4c3f-a631-2ce39ccf50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-78fde11c-a537-4020-a993-6e5c102858c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-9581735e-497e-44fc-812f-21bd5d1fa479,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-01eeca19-12c6-44e1-84db-7e95815e830b,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-56b6f161-f4b0-48fa-acbd-6051ed23d78d,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-c924bca8-5248-4cd8-8c0f-c2e250f9e10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625262367-172.17.0.14-1595831242603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38099,DS-9d35036a-2ab3-4107-91d5-408aa99d686c,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-694d678e-9675-42fe-9eee-4ebb38ce3ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-6c3f4837-8371-4e4a-a0d1-93d3d319d284,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-5842d7f1-eab9-4a03-ba22-44c4de0864f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-181a95bc-0657-45f2-bac3-d5ad2900c552,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-05e1f64b-c385-4eba-80bc-1a644c3588f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-d465b8c0-cc1d-48fe-a000-c58ac1f65fec,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-ca58fa76-9cea-419a-9d72-8387b9e67304,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625262367-172.17.0.14-1595831242603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38099,DS-9d35036a-2ab3-4107-91d5-408aa99d686c,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-694d678e-9675-42fe-9eee-4ebb38ce3ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-6c3f4837-8371-4e4a-a0d1-93d3d319d284,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-5842d7f1-eab9-4a03-ba22-44c4de0864f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-181a95bc-0657-45f2-bac3-d5ad2900c552,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-05e1f64b-c385-4eba-80bc-1a644c3588f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-d465b8c0-cc1d-48fe-a000-c58ac1f65fec,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-ca58fa76-9cea-419a-9d72-8387b9e67304,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629551752-172.17.0.14-1595831407747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35790,DS-6a636192-da82-472d-9fb0-32991df2e1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-c7eabcec-862d-4cd0-9e9f-397eae57e477,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-0841a77b-dc4a-4284-87f9-f6d08ebc7472,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-377b95e7-935e-485a-be6a-dca4ec62668b,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-5a5d6287-b13a-4761-b3b0-4851223cb566,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-a5156184-723a-4bd6-baca-578b8621bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-bf37d88c-5f1e-4fdb-95ca-78b98201eb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-8b2ccadf-b49e-49ab-b20f-0111b132fbd3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629551752-172.17.0.14-1595831407747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35790,DS-6a636192-da82-472d-9fb0-32991df2e1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-c7eabcec-862d-4cd0-9e9f-397eae57e477,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-0841a77b-dc4a-4284-87f9-f6d08ebc7472,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-377b95e7-935e-485a-be6a-dca4ec62668b,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-5a5d6287-b13a-4761-b3b0-4851223cb566,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-a5156184-723a-4bd6-baca-578b8621bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-bf37d88c-5f1e-4fdb-95ca-78b98201eb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-8b2ccadf-b49e-49ab-b20f-0111b132fbd3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781064476-172.17.0.14-1595831580988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46291,DS-73bc4408-0bb5-45dd-90ea-d846cadc6bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-82f85d70-00b6-41b2-be5d-3dfce747d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-5f1be8d2-3370-4fa4-bca2-e5723aa74470,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-bae76e30-d728-4c76-a9c1-97b31c93476e,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-d9fe4e1f-74da-4282-ab17-cdda8ab3938d,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-2b970c2f-d786-44d7-b0a1-5cb06210f59b,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-70696ac1-f5a2-48c5-bd8a-d8c87231a8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-dfd6b58f-43e4-4ea4-8163-19152ae4165a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781064476-172.17.0.14-1595831580988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46291,DS-73bc4408-0bb5-45dd-90ea-d846cadc6bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-82f85d70-00b6-41b2-be5d-3dfce747d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-5f1be8d2-3370-4fa4-bca2-e5723aa74470,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-bae76e30-d728-4c76-a9c1-97b31c93476e,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-d9fe4e1f-74da-4282-ab17-cdda8ab3938d,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-2b970c2f-d786-44d7-b0a1-5cb06210f59b,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-70696ac1-f5a2-48c5-bd8a-d8c87231a8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-dfd6b58f-43e4-4ea4-8163-19152ae4165a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098447463-172.17.0.14-1595832414789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-29544cc8-d214-4458-9465-81441ae799f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-9c9db437-2647-4029-9c90-f18b569eff40,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-f1d44126-8907-4a7d-b914-dc8eb99cebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-3e617bd4-d09f-4faa-9fd4-5c25fc469f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-2fddfd13-ce97-49b4-a2ef-4b2f4a837db7,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-8c78f9a5-0b5f-48a6-ac73-c50fa1e978ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-62eed363-cac9-4325-80b5-e936e232681b,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-2fb07781-fa97-48e2-a090-8a30674b7c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098447463-172.17.0.14-1595832414789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-29544cc8-d214-4458-9465-81441ae799f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-9c9db437-2647-4029-9c90-f18b569eff40,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-f1d44126-8907-4a7d-b914-dc8eb99cebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-3e617bd4-d09f-4faa-9fd4-5c25fc469f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-2fddfd13-ce97-49b4-a2ef-4b2f4a837db7,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-8c78f9a5-0b5f-48a6-ac73-c50fa1e978ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-62eed363-cac9-4325-80b5-e936e232681b,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-2fb07781-fa97-48e2-a090-8a30674b7c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289820689-172.17.0.14-1595832455687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33057,DS-9e3d92f1-691d-492a-82c8-d18d87ba0d32,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-771a4540-2e48-4207-a5ae-c3a5678a37ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-ff67c091-cb37-4d9c-8c75-c5424e91e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-7bdbf721-bebe-4aa1-9873-21fc3dc9677f,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-94a541c9-0c93-4df1-93c3-8e9cf280df7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-2b3d27aa-0cc9-4b96-ad12-7c3220a789b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-d3f826c3-6f58-49f3-9d4d-3c00efe08bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-d942ef94-0438-4ba0-ab04-37a23acdf165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289820689-172.17.0.14-1595832455687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33057,DS-9e3d92f1-691d-492a-82c8-d18d87ba0d32,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-771a4540-2e48-4207-a5ae-c3a5678a37ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-ff67c091-cb37-4d9c-8c75-c5424e91e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-7bdbf721-bebe-4aa1-9873-21fc3dc9677f,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-94a541c9-0c93-4df1-93c3-8e9cf280df7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-2b3d27aa-0cc9-4b96-ad12-7c3220a789b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-d3f826c3-6f58-49f3-9d4d-3c00efe08bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-d942ef94-0438-4ba0-ab04-37a23acdf165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997061944-172.17.0.14-1595832741892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38190,DS-bad01b70-46b7-4056-83ce-5a91186eb7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-a28c3dbb-1b96-44c6-88fd-597c70741e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-7184dd29-e8ba-49cc-8c29-a0c018fa1392,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-2e4e0823-e7cc-43a4-8a07-f5d8a7cf30f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-c9e1afd7-e3b1-474d-b3f3-6ac089861343,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-9036dbfb-74b5-4421-adba-a5345e129d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-d13ac274-44e5-43ba-a999-38cae44b33fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-f2cbe618-a944-4b6d-aba1-bdd60dbf3a21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997061944-172.17.0.14-1595832741892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38190,DS-bad01b70-46b7-4056-83ce-5a91186eb7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-a28c3dbb-1b96-44c6-88fd-597c70741e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-7184dd29-e8ba-49cc-8c29-a0c018fa1392,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-2e4e0823-e7cc-43a4-8a07-f5d8a7cf30f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-c9e1afd7-e3b1-474d-b3f3-6ac089861343,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-9036dbfb-74b5-4421-adba-a5345e129d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-d13ac274-44e5-43ba-a999-38cae44b33fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-f2cbe618-a944-4b6d-aba1-bdd60dbf3a21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395876018-172.17.0.14-1595833161445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42409,DS-3e044a61-72aa-441f-8ac3-8e402f433ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-9a075315-8aed-42e3-ab11-9920e1ad38b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-45cd850f-500d-47bd-b282-3c9d7b145a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-98aac772-3f77-428a-bd63-1921cbbf3caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-2886182e-a19f-43bf-9169-15ba1dc4a479,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-09dd01cc-0b76-4560-b63e-3e6b195888d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-e67a7fd5-7600-48fb-bcfe-f41af0789db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-8e312a86-d156-4961-9116-658e84a6fe8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395876018-172.17.0.14-1595833161445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42409,DS-3e044a61-72aa-441f-8ac3-8e402f433ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-9a075315-8aed-42e3-ab11-9920e1ad38b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-45cd850f-500d-47bd-b282-3c9d7b145a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-98aac772-3f77-428a-bd63-1921cbbf3caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-2886182e-a19f-43bf-9169-15ba1dc4a479,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-09dd01cc-0b76-4560-b63e-3e6b195888d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-e67a7fd5-7600-48fb-bcfe-f41af0789db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-8e312a86-d156-4961-9116-658e84a6fe8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013920170-172.17.0.14-1595833196779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-522285be-2be5-4d73-94b5-701556492fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-1308a746-b5cc-4759-a3b4-9e9f74d143da,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-bb37a29a-8ec1-414c-a063-6e50ef2b8dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-0c12c1d5-7ced-44fb-b7d2-3d98f1092349,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-1970ccf5-16c8-4c74-8826-d2199a663662,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-495ca44e-e1be-44b0-a5bb-39a43b990757,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-23f66cfe-9010-4038-b222-9af53a7e882f,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-576944d9-21e1-4147-81ff-51adb887979e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013920170-172.17.0.14-1595833196779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-522285be-2be5-4d73-94b5-701556492fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-1308a746-b5cc-4759-a3b4-9e9f74d143da,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-bb37a29a-8ec1-414c-a063-6e50ef2b8dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-0c12c1d5-7ced-44fb-b7d2-3d98f1092349,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-1970ccf5-16c8-4c74-8826-d2199a663662,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-495ca44e-e1be-44b0-a5bb-39a43b990757,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-23f66cfe-9010-4038-b222-9af53a7e882f,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-576944d9-21e1-4147-81ff-51adb887979e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289161537-172.17.0.14-1595833311017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43569,DS-738176c2-16bb-48ef-a5cf-6a96b83d1ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-8e260339-57be-4cd3-b282-d8387f5fa806,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-69ec5da1-36b7-47df-844f-65ead8b3395f,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-54b21f43-83da-41c3-a821-c34b0deabf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-6cb21f67-d6d1-427e-bfda-f8d3e35c6d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-e996aa6b-c1fc-436d-8529-8a29cf509089,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-adb6b011-6062-424e-a7f0-a90a5ba643df,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-3b71eefc-be2a-4521-81f3-b7f0eb5fb3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289161537-172.17.0.14-1595833311017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43569,DS-738176c2-16bb-48ef-a5cf-6a96b83d1ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-8e260339-57be-4cd3-b282-d8387f5fa806,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-69ec5da1-36b7-47df-844f-65ead8b3395f,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-54b21f43-83da-41c3-a821-c34b0deabf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-6cb21f67-d6d1-427e-bfda-f8d3e35c6d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-e996aa6b-c1fc-436d-8529-8a29cf509089,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-adb6b011-6062-424e-a7f0-a90a5ba643df,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-3b71eefc-be2a-4521-81f3-b7f0eb5fb3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071623132-172.17.0.14-1595833354329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-3fa0313a-b116-4a15-9895-776be5581403,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-8e654af0-1f3a-4a46-8313-3c50d3c15b36,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-b76b5263-b63e-41e5-8acc-9248a0dd0c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-90c81c22-1768-469a-882a-8dce7dea6207,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-cef63caf-0eae-4ca6-85b9-44187312b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-7fb0f08e-5ad2-411d-8677-fe9dc626ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-266633a3-2377-4387-bf39-2e97a916012f,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-c7d06433-09df-4675-a1e4-42232f8b68c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071623132-172.17.0.14-1595833354329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-3fa0313a-b116-4a15-9895-776be5581403,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-8e654af0-1f3a-4a46-8313-3c50d3c15b36,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-b76b5263-b63e-41e5-8acc-9248a0dd0c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-90c81c22-1768-469a-882a-8dce7dea6207,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-cef63caf-0eae-4ca6-85b9-44187312b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-7fb0f08e-5ad2-411d-8677-fe9dc626ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-266633a3-2377-4387-bf39-2e97a916012f,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-c7d06433-09df-4675-a1e4-42232f8b68c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919712662-172.17.0.14-1595833665427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46717,DS-8d9f4db6-55ea-4f53-8b1c-ee076a89e466,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-00f32c8a-a478-498e-b39a-a386570effdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-ea915e22-a874-4481-9a46-3ccb3833a09f,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-700882cf-26a0-4106-ad72-4696bf8b7e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-c899e957-a82e-457c-a321-55ca91cdce38,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-9b5fdc87-b1ea-4ce5-a0fa-7a01940702c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-07e6a17a-506d-4bea-901e-9ae3e244a284,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-1c5ff912-6e50-4ee7-b849-da3feafd3d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919712662-172.17.0.14-1595833665427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46717,DS-8d9f4db6-55ea-4f53-8b1c-ee076a89e466,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-00f32c8a-a478-498e-b39a-a386570effdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-ea915e22-a874-4481-9a46-3ccb3833a09f,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-700882cf-26a0-4106-ad72-4696bf8b7e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-c899e957-a82e-457c-a321-55ca91cdce38,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-9b5fdc87-b1ea-4ce5-a0fa-7a01940702c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-07e6a17a-506d-4bea-901e-9ae3e244a284,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-1c5ff912-6e50-4ee7-b849-da3feafd3d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5519
