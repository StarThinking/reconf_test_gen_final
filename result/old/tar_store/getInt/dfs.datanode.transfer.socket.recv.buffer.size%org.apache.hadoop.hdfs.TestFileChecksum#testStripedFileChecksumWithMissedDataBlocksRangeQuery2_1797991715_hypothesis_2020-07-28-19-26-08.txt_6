reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047420016-172.17.0.19-1595964423970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40827,DS-7d1b9413-efce-42ca-ae18-019a7d8b9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-378e759b-c306-4861-ac7b-d79c213f0c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-343d97f1-ad05-4f32-87d4-e32c333a21d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-280e40da-8652-4bc4-8a16-6b4561c84217,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-a79c0f07-0a7b-4174-8e88-2bdf5a0aa1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-78d1f830-bedb-4401-8575-c26ac3b33a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-8aa423b4-24ff-49ff-8567-5bfb5886bdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-815bc927-8c94-43cb-aea7-8f09cdb0b936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047420016-172.17.0.19-1595964423970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40827,DS-7d1b9413-efce-42ca-ae18-019a7d8b9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-378e759b-c306-4861-ac7b-d79c213f0c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-343d97f1-ad05-4f32-87d4-e32c333a21d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-280e40da-8652-4bc4-8a16-6b4561c84217,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-a79c0f07-0a7b-4174-8e88-2bdf5a0aa1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-78d1f830-bedb-4401-8575-c26ac3b33a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-8aa423b4-24ff-49ff-8567-5bfb5886bdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-815bc927-8c94-43cb-aea7-8f09cdb0b936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218285278-172.17.0.19-1595965609045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-8533def5-549b-4e58-8ba7-86c23e99e830,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-0ffb865e-1dbf-45f5-b183-f64cdb415047,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-18a03a75-8c09-4c36-a5b8-33b79a610c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-d49e2786-00f0-4925-9fc5-c816e4635fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-81422c4f-e237-4353-8408-4c9ac22a9e35,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-47105bb3-b4ab-4db8-89e8-a63cd865dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-f03e8c1a-e7ee-43e6-992f-09bd8ecf7420,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-7010f3d6-c7f9-442a-a321-0ad760728030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218285278-172.17.0.19-1595965609045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-8533def5-549b-4e58-8ba7-86c23e99e830,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-0ffb865e-1dbf-45f5-b183-f64cdb415047,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-18a03a75-8c09-4c36-a5b8-33b79a610c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-d49e2786-00f0-4925-9fc5-c816e4635fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-81422c4f-e237-4353-8408-4c9ac22a9e35,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-47105bb3-b4ab-4db8-89e8-a63cd865dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-f03e8c1a-e7ee-43e6-992f-09bd8ecf7420,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-7010f3d6-c7f9-442a-a321-0ad760728030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730137525-172.17.0.19-1595966268056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-b2eea900-be59-4fcb-89a6-177b671bcfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-90cb62ac-5239-4b4c-8b0f-241d306bdbad,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-94fccdfc-70c5-457a-a01c-9c64f5ca1e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-ddc0a316-322b-42af-a99f-ee7bf53aef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-2c7733e7-fc71-4997-bada-2edb68da826e,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-d2adb6fc-8045-49fc-a5e3-d13b6dea40b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-d2e61868-40c6-47ca-82eb-7a6c962be15b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-5739c7aa-5667-43d4-b876-a72cc083f052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730137525-172.17.0.19-1595966268056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-b2eea900-be59-4fcb-89a6-177b671bcfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-90cb62ac-5239-4b4c-8b0f-241d306bdbad,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-94fccdfc-70c5-457a-a01c-9c64f5ca1e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-ddc0a316-322b-42af-a99f-ee7bf53aef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-2c7733e7-fc71-4997-bada-2edb68da826e,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-d2adb6fc-8045-49fc-a5e3-d13b6dea40b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-d2e61868-40c6-47ca-82eb-7a6c962be15b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-5739c7aa-5667-43d4-b876-a72cc083f052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043551500-172.17.0.19-1595966470528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-f1947ee5-1fd2-4f25-97de-08d4558ffee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-31861227-23e0-46f4-a034-3e49e3dfea73,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-690756ba-3727-4aff-94cb-382fc33ba486,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-4ba7d0c9-f7c7-4ad6-96ab-c714c71c3023,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-28e9846f-393d-485e-a240-39a54a0d0789,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-3db1c684-72b0-418c-9ca5-8a4441562c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-4c20bd8e-b2cc-462f-a354-4810557f501d,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-d2923618-7829-4be5-8ed9-97b931e2f45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043551500-172.17.0.19-1595966470528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-f1947ee5-1fd2-4f25-97de-08d4558ffee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-31861227-23e0-46f4-a034-3e49e3dfea73,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-690756ba-3727-4aff-94cb-382fc33ba486,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-4ba7d0c9-f7c7-4ad6-96ab-c714c71c3023,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-28e9846f-393d-485e-a240-39a54a0d0789,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-3db1c684-72b0-418c-9ca5-8a4441562c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-4c20bd8e-b2cc-462f-a354-4810557f501d,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-d2923618-7829-4be5-8ed9-97b931e2f45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022465427-172.17.0.19-1595966661565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-5542650d-0ca3-408b-a9e7-963a6b325e41,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-bb48c7c9-5015-4152-953a-45a782e10d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-43d93bbf-581d-4bb4-b98f-77e551eb2d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-6dddaaec-445d-4d46-b2db-397b9c15ce63,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-fb0c3caa-7542-4da9-a2e6-3b51b4d6498f,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-dde71261-dc90-4a74-a83d-8284668d8278,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-0fdf99a9-44e4-43c0-9b6b-89c423952a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-e863d040-175c-4ea3-a634-dd4f9ff6d9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022465427-172.17.0.19-1595966661565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-5542650d-0ca3-408b-a9e7-963a6b325e41,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-bb48c7c9-5015-4152-953a-45a782e10d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-43d93bbf-581d-4bb4-b98f-77e551eb2d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-6dddaaec-445d-4d46-b2db-397b9c15ce63,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-fb0c3caa-7542-4da9-a2e6-3b51b4d6498f,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-dde71261-dc90-4a74-a83d-8284668d8278,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-0fdf99a9-44e4-43c0-9b6b-89c423952a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-e863d040-175c-4ea3-a634-dd4f9ff6d9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458865793-172.17.0.19-1595967148122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-bbdf59d0-0a74-4be8-ab0b-741841231bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-cbc076d4-9f77-41ff-a536-9de3bf9ca5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-033e9eb9-964e-4297-8784-7e0f53b39113,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-aa4c529b-e715-43a8-9463-940c355a8589,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-83871ea4-4d7c-480b-94ae-51ef1dc02650,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-f0c57efc-adee-4d41-8843-3026a00a8c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-e37c5fb4-6fb8-48dc-a854-4ace2913ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-935b1e6e-7137-4bf0-9d5c-1249c61c6157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458865793-172.17.0.19-1595967148122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-bbdf59d0-0a74-4be8-ab0b-741841231bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-cbc076d4-9f77-41ff-a536-9de3bf9ca5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-033e9eb9-964e-4297-8784-7e0f53b39113,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-aa4c529b-e715-43a8-9463-940c355a8589,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-83871ea4-4d7c-480b-94ae-51ef1dc02650,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-f0c57efc-adee-4d41-8843-3026a00a8c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-e37c5fb4-6fb8-48dc-a854-4ace2913ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-935b1e6e-7137-4bf0-9d5c-1249c61c6157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928904511-172.17.0.19-1595967283219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-c693686e-5dac-4b01-98b1-fa6853343c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-46324a06-fad3-4312-9082-aa573def161c,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-2cf83c74-4c8c-453f-a802-f0050b80d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-f95ead0f-5bc7-44e3-a473-9943c7b1687f,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-8fcf8c44-cc0b-4ec3-8009-26b44190830a,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-087127c0-c364-4941-954f-34cd6f801643,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-f341b487-b5d8-442d-9b54-5a7121dd6f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-3d6d8a2e-c3d4-4c3b-9f91-7c382a33742a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928904511-172.17.0.19-1595967283219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-c693686e-5dac-4b01-98b1-fa6853343c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-46324a06-fad3-4312-9082-aa573def161c,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-2cf83c74-4c8c-453f-a802-f0050b80d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-f95ead0f-5bc7-44e3-a473-9943c7b1687f,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-8fcf8c44-cc0b-4ec3-8009-26b44190830a,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-087127c0-c364-4941-954f-34cd6f801643,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-f341b487-b5d8-442d-9b54-5a7121dd6f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-3d6d8a2e-c3d4-4c3b-9f91-7c382a33742a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140929108-172.17.0.19-1595967592199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32829,DS-5e3ffd80-a4d2-4bea-9edc-a95446de0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-68e9b357-51fa-4bea-ba3f-2b9f5fe4154b,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-941f7fe9-c580-4878-8790-a1659b79690c,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-785da6f8-969d-4b92-b908-decd8d59bc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-c6aca1a5-0035-4607-9317-44bedd92b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-37df8be2-ee77-4144-bcf5-d7b2655aa7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-e4a7e535-32fc-423d-968b-cf949fd38698,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-374771d2-b8c2-4d6d-a536-d34cd3e51e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140929108-172.17.0.19-1595967592199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32829,DS-5e3ffd80-a4d2-4bea-9edc-a95446de0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-68e9b357-51fa-4bea-ba3f-2b9f5fe4154b,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-941f7fe9-c580-4878-8790-a1659b79690c,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-785da6f8-969d-4b92-b908-decd8d59bc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-c6aca1a5-0035-4607-9317-44bedd92b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-37df8be2-ee77-4144-bcf5-d7b2655aa7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-e4a7e535-32fc-423d-968b-cf949fd38698,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-374771d2-b8c2-4d6d-a536-d34cd3e51e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737603132-172.17.0.19-1595967719422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-9bd59724-0913-4ec0-b71a-a217a8ba7a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-41488828-32c5-4a0b-bd09-b7b837329d20,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-02055610-61f4-4d4c-8ce3-249c14a1bbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-83ab08f2-1766-4356-b631-93e9d4380107,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-3473f3ca-4896-4d63-a25f-ae74cbe89c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-cbfb4084-6904-4e5e-ba09-ad10304a2977,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-9766bf86-6d75-4e9e-a0b0-7350c1b91f78,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-8851bc20-1d4f-4527-9476-3699499abe0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737603132-172.17.0.19-1595967719422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-9bd59724-0913-4ec0-b71a-a217a8ba7a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-41488828-32c5-4a0b-bd09-b7b837329d20,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-02055610-61f4-4d4c-8ce3-249c14a1bbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-83ab08f2-1766-4356-b631-93e9d4380107,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-3473f3ca-4896-4d63-a25f-ae74cbe89c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-cbfb4084-6904-4e5e-ba09-ad10304a2977,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-9766bf86-6d75-4e9e-a0b0-7350c1b91f78,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-8851bc20-1d4f-4527-9476-3699499abe0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720888618-172.17.0.19-1595968163855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-db98ba53-8748-4f3c-9105-153eea5e8e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-1e5063ce-2dbf-497d-8ac0-bc188d0f8acc,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-1ef8b457-6313-4695-b2b1-a700bce29d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-a1aca921-a0e1-48a1-b3f9-951938f4c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-1d722a8f-d824-47cf-989a-16e0c7fcbf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-63bede95-2177-4dc2-87e0-38fedd022a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-5967af2b-8000-4e15-b91b-e60671e58c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-5b55bb6e-0962-49ed-a5d9-8439930d6c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720888618-172.17.0.19-1595968163855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-db98ba53-8748-4f3c-9105-153eea5e8e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-1e5063ce-2dbf-497d-8ac0-bc188d0f8acc,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-1ef8b457-6313-4695-b2b1-a700bce29d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-a1aca921-a0e1-48a1-b3f9-951938f4c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-1d722a8f-d824-47cf-989a-16e0c7fcbf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-63bede95-2177-4dc2-87e0-38fedd022a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-5967af2b-8000-4e15-b91b-e60671e58c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-5b55bb6e-0962-49ed-a5d9-8439930d6c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199076651-172.17.0.19-1595968458406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-f7d6b8dd-1caf-40d5-bed0-362d7f892db3,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-be5bb38d-4288-453f-9ed8-cba249623695,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-dd9060e5-7f26-4abc-a67a-f3d537fdcc17,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-34664a5e-c84f-478f-8e2b-c01ea6bcfe41,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-e37da83b-4fe0-410c-80bd-066afe292b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-a4856521-e746-43e7-a8c4-1412da8d0263,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-d1eebfb2-9e34-488e-8771-d78b0639289f,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-f20b968b-a70a-44c2-82ed-210599f2b465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199076651-172.17.0.19-1595968458406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-f7d6b8dd-1caf-40d5-bed0-362d7f892db3,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-be5bb38d-4288-453f-9ed8-cba249623695,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-dd9060e5-7f26-4abc-a67a-f3d537fdcc17,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-34664a5e-c84f-478f-8e2b-c01ea6bcfe41,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-e37da83b-4fe0-410c-80bd-066afe292b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-a4856521-e746-43e7-a8c4-1412da8d0263,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-d1eebfb2-9e34-488e-8771-d78b0639289f,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-f20b968b-a70a-44c2-82ed-210599f2b465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941695040-172.17.0.19-1595968575597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-e450ebc5-3faa-4718-8fb0-37c7d1e0bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-e85ee151-5adc-4472-a759-8e95925ff64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-bf805fac-7e6f-4633-826d-d7f3ea565c59,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-6b14c9fb-4300-483f-97d3-44c6376bafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-04d7f168-0443-462d-9e2b-2c2af9ebc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-22606c56-8b2e-45a1-94d7-050ac0840491,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-52959171-8fcd-46ec-a6ed-bdf36507ab85,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-31d79c36-959c-4d38-9d99-208ee3b4f983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941695040-172.17.0.19-1595968575597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-e450ebc5-3faa-4718-8fb0-37c7d1e0bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-e85ee151-5adc-4472-a759-8e95925ff64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-bf805fac-7e6f-4633-826d-d7f3ea565c59,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-6b14c9fb-4300-483f-97d3-44c6376bafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-04d7f168-0443-462d-9e2b-2c2af9ebc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-22606c56-8b2e-45a1-94d7-050ac0840491,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-52959171-8fcd-46ec-a6ed-bdf36507ab85,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-31d79c36-959c-4d38-9d99-208ee3b4f983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494997010-172.17.0.19-1595968945670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-d3c6578f-c0ce-4d35-9a83-956f3efe018d,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-fbd07561-fd72-48b0-b73b-5044fc32d145,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-86d7017f-fc5b-47a2-ba4b-1bfacb1b3796,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-1d30b5aa-6a52-459a-a381-4312cc19faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-7e4d94b3-6947-4c52-9c4c-5e374095bd73,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-9c9924a9-69ef-418e-a78b-d38baddf3aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-3dc481b2-b4a7-4d95-9743-cff31c88de17,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-2d2e23c8-37c9-46de-8f43-34003c20884e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494997010-172.17.0.19-1595968945670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-d3c6578f-c0ce-4d35-9a83-956f3efe018d,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-fbd07561-fd72-48b0-b73b-5044fc32d145,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-86d7017f-fc5b-47a2-ba4b-1bfacb1b3796,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-1d30b5aa-6a52-459a-a381-4312cc19faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-7e4d94b3-6947-4c52-9c4c-5e374095bd73,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-9c9924a9-69ef-418e-a78b-d38baddf3aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-3dc481b2-b4a7-4d95-9743-cff31c88de17,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-2d2e23c8-37c9-46de-8f43-34003c20884e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581301091-172.17.0.19-1595968984349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-f690de69-2caf-409c-9068-9e828345f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-4b99d968-6809-4ba6-84ee-b39feaff3884,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-1f3013db-4593-4cec-a66a-f5223582ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-5ea82e24-6a71-4db2-a5f0-12549cfaad84,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-4db24b94-6371-4537-b6c1-d8b65c07152a,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-8e511d4a-b52d-45fc-98f2-3b6421fb3e27,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-9d9570aa-f8c3-499d-ae13-525bf33a06c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-c4de1643-812e-4544-9a59-07507bec3cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581301091-172.17.0.19-1595968984349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-f690de69-2caf-409c-9068-9e828345f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-4b99d968-6809-4ba6-84ee-b39feaff3884,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-1f3013db-4593-4cec-a66a-f5223582ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-5ea82e24-6a71-4db2-a5f0-12549cfaad84,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-4db24b94-6371-4537-b6c1-d8b65c07152a,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-8e511d4a-b52d-45fc-98f2-3b6421fb3e27,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-9d9570aa-f8c3-499d-ae13-525bf33a06c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-c4de1643-812e-4544-9a59-07507bec3cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073454966-172.17.0.19-1595969242918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-ba8e5f88-a316-43da-ae00-7e28741a28c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-571d629d-a923-469f-ba72-d84566df7d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-219a96bf-e85f-4904-be35-0bca19cdff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-661c9746-12aa-4f9f-bbeb-f100eced3a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-58fcbf84-bc8c-4778-a396-6c396011781e,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-61a317b5-104d-4f09-b5c0-0001bee9fdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-e6354550-171c-47b1-838a-f68d393f6c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-c0257503-82bc-4804-ba74-24b70c8023d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073454966-172.17.0.19-1595969242918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-ba8e5f88-a316-43da-ae00-7e28741a28c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-571d629d-a923-469f-ba72-d84566df7d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-219a96bf-e85f-4904-be35-0bca19cdff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-661c9746-12aa-4f9f-bbeb-f100eced3a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-58fcbf84-bc8c-4778-a396-6c396011781e,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-61a317b5-104d-4f09-b5c0-0001bee9fdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-e6354550-171c-47b1-838a-f68d393f6c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-c0257503-82bc-4804-ba74-24b70c8023d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956810897-172.17.0.19-1595969288775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40974,DS-1e1a7171-dc35-4ad6-a9bc-cab528ddef55,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-4ccdbf96-e2a8-4776-b4a8-3314bc94b589,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-d9b1f97c-50d2-4552-b0e5-2af6f2a053ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-a00ad089-612f-4b08-99b2-b11da0bb1214,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-321bf968-bf29-43c4-912b-4d5c9e780dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-e8cf2be2-f260-4bf4-ae8a-ccf55fd60204,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-0c6785cb-b74a-4167-bea8-dbf6c08d6bed,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-f855ada6-1820-4490-a182-d7f3542bc5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956810897-172.17.0.19-1595969288775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40974,DS-1e1a7171-dc35-4ad6-a9bc-cab528ddef55,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-4ccdbf96-e2a8-4776-b4a8-3314bc94b589,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-d9b1f97c-50d2-4552-b0e5-2af6f2a053ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-a00ad089-612f-4b08-99b2-b11da0bb1214,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-321bf968-bf29-43c4-912b-4d5c9e780dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-e8cf2be2-f260-4bf4-ae8a-ccf55fd60204,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-0c6785cb-b74a-4167-bea8-dbf6c08d6bed,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-f855ada6-1820-4490-a182-d7f3542bc5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146994266-172.17.0.19-1595969903544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34292,DS-65676bb8-a828-41cb-aa3c-a6dd40d754c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-847e8953-fb3a-4243-9055-59138506066d,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-78a5db17-dfa1-4e4d-ad9a-51a421fb35f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-bb92b222-2fb2-4d8d-bede-f0e2662b776a,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-5b100e89-b3bb-4d22-b044-55074c148c44,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-92b9ca91-7121-43f7-92db-3f1e85046fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-00109f4b-ba8e-4cca-87f5-bdb118f581b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-e819b8d6-4fbd-4c24-8117-a5bfd726219e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146994266-172.17.0.19-1595969903544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34292,DS-65676bb8-a828-41cb-aa3c-a6dd40d754c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-847e8953-fb3a-4243-9055-59138506066d,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-78a5db17-dfa1-4e4d-ad9a-51a421fb35f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-bb92b222-2fb2-4d8d-bede-f0e2662b776a,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-5b100e89-b3bb-4d22-b044-55074c148c44,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-92b9ca91-7121-43f7-92db-3f1e85046fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-00109f4b-ba8e-4cca-87f5-bdb118f581b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-e819b8d6-4fbd-4c24-8117-a5bfd726219e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130910788-172.17.0.19-1595969944771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41034,DS-9076920a-d396-4895-b801-b55b16803ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-b45e1b5a-8750-4830-9f54-81c6edbcce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-a728f796-fc83-4551-a0d8-541976ff52d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-d2ad2cbd-9311-4321-851f-4baec530a8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-1c97a8d0-b99f-456c-89bc-3b5f0c6a8e36,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-2d861a0f-b649-49a2-833d-133d8046a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-4a16337d-dc79-4738-ad90-11d1709e710e,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-e3efa01e-45fe-45b9-8049-ecab862942da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130910788-172.17.0.19-1595969944771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41034,DS-9076920a-d396-4895-b801-b55b16803ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-b45e1b5a-8750-4830-9f54-81c6edbcce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-a728f796-fc83-4551-a0d8-541976ff52d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-d2ad2cbd-9311-4321-851f-4baec530a8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-1c97a8d0-b99f-456c-89bc-3b5f0c6a8e36,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-2d861a0f-b649-49a2-833d-133d8046a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-4a16337d-dc79-4738-ad90-11d1709e710e,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-e3efa01e-45fe-45b9-8049-ecab862942da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652710789-172.17.0.19-1595969988683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38179,DS-c35e25e8-1f4e-40fe-9bdc-0627651155b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-83af5f88-c850-4a11-a075-6ce5fcf57ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-559e879b-1ac8-4d35-93d2-bc2135c0065b,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-302230af-a9d2-4aa1-b9b3-ae14878cc6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-6c037db1-6e57-4aff-b41e-10c1d4ae0098,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-f6343138-8430-4161-80dc-0c48832a8c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-5d2e3f10-8da9-4bf6-84d2-dd60be0da69a,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-a061b89b-738e-4904-8777-5cef126cabff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652710789-172.17.0.19-1595969988683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38179,DS-c35e25e8-1f4e-40fe-9bdc-0627651155b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-83af5f88-c850-4a11-a075-6ce5fcf57ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-559e879b-1ac8-4d35-93d2-bc2135c0065b,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-302230af-a9d2-4aa1-b9b3-ae14878cc6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-6c037db1-6e57-4aff-b41e-10c1d4ae0098,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-f6343138-8430-4161-80dc-0c48832a8c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-5d2e3f10-8da9-4bf6-84d2-dd60be0da69a,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-a061b89b-738e-4904-8777-5cef126cabff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743819071-172.17.0.19-1595970080790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-53177020-a2d9-482b-926e-271f46b9f072,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-8a4c260e-8617-4607-9827-b6e887fef226,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-a1872d14-b01a-4327-9afe-11fdbd4563fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-cff20728-7a6a-4846-b3d2-56503d33ee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-a23f04f9-78db-443a-a799-8ebb4969f3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-762c5a93-114b-4c30-9b7c-5579cc94538d,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5f68ba04-507d-42a3-a4b7-d1c5cb62ece1,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-953e7d47-b783-4070-8750-58d982e28e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743819071-172.17.0.19-1595970080790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-53177020-a2d9-482b-926e-271f46b9f072,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-8a4c260e-8617-4607-9827-b6e887fef226,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-a1872d14-b01a-4327-9afe-11fdbd4563fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-cff20728-7a6a-4846-b3d2-56503d33ee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-a23f04f9-78db-443a-a799-8ebb4969f3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-762c5a93-114b-4c30-9b7c-5579cc94538d,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5f68ba04-507d-42a3-a4b7-d1c5cb62ece1,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-953e7d47-b783-4070-8750-58d982e28e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5894
