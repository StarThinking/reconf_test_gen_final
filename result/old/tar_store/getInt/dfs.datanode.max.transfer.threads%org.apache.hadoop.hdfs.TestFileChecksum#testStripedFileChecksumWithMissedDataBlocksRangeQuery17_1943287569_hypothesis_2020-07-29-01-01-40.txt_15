reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649460675-172.17.0.11-1595984548778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42654,DS-4e2ff4d8-53fd-42b7-b293-dd6220cbd2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-9a7a59e1-b282-42d5-9e98-b7c6541fe50b,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-100dd8b8-77b5-4f7d-a933-7cc6d75e2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-88ab1260-7bca-4844-83e7-684b8481044c,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-7a654309-7391-427e-9a62-d02b76041092,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-672dbca8-d481-4d42-85bc-f7690646111e,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-c183b7c3-9ced-4694-977a-f30bb51ea920,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-f8d29347-1c31-46b6-8003-6fb120583ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649460675-172.17.0.11-1595984548778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42654,DS-4e2ff4d8-53fd-42b7-b293-dd6220cbd2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-9a7a59e1-b282-42d5-9e98-b7c6541fe50b,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-100dd8b8-77b5-4f7d-a933-7cc6d75e2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-88ab1260-7bca-4844-83e7-684b8481044c,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-7a654309-7391-427e-9a62-d02b76041092,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-672dbca8-d481-4d42-85bc-f7690646111e,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-c183b7c3-9ced-4694-977a-f30bb51ea920,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-f8d29347-1c31-46b6-8003-6fb120583ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990572919-172.17.0.11-1595984727277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37141,DS-87e55958-4b19-4a1b-98d0-dbd85a02075f,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-ab00c86b-4c8b-48ce-9fc5-9b9b65d73d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-85c24b39-0116-4ed5-b69b-db2c7a916cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-8cac3413-e1a4-4b34-b1c9-76b8fb574723,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-6c28641b-84e9-406a-9ccf-00e8dc6f371d,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-69614f0c-5ee3-42c9-8881-19ae80be3619,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-c5d98823-6173-4128-8657-eb17568d0798,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-5b4529e4-fecc-402e-a661-c278b14e162c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990572919-172.17.0.11-1595984727277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37141,DS-87e55958-4b19-4a1b-98d0-dbd85a02075f,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-ab00c86b-4c8b-48ce-9fc5-9b9b65d73d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-85c24b39-0116-4ed5-b69b-db2c7a916cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-8cac3413-e1a4-4b34-b1c9-76b8fb574723,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-6c28641b-84e9-406a-9ccf-00e8dc6f371d,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-69614f0c-5ee3-42c9-8881-19ae80be3619,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-c5d98823-6173-4128-8657-eb17568d0798,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-5b4529e4-fecc-402e-a661-c278b14e162c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112788159-172.17.0.11-1595984836361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38271,DS-39523581-4f11-414c-ac38-b37d6c902d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-65fdc9bd-3f93-4a49-9c12-cb49ca0d6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-5a1c5753-8d79-4792-b632-bb7c1837d201,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-318b1ba2-92fa-43e8-b6e6-e4f05ef7380b,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e97a59bb-3e38-4e84-a9f0-d272335a3fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-66360ec2-cc37-4d41-82b9-474e885535a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-fe4bd448-8af4-40ea-a3fe-d5f68c635417,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-25d8d777-a2ca-4942-a8c8-c34ace4b6080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112788159-172.17.0.11-1595984836361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38271,DS-39523581-4f11-414c-ac38-b37d6c902d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-65fdc9bd-3f93-4a49-9c12-cb49ca0d6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-5a1c5753-8d79-4792-b632-bb7c1837d201,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-318b1ba2-92fa-43e8-b6e6-e4f05ef7380b,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e97a59bb-3e38-4e84-a9f0-d272335a3fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-66360ec2-cc37-4d41-82b9-474e885535a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-fe4bd448-8af4-40ea-a3fe-d5f68c635417,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-25d8d777-a2ca-4942-a8c8-c34ace4b6080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142432673-172.17.0.11-1595984871020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-0fc5ed91-6da2-4bcf-b201-eac5e6738e28,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-18b8c9ff-3388-4bda-9415-c5840527da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-76e9d40c-ee31-4f1d-8b72-559131557a91,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-3d21d219-3e6e-4e83-8db2-216251b83a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-3d9db344-0ba0-46ac-8d91-74f53cbcfbed,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-068fd18e-d96b-4697-9c4a-fc6a4a4a1864,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-b15c28d6-d9cc-4493-ad5e-b6406bfed421,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-8ba692f9-034f-440a-9958-79d5107b2c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142432673-172.17.0.11-1595984871020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-0fc5ed91-6da2-4bcf-b201-eac5e6738e28,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-18b8c9ff-3388-4bda-9415-c5840527da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-76e9d40c-ee31-4f1d-8b72-559131557a91,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-3d21d219-3e6e-4e83-8db2-216251b83a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-3d9db344-0ba0-46ac-8d91-74f53cbcfbed,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-068fd18e-d96b-4697-9c4a-fc6a4a4a1864,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-b15c28d6-d9cc-4493-ad5e-b6406bfed421,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-8ba692f9-034f-440a-9958-79d5107b2c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928562755-172.17.0.11-1595984909556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-d22a7180-4b3b-456f-b599-9ca00eea1386,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-997cd11e-0dfb-4aaf-9eeb-7aaf9a3378c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-670a9a64-9d36-436e-b142-00ab87752474,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-28f4df89-d8fa-4901-be3f-62b4898764f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-797974da-90a9-4b50-bcaa-829069911016,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-9134859d-c898-49f7-a3f7-a2fcbf68a560,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-9f912b13-812a-4887-86b2-bf52ac6a75c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-527a823b-91e6-483d-93da-bfa5b447eece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928562755-172.17.0.11-1595984909556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-d22a7180-4b3b-456f-b599-9ca00eea1386,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-997cd11e-0dfb-4aaf-9eeb-7aaf9a3378c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-670a9a64-9d36-436e-b142-00ab87752474,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-28f4df89-d8fa-4901-be3f-62b4898764f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-797974da-90a9-4b50-bcaa-829069911016,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-9134859d-c898-49f7-a3f7-a2fcbf68a560,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-9f912b13-812a-4887-86b2-bf52ac6a75c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-527a823b-91e6-483d-93da-bfa5b447eece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880504922-172.17.0.11-1595985057941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-bf170da0-67fd-4208-8122-a7706ecbb3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-8bf8a758-7ca0-49a1-a957-9b0038717b41,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-d29ec33c-a02c-4ab8-b7e8-f3ae96d2e4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-6b508981-ad3d-44b0-9648-9a221160ce45,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-70d902e5-59de-402c-b105-3955a358ceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-9b787d65-2bb5-4e26-b374-ceb0144ba395,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-ba1a1e93-09dd-4112-85f0-4c8fc73cbee2,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-a193bd7f-54e2-45e1-9e7a-9a214a30ef3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880504922-172.17.0.11-1595985057941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-bf170da0-67fd-4208-8122-a7706ecbb3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-8bf8a758-7ca0-49a1-a957-9b0038717b41,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-d29ec33c-a02c-4ab8-b7e8-f3ae96d2e4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-6b508981-ad3d-44b0-9648-9a221160ce45,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-70d902e5-59de-402c-b105-3955a358ceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-9b787d65-2bb5-4e26-b374-ceb0144ba395,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-ba1a1e93-09dd-4112-85f0-4c8fc73cbee2,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-a193bd7f-54e2-45e1-9e7a-9a214a30ef3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116977306-172.17.0.11-1595985385566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34646,DS-16e4ba77-1859-492e-ac3a-911155a1f7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-c5e22225-ca49-4588-bb84-2d73e6dc3b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-a445d5e1-c3d9-47d2-9c49-7aa7135373ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-58f05c26-0f65-478b-bf71-d4878691119f,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-7794c79c-8068-493e-a512-53c22bbe0ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-81f4463b-79e1-4dd2-be30-d96749d34ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-30fec5e5-844e-4a98-b33c-cb8d1e0312ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-27dbc5fe-e700-4a7d-84fb-d1ded2ffac6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116977306-172.17.0.11-1595985385566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34646,DS-16e4ba77-1859-492e-ac3a-911155a1f7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-c5e22225-ca49-4588-bb84-2d73e6dc3b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-a445d5e1-c3d9-47d2-9c49-7aa7135373ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-58f05c26-0f65-478b-bf71-d4878691119f,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-7794c79c-8068-493e-a512-53c22bbe0ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-81f4463b-79e1-4dd2-be30-d96749d34ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-30fec5e5-844e-4a98-b33c-cb8d1e0312ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-27dbc5fe-e700-4a7d-84fb-d1ded2ffac6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248551668-172.17.0.11-1595985424048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-b2d0ad15-042f-442d-9cdd-05dce4919262,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-e11c827e-250c-4dfe-8fe6-7faf9063d090,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-532548c5-3e80-4775-a4f6-3ad101a20e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-307f537d-4f37-4062-a8a2-b5831e265a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-9fdb46f9-057a-40d6-94bb-2ff7e9887c84,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-caa06e19-1c8c-49a3-9551-e5ed2ef4a50e,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-aad43b3a-56a8-42dc-9a7f-dceacc9082dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-0489598d-10e9-4ff6-9928-c851f80995c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248551668-172.17.0.11-1595985424048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-b2d0ad15-042f-442d-9cdd-05dce4919262,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-e11c827e-250c-4dfe-8fe6-7faf9063d090,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-532548c5-3e80-4775-a4f6-3ad101a20e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-307f537d-4f37-4062-a8a2-b5831e265a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-9fdb46f9-057a-40d6-94bb-2ff7e9887c84,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-caa06e19-1c8c-49a3-9551-e5ed2ef4a50e,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-aad43b3a-56a8-42dc-9a7f-dceacc9082dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-0489598d-10e9-4ff6-9928-c851f80995c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218827811-172.17.0.11-1595985611240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-f9dd70d8-c01e-4129-8253-afb529cba443,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-21ce1268-4fe6-458c-b853-3daaeea2ccc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-c7579c4c-a319-436b-b30e-9e01808e0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-6d6023ea-7385-4c0e-90d4-20dcc8828b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-80d8240b-d957-450f-97eb-49a44f54bda6,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-5b242960-b192-41e6-8dcc-b3b996895f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-c532c790-002d-4eb2-86c5-fd80926a5a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-136c44d0-74eb-497a-bd97-75cfd7a50d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218827811-172.17.0.11-1595985611240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-f9dd70d8-c01e-4129-8253-afb529cba443,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-21ce1268-4fe6-458c-b853-3daaeea2ccc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-c7579c4c-a319-436b-b30e-9e01808e0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-6d6023ea-7385-4c0e-90d4-20dcc8828b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-80d8240b-d957-450f-97eb-49a44f54bda6,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-5b242960-b192-41e6-8dcc-b3b996895f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-c532c790-002d-4eb2-86c5-fd80926a5a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-136c44d0-74eb-497a-bd97-75cfd7a50d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951397640-172.17.0.11-1595985726906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-3a3affa1-940f-4d42-9f62-d0bf8da0641d,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-2f8c43ef-f8d9-4a1c-8758-b936c3e3a3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-44f75b5a-b2ba-477e-b6bc-ce9ad3dab07c,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-ef0894f4-b801-42a9-8a57-a3d447477ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-116ec475-48ac-4990-bce4-9b3a5211d652,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-eeb1de18-6868-4f1d-a49a-a89467f04de4,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-05722a5b-699c-4a5d-8c36-c3a92da4f0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-7b114d76-db76-4e19-b4aa-bd34625a154c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951397640-172.17.0.11-1595985726906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43577,DS-3a3affa1-940f-4d42-9f62-d0bf8da0641d,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-2f8c43ef-f8d9-4a1c-8758-b936c3e3a3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-44f75b5a-b2ba-477e-b6bc-ce9ad3dab07c,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-ef0894f4-b801-42a9-8a57-a3d447477ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-116ec475-48ac-4990-bce4-9b3a5211d652,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-eeb1de18-6868-4f1d-a49a-a89467f04de4,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-05722a5b-699c-4a5d-8c36-c3a92da4f0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-7b114d76-db76-4e19-b4aa-bd34625a154c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543708502-172.17.0.11-1595985850332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-9fef209c-ee31-4c14-9c50-9b7d96931e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-ccca1ac7-2fad-4154-8613-d33b088ec87e,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-d5f45aa5-0e77-441c-97a3-a2c6edfb4885,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-0faa032a-cd98-45e2-9c9c-68b13e378b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-4f97a883-e245-45f3-9bfe-90402dc414f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-40f140d3-bc3f-47f1-a7d0-e01236863c68,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-57bf95ac-47fa-49b6-8832-18e73dbc5cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-601e6454-e8e7-497c-90de-f8711bd6b481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543708502-172.17.0.11-1595985850332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-9fef209c-ee31-4c14-9c50-9b7d96931e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-ccca1ac7-2fad-4154-8613-d33b088ec87e,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-d5f45aa5-0e77-441c-97a3-a2c6edfb4885,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-0faa032a-cd98-45e2-9c9c-68b13e378b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-4f97a883-e245-45f3-9bfe-90402dc414f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-40f140d3-bc3f-47f1-a7d0-e01236863c68,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-57bf95ac-47fa-49b6-8832-18e73dbc5cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-601e6454-e8e7-497c-90de-f8711bd6b481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970192853-172.17.0.11-1595986114193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42232,DS-19aeb871-c6e2-440b-af89-c62cc306d601,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-ab46679b-63b3-4e5b-bdaa-a7e4e16eb49d,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-7706a703-2774-482a-ac9d-2b15e5f59688,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-b1ce7944-f54b-4375-890c-89197c6c365e,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-87b5af80-e0e3-40c9-ad1c-593af79590e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-6f0b6ac0-7d5f-49b6-a91b-fdf4d0b2cbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-6bfce25f-8db8-4a81-ab7a-73951c80bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-43512a99-f36a-49c6-bf65-ffef588d9758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970192853-172.17.0.11-1595986114193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42232,DS-19aeb871-c6e2-440b-af89-c62cc306d601,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-ab46679b-63b3-4e5b-bdaa-a7e4e16eb49d,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-7706a703-2774-482a-ac9d-2b15e5f59688,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-b1ce7944-f54b-4375-890c-89197c6c365e,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-87b5af80-e0e3-40c9-ad1c-593af79590e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-6f0b6ac0-7d5f-49b6-a91b-fdf4d0b2cbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-6bfce25f-8db8-4a81-ab7a-73951c80bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-43512a99-f36a-49c6-bf65-ffef588d9758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492846443-172.17.0.11-1595986308925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-a49dde46-1e3e-437a-983b-af9fc66d8059,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-14db2cef-2fff-4324-bb34-4643c9c67cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-c72c6446-ca28-42ad-844d-00e085915e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-00d0352d-aa62-4bb1-869e-0d897bf63821,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-01bbc849-ddd6-4c52-b13d-716deeba6aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-b305a5c8-80c3-4619-9d89-486b25a201fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-fbf5a550-0103-42cc-97de-ffef3ad805a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-af9e4c98-bd53-459e-bfb7-ebed53a112c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492846443-172.17.0.11-1595986308925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-a49dde46-1e3e-437a-983b-af9fc66d8059,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-14db2cef-2fff-4324-bb34-4643c9c67cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-c72c6446-ca28-42ad-844d-00e085915e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-00d0352d-aa62-4bb1-869e-0d897bf63821,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-01bbc849-ddd6-4c52-b13d-716deeba6aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-b305a5c8-80c3-4619-9d89-486b25a201fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-fbf5a550-0103-42cc-97de-ffef3ad805a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-af9e4c98-bd53-459e-bfb7-ebed53a112c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513258301-172.17.0.11-1595987500701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-9889244e-22b5-48d8-a3fe-9a5e08f56609,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-c1a7bdd9-5a0b-44b9-a7c7-79fd67fc2d65,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-b3fc6ed6-5fe6-4e8a-9142-6ff89d5dc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-f0b08f9d-e407-4a3c-8c9f-71459b92d99a,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-84c7a42a-daa7-4bac-b4a0-96a3a15b5a21,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-455450a8-30ac-46a4-9fe7-f3e2d4210018,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-21bc9b6d-29be-4d1b-a267-e6267bc03ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-ef641de6-9d4c-4ac3-a4c8-b0bb38a898a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513258301-172.17.0.11-1595987500701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-9889244e-22b5-48d8-a3fe-9a5e08f56609,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-c1a7bdd9-5a0b-44b9-a7c7-79fd67fc2d65,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-b3fc6ed6-5fe6-4e8a-9142-6ff89d5dc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-f0b08f9d-e407-4a3c-8c9f-71459b92d99a,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-84c7a42a-daa7-4bac-b4a0-96a3a15b5a21,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-455450a8-30ac-46a4-9fe7-f3e2d4210018,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-21bc9b6d-29be-4d1b-a267-e6267bc03ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-ef641de6-9d4c-4ac3-a4c8-b0bb38a898a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295145628-172.17.0.11-1595987624939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35921,DS-dc7452b4-d22f-4006-8208-35801f5d6e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-e7500d92-d248-43a5-9bab-baf160398cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-869cf41e-d63e-4c9c-94b2-8ea0166d1613,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-06a29acf-126e-4a5c-bdd3-e732490d119a,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-341d03d2-cf9d-42b9-b98e-3aeea20cbceb,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-fe3b6e13-4dfb-4cf0-ab8b-e4f2a0867040,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-93465749-0e9a-44ff-8897-170870d8d9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-db597dc2-5e92-41ae-a1d8-1df575c19716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295145628-172.17.0.11-1595987624939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35921,DS-dc7452b4-d22f-4006-8208-35801f5d6e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-e7500d92-d248-43a5-9bab-baf160398cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-869cf41e-d63e-4c9c-94b2-8ea0166d1613,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-06a29acf-126e-4a5c-bdd3-e732490d119a,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-341d03d2-cf9d-42b9-b98e-3aeea20cbceb,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-fe3b6e13-4dfb-4cf0-ab8b-e4f2a0867040,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-93465749-0e9a-44ff-8897-170870d8d9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-db597dc2-5e92-41ae-a1d8-1df575c19716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131235492-172.17.0.11-1595988055589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-0a7ceb58-b0be-4eba-85c0-df08f9b83a88,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-71e18835-bec0-4c87-a9dd-3a21f136e572,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-504ec412-186e-406c-8bfb-87da804e7d16,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-6845b99b-9487-40ae-a882-c65bbb10dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-729651ac-5a5f-44a2-b899-45ea7584277d,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-1cae1fe4-c99e-496f-a7ff-6de0dbb8561f,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-5b142ae9-2ced-4635-be66-17ad909f5474,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-db4e3344-13ea-4120-90aa-c18c69ae4106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131235492-172.17.0.11-1595988055589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-0a7ceb58-b0be-4eba-85c0-df08f9b83a88,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-71e18835-bec0-4c87-a9dd-3a21f136e572,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-504ec412-186e-406c-8bfb-87da804e7d16,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-6845b99b-9487-40ae-a882-c65bbb10dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-729651ac-5a5f-44a2-b899-45ea7584277d,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-1cae1fe4-c99e-496f-a7ff-6de0dbb8561f,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-5b142ae9-2ced-4635-be66-17ad909f5474,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-db4e3344-13ea-4120-90aa-c18c69ae4106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888974632-172.17.0.11-1595988470190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45608,DS-56836029-7f52-45cb-ba93-d4b4aefba66f,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-bdcbfe2e-5b36-412a-80c5-d87391c0982b,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-5f01f45e-796b-4054-8fda-09efd675b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-50fd58d4-5785-47e6-9be8-d0a6e8fd69a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-eba9e54e-a51c-4f07-b422-9315801b5292,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-4d6ecea4-7714-46b7-98c8-8f43bbd02846,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-77fdb412-ee3c-409d-a29f-3ba02d1fc0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-32ce9b9e-9979-43d4-9da7-c0192d8c7aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888974632-172.17.0.11-1595988470190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45608,DS-56836029-7f52-45cb-ba93-d4b4aefba66f,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-bdcbfe2e-5b36-412a-80c5-d87391c0982b,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-5f01f45e-796b-4054-8fda-09efd675b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-50fd58d4-5785-47e6-9be8-d0a6e8fd69a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-eba9e54e-a51c-4f07-b422-9315801b5292,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-4d6ecea4-7714-46b7-98c8-8f43bbd02846,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-77fdb412-ee3c-409d-a29f-3ba02d1fc0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-32ce9b9e-9979-43d4-9da7-c0192d8c7aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190217446-172.17.0.11-1595988576194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34729,DS-a9755ab0-fff2-4065-be55-ab2043a72955,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-29b4d8c7-5d12-4a0a-ad9e-d3321f7be638,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-2b8a24b5-cf44-4d7e-ba73-b77168cf4d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-ac67b963-94dc-4083-abf3-ca863e2abd85,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-87adcf60-356b-463d-b2ca-683d26d8b00b,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-3ab9a9f5-c7a4-43a1-ae8a-51480192f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-a11cc51c-c6e8-4b30-82a5-446a27880e27,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-550552f0-2d48-429f-befe-5cc67fd79277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190217446-172.17.0.11-1595988576194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34729,DS-a9755ab0-fff2-4065-be55-ab2043a72955,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-29b4d8c7-5d12-4a0a-ad9e-d3321f7be638,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-2b8a24b5-cf44-4d7e-ba73-b77168cf4d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-ac67b963-94dc-4083-abf3-ca863e2abd85,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-87adcf60-356b-463d-b2ca-683d26d8b00b,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-3ab9a9f5-c7a4-43a1-ae8a-51480192f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-a11cc51c-c6e8-4b30-82a5-446a27880e27,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-550552f0-2d48-429f-befe-5cc67fd79277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975660898-172.17.0.11-1595988690481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-ac2a7bcb-441c-430d-84dc-428e7b170143,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-4999a985-eb74-4a18-ae29-47abaeca7f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-67b70259-f2b2-4fc1-afbb-51616b4758ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-25779d25-9fc8-4e42-a3f5-ef5783f7fbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-35a29c51-8211-456f-b894-6694793bef64,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-b5041cea-f7b0-40c6-92e9-a929e4671fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-e6ceacef-a104-4903-9406-0a624e25359c,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-d345eda0-5c08-4cae-84c2-1c0315beca05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975660898-172.17.0.11-1595988690481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-ac2a7bcb-441c-430d-84dc-428e7b170143,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-4999a985-eb74-4a18-ae29-47abaeca7f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-67b70259-f2b2-4fc1-afbb-51616b4758ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-25779d25-9fc8-4e42-a3f5-ef5783f7fbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-35a29c51-8211-456f-b894-6694793bef64,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-b5041cea-f7b0-40c6-92e9-a929e4671fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-e6ceacef-a104-4903-9406-0a624e25359c,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-d345eda0-5c08-4cae-84c2-1c0315beca05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030045288-172.17.0.11-1595988841054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-3fd4842a-02e0-43d5-85a9-f6913fa9ecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-6b5d1a9b-c1ac-4d25-b775-70ee952c6603,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-61a56f3f-7c91-49db-a0fd-3d7d4a140238,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-d90250fc-5f4e-4a3d-a7d0-d139c95e0578,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-8f266079-80c8-4a30-8092-3e519af9d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-ebd47a60-434e-4bde-847c-075b3f09f74d,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-f95c852e-a4af-4493-9a5a-b2aa53564fba,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-5d873313-30fb-473a-9118-9753652d6e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030045288-172.17.0.11-1595988841054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-3fd4842a-02e0-43d5-85a9-f6913fa9ecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-6b5d1a9b-c1ac-4d25-b775-70ee952c6603,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-61a56f3f-7c91-49db-a0fd-3d7d4a140238,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-d90250fc-5f4e-4a3d-a7d0-d139c95e0578,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-8f266079-80c8-4a30-8092-3e519af9d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-ebd47a60-434e-4bde-847c-075b3f09f74d,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-f95c852e-a4af-4493-9a5a-b2aa53564fba,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-5d873313-30fb-473a-9118-9753652d6e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 32
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014301427-172.17.0.11-1595989807312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44344,DS-26365bda-ffc3-4688-8cd9-32dab6a7ecaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-75f591bd-a2e6-4558-b162-1e3a3f6eeb41,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-aacc72ef-f4c5-4798-82f4-0b921ccf10e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-5b665ead-fa13-4e57-b7ca-7b4a0b30f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-73067ee4-327d-444c-a7c5-b9578dc92c60,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-9e50b55d-a8bf-49b6-813b-071f946c36c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-2816450e-2d68-4bd8-af5a-92d76e5e90b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-e8c00963-e36a-4d9a-89fa-5af9eb1d202e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014301427-172.17.0.11-1595989807312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44344,DS-26365bda-ffc3-4688-8cd9-32dab6a7ecaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-75f591bd-a2e6-4558-b162-1e3a3f6eeb41,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-aacc72ef-f4c5-4798-82f4-0b921ccf10e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-5b665ead-fa13-4e57-b7ca-7b4a0b30f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-73067ee4-327d-444c-a7c5-b9578dc92c60,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-9e50b55d-a8bf-49b6-813b-071f946c36c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-2816450e-2d68-4bd8-af5a-92d76e5e90b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-e8c00963-e36a-4d9a-89fa-5af9eb1d202e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5615
