reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575592534-172.17.0.10-1596051379700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43632,DS-003db09c-e38c-47c5-ba05-1299fd3e1e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-b11e4180-8571-40af-a9e2-53f0e23ceb28,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-1aec4d31-9faa-42fb-9c8c-02d5f5dfb8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-8186a4bc-b30b-422a-b820-49063c918515,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-484a7f22-7a16-4aa4-a82f-be30d6ff128b,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1b520716-d1e6-4417-8523-738496ae4881,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-dcfddb28-c876-4d7f-afce-cb04d1c4c159,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-93d3b904-0391-40b1-92ed-fac90fff6d5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575592534-172.17.0.10-1596051379700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43632,DS-003db09c-e38c-47c5-ba05-1299fd3e1e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-b11e4180-8571-40af-a9e2-53f0e23ceb28,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-1aec4d31-9faa-42fb-9c8c-02d5f5dfb8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-8186a4bc-b30b-422a-b820-49063c918515,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-484a7f22-7a16-4aa4-a82f-be30d6ff128b,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1b520716-d1e6-4417-8523-738496ae4881,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-dcfddb28-c876-4d7f-afce-cb04d1c4c159,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-93d3b904-0391-40b1-92ed-fac90fff6d5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743610043-172.17.0.10-1596051645008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-6de42b77-76d6-479e-aecd-afe58549f796,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-796e18e4-dcee-4495-b647-3a28530facf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-09b28842-06b1-4afd-8e22-74950343b8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-015c7d90-fd3c-40fa-974a-956e4876f605,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-6c1066cc-1305-4695-801a-986b10f43a24,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-7ad8f0b0-da80-4ab4-950f-1c9cd03dc0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-6256dbb1-c97b-4063-bae2-8dcb547e657f,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-c66d2c0c-3666-4885-b1a4-5440f45fb830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743610043-172.17.0.10-1596051645008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-6de42b77-76d6-479e-aecd-afe58549f796,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-796e18e4-dcee-4495-b647-3a28530facf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-09b28842-06b1-4afd-8e22-74950343b8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-015c7d90-fd3c-40fa-974a-956e4876f605,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-6c1066cc-1305-4695-801a-986b10f43a24,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-7ad8f0b0-da80-4ab4-950f-1c9cd03dc0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-6256dbb1-c97b-4063-bae2-8dcb547e657f,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-c66d2c0c-3666-4885-b1a4-5440f45fb830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143732316-172.17.0.10-1596051688156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-22b844d6-6f8c-4779-965b-08ef8a7ce3af,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-ea96b91a-47f2-4b9b-bbf4-5be42f5c29f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-fbdfeab9-4c31-4bd3-ba2e-87a71b2bf61a,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-716faa03-a9fd-4cd1-a10d-f4e1eae1d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-d9762812-0600-4997-ad41-feeb77e26f86,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-713d9b8a-c2f9-4ccb-8100-42b30eec7aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-c33318d1-9c99-44ee-aa73-a9b53122e46f,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-d2141815-aa54-4438-8e65-4fae0b1a56ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143732316-172.17.0.10-1596051688156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-22b844d6-6f8c-4779-965b-08ef8a7ce3af,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-ea96b91a-47f2-4b9b-bbf4-5be42f5c29f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-fbdfeab9-4c31-4bd3-ba2e-87a71b2bf61a,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-716faa03-a9fd-4cd1-a10d-f4e1eae1d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-d9762812-0600-4997-ad41-feeb77e26f86,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-713d9b8a-c2f9-4ccb-8100-42b30eec7aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-c33318d1-9c99-44ee-aa73-a9b53122e46f,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-d2141815-aa54-4438-8e65-4fae0b1a56ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295623224-172.17.0.10-1596051735334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-81ac352a-ab2e-4764-889c-6f51a679f03c,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-b0da804c-22a9-44f4-b2c9-cf019b8ce50c,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-ea950801-943d-4e97-a246-410f6d36900b,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-be51c630-e5fd-4365-85bd-934094acae43,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-5160646f-bd1a-47bd-a746-0e7cb3c27092,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-c06f58c2-fd8b-42df-9cd4-f9f52fbfff3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-4eb4dfd8-acae-4fe9-8577-a2770496b140,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-73f065fb-4214-4285-84dc-97e10f050194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295623224-172.17.0.10-1596051735334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-81ac352a-ab2e-4764-889c-6f51a679f03c,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-b0da804c-22a9-44f4-b2c9-cf019b8ce50c,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-ea950801-943d-4e97-a246-410f6d36900b,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-be51c630-e5fd-4365-85bd-934094acae43,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-5160646f-bd1a-47bd-a746-0e7cb3c27092,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-c06f58c2-fd8b-42df-9cd4-f9f52fbfff3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-4eb4dfd8-acae-4fe9-8577-a2770496b140,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-73f065fb-4214-4285-84dc-97e10f050194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074255031-172.17.0.10-1596051953379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-3eafbecf-5c82-42c0-a893-f4997020f602,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-edb40e98-ca0f-4328-b40a-49ad882ca464,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-1a690c4f-dd36-4b69-85b9-19e13835b095,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-12f8935a-7abf-417f-a840-20a02fda0f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-6629ae7e-d2c4-497f-8641-aae7a90b39a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-354549aa-4070-4069-8965-d88ff6faccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-b5a75280-6d31-4582-a486-9ebee61eb98c,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-00e53e9e-d6be-4170-b65c-2ed9f1c5a044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074255031-172.17.0.10-1596051953379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-3eafbecf-5c82-42c0-a893-f4997020f602,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-edb40e98-ca0f-4328-b40a-49ad882ca464,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-1a690c4f-dd36-4b69-85b9-19e13835b095,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-12f8935a-7abf-417f-a840-20a02fda0f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-6629ae7e-d2c4-497f-8641-aae7a90b39a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-354549aa-4070-4069-8965-d88ff6faccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-b5a75280-6d31-4582-a486-9ebee61eb98c,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-00e53e9e-d6be-4170-b65c-2ed9f1c5a044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683947582-172.17.0.10-1596052040751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-98f0cbe6-2a4c-4028-bc64-b938be6b079c,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-c2c4c26e-dfd2-4a3b-aa87-38a79750dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-e908b179-0ec9-481a-a327-691ff6944a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-7a7841d7-3351-4bfd-999b-3c1697ad88c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-4847fe91-0463-4eb8-a47a-a579928d5e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-006d4c5c-f34e-4f1d-891a-9ad3b5dab2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-2656e038-d4af-4d0d-bdeb-264e2b099665,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-3f212324-f9c3-4fbd-a369-078ae06b1423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683947582-172.17.0.10-1596052040751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-98f0cbe6-2a4c-4028-bc64-b938be6b079c,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-c2c4c26e-dfd2-4a3b-aa87-38a79750dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-e908b179-0ec9-481a-a327-691ff6944a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-7a7841d7-3351-4bfd-999b-3c1697ad88c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-4847fe91-0463-4eb8-a47a-a579928d5e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-006d4c5c-f34e-4f1d-891a-9ad3b5dab2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-2656e038-d4af-4d0d-bdeb-264e2b099665,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-3f212324-f9c3-4fbd-a369-078ae06b1423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967942952-172.17.0.10-1596052200887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-836b27f8-8590-4b2f-b9b3-e88f38796b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-24b58990-a953-4046-a3f4-9052d4e1f8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0bb06fbb-fa5e-4686-b325-15e452bc7504,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-714959f6-cc8d-48b3-91f0-13b4011ffbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-cf44caeb-420f-45ee-beb2-ecf5a87e7208,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-0ed2e288-ea16-4ee3-b91e-26734239d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-84d759f8-90f5-4755-9502-0d135e3f8f75,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-e4d1ca92-7ece-46f4-8b07-88b16547199e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967942952-172.17.0.10-1596052200887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-836b27f8-8590-4b2f-b9b3-e88f38796b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-24b58990-a953-4046-a3f4-9052d4e1f8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0bb06fbb-fa5e-4686-b325-15e452bc7504,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-714959f6-cc8d-48b3-91f0-13b4011ffbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-cf44caeb-420f-45ee-beb2-ecf5a87e7208,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-0ed2e288-ea16-4ee3-b91e-26734239d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-84d759f8-90f5-4755-9502-0d135e3f8f75,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-e4d1ca92-7ece-46f4-8b07-88b16547199e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926562135-172.17.0.10-1596052394230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-0235e1d6-2d65-40eb-b74e-daafd14f7931,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-fc8859c7-d0e2-4e10-a048-4d14d2902845,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-c8b6427e-f9a7-4575-885e-0ca5ffb1aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-2efb9166-7da1-41a3-8c0c-c88ad729d83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-63ccc143-0bde-4c50-b8ae-bb36e0397ede,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-4aa65192-2e6d-4fa1-a1ba-35ed3deed295,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-2593fd70-84df-4fcf-b606-7da14856cd98,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-c7539220-0d01-435d-b026-2fdd859a6552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926562135-172.17.0.10-1596052394230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-0235e1d6-2d65-40eb-b74e-daafd14f7931,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-fc8859c7-d0e2-4e10-a048-4d14d2902845,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-c8b6427e-f9a7-4575-885e-0ca5ffb1aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-2efb9166-7da1-41a3-8c0c-c88ad729d83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-63ccc143-0bde-4c50-b8ae-bb36e0397ede,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-4aa65192-2e6d-4fa1-a1ba-35ed3deed295,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-2593fd70-84df-4fcf-b606-7da14856cd98,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-c7539220-0d01-435d-b026-2fdd859a6552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584151325-172.17.0.10-1596052428101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44953,DS-963dcc1f-1cac-4c93-9d78-2240146d138a,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-37fff87b-761a-4757-b125-35a8d61f7267,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-bc6db83e-3f66-4fb5-b6a1-61bdb07a4c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-628ba207-0e6a-4c9b-bc32-6207f3979eab,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-54391100-aa4b-49d0-8617-8a787271823d,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-b97e2d2c-b56a-47e8-ab7d-112157ad62b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-e551d1a2-73a2-4b41-a874-70feaa57007a,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-07c3dc9e-fca6-42af-b9ea-fec555f96618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584151325-172.17.0.10-1596052428101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44953,DS-963dcc1f-1cac-4c93-9d78-2240146d138a,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-37fff87b-761a-4757-b125-35a8d61f7267,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-bc6db83e-3f66-4fb5-b6a1-61bdb07a4c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-628ba207-0e6a-4c9b-bc32-6207f3979eab,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-54391100-aa4b-49d0-8617-8a787271823d,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-b97e2d2c-b56a-47e8-ab7d-112157ad62b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-e551d1a2-73a2-4b41-a874-70feaa57007a,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-07c3dc9e-fca6-42af-b9ea-fec555f96618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275940309-172.17.0.10-1596052862463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40346,DS-21a3aff7-7b20-4acf-ba48-5b05662d57fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-b0bc408f-ea63-4b8c-8cbe-4fa217e0878a,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-6e613da3-8a58-432c-8746-6fe12ea37913,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-eea0b673-4536-4a3c-a075-1316ba984088,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-9d9bffdd-8977-4d5e-ad62-7d9f72f7f978,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-aff2532b-b1f5-44ba-8868-9e0582838166,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-9b2178db-f939-45e0-954d-0ee53f50b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-83c1d53c-fc77-405b-9415-fd6dcf8d3bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275940309-172.17.0.10-1596052862463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40346,DS-21a3aff7-7b20-4acf-ba48-5b05662d57fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-b0bc408f-ea63-4b8c-8cbe-4fa217e0878a,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-6e613da3-8a58-432c-8746-6fe12ea37913,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-eea0b673-4536-4a3c-a075-1316ba984088,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-9d9bffdd-8977-4d5e-ad62-7d9f72f7f978,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-aff2532b-b1f5-44ba-8868-9e0582838166,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-9b2178db-f939-45e0-954d-0ee53f50b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-83c1d53c-fc77-405b-9415-fd6dcf8d3bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325594053-172.17.0.10-1596053199235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38588,DS-cce9f3a1-65e8-430f-b030-44ab30d842cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-26b99e3b-0cc7-438b-97c0-bd12542180dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-60934275-f4a1-43e8-9cc7-a712ad1f5849,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-f2cbc60d-2ee5-48bb-ac19-2e0540ef6921,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-1b12469d-b423-4fd9-bb45-62f5aaf1e2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-88e09dda-5045-420c-aed1-59c1b2018763,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-fd0fd2c9-18f1-4ea9-ad71-a4b391164a18,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-f0721af3-0d04-4d8e-9e0b-1460235ac898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325594053-172.17.0.10-1596053199235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38588,DS-cce9f3a1-65e8-430f-b030-44ab30d842cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-26b99e3b-0cc7-438b-97c0-bd12542180dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-60934275-f4a1-43e8-9cc7-a712ad1f5849,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-f2cbc60d-2ee5-48bb-ac19-2e0540ef6921,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-1b12469d-b423-4fd9-bb45-62f5aaf1e2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-88e09dda-5045-420c-aed1-59c1b2018763,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-fd0fd2c9-18f1-4ea9-ad71-a4b391164a18,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-f0721af3-0d04-4d8e-9e0b-1460235ac898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245563754-172.17.0.10-1596053646955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-2b92ea56-3290-4ddc-9b58-a508d561276c,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-4ec5aa9e-1ce4-4b02-b03c-8a23d3df27dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-4c18dcde-f4ca-4296-9368-53d5576d4f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-a91d29d5-0603-412c-b6fd-16c6687bf7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-2bdc6ed8-34bf-4c8b-9607-1641a7ff4013,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-5f179b07-7373-4c26-8db4-2d1e34386b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-e5716a70-3aba-4839-a200-6e713a4acf73,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-0c4f53ac-7e54-41cf-9279-ede2613e8c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245563754-172.17.0.10-1596053646955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-2b92ea56-3290-4ddc-9b58-a508d561276c,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-4ec5aa9e-1ce4-4b02-b03c-8a23d3df27dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-4c18dcde-f4ca-4296-9368-53d5576d4f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-a91d29d5-0603-412c-b6fd-16c6687bf7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-2bdc6ed8-34bf-4c8b-9607-1641a7ff4013,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-5f179b07-7373-4c26-8db4-2d1e34386b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-e5716a70-3aba-4839-a200-6e713a4acf73,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-0c4f53ac-7e54-41cf-9279-ede2613e8c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255207938-172.17.0.10-1596053684130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43992,DS-7b514bd1-a05b-42ef-bd43-c161fc0cf93b,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-3c5a156b-6f82-4ae8-b86c-5d696c818459,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-383fd899-234f-4568-884e-0f869cb49598,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-3dece478-f819-486f-9195-50428e1764cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-5bd5f381-a783-4e14-815a-502f5eafe677,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-b72b892f-7011-4fe0-9c84-daf45bdd8833,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-f986670d-2a1a-4315-bace-f4a7e7188e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-cb18a04f-77c3-4cc1-8974-4e535245565b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255207938-172.17.0.10-1596053684130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43992,DS-7b514bd1-a05b-42ef-bd43-c161fc0cf93b,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-3c5a156b-6f82-4ae8-b86c-5d696c818459,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-383fd899-234f-4568-884e-0f869cb49598,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-3dece478-f819-486f-9195-50428e1764cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-5bd5f381-a783-4e14-815a-502f5eafe677,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-b72b892f-7011-4fe0-9c84-daf45bdd8833,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-f986670d-2a1a-4315-bace-f4a7e7188e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-cb18a04f-77c3-4cc1-8974-4e535245565b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595635271-172.17.0.10-1596054842364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-02360b2e-b401-4114-afbc-b2ced85156bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-52b23485-2f92-48b0-9c53-5c062ccacfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-fb8d1c01-c434-497f-acb2-e30d31e72a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-aca2f4e5-c6a2-4282-a73c-af1592b74d94,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-55318388-ac9d-4149-ae44-c49412dd154a,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-25bec685-26ba-4aa2-a584-4a4a6ca5044e,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-13c475b4-e15f-46e8-86ef-dac986c5aa79,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-b4571b6e-bd63-4a9a-a5a8-08c208145e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595635271-172.17.0.10-1596054842364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-02360b2e-b401-4114-afbc-b2ced85156bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-52b23485-2f92-48b0-9c53-5c062ccacfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-fb8d1c01-c434-497f-acb2-e30d31e72a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-aca2f4e5-c6a2-4282-a73c-af1592b74d94,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-55318388-ac9d-4149-ae44-c49412dd154a,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-25bec685-26ba-4aa2-a584-4a4a6ca5044e,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-13c475b4-e15f-46e8-86ef-dac986c5aa79,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-b4571b6e-bd63-4a9a-a5a8-08c208145e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797348013-172.17.0.10-1596054981768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39750,DS-badb167d-e09e-44ca-9391-3ddf799ae6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-374bbaef-cd9f-4122-ab67-d5f6dd797736,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-07ee50f2-3706-47fd-9e67-52a60096adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-67c14af7-980e-40cf-9841-0e05612f568b,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-5f268b92-2e93-4ba8-b29c-810a17715bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-d55200ac-4818-4c97-b790-0c5e4d67f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-3f5f224e-aa11-4fc6-8512-4acfb24fd5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-0d517e72-ba31-42e1-9537-3f6812fc5379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797348013-172.17.0.10-1596054981768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39750,DS-badb167d-e09e-44ca-9391-3ddf799ae6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-374bbaef-cd9f-4122-ab67-d5f6dd797736,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-07ee50f2-3706-47fd-9e67-52a60096adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-67c14af7-980e-40cf-9841-0e05612f568b,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-5f268b92-2e93-4ba8-b29c-810a17715bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-d55200ac-4818-4c97-b790-0c5e4d67f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-3f5f224e-aa11-4fc6-8512-4acfb24fd5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-0d517e72-ba31-42e1-9537-3f6812fc5379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535552567-172.17.0.10-1596055214804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-acc2d500-090d-4354-b654-5ed78a0e7195,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-b9f4cd68-c848-4241-a20e-54d3f68275cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-89772749-b0de-468b-9ca5-35556b60c0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-db8fc67c-170a-4e8d-acea-63fcfd97def1,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-6c147c32-ff8f-49df-a67e-084405d5bb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-22f3e5c4-2d58-4e12-a244-d657b901e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-4fff48c2-30c6-4031-9aa2-3158b1406cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-884377a6-0a62-4003-8b4a-a4cd84fa02fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535552567-172.17.0.10-1596055214804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-acc2d500-090d-4354-b654-5ed78a0e7195,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-b9f4cd68-c848-4241-a20e-54d3f68275cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-89772749-b0de-468b-9ca5-35556b60c0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-db8fc67c-170a-4e8d-acea-63fcfd97def1,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-6c147c32-ff8f-49df-a67e-084405d5bb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-22f3e5c4-2d58-4e12-a244-d657b901e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-4fff48c2-30c6-4031-9aa2-3158b1406cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-884377a6-0a62-4003-8b4a-a4cd84fa02fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585410780-172.17.0.10-1596055839207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35794,DS-e80e9de8-95f9-4200-8499-b1b8fcddd4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b92eb1b2-f07b-4874-8b5c-807eb2297aae,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-e087bb5d-dbef-463d-8f07-c02b3d512d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-7a65956b-c6e7-430b-97c1-316e7367ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-3d10b405-36f3-4fa9-9fb8-382b5228f3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-2f34ce0f-c68c-45cb-8c56-06923bba1a43,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-e905ceb0-9c7b-41f3-9586-4b2539bff995,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-d58e6e00-8b30-4175-bc4e-87b0a945fa3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585410780-172.17.0.10-1596055839207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35794,DS-e80e9de8-95f9-4200-8499-b1b8fcddd4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b92eb1b2-f07b-4874-8b5c-807eb2297aae,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-e087bb5d-dbef-463d-8f07-c02b3d512d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-7a65956b-c6e7-430b-97c1-316e7367ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-3d10b405-36f3-4fa9-9fb8-382b5228f3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-2f34ce0f-c68c-45cb-8c56-06923bba1a43,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-e905ceb0-9c7b-41f3-9586-4b2539bff995,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-d58e6e00-8b30-4175-bc4e-87b0a945fa3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620063326-172.17.0.10-1596056188505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-41d02ff4-501a-4fe9-947d-8764dda4813f,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-80166d1f-da39-4013-9a04-91bbea76ef81,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-2105b8f7-0da6-452b-a47b-ae300f374563,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-1fc65bf8-b060-4915-b8ef-1228e7e0aada,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-550229df-741e-4bec-af6b-466781e1e508,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-592ba218-f0d9-450f-89cc-73b3993bf468,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-a03e7c15-d95c-434a-8262-2b6f8fbe02db,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-18b20e41-d2db-4073-9056-abcde9097a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620063326-172.17.0.10-1596056188505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-41d02ff4-501a-4fe9-947d-8764dda4813f,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-80166d1f-da39-4013-9a04-91bbea76ef81,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-2105b8f7-0da6-452b-a47b-ae300f374563,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-1fc65bf8-b060-4915-b8ef-1228e7e0aada,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-550229df-741e-4bec-af6b-466781e1e508,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-592ba218-f0d9-450f-89cc-73b3993bf468,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-a03e7c15-d95c-434a-8262-2b6f8fbe02db,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-18b20e41-d2db-4073-9056-abcde9097a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172572411-172.17.0.10-1596056230771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-89cca426-b4f7-42d8-b0fd-54d2b8c6ba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-d0a8c770-55d0-4df4-9dc1-dbeb722117f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-3d61cb02-1e60-4f71-9684-74d153edf45b,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-ba5bce74-a5d6-4ac8-ad43-e171829975f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-8f3004bc-fcf1-49f5-ac42-eee74862a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-de916f9c-03f4-42a8-8c2c-4a7ef067d538,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-c0bb7830-8b68-4c80-a74f-af627794e83c,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-617584e3-8082-472d-9c50-ddcfba9ac7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172572411-172.17.0.10-1596056230771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-89cca426-b4f7-42d8-b0fd-54d2b8c6ba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-d0a8c770-55d0-4df4-9dc1-dbeb722117f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-3d61cb02-1e60-4f71-9684-74d153edf45b,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-ba5bce74-a5d6-4ac8-ad43-e171829975f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-8f3004bc-fcf1-49f5-ac42-eee74862a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-de916f9c-03f4-42a8-8c2c-4a7ef067d538,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-c0bb7830-8b68-4c80-a74f-af627794e83c,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-617584e3-8082-472d-9c50-ddcfba9ac7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454985918-172.17.0.10-1596056406867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-df01d8a8-f6b1-4848-b539-e1e0242e7e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-09fd09f9-8a64-4152-947b-57e13f5bf42c,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-a2049041-eaba-4814-a3fa-3767fc9b9526,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-2c45242f-f0ad-4fb7-b839-4c9577c5789f,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-d61f3a49-66fa-4fe8-9812-04968f8ee24d,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-1854b7fb-3ab2-4793-a842-9284412c2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-6f9e8d38-0d2a-4086-a78c-2aac77730f60,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-465f682b-add2-4257-8484-0411ef85cafe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454985918-172.17.0.10-1596056406867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-df01d8a8-f6b1-4848-b539-e1e0242e7e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-09fd09f9-8a64-4152-947b-57e13f5bf42c,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-a2049041-eaba-4814-a3fa-3767fc9b9526,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-2c45242f-f0ad-4fb7-b839-4c9577c5789f,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-d61f3a49-66fa-4fe8-9812-04968f8ee24d,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-1854b7fb-3ab2-4793-a842-9284412c2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-6f9e8d38-0d2a-4086-a78c-2aac77730f60,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-465f682b-add2-4257-8484-0411ef85cafe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6311
