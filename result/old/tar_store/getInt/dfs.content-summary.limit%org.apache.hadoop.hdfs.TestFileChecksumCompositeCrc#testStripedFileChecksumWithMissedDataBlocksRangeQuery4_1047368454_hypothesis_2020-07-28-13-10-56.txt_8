reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640530692-172.17.0.5-1595941873779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-cbade4c9-7610-480f-82c2-f527073a85b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-b43f6a05-8304-4fb8-a4d5-e7e2589edd93,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-d4a5dc98-b2fa-4ab5-be85-270e26c8310c,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-5cd5e6b6-0081-4507-9a5e-91b4bcdd2da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-d277160b-59dd-4232-bb1c-7bb593277e48,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-222dd111-44e3-481c-acb0-f29b6da171ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-8d37b18a-232a-492e-a009-154e172f3278,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-826c3dac-b47a-4a34-a7f7-dc28492a97f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640530692-172.17.0.5-1595941873779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-cbade4c9-7610-480f-82c2-f527073a85b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-b43f6a05-8304-4fb8-a4d5-e7e2589edd93,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-d4a5dc98-b2fa-4ab5-be85-270e26c8310c,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-5cd5e6b6-0081-4507-9a5e-91b4bcdd2da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-d277160b-59dd-4232-bb1c-7bb593277e48,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-222dd111-44e3-481c-acb0-f29b6da171ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-8d37b18a-232a-492e-a009-154e172f3278,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-826c3dac-b47a-4a34-a7f7-dc28492a97f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120926095-172.17.0.5-1595942076910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-8b89457f-429e-412b-ae79-e79124fe395a,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-f43ac5b6-2655-4057-8aa8-7b2f287a71c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-4da44aeb-a58e-47b1-9fbb-cc5f79d5f402,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-7c7b8d87-ccde-4199-bf0c-4ed055f6d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-f73a4cda-0312-4889-a8a9-80f2384eafba,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-2afa6e46-6ede-47fc-b557-d36be4240024,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-949cc3b7-2708-411d-8f08-56647673905c,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-59c43c8e-7f0c-4f84-b34b-0efe548f2274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120926095-172.17.0.5-1595942076910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-8b89457f-429e-412b-ae79-e79124fe395a,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-f43ac5b6-2655-4057-8aa8-7b2f287a71c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-4da44aeb-a58e-47b1-9fbb-cc5f79d5f402,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-7c7b8d87-ccde-4199-bf0c-4ed055f6d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-f73a4cda-0312-4889-a8a9-80f2384eafba,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-2afa6e46-6ede-47fc-b557-d36be4240024,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-949cc3b7-2708-411d-8f08-56647673905c,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-59c43c8e-7f0c-4f84-b34b-0efe548f2274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152931544-172.17.0.5-1595942403617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35652,DS-1fde3130-bc9f-4fda-aaae-028c51b9bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-7c53a3ea-b8b7-459a-bf20-5655f3ed1019,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-85559a4a-1739-4a83-a12e-54cafbef09c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-08ba9d81-a8c9-488a-bd65-03768ba1580b,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-8d873a7d-69ab-4ba0-ba1c-e40868d94dae,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-f4e6b08f-c996-4196-aad9-1d7c8748be74,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-3492fffa-eb54-4ccc-bfb6-85ad150c2cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-e5cb5d6c-2f26-4434-b72e-cb89aef4f10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152931544-172.17.0.5-1595942403617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35652,DS-1fde3130-bc9f-4fda-aaae-028c51b9bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-7c53a3ea-b8b7-459a-bf20-5655f3ed1019,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-85559a4a-1739-4a83-a12e-54cafbef09c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-08ba9d81-a8c9-488a-bd65-03768ba1580b,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-8d873a7d-69ab-4ba0-ba1c-e40868d94dae,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-f4e6b08f-c996-4196-aad9-1d7c8748be74,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-3492fffa-eb54-4ccc-bfb6-85ad150c2cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-e5cb5d6c-2f26-4434-b72e-cb89aef4f10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171426072-172.17.0.5-1595942436026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36079,DS-af2ec1fd-500f-4904-95af-d8cbf6dc22d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-710296f1-644c-4739-8e87-3cf8ab2f45ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-fbdb0c48-c0d1-4b05-a95f-d47be89ba89a,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-6ef94cee-4f2a-447d-bf58-46c1d2cf565e,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-68703fde-8fe4-4b37-8dfb-12cc82738ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-edd1da47-2f47-416b-906b-a609f469792f,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-5098c5c9-068e-4c8c-88be-9e8ffd6acaae,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-013bc1b1-4612-4f1a-a7ff-5e675e7b2841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171426072-172.17.0.5-1595942436026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36079,DS-af2ec1fd-500f-4904-95af-d8cbf6dc22d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-710296f1-644c-4739-8e87-3cf8ab2f45ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-fbdb0c48-c0d1-4b05-a95f-d47be89ba89a,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-6ef94cee-4f2a-447d-bf58-46c1d2cf565e,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-68703fde-8fe4-4b37-8dfb-12cc82738ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-edd1da47-2f47-416b-906b-a609f469792f,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-5098c5c9-068e-4c8c-88be-9e8ffd6acaae,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-013bc1b1-4612-4f1a-a7ff-5e675e7b2841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670772902-172.17.0.5-1595942693178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44026,DS-170481ab-e32a-4ee2-ad41-6ec4fa3562e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-a2bb29c1-1d4a-4dc9-8104-cb07cdf04013,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-c6a24872-2bf6-4e02-a257-b982bc9c2cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-1872f9bc-0020-4009-ad6b-71bb2de5e622,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-728f6576-835e-48a7-836d-8fd5afaa619c,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-a919bd8c-acfe-4e88-8f16-0fb66f762ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-c60e0119-7d03-4aee-b7d1-fab64444f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-25c9c3ed-38b3-471a-9d72-407bc9891fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670772902-172.17.0.5-1595942693178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44026,DS-170481ab-e32a-4ee2-ad41-6ec4fa3562e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-a2bb29c1-1d4a-4dc9-8104-cb07cdf04013,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-c6a24872-2bf6-4e02-a257-b982bc9c2cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-1872f9bc-0020-4009-ad6b-71bb2de5e622,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-728f6576-835e-48a7-836d-8fd5afaa619c,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-a919bd8c-acfe-4e88-8f16-0fb66f762ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-c60e0119-7d03-4aee-b7d1-fab64444f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-25c9c3ed-38b3-471a-9d72-407bc9891fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191917047-172.17.0.5-1595942770923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37809,DS-b51e65d5-5e92-4920-a22d-4bc0b7940962,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-bfefda44-2030-44f5-accf-3dab9d8645b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-4bc22f29-d591-4450-b379-ccde626518db,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-49f96cb5-cd2c-4264-9fb1-303e69b0a7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-adca0b91-0662-4218-b5f0-b0325423ffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-d0d856a2-e6b5-43ec-b33e-d6dbd6f753fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-a4e35a86-6a0e-477c-8211-c7d58a015b23,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-180dc0f5-72ef-445f-86e5-08c22b17164f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191917047-172.17.0.5-1595942770923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37809,DS-b51e65d5-5e92-4920-a22d-4bc0b7940962,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-bfefda44-2030-44f5-accf-3dab9d8645b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-4bc22f29-d591-4450-b379-ccde626518db,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-49f96cb5-cd2c-4264-9fb1-303e69b0a7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-adca0b91-0662-4218-b5f0-b0325423ffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-d0d856a2-e6b5-43ec-b33e-d6dbd6f753fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-a4e35a86-6a0e-477c-8211-c7d58a015b23,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-180dc0f5-72ef-445f-86e5-08c22b17164f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461558307-172.17.0.5-1595943469725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36953,DS-fd6019eb-4445-4c76-ae41-6bc5ec3102af,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-e4cea906-95d3-4673-9325-a7723d7c0bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-93ff7fcb-4ced-4d4d-bfca-d952bfabb0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-87c4ec2a-1282-4cb0-beec-bd6adbd1abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-50c176b6-ef78-4401-b247-2e856b06219a,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-366e46f3-0ff1-4f65-884e-f76a27fc6ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-2cb1d096-e879-4c6e-856c-ed41e8d05781,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-0af0fcb9-21c7-4522-9425-303c83c8ce70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461558307-172.17.0.5-1595943469725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36953,DS-fd6019eb-4445-4c76-ae41-6bc5ec3102af,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-e4cea906-95d3-4673-9325-a7723d7c0bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-93ff7fcb-4ced-4d4d-bfca-d952bfabb0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-87c4ec2a-1282-4cb0-beec-bd6adbd1abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-50c176b6-ef78-4401-b247-2e856b06219a,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-366e46f3-0ff1-4f65-884e-f76a27fc6ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-2cb1d096-e879-4c6e-856c-ed41e8d05781,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-0af0fcb9-21c7-4522-9425-303c83c8ce70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946226213-172.17.0.5-1595943576222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-0fdd412c-a56d-4c28-a81c-0fbc5b5e0f13,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-13647c57-0fe4-48b4-a86c-73eebecf4882,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-98735cfb-5dc1-461c-8da4-44e954743745,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-9d66eb67-6e29-4bae-9f8a-5dfbdebab4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-f96ae143-914b-446b-b3b3-bca2d99f7786,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-9e8d4506-5b0a-4d72-aa9b-543f8f3fd8de,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-a41913c4-994c-4adf-90f8-2329837d5445,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-7d1d486f-6af9-4ca5-ab6a-84eaad58799b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946226213-172.17.0.5-1595943576222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-0fdd412c-a56d-4c28-a81c-0fbc5b5e0f13,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-13647c57-0fe4-48b4-a86c-73eebecf4882,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-98735cfb-5dc1-461c-8da4-44e954743745,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-9d66eb67-6e29-4bae-9f8a-5dfbdebab4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-f96ae143-914b-446b-b3b3-bca2d99f7786,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-9e8d4506-5b0a-4d72-aa9b-543f8f3fd8de,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-a41913c4-994c-4adf-90f8-2329837d5445,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-7d1d486f-6af9-4ca5-ab6a-84eaad58799b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784452830-172.17.0.5-1595944259230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41784,DS-ef3fdd56-45d8-4793-afac-d0c07c0b30af,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-b6ceffb0-2ee1-4b76-ac51-10f45d1b6417,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-604c9fb6-6974-4b61-93e3-ba8e9ce6d796,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-ef9c915d-72f9-4550-b7d5-f84a6cbdddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-90cee21d-69d1-400a-88cc-e5620263c820,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-dbf1326d-9544-4809-91e4-1129e5152c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-29527d5d-a3e5-4435-b8bf-e155d242fa09,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-9af5b8ce-174e-409a-a440-0d9e58f7c2ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784452830-172.17.0.5-1595944259230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41784,DS-ef3fdd56-45d8-4793-afac-d0c07c0b30af,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-b6ceffb0-2ee1-4b76-ac51-10f45d1b6417,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-604c9fb6-6974-4b61-93e3-ba8e9ce6d796,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-ef9c915d-72f9-4550-b7d5-f84a6cbdddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-90cee21d-69d1-400a-88cc-e5620263c820,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-dbf1326d-9544-4809-91e4-1129e5152c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-29527d5d-a3e5-4435-b8bf-e155d242fa09,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-9af5b8ce-174e-409a-a440-0d9e58f7c2ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664052284-172.17.0.5-1595945144591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-90175687-daa9-4090-8a2b-630ac32afefc,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-b969caac-e606-41ca-81cc-5ec0d0bbd2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-10230f44-f40f-423d-b5a1-7f663d97d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-3c5a0925-919a-446e-ae87-9de0536f86d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-744e0bdb-5fe8-47a0-bebb-e46ba1c7e792,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-eeb32c5d-14b0-4d34-895f-3dcdbcd8ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-0552565b-c878-4392-820d-b8d44b9d5ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-b3774f95-cbb5-4bbb-acb5-eec23a8e8cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664052284-172.17.0.5-1595945144591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45567,DS-90175687-daa9-4090-8a2b-630ac32afefc,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-b969caac-e606-41ca-81cc-5ec0d0bbd2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-10230f44-f40f-423d-b5a1-7f663d97d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-3c5a0925-919a-446e-ae87-9de0536f86d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-744e0bdb-5fe8-47a0-bebb-e46ba1c7e792,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-eeb32c5d-14b0-4d34-895f-3dcdbcd8ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-0552565b-c878-4392-820d-b8d44b9d5ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-b3774f95-cbb5-4bbb-acb5-eec23a8e8cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643070370-172.17.0.5-1595945986150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35264,DS-3f588b84-e562-414f-8311-3c727067b640,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-54659646-ffe4-46ad-a884-0aea3e496bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-60606515-292e-4a80-b650-f88bb7fb8f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-89c5e75f-5c0c-410d-9776-89d989fd9f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-d6f1e82b-0501-4282-ab6e-aeb601c3b345,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-132fd492-94eb-4811-ac14-931ae7414356,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-90ea3c0b-343d-4561-9354-5c1f58d4bee4,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-e73c2046-2e5f-47be-b9b0-854ebdda7fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643070370-172.17.0.5-1595945986150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35264,DS-3f588b84-e562-414f-8311-3c727067b640,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-54659646-ffe4-46ad-a884-0aea3e496bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-60606515-292e-4a80-b650-f88bb7fb8f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-89c5e75f-5c0c-410d-9776-89d989fd9f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-d6f1e82b-0501-4282-ab6e-aeb601c3b345,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-132fd492-94eb-4811-ac14-931ae7414356,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-90ea3c0b-343d-4561-9354-5c1f58d4bee4,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-e73c2046-2e5f-47be-b9b0-854ebdda7fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036021376-172.17.0.5-1595946300816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-88fc0f11-196a-4f1b-a7c3-92b3d85ae005,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-d34feff3-70a9-4723-a4c4-6ceaa3b13422,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-dd7fee5c-6aaa-45c6-8c51-eec3ae1df344,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-1a0f9358-71f3-4b06-a511-c2053ad29d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-1ce70d48-963f-43c4-a2fb-f8f0c22393aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-bd925498-7fa8-44ce-bcf3-996d7539ed08,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-cf6be17d-3681-4d35-b1fd-d7ef0f338eab,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-fd9278d7-3e87-4907-b939-484bda784ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036021376-172.17.0.5-1595946300816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-88fc0f11-196a-4f1b-a7c3-92b3d85ae005,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-d34feff3-70a9-4723-a4c4-6ceaa3b13422,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-dd7fee5c-6aaa-45c6-8c51-eec3ae1df344,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-1a0f9358-71f3-4b06-a511-c2053ad29d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-1ce70d48-963f-43c4-a2fb-f8f0c22393aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-bd925498-7fa8-44ce-bcf3-996d7539ed08,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-cf6be17d-3681-4d35-b1fd-d7ef0f338eab,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-fd9278d7-3e87-4907-b939-484bda784ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142960162-172.17.0.5-1595946381539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42057,DS-1a73bcd1-606e-4aae-b429-58457e61e4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-40a493cd-4ab1-47ff-b096-e1659b0bae81,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-1fef07bc-5c3c-49fe-9e0b-927206513b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-8994c1d2-8a47-4d5a-b377-26f083842b70,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-58521191-e760-4d96-9214-a966dc6a070a,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-e219f063-8039-4eb1-8c28-731756c9cbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-a664e36b-265d-4602-8ad1-5175b78ac697,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-88573072-d0cd-4a17-8455-4fe608ee062d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142960162-172.17.0.5-1595946381539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42057,DS-1a73bcd1-606e-4aae-b429-58457e61e4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-40a493cd-4ab1-47ff-b096-e1659b0bae81,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-1fef07bc-5c3c-49fe-9e0b-927206513b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-8994c1d2-8a47-4d5a-b377-26f083842b70,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-58521191-e760-4d96-9214-a966dc6a070a,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-e219f063-8039-4eb1-8c28-731756c9cbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-a664e36b-265d-4602-8ad1-5175b78ac697,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-88573072-d0cd-4a17-8455-4fe608ee062d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887851617-172.17.0.5-1595946456431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-3f1018ce-1e80-4d54-9249-06ed7defa2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-9605abd3-c846-43a5-9464-c79bb863d59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-2692d037-20d9-4b0f-8b8d-6295d93ed6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-b3b9dc49-3fe7-4cb2-ac2b-59d2544b3c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-9f49068a-b369-4f57-b0b9-a590a23d4622,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-b4033829-6582-4e09-b8a5-2b0478c111c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-76d0e0d2-0cb3-483b-8bb5-14c6c50cf11d,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-e51185bf-047b-4997-a22a-5688dfb62fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887851617-172.17.0.5-1595946456431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-3f1018ce-1e80-4d54-9249-06ed7defa2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-9605abd3-c846-43a5-9464-c79bb863d59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-2692d037-20d9-4b0f-8b8d-6295d93ed6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-b3b9dc49-3fe7-4cb2-ac2b-59d2544b3c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-9f49068a-b369-4f57-b0b9-a590a23d4622,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-b4033829-6582-4e09-b8a5-2b0478c111c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-76d0e0d2-0cb3-483b-8bb5-14c6c50cf11d,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-e51185bf-047b-4997-a22a-5688dfb62fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401273697-172.17.0.5-1595946541655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34705,DS-f67bc9b8-3572-416d-9c9f-748e5695e869,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-2c619cb4-36fa-48ea-9df3-f7afd02e8c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-18cbb616-ac39-46eb-bf1c-c62285bf2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-94fbe3dc-6213-4c5c-b6d7-74dcb8505541,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-32c8e7d2-5bb5-4b67-aeac-29482703a347,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-5a6f933a-867b-4b5c-aa12-8301e92f3433,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-59371b08-195f-4c7c-85d6-93fac54d37bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-7f102577-a6b7-4dea-95f5-eb02745c0804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401273697-172.17.0.5-1595946541655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34705,DS-f67bc9b8-3572-416d-9c9f-748e5695e869,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-2c619cb4-36fa-48ea-9df3-f7afd02e8c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-18cbb616-ac39-46eb-bf1c-c62285bf2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-94fbe3dc-6213-4c5c-b6d7-74dcb8505541,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-32c8e7d2-5bb5-4b67-aeac-29482703a347,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-5a6f933a-867b-4b5c-aa12-8301e92f3433,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-59371b08-195f-4c7c-85d6-93fac54d37bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-7f102577-a6b7-4dea-95f5-eb02745c0804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581889201-172.17.0.5-1595946576470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-8dee8faf-e493-4911-98f9-7dbba3374767,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-410faf6e-c323-4fa5-b2f1-0233a6b94368,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-37552603-8d29-47a9-b6b1-b687ce8f6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-f8e40f3a-1768-4114-bf85-9b04e659d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-c2e20c20-289d-449f-9b7c-2693ecaa8536,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-7d095d9f-7135-41d4-9680-bfb8755e29c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-5cdbf195-907a-476f-9772-f0202c57e0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-52369518-2186-4544-b22e-2a24f43f7426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581889201-172.17.0.5-1595946576470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-8dee8faf-e493-4911-98f9-7dbba3374767,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-410faf6e-c323-4fa5-b2f1-0233a6b94368,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-37552603-8d29-47a9-b6b1-b687ce8f6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-f8e40f3a-1768-4114-bf85-9b04e659d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-c2e20c20-289d-449f-9b7c-2693ecaa8536,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-7d095d9f-7135-41d4-9680-bfb8755e29c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-5cdbf195-907a-476f-9772-f0202c57e0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-52369518-2186-4544-b22e-2a24f43f7426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806554580-172.17.0.5-1595946789542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-26203c08-cd27-488c-bf33-1fbb27d1d22c,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-d6092021-3bcd-4dd8-becb-692e10dc37fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-d7debdf4-2649-4b23-aade-e3054c56710c,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-4348f74c-654b-48f0-a9e8-23612f0e9c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-2d33db02-c5f9-43ef-a2cb-3552c48cf42f,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-f45c4942-8c37-48a4-80ce-70c3f064e13e,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-9b693774-808e-4476-9360-ad0458205c52,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-076162b0-1bcf-46ed-b7f5-a3b9d2177007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806554580-172.17.0.5-1595946789542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-26203c08-cd27-488c-bf33-1fbb27d1d22c,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-d6092021-3bcd-4dd8-becb-692e10dc37fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-d7debdf4-2649-4b23-aade-e3054c56710c,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-4348f74c-654b-48f0-a9e8-23612f0e9c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-2d33db02-c5f9-43ef-a2cb-3552c48cf42f,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-f45c4942-8c37-48a4-80ce-70c3f064e13e,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-9b693774-808e-4476-9360-ad0458205c52,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-076162b0-1bcf-46ed-b7f5-a3b9d2177007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953731126-172.17.0.5-1595946950463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-121d4b94-76dd-49a5-9fd1-2e4c1c78eb79,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-7e93634c-7eac-4d2d-bc40-6bef9ec3f892,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-084a2a02-47a4-4947-8ee7-29ac9585284d,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-21ceae18-17c3-47bb-8bff-be9caf254566,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-85ff45ae-a65c-4265-a3f9-babdf4c6fd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-779e5156-4364-4896-9b70-46007fd028f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-7d04739a-5599-4f16-916e-3bf6fe8f2b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-94fe5ba7-634d-43a2-b409-02ba9140dd38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953731126-172.17.0.5-1595946950463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-121d4b94-76dd-49a5-9fd1-2e4c1c78eb79,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-7e93634c-7eac-4d2d-bc40-6bef9ec3f892,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-084a2a02-47a4-4947-8ee7-29ac9585284d,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-21ceae18-17c3-47bb-8bff-be9caf254566,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-85ff45ae-a65c-4265-a3f9-babdf4c6fd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-779e5156-4364-4896-9b70-46007fd028f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-7d04739a-5599-4f16-916e-3bf6fe8f2b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-94fe5ba7-634d-43a2-b409-02ba9140dd38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 5000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635592208-172.17.0.5-1595947027580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33739,DS-ca090e92-4f27-491e-94ce-6b888a8ebb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-a1c1d029-b11c-4016-9a3f-e3a84ec1fd42,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-4a7bbc31-6a80-44be-88d5-d81867d146a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-50852f41-cf4a-4f59-8076-d8b8275e7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-742b5c0e-9c4c-4653-b3cf-fada93d156d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-068b0576-900f-4e7c-8b2a-11e015292509,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-64f5c340-a4cb-4ae5-895e-49efd89915a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-3f89fdda-d40e-4629-be4c-00a3e0adb626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635592208-172.17.0.5-1595947027580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33739,DS-ca090e92-4f27-491e-94ce-6b888a8ebb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-a1c1d029-b11c-4016-9a3f-e3a84ec1fd42,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-4a7bbc31-6a80-44be-88d5-d81867d146a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-50852f41-cf4a-4f59-8076-d8b8275e7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-742b5c0e-9c4c-4653-b3cf-fada93d156d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-068b0576-900f-4e7c-8b2a-11e015292509,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-64f5c340-a4cb-4ae5-895e-49efd89915a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-3f89fdda-d40e-4629-be4c-00a3e0adb626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5409
