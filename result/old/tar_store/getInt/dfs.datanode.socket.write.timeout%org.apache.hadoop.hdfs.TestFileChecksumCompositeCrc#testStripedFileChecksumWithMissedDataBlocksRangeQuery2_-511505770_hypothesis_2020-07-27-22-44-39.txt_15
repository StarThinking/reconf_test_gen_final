reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741373220-172.17.0.16-1595890391059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34389,DS-7ff38260-fc0c-41c7-b2b9-efd1fdd67392,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-e84d294d-648e-4139-9175-fb4c7982e330,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-b436b4af-1ec3-4ab0-bdfb-df3e745b036b,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-be330995-e6b7-4a63-b27b-7d334dfbe6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-bf66d597-1970-4fe2-8915-d855c5b21a31,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-de6a131a-6f2f-4580-9cf4-472af30ed9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-6a667c19-680b-4f94-8e6c-44a7305bb051,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-3686f299-8b89-40c2-bb05-a22c09e1655b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741373220-172.17.0.16-1595890391059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34389,DS-7ff38260-fc0c-41c7-b2b9-efd1fdd67392,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-e84d294d-648e-4139-9175-fb4c7982e330,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-b436b4af-1ec3-4ab0-bdfb-df3e745b036b,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-be330995-e6b7-4a63-b27b-7d334dfbe6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-bf66d597-1970-4fe2-8915-d855c5b21a31,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-de6a131a-6f2f-4580-9cf4-472af30ed9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-6a667c19-680b-4f94-8e6c-44a7305bb051,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-3686f299-8b89-40c2-bb05-a22c09e1655b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285034910-172.17.0.16-1595890641422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-9bbb834b-b556-42eb-b27a-fe107bb17a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-7a6fbb75-7bd9-431b-962f-9d99f0cc1207,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-c8e31907-cdaf-482b-b7a7-579384418cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-f9527c72-a17f-4445-96a6-d9a1043aac14,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-df1b38d0-64bf-48d5-9a0e-ec7f3e74cee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-5a9ccb58-2ffb-4385-b420-45c4ae0ec07d,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-3db41bf7-639b-42f1-85c0-ef52d2a52afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-05360b15-99bd-4b8e-a53a-18735bc284db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285034910-172.17.0.16-1595890641422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-9bbb834b-b556-42eb-b27a-fe107bb17a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-7a6fbb75-7bd9-431b-962f-9d99f0cc1207,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-c8e31907-cdaf-482b-b7a7-579384418cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-f9527c72-a17f-4445-96a6-d9a1043aac14,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-df1b38d0-64bf-48d5-9a0e-ec7f3e74cee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-5a9ccb58-2ffb-4385-b420-45c4ae0ec07d,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-3db41bf7-639b-42f1-85c0-ef52d2a52afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-05360b15-99bd-4b8e-a53a-18735bc284db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665194534-172.17.0.16-1595890708472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38915,DS-1439aad2-0fdc-47e8-bc54-3fa7fbbc6fff,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-de6f58ae-e3b9-43be-a9f5-34e562b286e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-074c3b2a-a017-4158-90ec-f9955043581f,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-7acf0f86-8ffc-4d2e-824c-9b779159ae2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-d7e13de1-57f6-443e-89dd-0ec50c405bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-a29bb9ff-b270-4355-8640-c040f18528dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-212daa79-0def-4b9e-86c7-df35c36ff1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-be398ab1-c0bc-4afe-b50e-dd69190fe352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665194534-172.17.0.16-1595890708472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38915,DS-1439aad2-0fdc-47e8-bc54-3fa7fbbc6fff,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-de6f58ae-e3b9-43be-a9f5-34e562b286e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-074c3b2a-a017-4158-90ec-f9955043581f,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-7acf0f86-8ffc-4d2e-824c-9b779159ae2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-d7e13de1-57f6-443e-89dd-0ec50c405bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-a29bb9ff-b270-4355-8640-c040f18528dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-212daa79-0def-4b9e-86c7-df35c36ff1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-be398ab1-c0bc-4afe-b50e-dd69190fe352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662718305-172.17.0.16-1595892726470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41887,DS-5f101ffc-a2ef-491d-992e-419f6b16d474,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-43a7feeb-e58c-4c0e-8777-6422a4d735cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-e973b119-8f87-49cf-9abc-2992a628a25b,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-ec87958a-1ec5-4035-a920-3ae5c2b96a51,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-2fb9ea7d-94ec-4028-8183-dd44e1587a34,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-cfb9898f-ee88-45a2-a10f-298cae57246d,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-1c277e54-b58a-4c7f-a404-791a6a7730df,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-5e6b12ed-df9b-4511-85f8-26a2830aba94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662718305-172.17.0.16-1595892726470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41887,DS-5f101ffc-a2ef-491d-992e-419f6b16d474,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-43a7feeb-e58c-4c0e-8777-6422a4d735cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-e973b119-8f87-49cf-9abc-2992a628a25b,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-ec87958a-1ec5-4035-a920-3ae5c2b96a51,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-2fb9ea7d-94ec-4028-8183-dd44e1587a34,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-cfb9898f-ee88-45a2-a10f-298cae57246d,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-1c277e54-b58a-4c7f-a404-791a6a7730df,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-5e6b12ed-df9b-4511-85f8-26a2830aba94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077897456-172.17.0.16-1595892920942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-ac419d38-2308-4c6b-beef-7a67fc5adebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-118b3e94-37d2-441c-9297-f7e49cb93324,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-c39b22b5-85f3-47bd-ac62-d7851884a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-bb4a6f87-fb45-42e9-a515-5fb81e3f5028,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-7080cd23-01fd-4c19-9999-161cc6a0a2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-07d5ee4c-60e6-4d4d-8f34-d7621b14ef42,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-7feedc19-394a-4b2c-aaf3-85c53ab7c953,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-819d68fa-a5b1-49aa-848d-dabe43b1b177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077897456-172.17.0.16-1595892920942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-ac419d38-2308-4c6b-beef-7a67fc5adebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-118b3e94-37d2-441c-9297-f7e49cb93324,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-c39b22b5-85f3-47bd-ac62-d7851884a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-bb4a6f87-fb45-42e9-a515-5fb81e3f5028,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-7080cd23-01fd-4c19-9999-161cc6a0a2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-07d5ee4c-60e6-4d4d-8f34-d7621b14ef42,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-7feedc19-394a-4b2c-aaf3-85c53ab7c953,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-819d68fa-a5b1-49aa-848d-dabe43b1b177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962630775-172.17.0.16-1595893227835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37263,DS-5f0d463d-a666-46e6-80b1-9a03a6770209,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-7405987f-ba07-40d0-bfdf-4558c5dfd07e,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-52f133cc-4746-4fc2-b575-15f8fb56f9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-aa1b27e0-5c32-4d57-8ef8-60da9a2d9007,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-556592b3-d12c-42be-86eb-925215d8a32e,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-29c653bc-5311-4b9c-9409-80a314272018,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-fa5b2100-6bb1-4aed-adc7-25fb29841932,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-7c16f34a-ec64-45dd-b6bf-6575528745f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962630775-172.17.0.16-1595893227835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37263,DS-5f0d463d-a666-46e6-80b1-9a03a6770209,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-7405987f-ba07-40d0-bfdf-4558c5dfd07e,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-52f133cc-4746-4fc2-b575-15f8fb56f9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-aa1b27e0-5c32-4d57-8ef8-60da9a2d9007,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-556592b3-d12c-42be-86eb-925215d8a32e,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-29c653bc-5311-4b9c-9409-80a314272018,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-fa5b2100-6bb1-4aed-adc7-25fb29841932,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-7c16f34a-ec64-45dd-b6bf-6575528745f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917769102-172.17.0.16-1595893410628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-61d46b4d-1f56-4078-8af6-b4957c7e2990,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-a34256b4-acd0-4962-817f-f57a35552cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-72e123f5-ac78-44e1-bf9a-422a37f3cbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-d332c09b-8642-48d3-b2e5-a7c7208be8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-8fd8b2af-31b0-43aa-a139-76d559a28f09,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-ec022198-fadd-4b97-a67e-803e856b96e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-fbba220b-357a-479c-9cc4-126ef1fb27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-70ee1dfa-5cc8-439e-a1ca-fcb18633a3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917769102-172.17.0.16-1595893410628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-61d46b4d-1f56-4078-8af6-b4957c7e2990,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-a34256b4-acd0-4962-817f-f57a35552cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-72e123f5-ac78-44e1-bf9a-422a37f3cbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-d332c09b-8642-48d3-b2e5-a7c7208be8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-8fd8b2af-31b0-43aa-a139-76d559a28f09,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-ec022198-fadd-4b97-a67e-803e856b96e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-fbba220b-357a-479c-9cc4-126ef1fb27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-70ee1dfa-5cc8-439e-a1ca-fcb18633a3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751370837-172.17.0.16-1595893517159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-be1e8b53-492a-4533-a91f-91e5d680c009,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-d3df1fc0-fd07-44bb-8559-d2c67a485b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-63228518-bab2-43de-852f-9f67aaf5491a,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-83f10e7f-d8cc-4806-98b7-a95c6cf84c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-b6c3a580-8b46-4e82-9f63-99d4ce567490,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-cb45fac6-96c0-4032-afab-a85a741c41d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-b519039b-b25b-4d42-8422-b07e783d9503,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-a638fdd9-6095-4e16-892d-0bbed36fcf35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751370837-172.17.0.16-1595893517159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-be1e8b53-492a-4533-a91f-91e5d680c009,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-d3df1fc0-fd07-44bb-8559-d2c67a485b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-63228518-bab2-43de-852f-9f67aaf5491a,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-83f10e7f-d8cc-4806-98b7-a95c6cf84c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-b6c3a580-8b46-4e82-9f63-99d4ce567490,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-cb45fac6-96c0-4032-afab-a85a741c41d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-b519039b-b25b-4d42-8422-b07e783d9503,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-a638fdd9-6095-4e16-892d-0bbed36fcf35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399873071-172.17.0.16-1595894425730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33265,DS-38036f29-d295-4ad8-a174-ed6c872a6cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-c9868415-b46d-4906-b063-f8d078707686,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-87be5933-3ad5-4a87-b478-2757b1fa9628,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-2c6c93cc-179d-4da4-88bf-d59ba9820d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-b6dfacb4-158e-4833-a0b0-63d3ec9f5cac,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-980b7fec-eff6-4cb3-a7f2-c5462d992ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-50f82098-c6f2-4478-8ecf-40c8f356edbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-bf2a39dc-414a-48d7-9c55-2f44f302fb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399873071-172.17.0.16-1595894425730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33265,DS-38036f29-d295-4ad8-a174-ed6c872a6cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-c9868415-b46d-4906-b063-f8d078707686,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-87be5933-3ad5-4a87-b478-2757b1fa9628,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-2c6c93cc-179d-4da4-88bf-d59ba9820d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-b6dfacb4-158e-4833-a0b0-63d3ec9f5cac,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-980b7fec-eff6-4cb3-a7f2-c5462d992ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-50f82098-c6f2-4478-8ecf-40c8f356edbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-bf2a39dc-414a-48d7-9c55-2f44f302fb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675695840-172.17.0.16-1595895061091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44453,DS-0ee0917d-61ce-478e-a088-677b6ee94001,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-910e63a4-9533-47c8-ba65-003356052c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-7eee0f0c-2c49-4d58-950b-c4da5f46b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-3ec820d1-1490-4ab4-a2c7-7265b5b91c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-1f4614ed-bdf5-4f54-9245-1a21094fb257,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-a5fc57ec-dafd-4218-87f9-a12efd568e06,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-cd44cd21-7061-49e4-af87-de3b5e7eae5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-1b73bc20-c8e6-4672-8927-aae70ed9f08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675695840-172.17.0.16-1595895061091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44453,DS-0ee0917d-61ce-478e-a088-677b6ee94001,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-910e63a4-9533-47c8-ba65-003356052c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-7eee0f0c-2c49-4d58-950b-c4da5f46b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-3ec820d1-1490-4ab4-a2c7-7265b5b91c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-1f4614ed-bdf5-4f54-9245-1a21094fb257,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-a5fc57ec-dafd-4218-87f9-a12efd568e06,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-cd44cd21-7061-49e4-af87-de3b5e7eae5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-1b73bc20-c8e6-4672-8927-aae70ed9f08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605355799-172.17.0.16-1595895285855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-3088b80e-b663-4b32-8ebf-72a41d9476f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-9c3b875f-a067-4d28-a21b-691e670bb649,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-94e4b519-eab3-436e-830a-650c77ff41b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-891ae0d3-97a2-4799-abc6-3b8aefd90d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-c6ca5034-93f6-4634-85b3-2bd92810da0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-1d36b4a1-fa8f-4e86-8ff1-79d2e3465fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-3d61d058-73fe-4923-b00b-f9f5cf84024a,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-b8d34e44-3608-4321-92b6-f05d351bcf94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605355799-172.17.0.16-1595895285855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-3088b80e-b663-4b32-8ebf-72a41d9476f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-9c3b875f-a067-4d28-a21b-691e670bb649,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-94e4b519-eab3-436e-830a-650c77ff41b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-891ae0d3-97a2-4799-abc6-3b8aefd90d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-c6ca5034-93f6-4634-85b3-2bd92810da0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-1d36b4a1-fa8f-4e86-8ff1-79d2e3465fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-3d61d058-73fe-4923-b00b-f9f5cf84024a,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-b8d34e44-3608-4321-92b6-f05d351bcf94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5510
