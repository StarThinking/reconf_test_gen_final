reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302329247-172.17.0.11-1595813140800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45176,DS-06ff5f04-7800-4765-b5fe-7eb49eca3aea,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-8ce8cd99-7d2d-4169-ac71-33ac179977f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-e6c6d078-271a-4975-bcd6-3c6e5b94d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-24086cc9-af2c-4ca7-bda3-35416258ea85,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-7d2295ab-dd90-49da-94d0-1a5186c82e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-f9e237d6-6c6d-46df-b3ab-772e51a09679,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-96f069a7-e8b1-4c13-b7af-a015e4c8c5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-2f62cc0d-868b-4cf4-acf0-96e38909c86c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302329247-172.17.0.11-1595813140800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45176,DS-06ff5f04-7800-4765-b5fe-7eb49eca3aea,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-8ce8cd99-7d2d-4169-ac71-33ac179977f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-e6c6d078-271a-4975-bcd6-3c6e5b94d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-24086cc9-af2c-4ca7-bda3-35416258ea85,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-7d2295ab-dd90-49da-94d0-1a5186c82e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-f9e237d6-6c6d-46df-b3ab-772e51a09679,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-96f069a7-e8b1-4c13-b7af-a015e4c8c5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-2f62cc0d-868b-4cf4-acf0-96e38909c86c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923717815-172.17.0.11-1595813291072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41430,DS-201fcd07-8ced-4a22-8c75-daf2dd9a22f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-7d685082-b296-40b1-ae16-c2b10daf5f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-132c71df-c5f2-4047-9d03-661a24e53f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-e1a785b7-8a66-4cc6-b8a7-8347581c4169,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-19820915-9b2c-4f6f-a907-3a82f9d671bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-4b23e257-2851-47e0-b41d-8bf2aa4f5edd,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-41276a13-832f-4b43-8e2d-a5ec92541052,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-76fa6d1c-891b-4131-9e06-d53dedacc61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923717815-172.17.0.11-1595813291072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41430,DS-201fcd07-8ced-4a22-8c75-daf2dd9a22f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-7d685082-b296-40b1-ae16-c2b10daf5f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-132c71df-c5f2-4047-9d03-661a24e53f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-e1a785b7-8a66-4cc6-b8a7-8347581c4169,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-19820915-9b2c-4f6f-a907-3a82f9d671bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-4b23e257-2851-47e0-b41d-8bf2aa4f5edd,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-41276a13-832f-4b43-8e2d-a5ec92541052,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-76fa6d1c-891b-4131-9e06-d53dedacc61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611376025-172.17.0.11-1595813848689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-47922e29-825d-41f8-9008-7ddeda25bb31,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-9d7fd6e1-d24e-4dc2-8e33-c59f6962ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-3e9884ef-4436-474e-a4eb-ada6a4899af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-040d9f3a-0bda-430f-b80f-8e6f2b723470,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-25ce892f-72a1-4c8f-bdf5-dee1f7908f73,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-f8a22789-1ae8-412a-b3dc-f3fcae5751bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-51d34d7d-36ac-4783-b8fa-964c402f330f,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-6b3fdbb8-0cf2-4be5-94d8-1b19d6bb8cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611376025-172.17.0.11-1595813848689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-47922e29-825d-41f8-9008-7ddeda25bb31,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-9d7fd6e1-d24e-4dc2-8e33-c59f6962ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-3e9884ef-4436-474e-a4eb-ada6a4899af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-040d9f3a-0bda-430f-b80f-8e6f2b723470,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-25ce892f-72a1-4c8f-bdf5-dee1f7908f73,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-f8a22789-1ae8-412a-b3dc-f3fcae5751bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-51d34d7d-36ac-4783-b8fa-964c402f330f,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-6b3fdbb8-0cf2-4be5-94d8-1b19d6bb8cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280972044-172.17.0.11-1595813972645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43624,DS-9d91351f-ad34-41d7-8367-8bcc502c74f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-26d46609-df55-4779-a923-9f1eeb896cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-de89a51a-1ffd-4f51-9354-6b0b0ef48895,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-f1ffc58a-200a-4ae7-844c-eed172ae3001,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-300f9c01-ba13-4fd8-8bba-26090e89a160,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-dc3f8299-7d4c-4519-960d-d878f8bdc505,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-b49d836d-a649-4500-81bb-9d599fd3eb07,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-9c11bd8a-8d1e-4c3b-bee2-1ce97bc43815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280972044-172.17.0.11-1595813972645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43624,DS-9d91351f-ad34-41d7-8367-8bcc502c74f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-26d46609-df55-4779-a923-9f1eeb896cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-de89a51a-1ffd-4f51-9354-6b0b0ef48895,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-f1ffc58a-200a-4ae7-844c-eed172ae3001,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-300f9c01-ba13-4fd8-8bba-26090e89a160,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-dc3f8299-7d4c-4519-960d-d878f8bdc505,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-b49d836d-a649-4500-81bb-9d599fd3eb07,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-9c11bd8a-8d1e-4c3b-bee2-1ce97bc43815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254367838-172.17.0.11-1595814088432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45198,DS-fd03b3a0-4cbe-4602-a299-3d49b57a836d,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-8f5f1178-723c-446f-a974-2aaa1012f5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-9f222432-8f02-4730-8f0d-1a6f6e500e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-ad6a835f-c265-43bb-8c56-159116eaf9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-117a0eaf-676d-4862-9bed-6f46a19abcac,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-875e26a9-ad57-4717-9de2-12d3747d1d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-3dd29d89-2cbc-4ae2-93d3-9e865f7c9d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-6364bb4c-8ffb-4de6-9d2a-804de655d90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254367838-172.17.0.11-1595814088432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45198,DS-fd03b3a0-4cbe-4602-a299-3d49b57a836d,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-8f5f1178-723c-446f-a974-2aaa1012f5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-9f222432-8f02-4730-8f0d-1a6f6e500e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-ad6a835f-c265-43bb-8c56-159116eaf9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-117a0eaf-676d-4862-9bed-6f46a19abcac,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-875e26a9-ad57-4717-9de2-12d3747d1d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-3dd29d89-2cbc-4ae2-93d3-9e865f7c9d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-6364bb4c-8ffb-4de6-9d2a-804de655d90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684581409-172.17.0.11-1595814206524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46873,DS-69e80b0d-7441-46b4-9047-a46c470072ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-b60efb43-23a9-446d-b8ba-67af2fefeca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-9b543033-18e8-4612-b652-632a2b1096a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-d4fd74fd-3b39-4be7-b734-9d7be1422b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-3c4670b1-cc1f-440d-a96b-0585014ed3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-3340c5e0-4ded-42a4-a8e1-6f850f9f99ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-7b15c8af-6505-40fe-852b-803e97264dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-a96a6b8f-5979-439d-9081-fd46430ed4af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684581409-172.17.0.11-1595814206524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46873,DS-69e80b0d-7441-46b4-9047-a46c470072ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-b60efb43-23a9-446d-b8ba-67af2fefeca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-9b543033-18e8-4612-b652-632a2b1096a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-d4fd74fd-3b39-4be7-b734-9d7be1422b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-3c4670b1-cc1f-440d-a96b-0585014ed3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-3340c5e0-4ded-42a4-a8e1-6f850f9f99ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-7b15c8af-6505-40fe-852b-803e97264dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-a96a6b8f-5979-439d-9081-fd46430ed4af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140220151-172.17.0.11-1595814386835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34453,DS-91bd0c84-6bfd-4542-9d91-919ace361903,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-abfc7b26-b8cc-4d07-ad05-b5e86ac6fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-02f14bf3-de04-41a8-839e-cdca2115401b,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-bb2c8665-7a13-41f6-8101-e6424d15a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-751cd069-97d8-4217-892f-f59a44ae23f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-bf2e9733-5a50-44e9-a497-32ade0484072,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-bd58747f-d8f5-49bd-9566-e11dbb93140f,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-d6538553-2211-4403-86ab-1a3699a0aeed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140220151-172.17.0.11-1595814386835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34453,DS-91bd0c84-6bfd-4542-9d91-919ace361903,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-abfc7b26-b8cc-4d07-ad05-b5e86ac6fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-02f14bf3-de04-41a8-839e-cdca2115401b,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-bb2c8665-7a13-41f6-8101-e6424d15a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-751cd069-97d8-4217-892f-f59a44ae23f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-bf2e9733-5a50-44e9-a497-32ade0484072,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-bd58747f-d8f5-49bd-9566-e11dbb93140f,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-d6538553-2211-4403-86ab-1a3699a0aeed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979394387-172.17.0.11-1595815372325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-fe5d6ec0-eff4-4ad1-9a13-b349f91f1f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-8ad60f7d-f91c-4479-b900-cda1f2858aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-f449520c-d47f-40d7-8e6e-6593bc4f4f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-7ba65a13-521c-44b3-bbdf-7398a963ca98,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-1510ac92-f1b3-44ac-b625-8402c81ee8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-25dccc82-0008-42e6-a92b-973f7ad47c73,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-7857336b-954c-479c-829c-3902776364c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-dc35f174-e3ae-49e2-94cc-4575ec320ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979394387-172.17.0.11-1595815372325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-fe5d6ec0-eff4-4ad1-9a13-b349f91f1f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-8ad60f7d-f91c-4479-b900-cda1f2858aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-f449520c-d47f-40d7-8e6e-6593bc4f4f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-7ba65a13-521c-44b3-bbdf-7398a963ca98,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-1510ac92-f1b3-44ac-b625-8402c81ee8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-25dccc82-0008-42e6-a92b-973f7ad47c73,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-7857336b-954c-479c-829c-3902776364c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-dc35f174-e3ae-49e2-94cc-4575ec320ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249652105-172.17.0.11-1595815403664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-3d47bd36-1b4c-4ba5-b986-ebaf6e68b578,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-70ede0d6-f6c0-47c6-97dc-4da8a1d4be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-a4db6cc8-32ae-4754-aa46-d4d9ab83a955,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-29526ee7-55a5-40f0-92a4-5d4fa96de575,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-f97c9b37-99f8-4caf-895f-46bdbc854a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-1110ca7b-5f7e-470d-8385-9a5b153c73ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-ce31e4e8-6096-4c1b-b137-c56cc92e2758,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-e47fda12-dc7d-45df-8a9b-be34f1bf9e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249652105-172.17.0.11-1595815403664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-3d47bd36-1b4c-4ba5-b986-ebaf6e68b578,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-70ede0d6-f6c0-47c6-97dc-4da8a1d4be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-a4db6cc8-32ae-4754-aa46-d4d9ab83a955,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-29526ee7-55a5-40f0-92a4-5d4fa96de575,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-f97c9b37-99f8-4caf-895f-46bdbc854a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-1110ca7b-5f7e-470d-8385-9a5b153c73ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-ce31e4e8-6096-4c1b-b137-c56cc92e2758,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-e47fda12-dc7d-45df-8a9b-be34f1bf9e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630507469-172.17.0.11-1595815614518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-c61478cf-56e2-4060-b425-e9aa288b3b88,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-34832bca-70db-4c31-ab33-e29a93d4a28b,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-dc56ce73-b401-46f2-a3b9-aaad6ee3b208,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-3e0cbb67-d50c-4126-81ec-e25c6cc2ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-06f2184d-5bd0-4ad4-b555-233d56e7b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-a1402e1f-b598-4788-8446-fd2169e8ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-63ee412e-48dd-46be-acb2-c0557e34058d,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-1fd2410f-cfac-479c-a0ed-f621a5ca3dd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630507469-172.17.0.11-1595815614518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-c61478cf-56e2-4060-b425-e9aa288b3b88,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-34832bca-70db-4c31-ab33-e29a93d4a28b,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-dc56ce73-b401-46f2-a3b9-aaad6ee3b208,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-3e0cbb67-d50c-4126-81ec-e25c6cc2ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-06f2184d-5bd0-4ad4-b555-233d56e7b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-a1402e1f-b598-4788-8446-fd2169e8ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-63ee412e-48dd-46be-acb2-c0557e34058d,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-1fd2410f-cfac-479c-a0ed-f621a5ca3dd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958819581-172.17.0.11-1595816321853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-5671d606-4620-4680-8a5a-c1c82bef86ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-3ebe6491-96e6-4b8f-97ae-8bb96a7c0048,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-5e07cb1b-db6a-4e7e-9fcd-27b428327cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-b243ca48-0a37-4ac3-9a74-4d8eaea79bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-4f740d79-e942-40a7-a430-564ab42aa041,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-d495b895-dd18-4657-90d7-9b1a861bfbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-1405b54a-eb8d-482a-9316-3222376cacd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-bcb4c683-e11f-4dc8-a5c9-5f3cc5877075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958819581-172.17.0.11-1595816321853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-5671d606-4620-4680-8a5a-c1c82bef86ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-3ebe6491-96e6-4b8f-97ae-8bb96a7c0048,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-5e07cb1b-db6a-4e7e-9fcd-27b428327cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-b243ca48-0a37-4ac3-9a74-4d8eaea79bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-4f740d79-e942-40a7-a430-564ab42aa041,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-d495b895-dd18-4657-90d7-9b1a861bfbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-1405b54a-eb8d-482a-9316-3222376cacd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-bcb4c683-e11f-4dc8-a5c9-5f3cc5877075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891918233-172.17.0.11-1595816402714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-d90e8e60-f582-4521-99d0-33eed27b9337,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-3be31d66-6899-42bf-99e0-6fd3fe283972,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-aafdae5a-4421-4c30-bf80-c0487e3b2707,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-f2579041-73d8-4fce-8368-f34f4ec89e18,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-8bfed851-041f-4635-b493-6473da9312a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-e89cd5bb-511c-430c-a28d-84044e272c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-c973654a-47ad-4b5c-b247-b75fc503f328,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-9ec6e1a0-fbfd-4819-a2eb-f435b13f8306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891918233-172.17.0.11-1595816402714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-d90e8e60-f582-4521-99d0-33eed27b9337,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-3be31d66-6899-42bf-99e0-6fd3fe283972,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-aafdae5a-4421-4c30-bf80-c0487e3b2707,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-f2579041-73d8-4fce-8368-f34f4ec89e18,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-8bfed851-041f-4635-b493-6473da9312a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-e89cd5bb-511c-430c-a28d-84044e272c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-c973654a-47ad-4b5c-b247-b75fc503f328,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-9ec6e1a0-fbfd-4819-a2eb-f435b13f8306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178076694-172.17.0.11-1595817747364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40157,DS-4368a988-ae55-4bc2-b50d-2b9949852551,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-5ddbbc9e-b849-4938-95d2-816ea17f2a08,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-90374622-a739-4fe0-bc58-a6840081c6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-e37e323b-d4f7-407d-b925-b19dfcba228a,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-73d6c7a6-a0ab-45b2-ab30-00e653588050,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-c013faf6-26ff-4ffe-8c25-54835ededf47,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-598cabc7-518f-490d-86f3-be55a3507873,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-20ce0366-6677-4256-a740-a1a4b97efc8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178076694-172.17.0.11-1595817747364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40157,DS-4368a988-ae55-4bc2-b50d-2b9949852551,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-5ddbbc9e-b849-4938-95d2-816ea17f2a08,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-90374622-a739-4fe0-bc58-a6840081c6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-e37e323b-d4f7-407d-b925-b19dfcba228a,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-73d6c7a6-a0ab-45b2-ab30-00e653588050,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-c013faf6-26ff-4ffe-8c25-54835ededf47,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-598cabc7-518f-490d-86f3-be55a3507873,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-20ce0366-6677-4256-a740-a1a4b97efc8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512187807-172.17.0.11-1595818356306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40258,DS-03469c2d-6c75-41f7-a41d-d4f88d391ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-7b5e37dd-33d7-443b-b6eb-ec4339f790eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-a80f31e2-7386-41f4-a654-3d71b749c022,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-a7575427-0408-4f84-93db-eacdbb549f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-db0e8ca5-416f-40a6-8cce-fec107627897,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-3eb38211-57eb-402e-ba0a-03821a4ae535,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-772773e6-3ebb-4f46-b706-31bedc7d137b,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-02d245be-f93a-4645-ab53-6e92e92fde48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512187807-172.17.0.11-1595818356306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40258,DS-03469c2d-6c75-41f7-a41d-d4f88d391ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-7b5e37dd-33d7-443b-b6eb-ec4339f790eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-a80f31e2-7386-41f4-a654-3d71b749c022,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-a7575427-0408-4f84-93db-eacdbb549f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-db0e8ca5-416f-40a6-8cce-fec107627897,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-3eb38211-57eb-402e-ba0a-03821a4ae535,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-772773e6-3ebb-4f46-b706-31bedc7d137b,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-02d245be-f93a-4645-ab53-6e92e92fde48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999889849-172.17.0.11-1595818392220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-6d6d8f9a-9f1d-4607-bf92-bce0f1fe8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-bf7c3174-9b65-4e86-8eb0-8468bfc382d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-f6c7951e-56cc-413c-8108-01560e484cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-a9b3117a-0a0e-4902-97d1-ea1c3e3af3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-ee964717-6842-4f8d-be98-6a0e460d909a,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-86336acb-7d75-4de7-ac7e-99035e5c6257,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-f4f69a09-9e25-4097-8857-cf29651a9c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-8494f57d-337b-4c3e-92d7-91b2c0b13e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999889849-172.17.0.11-1595818392220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-6d6d8f9a-9f1d-4607-bf92-bce0f1fe8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-bf7c3174-9b65-4e86-8eb0-8468bfc382d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-f6c7951e-56cc-413c-8108-01560e484cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-a9b3117a-0a0e-4902-97d1-ea1c3e3af3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-ee964717-6842-4f8d-be98-6a0e460d909a,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-86336acb-7d75-4de7-ac7e-99035e5c6257,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-f4f69a09-9e25-4097-8857-cf29651a9c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-8494f57d-337b-4c3e-92d7-91b2c0b13e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177800724-172.17.0.11-1595818452524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37708,DS-854adca6-7f58-4b57-af2f-93526095ac27,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-232c91f2-9d42-4d22-9175-989cbd18616f,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-8af795bd-333d-4b6a-976a-73a324d5828d,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-b567c525-08f6-4be7-86e4-54b79313126a,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-66e0e386-4f0e-43e4-adb7-5b98b5684c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-2df196ae-5a8c-4ff0-bc5a-1a584889b572,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-a0339b19-40fb-48b2-bc27-a2eb450c43f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-6a837d6b-a59d-4f09-8518-238ed12b2882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177800724-172.17.0.11-1595818452524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37708,DS-854adca6-7f58-4b57-af2f-93526095ac27,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-232c91f2-9d42-4d22-9175-989cbd18616f,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-8af795bd-333d-4b6a-976a-73a324d5828d,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-b567c525-08f6-4be7-86e4-54b79313126a,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-66e0e386-4f0e-43e4-adb7-5b98b5684c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-2df196ae-5a8c-4ff0-bc5a-1a584889b572,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-a0339b19-40fb-48b2-bc27-a2eb450c43f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-6a837d6b-a59d-4f09-8518-238ed12b2882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5416
