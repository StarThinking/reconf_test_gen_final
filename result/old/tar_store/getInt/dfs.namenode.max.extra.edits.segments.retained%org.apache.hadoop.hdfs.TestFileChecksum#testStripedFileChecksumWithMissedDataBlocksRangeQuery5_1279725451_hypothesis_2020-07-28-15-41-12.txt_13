reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896425867-172.17.0.19-1595951374991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33371,DS-1ca44d0a-ab83-4c8d-b3e4-7ee7fc8f978d,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-4a7bf63a-2f2a-40f3-b522-3259c0d2b1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-774607d6-68f9-4ba2-8812-072c0bbe3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-a2dafd10-c989-43bb-a0a9-bf25c8070237,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-6e1767c9-afb7-47b0-a40f-57994d712ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-770f942f-8d44-4305-b749-317e3d892afd,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-85c39b48-8a3a-4981-b371-659ee99ecd28,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-8f3b0a75-cff5-49d2-ab38-e3afe05ccadf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896425867-172.17.0.19-1595951374991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33371,DS-1ca44d0a-ab83-4c8d-b3e4-7ee7fc8f978d,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-4a7bf63a-2f2a-40f3-b522-3259c0d2b1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-774607d6-68f9-4ba2-8812-072c0bbe3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-a2dafd10-c989-43bb-a0a9-bf25c8070237,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-6e1767c9-afb7-47b0-a40f-57994d712ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-770f942f-8d44-4305-b749-317e3d892afd,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-85c39b48-8a3a-4981-b371-659ee99ecd28,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-8f3b0a75-cff5-49d2-ab38-e3afe05ccadf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129002224-172.17.0.19-1595951414717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-7c6dd1fd-077f-4f22-bd55-4f9ba0d4393a,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-cdfbadd9-0d6a-41b2-94a6-59341a1924a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-d0f355cc-a29b-4e8d-a8af-c303ab4596b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-25e7395f-2b96-4108-b83b-fcd3ec84e7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-92dfd4fb-290a-4d83-9751-d235d01a50ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-10fa9091-34dc-449b-9f4b-fb284939448e,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-69707e44-7f90-4109-a710-34fb94d7394b,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-0f43c101-3ba0-414a-bfcf-658af6323c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129002224-172.17.0.19-1595951414717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-7c6dd1fd-077f-4f22-bd55-4f9ba0d4393a,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-cdfbadd9-0d6a-41b2-94a6-59341a1924a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-d0f355cc-a29b-4e8d-a8af-c303ab4596b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-25e7395f-2b96-4108-b83b-fcd3ec84e7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-92dfd4fb-290a-4d83-9751-d235d01a50ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-10fa9091-34dc-449b-9f4b-fb284939448e,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-69707e44-7f90-4109-a710-34fb94d7394b,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-0f43c101-3ba0-414a-bfcf-658af6323c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423825595-172.17.0.19-1595951489185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-726b2ab0-d36d-4161-9160-07e998c88795,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-0357a27d-807f-47c7-b35c-d6998efb6ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-c10970bc-9f88-4b41-a2f5-005fa5ef8123,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-267439b3-5b42-4376-aee7-03d4a2a732fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-931c5adc-1d0e-494c-91c1-6592114f43f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-535b608c-c790-4a01-a109-388de52ca8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-58d4286a-7a8d-4eb6-a895-74a34410bfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-5372e00e-25fa-4431-b103-f21b2a6fb87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423825595-172.17.0.19-1595951489185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-726b2ab0-d36d-4161-9160-07e998c88795,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-0357a27d-807f-47c7-b35c-d6998efb6ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-c10970bc-9f88-4b41-a2f5-005fa5ef8123,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-267439b3-5b42-4376-aee7-03d4a2a732fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-931c5adc-1d0e-494c-91c1-6592114f43f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-535b608c-c790-4a01-a109-388de52ca8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-58d4286a-7a8d-4eb6-a895-74a34410bfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-5372e00e-25fa-4431-b103-f21b2a6fb87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267245534-172.17.0.19-1595951793976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-3df1868b-59c5-492d-b959-551651ae6bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-4f5221de-9e3f-495a-98e6-64ad06ec2922,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-f35a2457-fd38-4851-b98d-045a042d694c,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-1ab572e4-8b5f-4dff-8101-350fac2f4c78,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-8e13c788-eec4-4010-9a48-8b06b88da40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-8d9b23a0-74df-41b4-bc65-39e30ddfe89f,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-99382ddb-ee90-4f66-91bd-a6b2335a64a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-eaae1267-f384-44a3-8219-4573abfc06b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267245534-172.17.0.19-1595951793976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-3df1868b-59c5-492d-b959-551651ae6bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-4f5221de-9e3f-495a-98e6-64ad06ec2922,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-f35a2457-fd38-4851-b98d-045a042d694c,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-1ab572e4-8b5f-4dff-8101-350fac2f4c78,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-8e13c788-eec4-4010-9a48-8b06b88da40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-8d9b23a0-74df-41b4-bc65-39e30ddfe89f,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-99382ddb-ee90-4f66-91bd-a6b2335a64a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-eaae1267-f384-44a3-8219-4573abfc06b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072175863-172.17.0.19-1595951871629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-f2d83423-a27e-40f8-85d4-43677ddd0282,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-69e633fd-fb13-40c2-9bdc-859fb9672cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-e9dec041-5e08-463e-8637-c6c27b4089f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-8ad6a0a6-0903-4bf4-b634-d95c559ef692,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-d8e3f29c-d213-4957-82b0-76f8c899ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-caf830d7-005b-4c88-9d4c-175775a262f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-4a901f30-c9ff-41db-8e47-9159b02e90dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-dfa4bdea-d3e3-46fc-8b43-7c4a07a4911d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072175863-172.17.0.19-1595951871629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-f2d83423-a27e-40f8-85d4-43677ddd0282,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-69e633fd-fb13-40c2-9bdc-859fb9672cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-e9dec041-5e08-463e-8637-c6c27b4089f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-8ad6a0a6-0903-4bf4-b634-d95c559ef692,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-d8e3f29c-d213-4957-82b0-76f8c899ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-caf830d7-005b-4c88-9d4c-175775a262f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-4a901f30-c9ff-41db-8e47-9159b02e90dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-dfa4bdea-d3e3-46fc-8b43-7c4a07a4911d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245485441-172.17.0.19-1595951908415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-e63cde2d-0229-4d36-92c6-022a71282481,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-7e09af8a-a275-4f7a-b23f-d5d75d7ab9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-c3dfa1f0-b0cd-45e4-97a5-13b23ea4315e,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-18d787ac-5476-4ac5-8bc6-d7096e0b9c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-6d1f9161-1dc9-44ce-a485-7ab41da97adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-2e70011c-6847-4fbb-a1d6-0745562e963d,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-32df1d90-1574-4934-a7db-130e2d76d1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-dc3e4d5b-fe0a-40ec-b842-f2c719f6d5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245485441-172.17.0.19-1595951908415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-e63cde2d-0229-4d36-92c6-022a71282481,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-7e09af8a-a275-4f7a-b23f-d5d75d7ab9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-c3dfa1f0-b0cd-45e4-97a5-13b23ea4315e,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-18d787ac-5476-4ac5-8bc6-d7096e0b9c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-6d1f9161-1dc9-44ce-a485-7ab41da97adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-2e70011c-6847-4fbb-a1d6-0745562e963d,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-32df1d90-1574-4934-a7db-130e2d76d1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-dc3e4d5b-fe0a-40ec-b842-f2c719f6d5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371109809-172.17.0.19-1595951952808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-fec39790-2031-4e75-b8a7-dde8824f8233,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-b3b7bd47-2529-4563-b32d-12cf8c046dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-56c038a3-fbc2-4994-8547-42f97bd730ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-2e43d374-934a-4415-a6a0-75ed8e51af89,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-1ea62d2b-e60e-425a-9813-cdbb6a215bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-24815b1a-f797-4276-abe0-06769ce690eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-c98e9b80-0d79-4475-beff-00603546c116,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-269132b9-4eda-4e74-bce5-d80b4dfdb770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371109809-172.17.0.19-1595951952808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-fec39790-2031-4e75-b8a7-dde8824f8233,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-b3b7bd47-2529-4563-b32d-12cf8c046dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-56c038a3-fbc2-4994-8547-42f97bd730ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-2e43d374-934a-4415-a6a0-75ed8e51af89,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-1ea62d2b-e60e-425a-9813-cdbb6a215bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-24815b1a-f797-4276-abe0-06769ce690eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-c98e9b80-0d79-4475-beff-00603546c116,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-269132b9-4eda-4e74-bce5-d80b4dfdb770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087695746-172.17.0.19-1595952190716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41677,DS-f31eca43-8b8b-4034-8517-b4a8fddc397b,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-0a35a505-1fab-4576-a989-94f6c7fb6961,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-15a3fa3c-82e5-46ae-a243-8e26fc61836d,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-6f828d3b-7a02-46e9-b211-985b477d98af,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-cc591f38-3dd4-422b-ae17-fea4c0e47769,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-f3603229-184a-4329-b9d2-70f05db9cd59,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-9ad2066b-c438-4972-8358-a2bcffc54a15,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-609b1d5a-8d09-4f64-b5ae-369d95f2f054,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087695746-172.17.0.19-1595952190716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41677,DS-f31eca43-8b8b-4034-8517-b4a8fddc397b,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-0a35a505-1fab-4576-a989-94f6c7fb6961,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-15a3fa3c-82e5-46ae-a243-8e26fc61836d,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-6f828d3b-7a02-46e9-b211-985b477d98af,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-cc591f38-3dd4-422b-ae17-fea4c0e47769,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-f3603229-184a-4329-b9d2-70f05db9cd59,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-9ad2066b-c438-4972-8358-a2bcffc54a15,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-609b1d5a-8d09-4f64-b5ae-369d95f2f054,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783903847-172.17.0.19-1595952991175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42697,DS-c2ab55b6-412b-4c3e-87c1-adca8e28733c,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-a85b7b9e-e19f-4c9b-9999-62a604d8c696,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-0e36c9c9-430a-4171-8cd7-3f77da56f079,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-300f0729-0fb0-412f-93e4-34648b1716a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-89a4dc99-3579-4170-9891-86e0c11cef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-8eb665ae-0e9d-409d-9c75-4a16a558e87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-0a061e2a-2729-434c-be86-154c5724138e,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-b896b665-fb36-4d3a-836e-1efad38200cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783903847-172.17.0.19-1595952991175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42697,DS-c2ab55b6-412b-4c3e-87c1-adca8e28733c,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-a85b7b9e-e19f-4c9b-9999-62a604d8c696,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-0e36c9c9-430a-4171-8cd7-3f77da56f079,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-300f0729-0fb0-412f-93e4-34648b1716a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-89a4dc99-3579-4170-9891-86e0c11cef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-8eb665ae-0e9d-409d-9c75-4a16a558e87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-0a061e2a-2729-434c-be86-154c5724138e,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-b896b665-fb36-4d3a-836e-1efad38200cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173639760-172.17.0.19-1595953211443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38416,DS-031fbee8-92a8-439e-965d-a12b9359bcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-66fc6d12-525e-4fd7-b5cc-4c5cceb58253,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-0be8c73e-12bd-448e-a154-dd6892f04e21,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-4c0a8026-d605-4c22-a760-0cd76ad35b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-eae2422c-0625-4e8a-9520-bf22d870a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-c8772186-c062-4370-b593-9af0094abba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-ca9af81a-1ce0-4c5d-a522-5d8de1870b84,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-425feb92-49b6-40d1-b7bf-191b849685e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173639760-172.17.0.19-1595953211443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38416,DS-031fbee8-92a8-439e-965d-a12b9359bcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-66fc6d12-525e-4fd7-b5cc-4c5cceb58253,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-0be8c73e-12bd-448e-a154-dd6892f04e21,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-4c0a8026-d605-4c22-a760-0cd76ad35b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-eae2422c-0625-4e8a-9520-bf22d870a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-c8772186-c062-4370-b593-9af0094abba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-ca9af81a-1ce0-4c5d-a522-5d8de1870b84,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-425feb92-49b6-40d1-b7bf-191b849685e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120094276-172.17.0.19-1595953246863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46876,DS-ec379d65-29f4-4432-835d-0df2609fb68a,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-809dadac-e037-4361-ac59-edb45fb59ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-de9e2b62-0775-44d9-9aec-b354855fd145,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-6556d107-7d57-423a-853c-3a9bcd56e900,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-f5facdf2-70cb-4e29-8441-3c7de684b84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-92074201-e430-4273-8592-4dd76e66d45f,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-8ccc14f3-6bd8-42f4-aee1-b3792b34877b,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-9f7cf6f0-e7a3-4639-be38-98273784d40e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120094276-172.17.0.19-1595953246863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46876,DS-ec379d65-29f4-4432-835d-0df2609fb68a,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-809dadac-e037-4361-ac59-edb45fb59ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-de9e2b62-0775-44d9-9aec-b354855fd145,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-6556d107-7d57-423a-853c-3a9bcd56e900,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-f5facdf2-70cb-4e29-8441-3c7de684b84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-92074201-e430-4273-8592-4dd76e66d45f,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-8ccc14f3-6bd8-42f4-aee1-b3792b34877b,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-9f7cf6f0-e7a3-4639-be38-98273784d40e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557522104-172.17.0.19-1595953319975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39792,DS-476088a3-a653-4146-9860-eec9c2ef95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-0e99ba38-6088-4369-89b6-b0ad274b4c39,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-2316c8a9-7446-4df8-a586-1342a898c9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-2c1c2650-b358-4238-949d-64e3bbb956de,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-5ae7369d-3e77-470a-aa82-3c59b72858e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-4d2153c3-4de6-4f77-a49a-a8df227540e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-9b9aad1c-70d5-4c0b-b428-d824b81886ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-86343858-913f-4788-b34a-66dfa2a667c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557522104-172.17.0.19-1595953319975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39792,DS-476088a3-a653-4146-9860-eec9c2ef95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-0e99ba38-6088-4369-89b6-b0ad274b4c39,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-2316c8a9-7446-4df8-a586-1342a898c9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-2c1c2650-b358-4238-949d-64e3bbb956de,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-5ae7369d-3e77-470a-aa82-3c59b72858e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-4d2153c3-4de6-4f77-a49a-a8df227540e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-9b9aad1c-70d5-4c0b-b428-d824b81886ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-86343858-913f-4788-b34a-66dfa2a667c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208934644-172.17.0.19-1595953393357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-6695566f-a0bd-4aba-a468-5f0ad8110c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-075997dd-6b93-435e-baaa-0674105f1fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-d7a9a1ef-d092-4436-ba5f-de8afe309607,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-27cd03e1-09bc-4baf-b1d8-6e61380664ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-e2bfa55b-fbbd-4c2a-9ab7-1f01f0264778,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-58ab2adf-b103-410f-b3df-ae602a4307b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-3b114a49-9cce-49e8-a99d-072f42e26345,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-a108e905-bdfe-409c-9d51-6b4f685c84c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208934644-172.17.0.19-1595953393357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-6695566f-a0bd-4aba-a468-5f0ad8110c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-075997dd-6b93-435e-baaa-0674105f1fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-d7a9a1ef-d092-4436-ba5f-de8afe309607,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-27cd03e1-09bc-4baf-b1d8-6e61380664ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-e2bfa55b-fbbd-4c2a-9ab7-1f01f0264778,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-58ab2adf-b103-410f-b3df-ae602a4307b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-3b114a49-9cce-49e8-a99d-072f42e26345,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-a108e905-bdfe-409c-9d51-6b4f685c84c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897594324-172.17.0.19-1595953526681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40380,DS-fb7f582d-7ead-4044-8aac-11a0e66a63ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-5ec19df7-bb92-49d4-a873-63a1d0b3f042,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-916e0f2b-adb5-424d-a131-258e480e9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-3f4ea024-0936-4977-8858-f59f952dff33,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-30b3f957-b859-449d-8d74-553ffc4184af,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-a71ac2a4-0e59-41c3-840a-4f95d66c02bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-884de238-176a-4dd6-9560-2a6988027368,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-253a4851-a3bc-47f1-a93b-678d7342a40d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897594324-172.17.0.19-1595953526681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40380,DS-fb7f582d-7ead-4044-8aac-11a0e66a63ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-5ec19df7-bb92-49d4-a873-63a1d0b3f042,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-916e0f2b-adb5-424d-a131-258e480e9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-3f4ea024-0936-4977-8858-f59f952dff33,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-30b3f957-b859-449d-8d74-553ffc4184af,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-a71ac2a4-0e59-41c3-840a-4f95d66c02bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-884de238-176a-4dd6-9560-2a6988027368,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-253a4851-a3bc-47f1-a93b-678d7342a40d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501638435-172.17.0.19-1595953705294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-18912fb6-01a5-4f22-ae59-93205d8029f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-fee4ed5f-00bd-4e42-8209-ce778e60a531,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-15b3f99a-abda-4095-96b5-8142c343f122,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-8636e2d3-9358-4752-b158-823e609ad80e,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-f6ed9f53-c200-45d3-982b-003fbcbd10cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-0f0bccaa-2e06-46cd-a76c-a1df43d1ab96,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-2bbbd472-a9fe-492b-8f6a-29463ff2992d,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-90497162-f7d2-48d8-8a4c-330a5ebdb76b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501638435-172.17.0.19-1595953705294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-18912fb6-01a5-4f22-ae59-93205d8029f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-fee4ed5f-00bd-4e42-8209-ce778e60a531,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-15b3f99a-abda-4095-96b5-8142c343f122,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-8636e2d3-9358-4752-b158-823e609ad80e,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-f6ed9f53-c200-45d3-982b-003fbcbd10cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-0f0bccaa-2e06-46cd-a76c-a1df43d1ab96,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-2bbbd472-a9fe-492b-8f6a-29463ff2992d,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-90497162-f7d2-48d8-8a4c-330a5ebdb76b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972095890-172.17.0.19-1595954221641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42498,DS-7a72f375-7149-46a7-adfe-46a12556efff,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-691c05cd-1401-47c7-9624-e1fcc70b30f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-55644b1a-afef-450e-864c-43e15175e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-7b90e150-1c18-45e8-83b7-9b8e1d1368d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-9331573a-a6dd-430c-ac28-2eab458b67f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-536d6a02-024c-4b2a-a6f1-6f651f842948,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-888aa716-e320-41b2-a9a6-75a5cdbbc0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-b6a79678-dd3b-4f20-b66d-b574f9c9040d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972095890-172.17.0.19-1595954221641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42498,DS-7a72f375-7149-46a7-adfe-46a12556efff,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-691c05cd-1401-47c7-9624-e1fcc70b30f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-55644b1a-afef-450e-864c-43e15175e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-7b90e150-1c18-45e8-83b7-9b8e1d1368d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-9331573a-a6dd-430c-ac28-2eab458b67f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-536d6a02-024c-4b2a-a6f1-6f651f842948,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-888aa716-e320-41b2-a9a6-75a5cdbbc0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-b6a79678-dd3b-4f20-b66d-b574f9c9040d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105537240-172.17.0.19-1595954848942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-79a4ab3b-5816-46d0-823e-b125c656ee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-9b2c309a-b085-4d26-871e-06df42131b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-d3af29ab-c649-4457-a929-31fe8bdb16c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-ec9079e3-5ecb-4d7f-9e44-edf0eebd827a,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-36c8cacb-5f9f-44a6-bab9-bf5c21468d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-9b7df935-f1bc-4ec6-8095-b9d10bd5978f,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-c5317a0a-9b6b-45db-86be-637a92c22977,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-0e9d44ed-5201-4d35-9cf5-5d0b6a8e4c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105537240-172.17.0.19-1595954848942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-79a4ab3b-5816-46d0-823e-b125c656ee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-9b2c309a-b085-4d26-871e-06df42131b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-d3af29ab-c649-4457-a929-31fe8bdb16c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-ec9079e3-5ecb-4d7f-9e44-edf0eebd827a,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-36c8cacb-5f9f-44a6-bab9-bf5c21468d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-9b7df935-f1bc-4ec6-8095-b9d10bd5978f,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-c5317a0a-9b6b-45db-86be-637a92c22977,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-0e9d44ed-5201-4d35-9cf5-5d0b6a8e4c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271174099-172.17.0.19-1595955617465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35947,DS-055efd51-6c31-49d6-bba3-f048988863b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-553f17d9-abed-43a3-9efb-d212ddc8e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-d2cce401-7874-4f27-bde9-77f69a88d13b,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-0b3141c5-0530-4008-8ef0-7b5575eabc18,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-f0725429-6c51-457b-8c37-8bf1c45acf36,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-536cfd2c-7b05-44f9-9a4b-cf6a421de384,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-05e1ea01-d44d-43f9-86a3-f20aaad2f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-1b83691c-2428-4471-87ac-ae774e44bc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271174099-172.17.0.19-1595955617465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35947,DS-055efd51-6c31-49d6-bba3-f048988863b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-553f17d9-abed-43a3-9efb-d212ddc8e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-d2cce401-7874-4f27-bde9-77f69a88d13b,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-0b3141c5-0530-4008-8ef0-7b5575eabc18,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-f0725429-6c51-457b-8c37-8bf1c45acf36,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-536cfd2c-7b05-44f9-9a4b-cf6a421de384,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-05e1ea01-d44d-43f9-86a3-f20aaad2f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-1b83691c-2428-4471-87ac-ae774e44bc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526908149-172.17.0.19-1595955783444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-e0d1cecf-2ab4-4abb-b9a1-be0519e9a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-7c2be00f-1456-4975-8537-573c26d74a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-7bc1d2df-7845-47b9-abf5-9c231a3e58dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-0c8f49d8-2002-40be-847c-194c26222427,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-f7b4e5bc-5f7a-4f3a-b8cb-0dc29ff75f23,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-6de99b1e-f660-4bf3-8ff0-3d88f568e974,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-9e7ebce6-8761-4a27-a5ca-5e2868451cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-1794192c-f9eb-4566-8428-b19bbf4a7b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526908149-172.17.0.19-1595955783444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32782,DS-e0d1cecf-2ab4-4abb-b9a1-be0519e9a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-7c2be00f-1456-4975-8537-573c26d74a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-7bc1d2df-7845-47b9-abf5-9c231a3e58dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-0c8f49d8-2002-40be-847c-194c26222427,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-f7b4e5bc-5f7a-4f3a-b8cb-0dc29ff75f23,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-6de99b1e-f660-4bf3-8ff0-3d88f568e974,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-9e7ebce6-8761-4a27-a5ca-5e2868451cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-1794192c-f9eb-4566-8428-b19bbf4a7b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.extra.edits.segments.retained
component: hdfs:NameNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168977699-172.17.0.19-1595955819150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-ad6eab1c-c9be-46a5-a7ee-29fe731c7e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-18c045d9-86d6-4e4f-8dae-9117ae2e223c,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-118881b5-bc4e-44cd-823f-9170be11a06d,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-81fd475a-ab9e-4cc7-a2cb-486e9617c288,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-138e0bbc-71b4-49be-83d7-fb29c0a7f333,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-887e736a-fff4-490c-8995-c00372186871,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-b0c8150f-ce25-42f4-9dd3-a6ac75b338c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-fa1c8461-537b-464d-8440-242fc8bbc66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168977699-172.17.0.19-1595955819150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-ad6eab1c-c9be-46a5-a7ee-29fe731c7e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-18c045d9-86d6-4e4f-8dae-9117ae2e223c,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-118881b5-bc4e-44cd-823f-9170be11a06d,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-81fd475a-ab9e-4cc7-a2cb-486e9617c288,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-138e0bbc-71b4-49be-83d7-fb29c0a7f333,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-887e736a-fff4-490c-8995-c00372186871,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-b0c8150f-ce25-42f4-9dd3-a6ac75b338c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-fa1c8461-537b-464d-8440-242fc8bbc66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5463
