reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148901857-172.17.0.17-1595893611083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45629,DS-875bb16f-49a1-4981-a7c4-4461a81524bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-dd8a6b8f-fe87-43e6-8c20-3dbe1c5056b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-aeadf940-74fd-4018-a092-89d047c65ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-10fd0d20-a2d8-4c43-98a4-09ae7e52c9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-790dd98f-5648-44d6-ac54-9df01d9543de,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-2c162455-6b76-48b2-9531-fdbdb97edcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-23076c16-ad7e-423f-82f1-bb55ca0459ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-2d3ca2ec-dc42-423e-8402-668c96e6d6cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148901857-172.17.0.17-1595893611083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45629,DS-875bb16f-49a1-4981-a7c4-4461a81524bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-dd8a6b8f-fe87-43e6-8c20-3dbe1c5056b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-aeadf940-74fd-4018-a092-89d047c65ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-10fd0d20-a2d8-4c43-98a4-09ae7e52c9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-790dd98f-5648-44d6-ac54-9df01d9543de,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-2c162455-6b76-48b2-9531-fdbdb97edcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-23076c16-ad7e-423f-82f1-bb55ca0459ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-2d3ca2ec-dc42-423e-8402-668c96e6d6cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175519623-172.17.0.17-1595893790316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-c12915a4-a8d3-4c5f-a459-3ef505d721cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-1c89f5de-732f-48d1-85c5-e237231069ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-13caa6ec-a614-4733-985e-3d04e3591a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-87affed3-d143-4b0a-8bbc-c641b16564d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-9c9f19b8-8687-48dc-95ff-04a4c564485b,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-fa93d3c2-9f75-49c1-8933-81de67725d82,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-60bea888-dac6-4837-9e95-dfab02928947,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-dadcbce7-34ad-4ba9-9eea-aae67b6a2c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175519623-172.17.0.17-1595893790316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-c12915a4-a8d3-4c5f-a459-3ef505d721cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-1c89f5de-732f-48d1-85c5-e237231069ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-13caa6ec-a614-4733-985e-3d04e3591a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-87affed3-d143-4b0a-8bbc-c641b16564d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-9c9f19b8-8687-48dc-95ff-04a4c564485b,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-fa93d3c2-9f75-49c1-8933-81de67725d82,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-60bea888-dac6-4837-9e95-dfab02928947,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-dadcbce7-34ad-4ba9-9eea-aae67b6a2c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773247379-172.17.0.17-1595894157296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-c420f056-0e86-49ac-b118-82815f917598,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-e018bc76-0b5d-4ae2-92ec-2147817ffad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-2a84fbf0-d106-456a-8808-39942837b0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-11fd6346-2ff4-4b9a-9a44-ca320940783e,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-46c7cb24-bf38-4d07-b541-2636689866f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-02182d7f-97be-49af-a765-f79ef15d236d,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-1b20cf57-e51a-45e1-a8b4-7a2bc4188672,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-5ca2ed70-de81-4ffe-b8b5-53d9d3c86b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773247379-172.17.0.17-1595894157296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-c420f056-0e86-49ac-b118-82815f917598,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-e018bc76-0b5d-4ae2-92ec-2147817ffad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-2a84fbf0-d106-456a-8808-39942837b0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-11fd6346-2ff4-4b9a-9a44-ca320940783e,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-46c7cb24-bf38-4d07-b541-2636689866f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-02182d7f-97be-49af-a765-f79ef15d236d,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-1b20cf57-e51a-45e1-a8b4-7a2bc4188672,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-5ca2ed70-de81-4ffe-b8b5-53d9d3c86b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322967474-172.17.0.17-1595894538896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36203,DS-444e81c6-2f10-4fe7-a835-551b2f16a331,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-eb7dd20f-a029-474b-acc9-9d87e0d16e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-77d82824-8ff3-4449-aa2f-cece8a83464e,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-003e17e0-3839-457c-bf66-1fce7f73b463,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-dffc4106-e2fb-4474-8ea9-d87a112916f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-d13d3413-0481-40bb-b11b-1d2a1282cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-b0635a2a-135f-4313-9a40-0909a12948c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-13b9acd1-0d2f-47ca-952c-220c330eca23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322967474-172.17.0.17-1595894538896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36203,DS-444e81c6-2f10-4fe7-a835-551b2f16a331,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-eb7dd20f-a029-474b-acc9-9d87e0d16e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-77d82824-8ff3-4449-aa2f-cece8a83464e,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-003e17e0-3839-457c-bf66-1fce7f73b463,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-dffc4106-e2fb-4474-8ea9-d87a112916f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-d13d3413-0481-40bb-b11b-1d2a1282cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-b0635a2a-135f-4313-9a40-0909a12948c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-13b9acd1-0d2f-47ca-952c-220c330eca23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397405037-172.17.0.17-1595894575626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-ebef99ad-d640-4a6d-b821-88d8746d93ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-de132330-2319-4d85-ad8b-eb6881d5f183,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-844f66fe-b360-4e23-b96f-c5c076e4e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-9b3cc019-bcf0-4dae-8526-1f9e88994afb,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-69e9dbbc-3ba2-4a34-8307-a179ad961975,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-c5467049-a07c-48dc-bb6e-9f4a991f492a,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-b6872ef8-2305-4ee2-b799-6dc9a57769d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-488feed6-8db0-4c29-b0a5-e214fc2caba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397405037-172.17.0.17-1595894575626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-ebef99ad-d640-4a6d-b821-88d8746d93ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-de132330-2319-4d85-ad8b-eb6881d5f183,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-844f66fe-b360-4e23-b96f-c5c076e4e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-9b3cc019-bcf0-4dae-8526-1f9e88994afb,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-69e9dbbc-3ba2-4a34-8307-a179ad961975,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-c5467049-a07c-48dc-bb6e-9f4a991f492a,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-b6872ef8-2305-4ee2-b799-6dc9a57769d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-488feed6-8db0-4c29-b0a5-e214fc2caba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401415716-172.17.0.17-1595894618049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42404,DS-bcb71728-6b82-4db8-8235-e4d81e902824,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-f1217185-b574-44b4-9b14-b124c1c692b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-96524556-12c9-4a74-a251-a09dbb3768d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-0ee529d6-a562-4e80-8557-4c97a49156af,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-77682ad0-847b-4daa-bbe2-1298ed629a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-48a39060-5082-492b-82e5-318ff7188714,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-943326ee-f3e6-4c73-a412-58f57ed35869,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-003cee20-b268-4774-93cd-e9198660f8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401415716-172.17.0.17-1595894618049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42404,DS-bcb71728-6b82-4db8-8235-e4d81e902824,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-f1217185-b574-44b4-9b14-b124c1c692b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-96524556-12c9-4a74-a251-a09dbb3768d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-0ee529d6-a562-4e80-8557-4c97a49156af,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-77682ad0-847b-4daa-bbe2-1298ed629a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-48a39060-5082-492b-82e5-318ff7188714,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-943326ee-f3e6-4c73-a412-58f57ed35869,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-003cee20-b268-4774-93cd-e9198660f8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523678763-172.17.0.17-1595894647294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-fc410e74-6029-4223-a45b-748ecbbcbede,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-c82c2f8e-3880-4b38-97f0-56d4b7cbe2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-2f8e31cd-8e54-42e8-904a-3a69cc7cc63e,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-a9797fb5-bca0-4689-81e8-e86421208642,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-0fec3f40-0b67-40c4-b231-07095f2401e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-d0599859-71d8-4991-86ef-ce0502e1f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-3b37a081-427c-47c8-a07b-a8f0eb99a43d,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-869af8ef-e205-47ad-b9ba-27988b5b951d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523678763-172.17.0.17-1595894647294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-fc410e74-6029-4223-a45b-748ecbbcbede,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-c82c2f8e-3880-4b38-97f0-56d4b7cbe2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-2f8e31cd-8e54-42e8-904a-3a69cc7cc63e,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-a9797fb5-bca0-4689-81e8-e86421208642,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-0fec3f40-0b67-40c4-b231-07095f2401e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-d0599859-71d8-4991-86ef-ce0502e1f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-3b37a081-427c-47c8-a07b-a8f0eb99a43d,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-869af8ef-e205-47ad-b9ba-27988b5b951d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532499735-172.17.0.17-1595894851277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39716,DS-6546515f-de5c-4579-8430-175f0205fe5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-d924bee5-8d4f-4fac-9ce0-a39be6689e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-de401b12-70df-41e7-a679-3a8464b9aafd,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-b314925c-7655-47ea-b355-993bc2f55891,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b0389a0a-6229-474c-9330-cb0fc1af5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-06b59a58-d1ad-4901-aa22-1764cf5a0b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-ab60069e-63b2-4e54-8139-56f178e88411,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-449c25d4-3b69-45a3-980d-709b6928c133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532499735-172.17.0.17-1595894851277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39716,DS-6546515f-de5c-4579-8430-175f0205fe5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-d924bee5-8d4f-4fac-9ce0-a39be6689e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-de401b12-70df-41e7-a679-3a8464b9aafd,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-b314925c-7655-47ea-b355-993bc2f55891,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b0389a0a-6229-474c-9330-cb0fc1af5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-06b59a58-d1ad-4901-aa22-1764cf5a0b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-ab60069e-63b2-4e54-8139-56f178e88411,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-449c25d4-3b69-45a3-980d-709b6928c133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753706820-172.17.0.17-1595894942332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45532,DS-88fc7847-8047-4a78-b8cd-7f1705dc35e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-b16f2160-c36c-43fb-bbb6-8bd126c3d91f,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-8d157cb5-e3c1-43eb-9a2b-0145c55ec0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-e2360fd1-4b9e-4036-8802-11d4dfea59f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-918442fb-92c5-4465-9347-330eee18343d,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-4c093ccf-a97f-488e-bc04-b04313d5301a,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-8afe9249-1ad1-4e6d-97bb-c442c5a04bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-483ea70f-7f98-490d-af12-7f95efa973b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753706820-172.17.0.17-1595894942332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45532,DS-88fc7847-8047-4a78-b8cd-7f1705dc35e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-b16f2160-c36c-43fb-bbb6-8bd126c3d91f,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-8d157cb5-e3c1-43eb-9a2b-0145c55ec0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-e2360fd1-4b9e-4036-8802-11d4dfea59f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-918442fb-92c5-4465-9347-330eee18343d,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-4c093ccf-a97f-488e-bc04-b04313d5301a,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-8afe9249-1ad1-4e6d-97bb-c442c5a04bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-483ea70f-7f98-490d-af12-7f95efa973b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752398939-172.17.0.17-1595895187142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39338,DS-83f83a33-da50-4abc-8356-58981ced5a97,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-f90ee2f7-1896-4657-920c-5f0d0da5eeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-658c8527-ee7c-4c0c-ac15-8b9a25a22b98,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-95240eeb-c36b-40db-b314-5fcdc838df95,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-525d582f-2f21-4700-8b0d-9e3114f13220,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-fd5153c0-8e77-4e1f-91b9-29ee102b40b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-109a63a5-7e19-447c-b26e-3c3fa2c932d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-bfd3ca6c-a462-48d0-8cdb-8a0365f8e4a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752398939-172.17.0.17-1595895187142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39338,DS-83f83a33-da50-4abc-8356-58981ced5a97,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-f90ee2f7-1896-4657-920c-5f0d0da5eeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-658c8527-ee7c-4c0c-ac15-8b9a25a22b98,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-95240eeb-c36b-40db-b314-5fcdc838df95,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-525d582f-2f21-4700-8b0d-9e3114f13220,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-fd5153c0-8e77-4e1f-91b9-29ee102b40b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-109a63a5-7e19-447c-b26e-3c3fa2c932d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-bfd3ca6c-a462-48d0-8cdb-8a0365f8e4a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640855494-172.17.0.17-1595895847733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-3908eebf-25c6-4bca-a739-9ccdb3591fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-31b78217-8dd4-4a1d-982c-4a2148747798,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-a2d75435-6eaf-45b6-a239-2b7999d51f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-9efe3170-fa65-4fd6-9a11-09801303e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-79eb0fc5-f0dd-4b1a-97df-a77ef0c529de,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-a7d991f7-7b4a-4e5e-bd1d-3cad9dbd694b,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-cef15f28-8b47-45fb-9955-277c40b7f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-a8c0eefd-2ad6-4b83-aa2e-2b3589cdf480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640855494-172.17.0.17-1595895847733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-3908eebf-25c6-4bca-a739-9ccdb3591fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-31b78217-8dd4-4a1d-982c-4a2148747798,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-a2d75435-6eaf-45b6-a239-2b7999d51f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-9efe3170-fa65-4fd6-9a11-09801303e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-79eb0fc5-f0dd-4b1a-97df-a77ef0c529de,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-a7d991f7-7b4a-4e5e-bd1d-3cad9dbd694b,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-cef15f28-8b47-45fb-9955-277c40b7f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-a8c0eefd-2ad6-4b83-aa2e-2b3589cdf480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155002025-172.17.0.17-1595895913200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39442,DS-ce1a2843-e215-47ed-88e0-043b1dcd1f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-deff19a1-002e-4fc2-8494-5134c74f4527,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-4a469bfb-b78b-444c-8d20-ba0c183cba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-fd59800e-b620-4de6-b8ee-f945d07d0cba,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-5e919a9b-615b-40ac-8182-7f544f28815c,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-3152a291-0f6b-407e-802b-b8b1bb148cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-8832f51a-a022-4b37-8ebf-9395ae4b28f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-a4782518-d796-48fb-bc5d-f0420e05f3e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155002025-172.17.0.17-1595895913200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39442,DS-ce1a2843-e215-47ed-88e0-043b1dcd1f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-deff19a1-002e-4fc2-8494-5134c74f4527,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-4a469bfb-b78b-444c-8d20-ba0c183cba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-fd59800e-b620-4de6-b8ee-f945d07d0cba,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-5e919a9b-615b-40ac-8182-7f544f28815c,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-3152a291-0f6b-407e-802b-b8b1bb148cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-8832f51a-a022-4b37-8ebf-9395ae4b28f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-a4782518-d796-48fb-bc5d-f0420e05f3e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356930227-172.17.0.17-1595896048454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-cb7772a6-8de0-4cc9-8dcc-6ec6a5dd58ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-0d711b11-3878-4a79-98e3-d7d563d42c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-335d8d42-132e-496d-b013-e88069437138,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-5b1b38c0-aa4a-4d69-ba74-b74c2f3c6a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-404f38c1-e583-4169-8710-aace80e460a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-b1dbab79-5a26-4043-a235-316470dd1f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-1356f813-38b3-4290-85cb-30cffab49249,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-8784be9d-7ede-4f85-96a0-63e4f6c36eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356930227-172.17.0.17-1595896048454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-cb7772a6-8de0-4cc9-8dcc-6ec6a5dd58ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-0d711b11-3878-4a79-98e3-d7d563d42c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-335d8d42-132e-496d-b013-e88069437138,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-5b1b38c0-aa4a-4d69-ba74-b74c2f3c6a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-404f38c1-e583-4169-8710-aace80e460a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-b1dbab79-5a26-4043-a235-316470dd1f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-1356f813-38b3-4290-85cb-30cffab49249,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-8784be9d-7ede-4f85-96a0-63e4f6c36eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486122809-172.17.0.17-1595896208448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-11314f5e-d2df-4bc4-8858-7a3c3accc1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-6b162dd4-e482-478f-952e-953db6085e26,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-78c02d64-79d1-4b7b-ba86-bab1dfe59db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-88ffe824-fddd-4c2f-88a5-6259dd6c222e,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-518f561c-0b2f-4a48-8710-929b3da7cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-3fc0c8b5-3e3e-4da6-93ff-0dc6a24f469e,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-f2286e97-0fd7-44e8-a270-9600a782d977,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-0b594b8a-d5e4-49f0-8c95-0725badef646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486122809-172.17.0.17-1595896208448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-11314f5e-d2df-4bc4-8858-7a3c3accc1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-6b162dd4-e482-478f-952e-953db6085e26,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-78c02d64-79d1-4b7b-ba86-bab1dfe59db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-88ffe824-fddd-4c2f-88a5-6259dd6c222e,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-518f561c-0b2f-4a48-8710-929b3da7cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-3fc0c8b5-3e3e-4da6-93ff-0dc6a24f469e,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-f2286e97-0fd7-44e8-a270-9600a782d977,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-0b594b8a-d5e4-49f0-8c95-0725badef646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112422538-172.17.0.17-1595896639291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-7c49adc1-e66a-4bfa-974d-90d12d20f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-2d912ea0-79da-4a16-b2c3-e7e18d97cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-a164b2b4-ec27-4876-aa4c-9dce0a530bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-5dae5498-5f79-4ce1-80b8-a803953db84f,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-e2a732b1-adec-4d8d-91f6-de28e2b79990,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-61c5d77b-08ed-41fc-a6f9-1cc36d8cf9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-1de8da5f-834b-4702-a3f0-20ff396b7ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-a4ab5172-f9c4-43cc-b2c7-9d45e88fd85d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112422538-172.17.0.17-1595896639291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-7c49adc1-e66a-4bfa-974d-90d12d20f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-2d912ea0-79da-4a16-b2c3-e7e18d97cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-a164b2b4-ec27-4876-aa4c-9dce0a530bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-5dae5498-5f79-4ce1-80b8-a803953db84f,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-e2a732b1-adec-4d8d-91f6-de28e2b79990,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-61c5d77b-08ed-41fc-a6f9-1cc36d8cf9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-1de8da5f-834b-4702-a3f0-20ff396b7ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-a4ab5172-f9c4-43cc-b2c7-9d45e88fd85d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59267391-172.17.0.17-1595896766676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-ad84fbc8-667b-4214-95c6-e7519f9aab3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-445fe66a-7ae8-490e-ab28-9b8a66c9ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-247f4700-3ab4-4016-b6f8-ec09acceabb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-370db239-8ac6-47dd-8ab9-7eb07fa2cc50,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-16c4150f-04ea-44e9-b570-eec3574baf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-ca0b5eaf-3c92-400e-8f04-218c6f3ff4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-94320317-b10f-4c61-8285-8f0b1d26c441,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4b860cae-a90b-4b10-927d-bcff1f4d8846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59267391-172.17.0.17-1595896766676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-ad84fbc8-667b-4214-95c6-e7519f9aab3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-445fe66a-7ae8-490e-ab28-9b8a66c9ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-247f4700-3ab4-4016-b6f8-ec09acceabb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-370db239-8ac6-47dd-8ab9-7eb07fa2cc50,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-16c4150f-04ea-44e9-b570-eec3574baf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-ca0b5eaf-3c92-400e-8f04-218c6f3ff4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-94320317-b10f-4c61-8285-8f0b1d26c441,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4b860cae-a90b-4b10-927d-bcff1f4d8846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681540198-172.17.0.17-1595896834681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40603,DS-fe61dd43-67f8-40fe-99ff-dde663139b06,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-8aa4000e-f3f1-4731-87f3-0ab5811cc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-0bacb708-69b2-4284-a457-6011627a66db,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-81bd09d9-569b-49ca-887c-3a964e1c29b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-4b95fc29-eac8-447e-87fb-2a9e832d3a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-1811f5b2-dcfa-44da-b7ed-18e784a4cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-a661060c-6b17-4bb1-ae83-e320b249c688,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-f82a26f2-0f78-4043-8658-61e6e0e315a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681540198-172.17.0.17-1595896834681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40603,DS-fe61dd43-67f8-40fe-99ff-dde663139b06,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-8aa4000e-f3f1-4731-87f3-0ab5811cc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-0bacb708-69b2-4284-a457-6011627a66db,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-81bd09d9-569b-49ca-887c-3a964e1c29b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-4b95fc29-eac8-447e-87fb-2a9e832d3a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-1811f5b2-dcfa-44da-b7ed-18e784a4cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-a661060c-6b17-4bb1-ae83-e320b249c688,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-f82a26f2-0f78-4043-8658-61e6e0e315a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473438359-172.17.0.17-1595896939676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35087,DS-bce31586-99cc-49ac-9913-3894fc0a34e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-4711a6ef-0199-4690-ad04-d3af7509dc34,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-d40e60d7-4cfd-48e5-bd39-bd2f8bcfaaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-871761ba-a557-4220-a860-edf43a64a158,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-f3b2fc01-7c97-4531-b477-eb442313e49f,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-d4477f7d-cdd9-42e9-98e5-4d13e535b020,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-da064848-d06f-4513-a3b1-3b38ff320a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-d0f982fa-c6cf-42c1-a72e-58672fc6e863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473438359-172.17.0.17-1595896939676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35087,DS-bce31586-99cc-49ac-9913-3894fc0a34e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-4711a6ef-0199-4690-ad04-d3af7509dc34,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-d40e60d7-4cfd-48e5-bd39-bd2f8bcfaaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-871761ba-a557-4220-a860-edf43a64a158,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-f3b2fc01-7c97-4531-b477-eb442313e49f,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-d4477f7d-cdd9-42e9-98e5-4d13e535b020,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-da064848-d06f-4513-a3b1-3b38ff320a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-d0f982fa-c6cf-42c1-a72e-58672fc6e863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624398944-172.17.0.17-1595897546500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44479,DS-7414b528-86d8-48e7-a698-87367a8597ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-73776c0a-b69f-4fc6-a325-48158a817fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-8254d5e7-cedd-43c6-a923-9b68b2ec824f,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-a3d23a79-1257-43ce-842e-1d62f4561189,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-2ed3ae02-3330-4454-8222-7dd32b21736d,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-174774db-3494-4f8d-a9d0-a75b3083ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-41667212-4892-4f83-bd5a-856a4a893c72,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-f4a9a88d-6a4a-4fc9-bc05-a96ca24e9cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624398944-172.17.0.17-1595897546500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44479,DS-7414b528-86d8-48e7-a698-87367a8597ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-73776c0a-b69f-4fc6-a325-48158a817fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-8254d5e7-cedd-43c6-a923-9b68b2ec824f,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-a3d23a79-1257-43ce-842e-1d62f4561189,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-2ed3ae02-3330-4454-8222-7dd32b21736d,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-174774db-3494-4f8d-a9d0-a75b3083ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-41667212-4892-4f83-bd5a-856a4a893c72,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-f4a9a88d-6a4a-4fc9-bc05-a96ca24e9cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082014943-172.17.0.17-1595897650875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-23b59b48-ed87-4676-acc7-a50ddddb009a,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-e175c177-88e4-475a-baff-2d35dfd9be38,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-703431fa-8f24-4abc-bdbe-9fc40bf2d97d,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-ead4542c-5ae7-4059-8865-ab3e942f3c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-b6b36da3-7d20-49b2-8225-b709c411743e,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-0f5d5f77-5951-4ea3-912b-db4f5c72c15a,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-529c956e-b2db-415f-916d-243586eef4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-01d72fda-8758-4180-ac31-74becaf9e401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082014943-172.17.0.17-1595897650875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-23b59b48-ed87-4676-acc7-a50ddddb009a,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-e175c177-88e4-475a-baff-2d35dfd9be38,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-703431fa-8f24-4abc-bdbe-9fc40bf2d97d,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-ead4542c-5ae7-4059-8865-ab3e942f3c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-b6b36da3-7d20-49b2-8225-b709c411743e,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-0f5d5f77-5951-4ea3-912b-db4f5c72c15a,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-529c956e-b2db-415f-916d-243586eef4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-01d72fda-8758-4180-ac31-74becaf9e401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759557694-172.17.0.17-1595897909163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37935,DS-fddd6bd9-6a7c-43ea-968c-4dee9ee91bab,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-1078a271-c523-496a-8a9d-0b1f3b027939,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-9f5a7bf1-b8d9-4e63-a29b-872da39b2498,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-64d3d571-97d9-4718-a11b-eb82136d1a47,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-0b68bc9d-9f2e-4832-9a32-abfb0c9c4528,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-dac9d379-ce06-44f9-9ca4-04e89e55c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-8266b83c-dc08-4afa-a27a-915368f5fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-5ee3c562-9bbb-426a-8a56-b14455c5a195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759557694-172.17.0.17-1595897909163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37935,DS-fddd6bd9-6a7c-43ea-968c-4dee9ee91bab,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-1078a271-c523-496a-8a9d-0b1f3b027939,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-9f5a7bf1-b8d9-4e63-a29b-872da39b2498,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-64d3d571-97d9-4718-a11b-eb82136d1a47,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-0b68bc9d-9f2e-4832-9a32-abfb0c9c4528,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-dac9d379-ce06-44f9-9ca4-04e89e55c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-8266b83c-dc08-4afa-a27a-915368f5fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-5ee3c562-9bbb-426a-8a56-b14455c5a195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534443894-172.17.0.17-1595897979586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-00b2b691-6b53-4d9a-80a7-e0ced7b74c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-8582ffc4-80dd-4ac9-b982-ab396aa77704,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-af4fe05f-7325-4878-9d89-8113615c96a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-38b6d04f-bac0-40e8-84a1-4085c4fe964b,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-965704e2-5cab-494f-9808-9762ab383815,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-92823cdd-4e82-4597-b1c0-4f939f3a21eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-62d2e1d6-d81b-4d0e-95ec-21fc0c5e769d,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a8e32b3e-6734-4d46-87c0-52819504d26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534443894-172.17.0.17-1595897979586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-00b2b691-6b53-4d9a-80a7-e0ced7b74c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-8582ffc4-80dd-4ac9-b982-ab396aa77704,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-af4fe05f-7325-4878-9d89-8113615c96a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-38b6d04f-bac0-40e8-84a1-4085c4fe964b,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-965704e2-5cab-494f-9808-9762ab383815,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-92823cdd-4e82-4597-b1c0-4f939f3a21eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-62d2e1d6-d81b-4d0e-95ec-21fc0c5e769d,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a8e32b3e-6734-4d46-87c0-52819504d26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: might be true error
Total execution time in seconds : 5131
