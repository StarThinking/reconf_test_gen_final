reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118188290-172.17.0.14-1595482516391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41952,DS-cc511abf-e541-412d-8c84-f91363ef09dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-36a928ee-88a3-484b-8ff4-d45b784a7994,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-aea92bd0-a8c9-4d20-8903-489fa777f895,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-7c10d9d2-1236-44fa-b9d9-20163feb46b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-dc746832-6ae1-40c3-b17e-e12afc216581,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-cdf98008-1123-4843-8850-bd6cb44f5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-83346369-b06d-4b36-8790-bcfc12979480,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-9b8ae91f-facd-4c85-8f76-cc0b5234ead4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118188290-172.17.0.14-1595482516391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41952,DS-cc511abf-e541-412d-8c84-f91363ef09dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-36a928ee-88a3-484b-8ff4-d45b784a7994,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-aea92bd0-a8c9-4d20-8903-489fa777f895,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-7c10d9d2-1236-44fa-b9d9-20163feb46b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-dc746832-6ae1-40c3-b17e-e12afc216581,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-cdf98008-1123-4843-8850-bd6cb44f5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-83346369-b06d-4b36-8790-bcfc12979480,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-9b8ae91f-facd-4c85-8f76-cc0b5234ead4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408912204-172.17.0.14-1595483558200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-7242caa9-1119-42f5-8976-c63c0d0710b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-3cda1f75-fc76-4afa-8f77-8b196e3aebea,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-7d3d2904-822a-49d3-97d0-918dad06ce70,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-ab4582cf-923a-4ef0-b810-3e1625a3c351,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-85f7e166-24df-44f4-8eb3-8cda02b55cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-ef100cf8-f39b-4032-925d-30fcf346fea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-d35fb6c9-399e-4a47-96b4-94ae6e76f0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-54447eb1-3c42-4482-b023-c7b789594443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408912204-172.17.0.14-1595483558200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-7242caa9-1119-42f5-8976-c63c0d0710b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-3cda1f75-fc76-4afa-8f77-8b196e3aebea,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-7d3d2904-822a-49d3-97d0-918dad06ce70,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-ab4582cf-923a-4ef0-b810-3e1625a3c351,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-85f7e166-24df-44f4-8eb3-8cda02b55cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-ef100cf8-f39b-4032-925d-30fcf346fea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-d35fb6c9-399e-4a47-96b4-94ae6e76f0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-54447eb1-3c42-4482-b023-c7b789594443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315506673-172.17.0.14-1595483993197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39578,DS-c98c80ed-9595-43d4-ba4f-faa2c7fe610c,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-679d4632-24e8-4c05-8b2c-17073467aa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-5bcbc13c-357b-4675-b480-4b73f71f7cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-aba3a3f2-336c-47ca-b2ed-1c653d285a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-aec3112c-3979-4482-97fc-ffee72a6df92,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-18eb7d5c-5c44-495f-9132-e4d8bdec77ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-498c4b50-cf49-459b-91f8-b960e3c3a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-0771e768-54d1-444d-a8fc-fdc7274bbbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315506673-172.17.0.14-1595483993197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39578,DS-c98c80ed-9595-43d4-ba4f-faa2c7fe610c,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-679d4632-24e8-4c05-8b2c-17073467aa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-5bcbc13c-357b-4675-b480-4b73f71f7cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-aba3a3f2-336c-47ca-b2ed-1c653d285a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-aec3112c-3979-4482-97fc-ffee72a6df92,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-18eb7d5c-5c44-495f-9132-e4d8bdec77ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-498c4b50-cf49-459b-91f8-b960e3c3a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-0771e768-54d1-444d-a8fc-fdc7274bbbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723582172-172.17.0.14-1595484809581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-cc31e978-b278-45a3-9784-dd547d15ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-f4d87b9c-37d8-4bea-956e-e611ac58ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-f5ff613a-6234-488d-bd29-dccb92fe846e,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-07460682-b884-43be-8172-458e17065818,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-02cc14f7-fe28-49fd-92c1-eff190438a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-2e5a7d5f-537a-408e-bd8e-c3ed2ce33d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-33119418-64bf-48b7-a70b-10cb846b5a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-3c72e95a-4127-4ccc-8d3e-2dfc637d2d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723582172-172.17.0.14-1595484809581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-cc31e978-b278-45a3-9784-dd547d15ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-f4d87b9c-37d8-4bea-956e-e611ac58ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-f5ff613a-6234-488d-bd29-dccb92fe846e,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-07460682-b884-43be-8172-458e17065818,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-02cc14f7-fe28-49fd-92c1-eff190438a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-2e5a7d5f-537a-408e-bd8e-c3ed2ce33d44,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-33119418-64bf-48b7-a70b-10cb846b5a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-3c72e95a-4127-4ccc-8d3e-2dfc637d2d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227648543-172.17.0.14-1595484963001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33077,DS-9ccc3a6b-ed03-4f68-8ae2-bb365d122012,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-a529968a-24de-45d5-8cf7-8aeaed94e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-1efa498c-094c-4339-8642-684460a8999e,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-4af8f6ea-ee04-4823-bbed-456b95fc845f,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-2867cba2-c8cc-4bad-9d89-19a8d802000a,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-ddf47adc-d3f6-4676-a90f-32a0dadd8697,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-f827b15f-c491-4e1a-8ae8-e58208ae1482,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-1ff8c55c-5070-41fe-8add-0d51a915371b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227648543-172.17.0.14-1595484963001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33077,DS-9ccc3a6b-ed03-4f68-8ae2-bb365d122012,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-a529968a-24de-45d5-8cf7-8aeaed94e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-1efa498c-094c-4339-8642-684460a8999e,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-4af8f6ea-ee04-4823-bbed-456b95fc845f,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-2867cba2-c8cc-4bad-9d89-19a8d802000a,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-ddf47adc-d3f6-4676-a90f-32a0dadd8697,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-f827b15f-c491-4e1a-8ae8-e58208ae1482,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-1ff8c55c-5070-41fe-8add-0d51a915371b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655432958-172.17.0.14-1595485002825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-4876c95e-07de-41d6-917b-18da39ab7eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-1aa820ea-387b-408b-b852-9bc69e9d18e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-1e6487df-f763-4f73-844a-cd17f5d470bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-31860ebe-3b10-49e4-9aba-b83905ce58f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-251f6c29-3a24-4477-ab3b-7eb082274896,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-97262c41-623c-4ebc-8309-ea59849f5a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-72241289-f245-4689-bc16-a4cfd44cdeea,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-b9ba8a44-2505-46bc-8993-117db45cb354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655432958-172.17.0.14-1595485002825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-4876c95e-07de-41d6-917b-18da39ab7eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-1aa820ea-387b-408b-b852-9bc69e9d18e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-1e6487df-f763-4f73-844a-cd17f5d470bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-31860ebe-3b10-49e4-9aba-b83905ce58f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-251f6c29-3a24-4477-ab3b-7eb082274896,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-97262c41-623c-4ebc-8309-ea59849f5a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-72241289-f245-4689-bc16-a4cfd44cdeea,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-b9ba8a44-2505-46bc-8993-117db45cb354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589272964-172.17.0.14-1595485519704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-520819b7-5a46-421f-bc1b-7115b047b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-231fb5b9-1893-416d-9b1d-db35f0fa5b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-70dc91c8-7730-4f75-8eb4-2e84a9a11e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-e2bdb846-408e-48f4-a04e-f542058b9fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-499f9433-bb23-4ea1-b533-85505f1c6aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-dc2b9a6b-55d4-4e58-83b9-8f2aea42b9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-bda8de25-8a93-4a1f-9284-95db05a66b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-8f766dae-dca1-4860-82e5-5b6fed78dac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589272964-172.17.0.14-1595485519704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-520819b7-5a46-421f-bc1b-7115b047b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-231fb5b9-1893-416d-9b1d-db35f0fa5b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-70dc91c8-7730-4f75-8eb4-2e84a9a11e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-e2bdb846-408e-48f4-a04e-f542058b9fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-499f9433-bb23-4ea1-b533-85505f1c6aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-dc2b9a6b-55d4-4e58-83b9-8f2aea42b9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-bda8de25-8a93-4a1f-9284-95db05a66b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-8f766dae-dca1-4860-82e5-5b6fed78dac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606884031-172.17.0.14-1595485988859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-eda04512-0764-43b0-90e3-faf84f9b709d,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-3ffdf3e1-d543-4ba9-aea9-75db0cd008ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-7032d082-9e64-4d83-8779-7ceef757be72,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-78cbb77c-f3da-48ea-86ac-8729e262bd77,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-06cdf621-75a7-4a5e-9c0a-aa5a67774c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-4ef34fda-90ad-46a9-a38b-074411eb2e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-519532d9-3c45-4e1c-9119-d4f81cda7f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-3fb24af2-8f4c-46f6-a699-340f2816ae72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606884031-172.17.0.14-1595485988859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-eda04512-0764-43b0-90e3-faf84f9b709d,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-3ffdf3e1-d543-4ba9-aea9-75db0cd008ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-7032d082-9e64-4d83-8779-7ceef757be72,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-78cbb77c-f3da-48ea-86ac-8729e262bd77,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-06cdf621-75a7-4a5e-9c0a-aa5a67774c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-4ef34fda-90ad-46a9-a38b-074411eb2e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-519532d9-3c45-4e1c-9119-d4f81cda7f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-3fb24af2-8f4c-46f6-a699-340f2816ae72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349572035-172.17.0.14-1595486128712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-b67b8d38-e1db-4d94-b4c3-f812e711fc93,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-bdb85510-9e70-48b0-8a20-95fa148e710a,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-6627d6c4-061a-4d23-8f41-6d9815a8f231,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-20243f4c-37ac-4a1b-a028-6b63d4e91e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-da4788a2-53e3-4c37-9174-3ff3eca62a63,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-49718c76-6b27-4b93-915a-60733e7023ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-995e85fc-ee80-43a2-92aa-d4033a85c937,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-d9a41da3-6b39-42e2-a5b4-f614ac2a7586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349572035-172.17.0.14-1595486128712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-b67b8d38-e1db-4d94-b4c3-f812e711fc93,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-bdb85510-9e70-48b0-8a20-95fa148e710a,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-6627d6c4-061a-4d23-8f41-6d9815a8f231,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-20243f4c-37ac-4a1b-a028-6b63d4e91e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-da4788a2-53e3-4c37-9174-3ff3eca62a63,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-49718c76-6b27-4b93-915a-60733e7023ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-995e85fc-ee80-43a2-92aa-d4033a85c937,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-d9a41da3-6b39-42e2-a5b4-f614ac2a7586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396149376-172.17.0.14-1595486307686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33229,DS-aaded06a-f888-43fd-8d2b-ee9e1de544f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-b2bbe680-ed11-4203-89b1-2b454f70d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-a46fe190-371d-4911-b62a-83ce4ac10c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-eaba86b8-bcbe-475b-b3d2-b5d58bbc836f,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-d851bb8d-c48f-4cb4-b3c5-e5c923389aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-71f424dc-2c74-4d69-9bfc-f6593723514c,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-504b7d4f-4fb9-4fc2-83da-f00620507e46,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-9b0f715b-3dae-4d7d-9be3-80b58f0613d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396149376-172.17.0.14-1595486307686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33229,DS-aaded06a-f888-43fd-8d2b-ee9e1de544f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-b2bbe680-ed11-4203-89b1-2b454f70d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-a46fe190-371d-4911-b62a-83ce4ac10c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-eaba86b8-bcbe-475b-b3d2-b5d58bbc836f,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-d851bb8d-c48f-4cb4-b3c5-e5c923389aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-71f424dc-2c74-4d69-9bfc-f6593723514c,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-504b7d4f-4fb9-4fc2-83da-f00620507e46,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-9b0f715b-3dae-4d7d-9be3-80b58f0613d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568655578-172.17.0.14-1595486669897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-fd786208-3c9c-4f8d-88df-ac22467f1b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-49ac70c7-bee3-4280-8eb5-e82c317f20d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-b4d0fe97-12fe-451b-93ef-4c381bfc81e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-6365e914-e528-4d2e-b6b0-5937ec9d767e,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-c0540711-4ab3-403a-8b66-cdad000afeca,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-0e322c67-895b-482c-8ba9-e41f15d81743,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-15f9e31b-9165-42bf-ab69-f1ba52787c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-ed86901a-79ba-4ae0-b7e0-6029f49f25ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568655578-172.17.0.14-1595486669897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-fd786208-3c9c-4f8d-88df-ac22467f1b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-49ac70c7-bee3-4280-8eb5-e82c317f20d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-b4d0fe97-12fe-451b-93ef-4c381bfc81e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-6365e914-e528-4d2e-b6b0-5937ec9d767e,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-c0540711-4ab3-403a-8b66-cdad000afeca,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-0e322c67-895b-482c-8ba9-e41f15d81743,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-15f9e31b-9165-42bf-ab69-f1ba52787c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-ed86901a-79ba-4ae0-b7e0-6029f49f25ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713870091-172.17.0.14-1595486953253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-8a6dc108-341c-4d3e-a7b7-f3a818b518bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-973230eb-a5f8-4f6c-91c2-24bde55c73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-bb6e4b51-b1ab-4698-a27d-82de6a051506,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-5a71c525-6e71-49c9-a5a0-8f0e2de17808,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-6baa0e0b-fbab-41a7-90d5-37ddacfda72a,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-041bc377-8db1-4db5-951d-d3c7b091d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-bdc9776e-69b8-4549-b918-6d87288a2278,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-9849074a-0b90-4192-933a-bb749a7eb53b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713870091-172.17.0.14-1595486953253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-8a6dc108-341c-4d3e-a7b7-f3a818b518bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-973230eb-a5f8-4f6c-91c2-24bde55c73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-bb6e4b51-b1ab-4698-a27d-82de6a051506,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-5a71c525-6e71-49c9-a5a0-8f0e2de17808,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-6baa0e0b-fbab-41a7-90d5-37ddacfda72a,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-041bc377-8db1-4db5-951d-d3c7b091d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-bdc9776e-69b8-4549-b918-6d87288a2278,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-9849074a-0b90-4192-933a-bb749a7eb53b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5311
