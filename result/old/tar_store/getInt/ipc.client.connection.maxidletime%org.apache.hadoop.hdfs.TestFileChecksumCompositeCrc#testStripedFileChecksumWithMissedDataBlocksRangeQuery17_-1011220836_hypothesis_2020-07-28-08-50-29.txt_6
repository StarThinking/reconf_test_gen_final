reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134255-172.17.0.9-1595926314385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42649,DS-2c3e8bb5-4794-4b3a-ac34-4f6f11c45ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-09cf292d-4af0-4132-a093-71d156b4eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-ff3073ca-a2d8-4900-8cf8-dd57d31f82fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-8071fd88-811a-4469-8492-87dbca99605f,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-46e937cb-fad0-40a3-a06e-b5623ae49968,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-ec7f3c70-358d-40b2-babf-7ea17f79d5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-dd21e476-2045-492c-adff-0d8d1fc82451,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-835c38f7-0a69-474e-af4a-32da8af27bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134255-172.17.0.9-1595926314385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42649,DS-2c3e8bb5-4794-4b3a-ac34-4f6f11c45ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-09cf292d-4af0-4132-a093-71d156b4eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-ff3073ca-a2d8-4900-8cf8-dd57d31f82fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-8071fd88-811a-4469-8492-87dbca99605f,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-46e937cb-fad0-40a3-a06e-b5623ae49968,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-ec7f3c70-358d-40b2-babf-7ea17f79d5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-dd21e476-2045-492c-adff-0d8d1fc82451,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-835c38f7-0a69-474e-af4a-32da8af27bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888962688-172.17.0.9-1595927701948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-4bd15c90-d1ea-41c2-a647-aedab3c1b628,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-dc8c588e-a228-4142-abb2-0ad3f5f0ba87,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-fec98c0d-3d87-4700-b85c-1e215a99550f,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-b786c136-4352-45d0-a58f-65ca91501db7,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-fc413668-828f-42c7-96b3-3783ecfda699,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-3a1ca019-5b0f-4c6a-8c44-eacc96c62bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-210b65d9-07ad-4af0-aa64-731f03c47a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-4d697f75-e207-4c7d-bdf2-2366e6e9f60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888962688-172.17.0.9-1595927701948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-4bd15c90-d1ea-41c2-a647-aedab3c1b628,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-dc8c588e-a228-4142-abb2-0ad3f5f0ba87,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-fec98c0d-3d87-4700-b85c-1e215a99550f,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-b786c136-4352-45d0-a58f-65ca91501db7,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-fc413668-828f-42c7-96b3-3783ecfda699,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-3a1ca019-5b0f-4c6a-8c44-eacc96c62bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-210b65d9-07ad-4af0-aa64-731f03c47a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-4d697f75-e207-4c7d-bdf2-2366e6e9f60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274986549-172.17.0.9-1595927932929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35471,DS-3f086009-531e-4e9e-9bea-d36a90125e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-0f8776f8-6132-46d0-9ad3-ba0c1eef785c,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-e5848d53-5d03-4a20-bd5f-8bd481c1d56d,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-232ba740-c493-4087-84b4-b4ca7b02b564,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-66388ed3-e45f-4cd2-a427-7183ad212b88,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-3babf3e7-6da5-432e-bb26-b6aae5aa4540,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-a905ae12-0703-4c8a-8a3a-4e712e4b1bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-b49330c7-1f62-43d7-9dfd-4aa437a0bcf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274986549-172.17.0.9-1595927932929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35471,DS-3f086009-531e-4e9e-9bea-d36a90125e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-0f8776f8-6132-46d0-9ad3-ba0c1eef785c,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-e5848d53-5d03-4a20-bd5f-8bd481c1d56d,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-232ba740-c493-4087-84b4-b4ca7b02b564,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-66388ed3-e45f-4cd2-a427-7183ad212b88,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-3babf3e7-6da5-432e-bb26-b6aae5aa4540,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-a905ae12-0703-4c8a-8a3a-4e712e4b1bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-b49330c7-1f62-43d7-9dfd-4aa437a0bcf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1364180391-172.17.0.9-1595928063299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46435,DS-f1cf3522-0943-4bed-9f55-93457eb6ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-fb3da0af-0b38-47c0-afaa-ac36d595eef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-17f4ac2f-9a02-49b7-8d7f-ed57467a9a47,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-27814164-19ea-4379-bc6e-974f4150af3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-8240e2a2-b83f-47cd-9580-ae9b8555dc82,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-73348483-1d29-43ae-a45c-ab61885af313,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-5d3fd6d8-b252-45fe-be6b-f14fad307a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-1e80625f-5027-4adc-88e5-f29421976edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1364180391-172.17.0.9-1595928063299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46435,DS-f1cf3522-0943-4bed-9f55-93457eb6ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-fb3da0af-0b38-47c0-afaa-ac36d595eef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-17f4ac2f-9a02-49b7-8d7f-ed57467a9a47,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-27814164-19ea-4379-bc6e-974f4150af3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-8240e2a2-b83f-47cd-9580-ae9b8555dc82,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-73348483-1d29-43ae-a45c-ab61885af313,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-5d3fd6d8-b252-45fe-be6b-f14fad307a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-1e80625f-5027-4adc-88e5-f29421976edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294940476-172.17.0.9-1595928169099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39683,DS-68fc490d-e56e-4e33-b3ff-2a91807a9ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-c9584419-b3c2-4162-b490-5afc0571012e,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-25bab73b-d9b0-48d1-8d83-fa6d2c2e5406,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-1a6b519d-b9ad-4e1f-beef-e4d1425926d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-bec43a17-5d40-49a9-870c-84306949434a,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-b9bc78a6-b760-4781-bfdd-eddb69683068,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-a6ba0a68-fc0f-424a-b244-c8edbefde5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-34f6f1dd-cb22-4626-893c-5dbf128377bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294940476-172.17.0.9-1595928169099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39683,DS-68fc490d-e56e-4e33-b3ff-2a91807a9ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-c9584419-b3c2-4162-b490-5afc0571012e,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-25bab73b-d9b0-48d1-8d83-fa6d2c2e5406,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-1a6b519d-b9ad-4e1f-beef-e4d1425926d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-bec43a17-5d40-49a9-870c-84306949434a,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-b9bc78a6-b760-4781-bfdd-eddb69683068,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-a6ba0a68-fc0f-424a-b244-c8edbefde5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-34f6f1dd-cb22-4626-893c-5dbf128377bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115163317-172.17.0.9-1595928670110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-00bcae49-18eb-4c96-8538-6d1dd623717c,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-521499e9-f1c6-4791-a312-9a65ca2920ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-9b0f78e5-57ea-4d07-a401-827a2953afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-08143461-7796-4712-9225-b78a7d3017ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-96f23885-047c-4aee-80ae-ae628fe52531,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-f1a8e2c7-c3c6-4230-8974-01bc4ef00ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-870b0617-d6bd-4ab8-8068-17fd9717d839,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-a8e04f16-db23-45b7-b51b-2272e4fd063f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115163317-172.17.0.9-1595928670110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-00bcae49-18eb-4c96-8538-6d1dd623717c,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-521499e9-f1c6-4791-a312-9a65ca2920ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-9b0f78e5-57ea-4d07-a401-827a2953afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-08143461-7796-4712-9225-b78a7d3017ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-96f23885-047c-4aee-80ae-ae628fe52531,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-f1a8e2c7-c3c6-4230-8974-01bc4ef00ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-870b0617-d6bd-4ab8-8068-17fd9717d839,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-a8e04f16-db23-45b7-b51b-2272e4fd063f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767753656-172.17.0.9-1595929170339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41279,DS-8468b120-3d24-4e56-a758-038f8a0807a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-ef42549b-9e72-45f9-9a0e-6dd2710c738e,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-eee1f433-fff4-4372-9708-dec972fc23bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-53fe7eae-6109-4686-9697-bd1d226317c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-11a2bfa4-f42d-481c-9b2a-f87141b950bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-5f1a490d-67bc-4ac8-9130-2cd5f10830be,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-05af659e-5e0d-49f6-9c2d-b567c8cf9731,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-3c936347-7eec-4a44-84fa-84e9f4c2c691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767753656-172.17.0.9-1595929170339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41279,DS-8468b120-3d24-4e56-a758-038f8a0807a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-ef42549b-9e72-45f9-9a0e-6dd2710c738e,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-eee1f433-fff4-4372-9708-dec972fc23bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-53fe7eae-6109-4686-9697-bd1d226317c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-11a2bfa4-f42d-481c-9b2a-f87141b950bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-5f1a490d-67bc-4ac8-9130-2cd5f10830be,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-05af659e-5e0d-49f6-9c2d-b567c8cf9731,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-3c936347-7eec-4a44-84fa-84e9f4c2c691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917166148-172.17.0.9-1595929373790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44533,DS-d15a2245-5f0e-4bf5-91ca-3c01fe899804,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-a2477155-b25a-42b8-840b-e0599034d744,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-81757c60-d133-4109-839d-389458e467a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-7ea17a11-e647-46cb-be26-0a3f8e94aa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-00eed3f8-2f09-43ef-b241-5efad3a1a10a,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-c7e7c149-d8fa-40a1-83f0-b9c0ebae116f,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-c276ae31-5c4a-471b-807b-936992e459e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-152197c9-21c5-442a-bf7c-11a15f4f4647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917166148-172.17.0.9-1595929373790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44533,DS-d15a2245-5f0e-4bf5-91ca-3c01fe899804,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-a2477155-b25a-42b8-840b-e0599034d744,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-81757c60-d133-4109-839d-389458e467a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-7ea17a11-e647-46cb-be26-0a3f8e94aa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-00eed3f8-2f09-43ef-b241-5efad3a1a10a,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-c7e7c149-d8fa-40a1-83f0-b9c0ebae116f,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-c276ae31-5c4a-471b-807b-936992e459e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-152197c9-21c5-442a-bf7c-11a15f4f4647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916879053-172.17.0.9-1595929442700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-2bb0f9e1-1d97-4054-8daa-461d3c20e8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-be134a44-de3f-4ca1-aa72-ef1a86619c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-15e02f17-6132-4e67-abb7-3de0c2993ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-a8ff13b7-d7e7-4215-b596-17227928c011,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-61ce7ed6-a2bd-407e-b8e0-1c332e818762,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-327332b9-fe83-4906-ad1e-f748f1ec9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-3a6496cd-3f7c-409f-8c12-01d8bf37802a,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-bed6843e-b485-48de-94d2-4000c19522a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916879053-172.17.0.9-1595929442700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-2bb0f9e1-1d97-4054-8daa-461d3c20e8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-be134a44-de3f-4ca1-aa72-ef1a86619c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-15e02f17-6132-4e67-abb7-3de0c2993ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-a8ff13b7-d7e7-4215-b596-17227928c011,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-61ce7ed6-a2bd-407e-b8e0-1c332e818762,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-327332b9-fe83-4906-ad1e-f748f1ec9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-3a6496cd-3f7c-409f-8c12-01d8bf37802a,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-bed6843e-b485-48de-94d2-4000c19522a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429073011-172.17.0.9-1595929477792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45712,DS-0da6dc61-8a00-485c-9bd4-5f4c2d8bca6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-a7336cdc-92f3-4e14-b26f-c4009eb4a831,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-0e0ae3c1-ba26-46ca-a052-a1468cc5922f,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-f1be0bb7-edac-4ef1-9b86-15aac93fbab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-a51cb3ad-0524-4cc0-b1a2-53b63f7bab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-ca63cf32-e954-49d9-a480-34ad4fdc9e85,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-13c8b258-14d2-4df7-92eb-a86bd3b52244,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-5741a7db-ffde-43b0-b39e-cf4399afa961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429073011-172.17.0.9-1595929477792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45712,DS-0da6dc61-8a00-485c-9bd4-5f4c2d8bca6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-a7336cdc-92f3-4e14-b26f-c4009eb4a831,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-0e0ae3c1-ba26-46ca-a052-a1468cc5922f,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-f1be0bb7-edac-4ef1-9b86-15aac93fbab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-a51cb3ad-0524-4cc0-b1a2-53b63f7bab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-ca63cf32-e954-49d9-a480-34ad4fdc9e85,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-13c8b258-14d2-4df7-92eb-a86bd3b52244,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-5741a7db-ffde-43b0-b39e-cf4399afa961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360281914-172.17.0.9-1595929553464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-327755e9-8cee-45da-9b49-8cec507dba29,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-ba80f349-1445-4a9c-8b16-db0408ff2fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-54abf424-bbd9-4cb9-b694-5a11fd59b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-a9dcf0fd-8af8-4e41-94b4-407f8c636c54,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-f8abfb90-deae-405f-88b8-b05f9245b582,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-31447b7a-bde4-4ee9-befd-feb7afd98732,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-fb4b4ff6-ce01-402e-98bb-ccf01427b402,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-5f56d6d9-e31a-467d-ad8c-651b3e872702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360281914-172.17.0.9-1595929553464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-327755e9-8cee-45da-9b49-8cec507dba29,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-ba80f349-1445-4a9c-8b16-db0408ff2fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-54abf424-bbd9-4cb9-b694-5a11fd59b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-a9dcf0fd-8af8-4e41-94b4-407f8c636c54,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-f8abfb90-deae-405f-88b8-b05f9245b582,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-31447b7a-bde4-4ee9-befd-feb7afd98732,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-fb4b4ff6-ce01-402e-98bb-ccf01427b402,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-5f56d6d9-e31a-467d-ad8c-651b3e872702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570070353-172.17.0.9-1595929940645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-11f5faad-8ec8-4834-818f-fd7f7367d681,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-e1ef45d7-e6f9-45c2-8939-cf55db2c47d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-7deb432b-2abf-4177-a4a4-d7ae7ba79d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-d38ccba1-72c4-4cea-a050-d5eaaf6dee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-bf097db5-d2c6-41b7-813f-9683343ce0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-ee0efff3-202b-4e5a-a779-bcd0d00557ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-0286e4ca-da01-4d0b-899c-47f3fae6a260,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-b049b51d-af45-430c-822c-501cf6926643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570070353-172.17.0.9-1595929940645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-11f5faad-8ec8-4834-818f-fd7f7367d681,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-e1ef45d7-e6f9-45c2-8939-cf55db2c47d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-7deb432b-2abf-4177-a4a4-d7ae7ba79d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-d38ccba1-72c4-4cea-a050-d5eaaf6dee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-bf097db5-d2c6-41b7-813f-9683343ce0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-ee0efff3-202b-4e5a-a779-bcd0d00557ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-0286e4ca-da01-4d0b-899c-47f3fae6a260,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-b049b51d-af45-430c-822c-501cf6926643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044127740-172.17.0.9-1595930113591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-3f599a22-1dd5-4918-bfe3-d61a9bf39e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-d3e5b2a0-1457-49d2-aade-f925f91be671,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-f05935fa-b031-48af-a349-9c7d22ed21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-30559d53-af2a-4991-a8a4-815e710957e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-dbc40cb3-3c04-41cd-907e-ae4d898c97a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-ac61d345-0ff6-474d-994d-7f7223a5e0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-c1558354-1259-41c3-aae4-ef0ec9764129,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-a4ba357f-7f38-40d4-9481-f5bdd1505ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044127740-172.17.0.9-1595930113591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-3f599a22-1dd5-4918-bfe3-d61a9bf39e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-d3e5b2a0-1457-49d2-aade-f925f91be671,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-f05935fa-b031-48af-a349-9c7d22ed21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-30559d53-af2a-4991-a8a4-815e710957e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-dbc40cb3-3c04-41cd-907e-ae4d898c97a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-ac61d345-0ff6-474d-994d-7f7223a5e0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-c1558354-1259-41c3-aae4-ef0ec9764129,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-a4ba357f-7f38-40d4-9481-f5bdd1505ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176614351-172.17.0.9-1595930393403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-9c25dcda-f344-4bd9-9e5b-599ab469d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-232e3dca-56d4-449f-ad83-fd4f13bcf838,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-1b4ccaa3-82c2-4e7b-b4f3-2c03b4353020,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-0302080a-b3a9-4b3e-ab03-69d5a4cc2df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-970352e0-3e37-440f-8baa-45bb13784abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-f3fd305d-919c-45d3-8549-52edd2d9cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-c1675a44-ec27-44a4-82f0-1ca6f3a70b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-07c3b238-d20a-4d55-b4d7-379a0ecd11ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176614351-172.17.0.9-1595930393403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-9c25dcda-f344-4bd9-9e5b-599ab469d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-232e3dca-56d4-449f-ad83-fd4f13bcf838,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-1b4ccaa3-82c2-4e7b-b4f3-2c03b4353020,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-0302080a-b3a9-4b3e-ab03-69d5a4cc2df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-970352e0-3e37-440f-8baa-45bb13784abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-f3fd305d-919c-45d3-8549-52edd2d9cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-c1675a44-ec27-44a4-82f0-1ca6f3a70b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-07c3b238-d20a-4d55-b4d7-379a0ecd11ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128901548-172.17.0.9-1595930526438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-b1c98f22-1555-4a0b-824b-c6064ed0c79f,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-376a20c1-107e-4527-a6b6-80b78501e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-23525c21-c724-4735-90db-b3e6ae290cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-30b7fdb5-6e80-4cb5-9761-f9dab8bd9e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-f30f0bd4-45e0-4a73-8fec-11db97273dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-79c5b532-d746-4cf3-87fb-7aa540c5ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-79d4c667-1e6f-49cf-a4e5-a500a2fbc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-d6820889-31d8-41cb-9c6a-91ad9ac74612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128901548-172.17.0.9-1595930526438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-b1c98f22-1555-4a0b-824b-c6064ed0c79f,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-376a20c1-107e-4527-a6b6-80b78501e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-23525c21-c724-4735-90db-b3e6ae290cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-30b7fdb5-6e80-4cb5-9761-f9dab8bd9e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-f30f0bd4-45e0-4a73-8fec-11db97273dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-79c5b532-d746-4cf3-87fb-7aa540c5ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-79d4c667-1e6f-49cf-a4e5-a500a2fbc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-d6820889-31d8-41cb-9c6a-91ad9ac74612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755988906-172.17.0.9-1595930634246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-7f1dc37c-27fa-4d14-9cae-9f37c09bb27b,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-ce068423-3aa9-46a2-bf8d-92bfd0d274b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-d40934fa-dca3-41f9-a688-fa95dec8f959,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-a2537766-b81f-44c7-80ef-f011ea748172,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-26ae285c-d741-4451-b4f3-31b983ccc0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-dcf5fbc6-c9f3-440a-8c00-6f337e26bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-61c50d4b-a9f1-461d-895a-30b820d8de69,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-05508db5-265a-4788-ae25-06a2f792f954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755988906-172.17.0.9-1595930634246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-7f1dc37c-27fa-4d14-9cae-9f37c09bb27b,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-ce068423-3aa9-46a2-bf8d-92bfd0d274b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-d40934fa-dca3-41f9-a688-fa95dec8f959,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-a2537766-b81f-44c7-80ef-f011ea748172,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-26ae285c-d741-4451-b4f3-31b983ccc0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-dcf5fbc6-c9f3-440a-8c00-6f337e26bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-61c50d4b-a9f1-461d-895a-30b820d8de69,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-05508db5-265a-4788-ae25-06a2f792f954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129101391-172.17.0.9-1595930781981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39020,DS-cc8d74bc-238d-4a28-bc29-3c3c4d99caba,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-54005a5a-d1ba-4754-8c3f-8cb275b031b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-99eff094-21ce-433b-93de-85bee8fa8a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-ca359e93-b591-44d8-903c-3f9e72a11a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-86fc50aa-d0d8-4fae-8273-91eeaad1fa58,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-e02e0668-bae0-42ff-a6c5-2047317398ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-40bf459b-9aad-4c4f-964c-a1d3b262b494,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-b97bd8e9-5da1-441c-9f28-b6dc53dcc71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129101391-172.17.0.9-1595930781981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39020,DS-cc8d74bc-238d-4a28-bc29-3c3c4d99caba,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-54005a5a-d1ba-4754-8c3f-8cb275b031b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-99eff094-21ce-433b-93de-85bee8fa8a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-ca359e93-b591-44d8-903c-3f9e72a11a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-86fc50aa-d0d8-4fae-8273-91eeaad1fa58,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-e02e0668-bae0-42ff-a6c5-2047317398ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-40bf459b-9aad-4c4f-964c-a1d3b262b494,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-b97bd8e9-5da1-441c-9f28-b6dc53dcc71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745260829-172.17.0.9-1595930934694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45101,DS-1b51f419-9e15-4b07-abd1-ede9e117fe49,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-f57e03d9-3585-4cdf-b859-43c8a75aa50f,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-2b8d7711-17af-4c96-95e7-775211e3fe10,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-d54f323d-4578-4336-ac0f-25f4e389009b,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-0f43ff3c-7970-4ffe-9ab6-4371701dbd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-a7727b07-3beb-48db-ac4b-4dce6f2df7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-0e7d8578-7efb-4987-92db-ded5a1714e71,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-c78d3eff-b689-44b0-8883-e45764c13c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745260829-172.17.0.9-1595930934694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45101,DS-1b51f419-9e15-4b07-abd1-ede9e117fe49,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-f57e03d9-3585-4cdf-b859-43c8a75aa50f,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-2b8d7711-17af-4c96-95e7-775211e3fe10,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-d54f323d-4578-4336-ac0f-25f4e389009b,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-0f43ff3c-7970-4ffe-9ab6-4371701dbd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-a7727b07-3beb-48db-ac4b-4dce6f2df7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-0e7d8578-7efb-4987-92db-ded5a1714e71,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-c78d3eff-b689-44b0-8883-e45764c13c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353408011-172.17.0.9-1595931348251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-487c794b-095a-46f0-88ea-66aace4196f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-0dbb019b-ad85-470e-b3c7-ba0012370e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-0d25ad7c-7ecc-41ea-82ef-e11d58c39843,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-72169e6c-7ed1-4390-9f7d-bd050caa4f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-68125210-8b22-476e-b5a9-d76de2e79d48,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-18ca2ab9-0b37-4d7f-a464-58321fafad75,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-eea06a96-894b-4cda-8874-067ad7e7c26c,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-d6df703b-6420-4ca5-ba4e-a93227099582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353408011-172.17.0.9-1595931348251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-487c794b-095a-46f0-88ea-66aace4196f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-0dbb019b-ad85-470e-b3c7-ba0012370e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-0d25ad7c-7ecc-41ea-82ef-e11d58c39843,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-72169e6c-7ed1-4390-9f7d-bd050caa4f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-68125210-8b22-476e-b5a9-d76de2e79d48,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-18ca2ab9-0b37-4d7f-a464-58321fafad75,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-eea06a96-894b-4cda-8874-067ad7e7c26c,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-d6df703b-6420-4ca5-ba4e-a93227099582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805873994-172.17.0.9-1595931452527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43089,DS-6b483d6d-2332-4445-95f1-8ba26a578116,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-d2188b06-3fa7-4469-8ef3-1aecd97f62c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-0aea767d-5c94-46fe-bc05-c88d02425b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-889acbbf-fedc-4f15-b0a8-5f879141a069,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-f63a5679-efb5-4dc2-bdd8-c4104a0d7d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-43df009e-3544-4fec-a1fc-7db2674b1ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-f0839d88-7135-4db8-871c-792ca758021c,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-36074ff3-769e-4532-bed3-f8f7ed3d41a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805873994-172.17.0.9-1595931452527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43089,DS-6b483d6d-2332-4445-95f1-8ba26a578116,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-d2188b06-3fa7-4469-8ef3-1aecd97f62c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-0aea767d-5c94-46fe-bc05-c88d02425b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-889acbbf-fedc-4f15-b0a8-5f879141a069,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-f63a5679-efb5-4dc2-bdd8-c4104a0d7d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-43df009e-3544-4fec-a1fc-7db2674b1ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-f0839d88-7135-4db8-871c-792ca758021c,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-36074ff3-769e-4532-bed3-f8f7ed3d41a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5320
