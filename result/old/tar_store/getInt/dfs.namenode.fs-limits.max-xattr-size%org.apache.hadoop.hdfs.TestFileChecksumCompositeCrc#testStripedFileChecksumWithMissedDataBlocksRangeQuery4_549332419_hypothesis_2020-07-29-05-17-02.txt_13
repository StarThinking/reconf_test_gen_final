reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196680888-172.17.0.7-1596000010800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-2213f500-7f4c-427d-8ca1-a1a1bc629f14,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-28b84640-abbe-4502-b990-3d4d6eda426e,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-9ae7e9f5-e682-4a01-922f-5f8c6e0b324e,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-e4bc6248-6d6c-4e00-8c8f-eac8f142ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-c9877408-37a1-4dcd-bab5-c83e07b118f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-af2c06a4-1877-468e-9018-3403fa1d4571,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-7354351c-2652-4952-ba17-78ef808f5ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-d00ff417-647d-4b3a-877b-bbdd974a6c20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196680888-172.17.0.7-1596000010800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-2213f500-7f4c-427d-8ca1-a1a1bc629f14,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-28b84640-abbe-4502-b990-3d4d6eda426e,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-9ae7e9f5-e682-4a01-922f-5f8c6e0b324e,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-e4bc6248-6d6c-4e00-8c8f-eac8f142ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-c9877408-37a1-4dcd-bab5-c83e07b118f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-af2c06a4-1877-468e-9018-3403fa1d4571,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-7354351c-2652-4952-ba17-78ef808f5ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-d00ff417-647d-4b3a-877b-bbdd974a6c20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229175258-172.17.0.7-1596000126709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36111,DS-3f6f9c3d-916a-4128-becb-c8fa19e5191e,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-bc0dc427-0cdd-4408-ad90-56655fdb3594,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-d40fd2bf-73af-4f32-b429-41967dad2913,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-eaa03117-cb6d-418f-9549-5e0adeccd0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-43c7c868-bf1e-4286-8f2c-70dbd7950f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-2426f9d7-031f-4691-a032-b7c757538d00,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b97f30a3-0565-4b9a-aebf-9e2a2bf38e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-4dadda27-c7c4-4c39-b991-e1c0192d46f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229175258-172.17.0.7-1596000126709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36111,DS-3f6f9c3d-916a-4128-becb-c8fa19e5191e,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-bc0dc427-0cdd-4408-ad90-56655fdb3594,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-d40fd2bf-73af-4f32-b429-41967dad2913,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-eaa03117-cb6d-418f-9549-5e0adeccd0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-43c7c868-bf1e-4286-8f2c-70dbd7950f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-2426f9d7-031f-4691-a032-b7c757538d00,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b97f30a3-0565-4b9a-aebf-9e2a2bf38e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-4dadda27-c7c4-4c39-b991-e1c0192d46f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31723746-172.17.0.7-1596000635732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32805,DS-7e80e8cc-0f40-43bd-827c-ae42cf8cf18d,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-12fb296a-161c-4596-825b-96a0cb5df504,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-4a475ac6-05d7-4791-af73-c747659f9f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-c60c9b72-dc9f-4ef8-82ad-6257d8e295ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-bf604860-6dd5-4296-ba28-299d2a2a2826,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-e72c33d2-63f3-4946-b8bb-f30cd960fda3,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-07b42687-5a70-4657-a2ac-346e6a538713,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-347764f6-a1bc-4538-b749-d13ef1f1c31b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31723746-172.17.0.7-1596000635732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32805,DS-7e80e8cc-0f40-43bd-827c-ae42cf8cf18d,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-12fb296a-161c-4596-825b-96a0cb5df504,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-4a475ac6-05d7-4791-af73-c747659f9f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-c60c9b72-dc9f-4ef8-82ad-6257d8e295ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-bf604860-6dd5-4296-ba28-299d2a2a2826,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-e72c33d2-63f3-4946-b8bb-f30cd960fda3,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-07b42687-5a70-4657-a2ac-346e6a538713,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-347764f6-a1bc-4538-b749-d13ef1f1c31b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650752308-172.17.0.7-1596000847978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38587,DS-1c9afdff-0938-4874-bde2-2649cbe17691,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-d6463408-3a3f-41cf-a76f-df07f0b1152a,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-42db97ae-33f5-4c59-9b83-00b9df7cfb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-4643fe8c-245b-4b02-b496-968113ea93ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-702a5d5b-970c-4bae-8006-e73e42858a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-11109b5a-e458-4bd9-b4c8-fa77379e5dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-3d975dd9-c9f9-4d7c-957c-1bc25af9c642,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-87599b72-5cbd-4082-8246-51435ed1fbe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650752308-172.17.0.7-1596000847978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38587,DS-1c9afdff-0938-4874-bde2-2649cbe17691,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-d6463408-3a3f-41cf-a76f-df07f0b1152a,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-42db97ae-33f5-4c59-9b83-00b9df7cfb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-4643fe8c-245b-4b02-b496-968113ea93ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-702a5d5b-970c-4bae-8006-e73e42858a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-11109b5a-e458-4bd9-b4c8-fa77379e5dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-3d975dd9-c9f9-4d7c-957c-1bc25af9c642,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-87599b72-5cbd-4082-8246-51435ed1fbe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142563324-172.17.0.7-1596000951797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34673,DS-23e1120f-dffb-43d3-9383-a972bca77475,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-3b1236bf-02a8-4e52-9c01-f386d12cac36,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-f0b8502b-1d2f-4d1c-ad2b-a80b8edab1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-7a298c92-1562-49dd-8dc4-0c0f0507ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-22fdea95-2eff-45bb-99ee-f63c12c15435,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-a7f7db85-898a-4f7b-9e50-d7f9e9614d52,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-60f53d3b-cf2f-41cc-9b11-7dfcd6d85e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-35cc6fb0-580b-4624-9742-91dcdb038c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142563324-172.17.0.7-1596000951797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34673,DS-23e1120f-dffb-43d3-9383-a972bca77475,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-3b1236bf-02a8-4e52-9c01-f386d12cac36,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-f0b8502b-1d2f-4d1c-ad2b-a80b8edab1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-7a298c92-1562-49dd-8dc4-0c0f0507ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-22fdea95-2eff-45bb-99ee-f63c12c15435,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-a7f7db85-898a-4f7b-9e50-d7f9e9614d52,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-60f53d3b-cf2f-41cc-9b11-7dfcd6d85e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-35cc6fb0-580b-4624-9742-91dcdb038c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131727806-172.17.0.7-1596001467923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-20103469-0594-421f-9ddb-d7eee858ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-ca239c6b-9b85-4162-8c54-5f35244a457f,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-ac6e4426-5de7-49b5-af36-8f65c09abb77,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-8c8f41f6-4a6a-44f4-acb8-611d497b6634,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-e5c767af-c640-4c39-9f85-de829460bf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-bf55a14b-7ed2-4934-baf5-8009ef5cfde7,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-f2ba5b9c-13fb-4d50-a7dd-82409af83729,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-b3ac5d6f-ccca-403c-9cdd-40f9855b98f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131727806-172.17.0.7-1596001467923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-20103469-0594-421f-9ddb-d7eee858ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-ca239c6b-9b85-4162-8c54-5f35244a457f,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-ac6e4426-5de7-49b5-af36-8f65c09abb77,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-8c8f41f6-4a6a-44f4-acb8-611d497b6634,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-e5c767af-c640-4c39-9f85-de829460bf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-bf55a14b-7ed2-4934-baf5-8009ef5cfde7,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-f2ba5b9c-13fb-4d50-a7dd-82409af83729,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-b3ac5d6f-ccca-403c-9cdd-40f9855b98f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767471340-172.17.0.7-1596001498588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46292,DS-6ad88ddd-0e34-4c4e-ad47-c42ebc5b8691,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-d27c369d-2d12-47d5-9e6b-c8716f3bfa92,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-4417801a-94dd-4698-9ba2-6ad4bf43b77d,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-c071979b-c9f5-477f-bea8-2d330cc1b0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-8d8fda15-4b19-4c94-a5a4-a566553a6b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-feac6090-9c5f-4fac-ad5b-47ceb6e7e4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-bddbf819-39a3-4760-99e2-456f7c0737a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-200aeef5-d800-4857-ae12-af4e8c5bb4e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767471340-172.17.0.7-1596001498588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46292,DS-6ad88ddd-0e34-4c4e-ad47-c42ebc5b8691,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-d27c369d-2d12-47d5-9e6b-c8716f3bfa92,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-4417801a-94dd-4698-9ba2-6ad4bf43b77d,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-c071979b-c9f5-477f-bea8-2d330cc1b0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-8d8fda15-4b19-4c94-a5a4-a566553a6b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-feac6090-9c5f-4fac-ad5b-47ceb6e7e4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-bddbf819-39a3-4760-99e2-456f7c0737a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-200aeef5-d800-4857-ae12-af4e8c5bb4e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061207215-172.17.0.7-1596001702409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41115,DS-ae276ea1-e85b-4ebb-9585-096c88d62fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-d6e5df58-c99e-4d3f-bd26-5a791b5e5423,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-e030cc98-5cfd-4efe-bc7e-8042ce0e56f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-7281f4ee-1edb-4e66-8cb0-6a5434619b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-4f550b57-50f9-4fa5-84bc-fa3c8693ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-b5ac97d7-9388-4426-8503-edc46df084f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-847d50df-0360-468b-aca3-3483eb3d362d,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-d3911e3e-ee3b-454c-a25c-b828469b61a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061207215-172.17.0.7-1596001702409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41115,DS-ae276ea1-e85b-4ebb-9585-096c88d62fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-d6e5df58-c99e-4d3f-bd26-5a791b5e5423,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-e030cc98-5cfd-4efe-bc7e-8042ce0e56f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-7281f4ee-1edb-4e66-8cb0-6a5434619b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-4f550b57-50f9-4fa5-84bc-fa3c8693ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-b5ac97d7-9388-4426-8503-edc46df084f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-847d50df-0360-468b-aca3-3483eb3d362d,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-d3911e3e-ee3b-454c-a25c-b828469b61a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972108530-172.17.0.7-1596001883427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35937,DS-b5d1ac6e-f2cf-4844-a972-f4aceefade32,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-3d938ec3-2d81-49a9-a151-80212d9996f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-e6527d05-d64c-4728-a7c5-670837c0fce7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-06ed2904-a79b-48cf-9598-d4b8df7b0c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-fca5189a-2598-4145-af6a-03818b69966c,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-b0e4e64a-1e14-4f1d-a07b-d9ed831f66f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-e8426d8a-df4a-4f73-8ae4-0fccf1163541,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-a775c8b7-1f8d-427c-b944-642c6730a7bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972108530-172.17.0.7-1596001883427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35937,DS-b5d1ac6e-f2cf-4844-a972-f4aceefade32,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-3d938ec3-2d81-49a9-a151-80212d9996f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-e6527d05-d64c-4728-a7c5-670837c0fce7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-06ed2904-a79b-48cf-9598-d4b8df7b0c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-fca5189a-2598-4145-af6a-03818b69966c,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-b0e4e64a-1e14-4f1d-a07b-d9ed831f66f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-e8426d8a-df4a-4f73-8ae4-0fccf1163541,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-a775c8b7-1f8d-427c-b944-642c6730a7bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57305099-172.17.0.7-1596002173140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-6eaa0af4-3783-4e31-9f8a-190745a47c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-91a19095-16ed-4a4d-8100-d79986085c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-304234c4-8290-408e-9e89-631580ac2f24,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-83ecb290-ccf8-4cfe-944b-0798c2ea19b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-830cbd0c-7ca2-476d-91d8-d4796f5f54a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-00642f33-419a-4665-b2f6-54b6a3f7be73,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-c9b73c61-4611-41dd-b218-029f94a2b935,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-95f15924-bb39-4f22-a8d6-9c3973c36b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57305099-172.17.0.7-1596002173140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-6eaa0af4-3783-4e31-9f8a-190745a47c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-91a19095-16ed-4a4d-8100-d79986085c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-304234c4-8290-408e-9e89-631580ac2f24,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-83ecb290-ccf8-4cfe-944b-0798c2ea19b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-830cbd0c-7ca2-476d-91d8-d4796f5f54a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-00642f33-419a-4665-b2f6-54b6a3f7be73,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-c9b73c61-4611-41dd-b218-029f94a2b935,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-95f15924-bb39-4f22-a8d6-9c3973c36b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714589271-172.17.0.7-1596003608898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-0a4eb4f9-0038-4649-85cb-bfc3040fe2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-7e1f508c-56cc-433d-9def-4c4842cba513,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-fb4a0504-4779-4e5a-9e32-abd9a3d93ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-c713b3f7-f804-4653-8ac4-19fc36c4cca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-ecfdd485-8cd0-473c-87b1-eb62ce535257,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-ef1a1e15-b3bb-4e04-90a7-bfc5778e8053,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-b4bf4a78-8801-46df-a8fb-46a400694dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-8aae3db0-0a9a-4f0c-bf50-662ae2bf5a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714589271-172.17.0.7-1596003608898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-0a4eb4f9-0038-4649-85cb-bfc3040fe2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-7e1f508c-56cc-433d-9def-4c4842cba513,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-fb4a0504-4779-4e5a-9e32-abd9a3d93ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-c713b3f7-f804-4653-8ac4-19fc36c4cca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-ecfdd485-8cd0-473c-87b1-eb62ce535257,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-ef1a1e15-b3bb-4e04-90a7-bfc5778e8053,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-b4bf4a78-8801-46df-a8fb-46a400694dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-8aae3db0-0a9a-4f0c-bf50-662ae2bf5a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286206164-172.17.0.7-1596004019266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-c4955bd4-a7d9-4589-bc61-1537aee281db,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-2cdfc4be-aec4-4249-a0e3-95ae53bc298f,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-c000492f-1572-48ef-af04-678493ef960d,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-be471058-c09b-4384-842f-58dcfed55d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-86182ebb-8d44-48e1-b7e5-36020deb6fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-3d946230-7c46-4203-98f3-1a87f8af2534,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-d0bade03-0570-4e63-9932-ab32e0832c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-d7fcedd8-3be1-4637-bf1f-d82ef0706473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286206164-172.17.0.7-1596004019266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-c4955bd4-a7d9-4589-bc61-1537aee281db,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-2cdfc4be-aec4-4249-a0e3-95ae53bc298f,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-c000492f-1572-48ef-af04-678493ef960d,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-be471058-c09b-4384-842f-58dcfed55d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-86182ebb-8d44-48e1-b7e5-36020deb6fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-3d946230-7c46-4203-98f3-1a87f8af2534,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-d0bade03-0570-4e63-9932-ab32e0832c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-d7fcedd8-3be1-4637-bf1f-d82ef0706473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738862685-172.17.0.7-1596004782260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-1c0e481e-737f-4fe5-badf-22ca3ddb3893,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-43a52571-729c-4e33-96a7-617d14d50efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-4cf0e33d-74d9-49b1-926c-3150fdfa466a,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-5d836a54-fd1a-4e63-861c-c39008dc0b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-478d6c53-f530-4c70-930c-57de09f47e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-9028f7ee-4bce-4951-9774-c5a5535063db,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-d00fa8e5-26c6-4bea-901c-f5ebf39e8bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-f87f4b42-ea9d-47c6-a14c-c09880f99094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738862685-172.17.0.7-1596004782260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-1c0e481e-737f-4fe5-badf-22ca3ddb3893,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-43a52571-729c-4e33-96a7-617d14d50efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-4cf0e33d-74d9-49b1-926c-3150fdfa466a,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-5d836a54-fd1a-4e63-861c-c39008dc0b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-478d6c53-f530-4c70-930c-57de09f47e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-9028f7ee-4bce-4951-9774-c5a5535063db,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-d00fa8e5-26c6-4bea-901c-f5ebf39e8bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-f87f4b42-ea9d-47c6-a14c-c09880f99094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158047733-172.17.0.7-1596004816910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-909ea05d-6ffe-4540-9fdf-aeb45bbb75db,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-0f4a968c-4c22-4918-904d-e779961caab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-e0f9fa69-b8ff-4bed-a185-650d76768e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-43ded955-8305-48c3-81b2-c27d75b3cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-24581db1-670a-402a-9b9d-ae58e8ef56e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-e50f5193-79a8-4a7e-acc4-558de8b3915f,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-23b60bb4-3a82-4240-ab86-be4c03d09b32,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-37a776ec-1c68-4099-9278-843279d11468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158047733-172.17.0.7-1596004816910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-909ea05d-6ffe-4540-9fdf-aeb45bbb75db,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-0f4a968c-4c22-4918-904d-e779961caab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-e0f9fa69-b8ff-4bed-a185-650d76768e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-43ded955-8305-48c3-81b2-c27d75b3cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-24581db1-670a-402a-9b9d-ae58e8ef56e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-e50f5193-79a8-4a7e-acc4-558de8b3915f,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-23b60bb4-3a82-4240-ab86-be4c03d09b32,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-37a776ec-1c68-4099-9278-843279d11468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5415
