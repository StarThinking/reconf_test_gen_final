reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508058817-172.17.0.7-1595806313752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39476,DS-14d3a6a5-d664-47b7-a73b-e8b2175fe85e,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-3efc74f3-675b-4388-8b79-488de867ae75,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-dd10e07f-48d7-4cf0-ab62-5b660d848332,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-3355e89f-7d7f-4147-a4aa-7683641e38c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-0a05e149-a03e-4d14-9864-6739d423f375,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-03554d71-2a5a-48bd-b154-9dcf46472307,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-e946a58e-8f04-49e7-8c55-933b71ae5b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-af8489ca-9553-4c98-b37c-1efd809d6f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508058817-172.17.0.7-1595806313752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39476,DS-14d3a6a5-d664-47b7-a73b-e8b2175fe85e,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-3efc74f3-675b-4388-8b79-488de867ae75,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-dd10e07f-48d7-4cf0-ab62-5b660d848332,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-3355e89f-7d7f-4147-a4aa-7683641e38c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-0a05e149-a03e-4d14-9864-6739d423f375,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-03554d71-2a5a-48bd-b154-9dcf46472307,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-e946a58e-8f04-49e7-8c55-933b71ae5b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-af8489ca-9553-4c98-b37c-1efd809d6f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752470057-172.17.0.7-1595806359967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38484,DS-fc28c059-109f-48c7-b533-8629853b296d,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-1e3e5603-5a70-4593-aa23-f0ff38e628f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-e823cec0-6695-4693-9ffc-9111d2199398,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-746b1ae6-7f87-4e3b-9442-776d0c9b97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-531054be-091a-4960-9596-367a18c14527,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-4f79d92b-7d89-427f-8d05-5b4f42c72b04,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-a6237120-f00a-44fe-a3fd-33eb5fc41991,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-7c089c38-483a-4e49-b941-5e0c2b8dd822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752470057-172.17.0.7-1595806359967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38484,DS-fc28c059-109f-48c7-b533-8629853b296d,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-1e3e5603-5a70-4593-aa23-f0ff38e628f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-e823cec0-6695-4693-9ffc-9111d2199398,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-746b1ae6-7f87-4e3b-9442-776d0c9b97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-531054be-091a-4960-9596-367a18c14527,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-4f79d92b-7d89-427f-8d05-5b4f42c72b04,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-a6237120-f00a-44fe-a3fd-33eb5fc41991,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-7c089c38-483a-4e49-b941-5e0c2b8dd822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993714224-172.17.0.7-1595806444822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34353,DS-4ff8ec13-7d01-4dec-832e-32f5902399d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-23c6d9b7-161f-43ed-997b-df1d45d73098,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-982f9d2b-a39b-48f5-9927-37ac4528a957,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-963d8f2d-b559-4c60-a31b-d6c2badec8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-221ff75b-7132-43a8-9d12-f5e4a484dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-b6b5b1ed-1125-4fc1-9daf-1c0bd43b593d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-dfe4eeae-6070-4d88-abd6-27eae06eb9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-43283349-6557-4d7c-b238-5a9a5d66fa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993714224-172.17.0.7-1595806444822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34353,DS-4ff8ec13-7d01-4dec-832e-32f5902399d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-23c6d9b7-161f-43ed-997b-df1d45d73098,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-982f9d2b-a39b-48f5-9927-37ac4528a957,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-963d8f2d-b559-4c60-a31b-d6c2badec8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-221ff75b-7132-43a8-9d12-f5e4a484dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-b6b5b1ed-1125-4fc1-9daf-1c0bd43b593d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-dfe4eeae-6070-4d88-abd6-27eae06eb9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-43283349-6557-4d7c-b238-5a9a5d66fa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365014360-172.17.0.7-1595806762471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-d6d2f9f6-fe68-45c0-80c4-cf31ee25533a,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-33dcafd7-1ac4-4bb3-b525-a00ff02c0a88,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-3bf7bb15-69a1-4c7d-b4c4-36f9f5c949c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-961e7701-aacb-43c7-a727-333b7d7445e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-9523e019-d477-49e6-aef8-686cfc094e12,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-a47b487d-6599-4082-9a38-998f091e7682,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-cf73b8b6-aa8c-4ea8-b6e2-b4ec9330a582,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-f1da8673-dcf4-41f0-be53-50cc2d0fb3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365014360-172.17.0.7-1595806762471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-d6d2f9f6-fe68-45c0-80c4-cf31ee25533a,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-33dcafd7-1ac4-4bb3-b525-a00ff02c0a88,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-3bf7bb15-69a1-4c7d-b4c4-36f9f5c949c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-961e7701-aacb-43c7-a727-333b7d7445e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-9523e019-d477-49e6-aef8-686cfc094e12,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-a47b487d-6599-4082-9a38-998f091e7682,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-cf73b8b6-aa8c-4ea8-b6e2-b4ec9330a582,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-f1da8673-dcf4-41f0-be53-50cc2d0fb3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011429088-172.17.0.7-1595807554380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-1675bdd0-d200-4fe3-ba53-f2c898c53c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-ec772236-99d3-4774-a3ca-8e3008e31841,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-b4f580c0-88a2-400b-86ce-865075808a49,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-11343a3a-4df5-4564-9949-a827f5c6f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-7f2e5dbf-557f-4787-ab1e-2b7a75cc81e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-3e37ee35-6cf5-44b3-89dd-c8b82246a777,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-9ed46bbe-2f63-4900-b5bd-b63123b2e520,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-5314e3dc-4495-46bb-8dc8-cd8b48ebc7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011429088-172.17.0.7-1595807554380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-1675bdd0-d200-4fe3-ba53-f2c898c53c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-ec772236-99d3-4774-a3ca-8e3008e31841,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-b4f580c0-88a2-400b-86ce-865075808a49,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-11343a3a-4df5-4564-9949-a827f5c6f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-7f2e5dbf-557f-4787-ab1e-2b7a75cc81e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-3e37ee35-6cf5-44b3-89dd-c8b82246a777,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-9ed46bbe-2f63-4900-b5bd-b63123b2e520,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-5314e3dc-4495-46bb-8dc8-cd8b48ebc7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210095719-172.17.0.7-1595808115700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-9c8e1022-d2e8-4bff-add7-756da27443cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-3024d5d8-747e-462d-8ffd-567f617b9891,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-cf0a9791-2c4d-446d-ba27-81649b449cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-8fec5de5-051a-474d-af13-30d5f172909e,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-c2123442-acd1-4642-ad3b-f00e8f80c87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-c732fc3c-812d-4982-a1af-f5901486e43a,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-55d604b1-8cb8-43c8-96e7-6801c228d134,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-4d016118-bba4-4f86-be3b-345480a3963d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210095719-172.17.0.7-1595808115700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-9c8e1022-d2e8-4bff-add7-756da27443cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-3024d5d8-747e-462d-8ffd-567f617b9891,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-cf0a9791-2c4d-446d-ba27-81649b449cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-8fec5de5-051a-474d-af13-30d5f172909e,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-c2123442-acd1-4642-ad3b-f00e8f80c87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-c732fc3c-812d-4982-a1af-f5901486e43a,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-55d604b1-8cb8-43c8-96e7-6801c228d134,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-4d016118-bba4-4f86-be3b-345480a3963d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356070164-172.17.0.7-1595808291682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35323,DS-b7fca888-808f-476a-a8df-798484477d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-a731783d-60e2-4462-96d5-56e2409c71e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-fe6d9196-5775-41e7-864e-5e62b4e29986,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-0b82c5a8-468d-4a9d-917f-a54a95dfab75,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-4089a7dc-50d6-4ae3-8544-e784c85592e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-835bf646-2708-4900-9597-2a0609d1a20a,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-08ca2a01-ac43-4bec-83f2-9188d4c6be41,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-5cbaf765-3686-436d-8caa-a9616388f09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356070164-172.17.0.7-1595808291682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35323,DS-b7fca888-808f-476a-a8df-798484477d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-a731783d-60e2-4462-96d5-56e2409c71e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-fe6d9196-5775-41e7-864e-5e62b4e29986,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-0b82c5a8-468d-4a9d-917f-a54a95dfab75,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-4089a7dc-50d6-4ae3-8544-e784c85592e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-835bf646-2708-4900-9597-2a0609d1a20a,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-08ca2a01-ac43-4bec-83f2-9188d4c6be41,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-5cbaf765-3686-436d-8caa-a9616388f09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701297680-172.17.0.7-1595808534051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-81222a42-5490-4200-9c46-e7f67cfac8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-e69ebbc0-e542-4d43-9162-dec9656c9222,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-cab8f79f-40c2-4521-af80-57baeb874138,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-04d968f7-1d41-4682-a613-0e857dcc045a,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-24bf7a52-84e3-476a-a0b8-2651e63890eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-238310dc-fc1b-4bc9-b3d9-4b5914c10231,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-db682925-64ee-4a5d-a08e-2d60c9dbd97b,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-e62cd33b-a1b7-4f78-b143-3d8e78b5e8ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701297680-172.17.0.7-1595808534051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-81222a42-5490-4200-9c46-e7f67cfac8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-e69ebbc0-e542-4d43-9162-dec9656c9222,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-cab8f79f-40c2-4521-af80-57baeb874138,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-04d968f7-1d41-4682-a613-0e857dcc045a,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-24bf7a52-84e3-476a-a0b8-2651e63890eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-238310dc-fc1b-4bc9-b3d9-4b5914c10231,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-db682925-64ee-4a5d-a08e-2d60c9dbd97b,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-e62cd33b-a1b7-4f78-b143-3d8e78b5e8ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826333513-172.17.0.7-1595808841838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45134,DS-87240c49-6f60-413d-9fea-dca613b6aaca,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-7807e34c-e2f3-48fe-9734-69158a7217bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-e4833359-1ba6-4f79-a1e0-2b170c20cc43,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a883d2f6-cc16-4664-96f1-9a734c12fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-85a2f07b-b70a-4b4f-b620-f2e7ca5a91b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-30e223fb-0f58-4dac-b7ef-80f6f4eafbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-35640ba7-b818-4810-9e71-7f4b417eb81e,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-396abc90-42d3-4c52-9cfd-e2d338aa9e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826333513-172.17.0.7-1595808841838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45134,DS-87240c49-6f60-413d-9fea-dca613b6aaca,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-7807e34c-e2f3-48fe-9734-69158a7217bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-e4833359-1ba6-4f79-a1e0-2b170c20cc43,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a883d2f6-cc16-4664-96f1-9a734c12fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-85a2f07b-b70a-4b4f-b620-f2e7ca5a91b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-30e223fb-0f58-4dac-b7ef-80f6f4eafbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-35640ba7-b818-4810-9e71-7f4b417eb81e,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-396abc90-42d3-4c52-9cfd-e2d338aa9e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097700082-172.17.0.7-1595808882434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37694,DS-cdd2449b-ae0b-4c68-b1f7-2bf22d932258,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-da28de19-4d75-4214-9265-5d148b9fa482,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-d66c28b4-0b39-4dab-9789-d0a4b73901b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-13fc6fcc-7de7-4574-a573-e11f7094a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-672d9b5f-efb4-4096-864d-3d8020b7ffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-112ff936-0d3f-4d28-b1bb-f39f5a259ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-e860dc92-4478-458f-847e-57f7ebb950b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-bd98022e-e9b8-487d-a879-beb7390bfacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097700082-172.17.0.7-1595808882434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37694,DS-cdd2449b-ae0b-4c68-b1f7-2bf22d932258,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-da28de19-4d75-4214-9265-5d148b9fa482,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-d66c28b4-0b39-4dab-9789-d0a4b73901b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-13fc6fcc-7de7-4574-a573-e11f7094a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-672d9b5f-efb4-4096-864d-3d8020b7ffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-112ff936-0d3f-4d28-b1bb-f39f5a259ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-e860dc92-4478-458f-847e-57f7ebb950b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-bd98022e-e9b8-487d-a879-beb7390bfacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267602770-172.17.0.7-1595808983401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-4cbd121c-9e85-48a7-88fd-2791c7138e76,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-e30d3d06-ff53-4289-bb09-7b3ad1b5092d,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-b4218aed-35ea-4eb6-b8bf-7c8d161e7b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-40d85b29-ba9d-4c94-8620-6e0d4dbde131,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-e5a6e5c2-76cc-4eca-ae4b-64ced5c99559,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-5fcaf41c-6251-4e60-a345-4d654b564874,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-ce14e58e-16b0-4da7-9455-076f6e56df13,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-50071519-2a98-4d16-bd4d-0cc2ba6a2cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267602770-172.17.0.7-1595808983401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-4cbd121c-9e85-48a7-88fd-2791c7138e76,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-e30d3d06-ff53-4289-bb09-7b3ad1b5092d,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-b4218aed-35ea-4eb6-b8bf-7c8d161e7b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-40d85b29-ba9d-4c94-8620-6e0d4dbde131,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-e5a6e5c2-76cc-4eca-ae4b-64ced5c99559,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-5fcaf41c-6251-4e60-a345-4d654b564874,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-ce14e58e-16b0-4da7-9455-076f6e56df13,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-50071519-2a98-4d16-bd4d-0cc2ba6a2cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812258629-172.17.0.7-1595810103161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43129,DS-78d9d74d-9b22-4ee7-bc72-caf5f3733fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-d1f0d185-81ae-40e9-af62-5a79dd360be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-7336f6a5-ac3c-43ec-a717-fbadc2f358ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-1060ce7f-6e4c-430c-9627-a851eb3dd0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-38de2944-2ff4-4a0d-a703-90f7675a85f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-1b9b4832-1322-4008-bace-05510c2b28d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-a1789fd0-fcda-45bf-a407-1ba9be8d8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-9f3bbbff-0dc7-4f38-af06-d97dd69b48bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812258629-172.17.0.7-1595810103161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43129,DS-78d9d74d-9b22-4ee7-bc72-caf5f3733fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-d1f0d185-81ae-40e9-af62-5a79dd360be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-7336f6a5-ac3c-43ec-a717-fbadc2f358ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-1060ce7f-6e4c-430c-9627-a851eb3dd0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-38de2944-2ff4-4a0d-a703-90f7675a85f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-1b9b4832-1322-4008-bace-05510c2b28d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-a1789fd0-fcda-45bf-a407-1ba9be8d8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-9f3bbbff-0dc7-4f38-af06-d97dd69b48bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323883486-172.17.0.7-1595810369731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38087,DS-b7f4ddef-ae94-4396-a7d1-c31fc017b9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-0a70e220-4f7f-4489-b725-b6e48723d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-1b913156-545a-40bc-baf1-4bf05235a637,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-5d0a7b70-5ad5-466d-8ee1-3b0d69dcf8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-e3d43705-16e1-461d-8176-b26a75390331,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-635a923e-0efb-4858-9d35-34a961da363d,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-7470efff-0e94-4e36-be64-f99ad307eb77,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-c294ba73-b77e-44be-b685-8762e4a97798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323883486-172.17.0.7-1595810369731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38087,DS-b7f4ddef-ae94-4396-a7d1-c31fc017b9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-0a70e220-4f7f-4489-b725-b6e48723d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-1b913156-545a-40bc-baf1-4bf05235a637,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-5d0a7b70-5ad5-466d-8ee1-3b0d69dcf8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-e3d43705-16e1-461d-8176-b26a75390331,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-635a923e-0efb-4858-9d35-34a961da363d,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-7470efff-0e94-4e36-be64-f99ad307eb77,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-c294ba73-b77e-44be-b685-8762e4a97798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10108152-172.17.0.7-1595810416091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36914,DS-46e2b48c-9109-45bc-a3f5-8cd60cf211c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-6f694724-6cda-4a15-84cd-f2d429dff434,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-913297f3-de03-4ccf-b0de-e6cbfaa9f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-3cfaebc9-3b66-4e89-80bf-22750cc75a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-b08e0c47-e9fd-45c6-875a-632bdca514fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-e9bf22b2-b880-4e88-90e1-8119cf5cc550,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-c36dfad4-37f2-4ef2-b202-84814f94a1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-5fafb988-4048-4387-9e41-003d0c04c2fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10108152-172.17.0.7-1595810416091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36914,DS-46e2b48c-9109-45bc-a3f5-8cd60cf211c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-6f694724-6cda-4a15-84cd-f2d429dff434,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-913297f3-de03-4ccf-b0de-e6cbfaa9f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-3cfaebc9-3b66-4e89-80bf-22750cc75a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-b08e0c47-e9fd-45c6-875a-632bdca514fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-e9bf22b2-b880-4e88-90e1-8119cf5cc550,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-c36dfad4-37f2-4ef2-b202-84814f94a1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-5fafb988-4048-4387-9e41-003d0c04c2fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351906732-172.17.0.7-1595810632988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-5173a464-f174-4f69-b40d-8fdf3c427bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-dec64f77-ffd9-4059-beee-6e95c5391b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-4b155f79-3aee-4ac0-8eef-887ef0c6179d,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-447f7ee1-84ef-49e4-b289-c228c2f9f087,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-72615f6f-3cb1-4087-a66c-bd3a5e0746e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-a157d272-99bd-462c-9c32-20295f183b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-471a5dc7-3ce6-450a-8254-1f4869364fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-fd10a373-2ac7-4835-b97a-99d709ce7ae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351906732-172.17.0.7-1595810632988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-5173a464-f174-4f69-b40d-8fdf3c427bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-dec64f77-ffd9-4059-beee-6e95c5391b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-4b155f79-3aee-4ac0-8eef-887ef0c6179d,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-447f7ee1-84ef-49e4-b289-c228c2f9f087,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-72615f6f-3cb1-4087-a66c-bd3a5e0746e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-a157d272-99bd-462c-9c32-20295f183b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-471a5dc7-3ce6-450a-8254-1f4869364fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-fd10a373-2ac7-4835-b97a-99d709ce7ae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547459861-172.17.0.7-1595810942717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41906,DS-19df3831-cb83-4766-b1d9-91c168bcdb86,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-1e67c087-a8a9-4b44-9470-608d124f1be9,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-cc2e2561-c811-4aae-8a9c-ebb76f317d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-63fb03cb-2090-4d4f-afc0-024fefa5f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-fd981d70-a68a-48e5-a0cd-e7ca501f32e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-1ea323ab-ecaa-43f7-944f-0cbc42d12e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-e85861d9-4f3a-4276-afa1-cb41789534c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-7309119a-912d-4950-8eeb-1272ad5501f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547459861-172.17.0.7-1595810942717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41906,DS-19df3831-cb83-4766-b1d9-91c168bcdb86,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-1e67c087-a8a9-4b44-9470-608d124f1be9,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-cc2e2561-c811-4aae-8a9c-ebb76f317d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-63fb03cb-2090-4d4f-afc0-024fefa5f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-fd981d70-a68a-48e5-a0cd-e7ca501f32e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-1ea323ab-ecaa-43f7-944f-0cbc42d12e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-e85861d9-4f3a-4276-afa1-cb41789534c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-7309119a-912d-4950-8eeb-1272ad5501f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326971061-172.17.0.7-1595811417282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-6b4e80bb-8f66-459d-a2e1-25e7bcac956c,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-04fc98b0-7d76-4f2f-9340-1ebc201267ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-7f450b53-acbf-4604-b020-b6e898093795,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-47915f7e-8424-43ee-b749-0189b58fe85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-f69e93aa-8a18-4d4a-84c1-3fb287f4a4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-27931cd3-d177-4f13-8ff9-a4142265bf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-af074e59-120b-4d4e-8c17-765b119a2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-3a4e82f2-8036-40c8-bdec-6688aaaa663b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326971061-172.17.0.7-1595811417282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-6b4e80bb-8f66-459d-a2e1-25e7bcac956c,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-04fc98b0-7d76-4f2f-9340-1ebc201267ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-7f450b53-acbf-4604-b020-b6e898093795,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-47915f7e-8424-43ee-b749-0189b58fe85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-f69e93aa-8a18-4d4a-84c1-3fb287f4a4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-27931cd3-d177-4f13-8ff9-a4142265bf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-af074e59-120b-4d4e-8c17-765b119a2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-3a4e82f2-8036-40c8-bdec-6688aaaa663b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086312259-172.17.0.7-1595811808817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-65f86d5c-77c9-4c68-ad3d-cb7f0437dd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-5900fdc4-a1be-4223-b8af-db73e7ad313b,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-dc6e4306-2649-4881-8a24-bd812af5bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-0bc1f3b1-efbb-48ff-a181-84481eaa656e,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-de10f2a9-be50-4f3c-a6c4-b1e1f51058b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-493cf51f-c3b0-49b1-8b9a-701045e54d29,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-d87b00dd-b7b2-44d3-98ac-ea3572cdf798,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-cf5482c4-ddbc-4a60-b4f6-a010ca18653a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086312259-172.17.0.7-1595811808817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-65f86d5c-77c9-4c68-ad3d-cb7f0437dd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-5900fdc4-a1be-4223-b8af-db73e7ad313b,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-dc6e4306-2649-4881-8a24-bd812af5bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-0bc1f3b1-efbb-48ff-a181-84481eaa656e,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-de10f2a9-be50-4f3c-a6c4-b1e1f51058b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-493cf51f-c3b0-49b1-8b9a-701045e54d29,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-d87b00dd-b7b2-44d3-98ac-ea3572cdf798,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-cf5482c4-ddbc-4a60-b4f6-a010ca18653a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349846073-172.17.0.7-1595812256767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-33c3cdf5-99c3-48d2-8867-35af4e22b395,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-8a0c94ae-cdbf-4746-b2d7-7fe4882fbbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-91ef2394-3ba9-415d-a6f7-7d9f1a5f2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-03186a9e-a70f-4d44-b7b9-f447c54a7c70,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-f41334da-46b4-429e-94fa-21f33927a932,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-1568d9c9-cd25-4e3f-a051-2e086a229b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-43f14e52-10bf-4e35-a73b-166e54f9c445,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-cab952da-826d-4f96-b949-09df3b8efb89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349846073-172.17.0.7-1595812256767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-33c3cdf5-99c3-48d2-8867-35af4e22b395,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-8a0c94ae-cdbf-4746-b2d7-7fe4882fbbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-91ef2394-3ba9-415d-a6f7-7d9f1a5f2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-03186a9e-a70f-4d44-b7b9-f447c54a7c70,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-f41334da-46b4-429e-94fa-21f33927a932,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-1568d9c9-cd25-4e3f-a051-2e086a229b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-43f14e52-10bf-4e35-a73b-166e54f9c445,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-cab952da-826d-4f96-b949-09df3b8efb89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849586903-172.17.0.7-1595812435781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-e64bc23b-c2ab-4ef5-a42c-8c78c10063ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-cbb2336f-71a7-4e5f-8c2a-11c587331683,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-ee28fe1b-d58a-450b-a536-e282fb80a271,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-2e9b4ec6-858c-404a-933b-14feeae65719,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-e29061b4-df54-414d-95ad-b9cf6ad0bf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-29088427-ccdd-43bb-9507-22403be0616c,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-3c2d5b72-2e60-4c5a-8be2-ec08df36d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-9ef066ea-c9eb-4a70-b9aa-e67a989c3132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849586903-172.17.0.7-1595812435781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-e64bc23b-c2ab-4ef5-a42c-8c78c10063ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-cbb2336f-71a7-4e5f-8c2a-11c587331683,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-ee28fe1b-d58a-450b-a536-e282fb80a271,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-2e9b4ec6-858c-404a-933b-14feeae65719,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-e29061b4-df54-414d-95ad-b9cf6ad0bf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-29088427-ccdd-43bb-9507-22403be0616c,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-3c2d5b72-2e60-4c5a-8be2-ec08df36d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-9ef066ea-c9eb-4a70-b9aa-e67a989c3132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987914821-172.17.0.7-1595812686542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37345,DS-832e585a-7607-48d6-bdc6-57eb72918a76,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-eb143cd3-f612-41aa-8255-49d3c5f8c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-984be5ae-8cc3-4581-8351-7abd389566a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-f30c6fd4-4629-4326-9654-aea79cbf2adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-b8de833d-b388-45b1-a704-6fcd65238d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-640d9dc2-11a9-4ec0-8b87-96ae50bc344d,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-c0cab271-14b6-4f63-a057-ef88e506570f,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-924a70f1-ede3-4e0c-8855-e0a4962fba55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987914821-172.17.0.7-1595812686542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37345,DS-832e585a-7607-48d6-bdc6-57eb72918a76,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-eb143cd3-f612-41aa-8255-49d3c5f8c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-984be5ae-8cc3-4581-8351-7abd389566a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-f30c6fd4-4629-4326-9654-aea79cbf2adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-b8de833d-b388-45b1-a704-6fcd65238d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-640d9dc2-11a9-4ec0-8b87-96ae50bc344d,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-c0cab271-14b6-4f63-a057-ef88e506570f,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-924a70f1-ede3-4e0c-8855-e0a4962fba55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6707
