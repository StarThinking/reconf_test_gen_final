reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879580188-172.17.0.21-1595579541589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37509,DS-03bcd8e6-d441-44b7-9048-fb2448ff4685,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-132b00ea-47ca-41b2-9aae-2ae28172f672,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-3089405b-df51-4714-85e2-9b21ae32950f,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-56cee692-541a-47b0-8296-681368bdd3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-b493d27c-9d32-4dc9-9681-67cf16f7f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-9f4e0394-da8f-4150-902f-fd1f09292a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-9c848d88-e8ab-4413-be64-81bdd64f792b,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-04afea47-710a-4a91-ad12-b60655036fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879580188-172.17.0.21-1595579541589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37509,DS-03bcd8e6-d441-44b7-9048-fb2448ff4685,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-132b00ea-47ca-41b2-9aae-2ae28172f672,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-3089405b-df51-4714-85e2-9b21ae32950f,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-56cee692-541a-47b0-8296-681368bdd3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-b493d27c-9d32-4dc9-9681-67cf16f7f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-9f4e0394-da8f-4150-902f-fd1f09292a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-9c848d88-e8ab-4413-be64-81bdd64f792b,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-04afea47-710a-4a91-ad12-b60655036fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400512793-172.17.0.21-1595579858328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43765,DS-e0aa3c18-770b-4365-949f-a5db977827c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-e44dd0d7-29f2-4a78-886b-c260010e804f,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-6c8e8bf3-ea52-4f0e-9c2e-3cd980081170,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-15d070ae-6b73-4819-b241-c09f48dedc95,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-5addb8a8-f98a-4390-a40e-f8426bc55dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-198df3ce-2622-4f51-86a5-244cb5da1b04,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-eda7988a-1653-4251-a990-7e79b4691099,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-1f12f778-14b8-4e67-b463-48af5bffe582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400512793-172.17.0.21-1595579858328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43765,DS-e0aa3c18-770b-4365-949f-a5db977827c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-e44dd0d7-29f2-4a78-886b-c260010e804f,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-6c8e8bf3-ea52-4f0e-9c2e-3cd980081170,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-15d070ae-6b73-4819-b241-c09f48dedc95,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-5addb8a8-f98a-4390-a40e-f8426bc55dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-198df3ce-2622-4f51-86a5-244cb5da1b04,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-eda7988a-1653-4251-a990-7e79b4691099,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-1f12f778-14b8-4e67-b463-48af5bffe582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048145828-172.17.0.21-1595580246153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39245,DS-04354e4f-79d6-48b7-8ae4-6e89682afd15,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-496bdd22-378d-45f5-893a-e0faffaf22c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-f1809195-5ddb-4eb8-812c-c77005536a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-2392b698-4d36-4fc5-bbd2-4bd3d4c547de,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-ab93cec6-a41a-46e0-874e-5ecd5d91895e,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-2e300572-905f-4482-abec-f5c01667065b,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-6fb017d2-7c93-4e3d-8d8f-79a6a47ed274,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-b66d7427-af9a-4f9e-939d-5ee165dea316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048145828-172.17.0.21-1595580246153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39245,DS-04354e4f-79d6-48b7-8ae4-6e89682afd15,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-496bdd22-378d-45f5-893a-e0faffaf22c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-f1809195-5ddb-4eb8-812c-c77005536a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-2392b698-4d36-4fc5-bbd2-4bd3d4c547de,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-ab93cec6-a41a-46e0-874e-5ecd5d91895e,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-2e300572-905f-4482-abec-f5c01667065b,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-6fb017d2-7c93-4e3d-8d8f-79a6a47ed274,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-b66d7427-af9a-4f9e-939d-5ee165dea316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369949069-172.17.0.21-1595580442056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-b704ed47-f79b-4753-80bc-58978a35d1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-d085befb-b7a1-47b5-a728-6191ea50aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-e8587316-b5a5-42bd-a0b2-8a9bc3fd9913,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-734a06f8-709f-4727-a7f6-6a7109de1c92,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-ec941e2e-d638-41d5-b889-879b95e02b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-fc6d21e4-a64f-4519-bc7e-7131af2d6fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-511769f7-d856-4d30-8bff-86e7ceb3ec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-476d82c4-bb02-47a1-a4c8-b8eaa0711d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369949069-172.17.0.21-1595580442056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-b704ed47-f79b-4753-80bc-58978a35d1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-d085befb-b7a1-47b5-a728-6191ea50aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-e8587316-b5a5-42bd-a0b2-8a9bc3fd9913,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-734a06f8-709f-4727-a7f6-6a7109de1c92,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-ec941e2e-d638-41d5-b889-879b95e02b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-fc6d21e4-a64f-4519-bc7e-7131af2d6fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-511769f7-d856-4d30-8bff-86e7ceb3ec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-476d82c4-bb02-47a1-a4c8-b8eaa0711d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64197968-172.17.0.21-1595580547208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-3ce77935-e6a7-4adc-83c2-27c5712342f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-4a3a56b7-db33-4008-80f0-b8f49649a684,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-f2025648-aa85-4631-b485-3624042cfbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-f5397880-f4ad-4f67-ab26-ef608133836b,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-eac9c659-ce5b-4c04-871f-37d574a53849,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-a719b0d5-53c9-4b26-8402-71106bc93100,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-f5883421-f877-4192-905b-d3c1baec57f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-c2ac67ac-1fe7-425c-a900-f14ddc34f8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64197968-172.17.0.21-1595580547208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-3ce77935-e6a7-4adc-83c2-27c5712342f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-4a3a56b7-db33-4008-80f0-b8f49649a684,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-f2025648-aa85-4631-b485-3624042cfbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-f5397880-f4ad-4f67-ab26-ef608133836b,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-eac9c659-ce5b-4c04-871f-37d574a53849,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-a719b0d5-53c9-4b26-8402-71106bc93100,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-f5883421-f877-4192-905b-d3c1baec57f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-c2ac67ac-1fe7-425c-a900-f14ddc34f8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720248600-172.17.0.21-1595580695567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33982,DS-5b232878-0dd6-424b-8182-2342cafe7616,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-dd1975e9-7467-4798-b444-da208f75ec8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-84fec87f-9259-42b6-a12a-58f577cdbbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-171a5b5e-8d0b-4d5d-a7c6-f458a50da3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-8d07ef94-5501-4ad4-98c5-a08c856b34b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-c31f9900-7740-4b3c-9836-dc3767e9a9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-e8aa7f70-4905-43d9-9041-f9639af553c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-7ed8223f-8d75-4ca0-87c1-5fb8790e8c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720248600-172.17.0.21-1595580695567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33982,DS-5b232878-0dd6-424b-8182-2342cafe7616,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-dd1975e9-7467-4798-b444-da208f75ec8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-84fec87f-9259-42b6-a12a-58f577cdbbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-171a5b5e-8d0b-4d5d-a7c6-f458a50da3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-8d07ef94-5501-4ad4-98c5-a08c856b34b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-c31f9900-7740-4b3c-9836-dc3767e9a9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-e8aa7f70-4905-43d9-9041-f9639af553c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-7ed8223f-8d75-4ca0-87c1-5fb8790e8c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748563913-172.17.0.21-1595581150881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45104,DS-04720b98-3329-4890-b3f1-9784a5c7c6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-65257a2c-cb70-4aa9-9805-7dc7969f5b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-355843e1-1eec-4271-88d6-135722f9bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-9a9c4d59-193b-4bab-baca-a6e294f198ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-90290b6b-20dd-4c08-bed2-b8e0faa74415,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-7aee8a21-e34c-48a2-b6fb-a397b0214db3,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-48d4996e-799d-4501-bd2f-abade0b7d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-0423334e-99e5-41f7-bb59-bb8446aacf28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748563913-172.17.0.21-1595581150881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45104,DS-04720b98-3329-4890-b3f1-9784a5c7c6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-65257a2c-cb70-4aa9-9805-7dc7969f5b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-355843e1-1eec-4271-88d6-135722f9bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-9a9c4d59-193b-4bab-baca-a6e294f198ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-90290b6b-20dd-4c08-bed2-b8e0faa74415,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-7aee8a21-e34c-48a2-b6fb-a397b0214db3,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-48d4996e-799d-4501-bd2f-abade0b7d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-0423334e-99e5-41f7-bb59-bb8446aacf28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533010901-172.17.0.21-1595582267895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43949,DS-717f680a-131f-4862-9801-af21b88da3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-a21e7e91-19f9-47f4-a92d-c4f4f81f89fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-e6deae73-29fc-46ee-b355-42ddf6969a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-9f5ae193-c918-4bf1-ab67-c91249f049ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-14a857d7-1e67-43ff-8cb8-5a31c46dfc55,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-5b0eeee7-c7f6-4509-b48f-dcc804887e51,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-94657320-0bd5-44ed-a2ba-8a4f1697a401,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-655bbcf8-91b4-4c96-8eb2-ece50703c548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533010901-172.17.0.21-1595582267895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43949,DS-717f680a-131f-4862-9801-af21b88da3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-a21e7e91-19f9-47f4-a92d-c4f4f81f89fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-e6deae73-29fc-46ee-b355-42ddf6969a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-9f5ae193-c918-4bf1-ab67-c91249f049ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-14a857d7-1e67-43ff-8cb8-5a31c46dfc55,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-5b0eeee7-c7f6-4509-b48f-dcc804887e51,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-94657320-0bd5-44ed-a2ba-8a4f1697a401,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-655bbcf8-91b4-4c96-8eb2-ece50703c548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97214442-172.17.0.21-1595582777878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36775,DS-178c1868-3a90-474b-be1a-ea9e7c02b7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-2620ac52-888a-4755-b719-f35ad574aa39,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-8ccf6738-1bd1-4068-a310-eaa31d43b8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-51a0ca63-7431-4605-8b46-af7bd3f6dc92,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-d1d01413-ec7c-45df-a2b9-17a939c59d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-3956e94a-0668-4eb5-9168-9e48861f7998,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-f2e19285-2f35-4789-b8fb-5bdb184fe719,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-2dcbc141-5b0f-4bb6-ae43-8c67fc9225d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97214442-172.17.0.21-1595582777878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36775,DS-178c1868-3a90-474b-be1a-ea9e7c02b7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-2620ac52-888a-4755-b719-f35ad574aa39,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-8ccf6738-1bd1-4068-a310-eaa31d43b8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-51a0ca63-7431-4605-8b46-af7bd3f6dc92,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-d1d01413-ec7c-45df-a2b9-17a939c59d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-3956e94a-0668-4eb5-9168-9e48861f7998,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-f2e19285-2f35-4789-b8fb-5bdb184fe719,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-2dcbc141-5b0f-4bb6-ae43-8c67fc9225d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220474379-172.17.0.21-1595582988960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46797,DS-82325036-e873-4ea6-abb7-5e18385db3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-73e87ea3-5b7a-4f12-b1da-9be1ad01bedd,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-294c0c3f-d8b1-4a59-a8e9-5cff5757df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-a25c7417-0892-4995-87ff-c2c62b158071,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-516d0557-b982-40ae-81f8-c425575755e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-96fb21fd-e18a-43bf-b82e-b30c9e392e91,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-f62b7034-bd8b-4774-8d5d-108c96f06213,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-cae2760d-bb13-43c3-8f11-045bbe5d2214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220474379-172.17.0.21-1595582988960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46797,DS-82325036-e873-4ea6-abb7-5e18385db3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-73e87ea3-5b7a-4f12-b1da-9be1ad01bedd,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-294c0c3f-d8b1-4a59-a8e9-5cff5757df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-a25c7417-0892-4995-87ff-c2c62b158071,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-516d0557-b982-40ae-81f8-c425575755e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-96fb21fd-e18a-43bf-b82e-b30c9e392e91,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-f62b7034-bd8b-4774-8d5d-108c96f06213,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-cae2760d-bb13-43c3-8f11-045bbe5d2214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149807002-172.17.0.21-1595583322012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42392,DS-5f8e77a0-c40f-41fb-9112-4bb6940e9f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-bedfec56-91ed-487c-bb72-e475ba489add,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-c64efc6f-97a7-4caa-b9f7-037800c84aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-3a00688f-77d7-46af-a444-78f11d5d8cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-70689d5d-0d25-4fe5-9f61-f9db9c70c64e,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-b037847b-8208-4e8e-87ed-8b1d95daa4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-587f08b0-1ae0-43ea-8191-4069e408757e,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-dd54160f-a7eb-4e0c-a24d-354befe793ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149807002-172.17.0.21-1595583322012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42392,DS-5f8e77a0-c40f-41fb-9112-4bb6940e9f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-bedfec56-91ed-487c-bb72-e475ba489add,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-c64efc6f-97a7-4caa-b9f7-037800c84aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-3a00688f-77d7-46af-a444-78f11d5d8cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-70689d5d-0d25-4fe5-9f61-f9db9c70c64e,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-b037847b-8208-4e8e-87ed-8b1d95daa4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-587f08b0-1ae0-43ea-8191-4069e408757e,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-dd54160f-a7eb-4e0c-a24d-354befe793ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984288794-172.17.0.21-1595583583357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-6b8ebf24-e017-4d48-8896-f71a0a660288,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-9110647a-fa93-4e28-9b96-800d81054de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-c9bdadee-25d5-4bd6-af33-25fc26f6f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-4d635054-f119-4ee0-860f-7dc405d4356e,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-eb2c2427-9d52-41ef-90eb-dce5f6ad5532,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-8ab7706b-84a4-4c7f-b638-a6e8e8f47b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-7c203b0c-f5c4-49e2-b4ca-f4d0e9bd7c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-9e995334-f2f3-4960-b40a-57b288f93047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984288794-172.17.0.21-1595583583357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-6b8ebf24-e017-4d48-8896-f71a0a660288,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-9110647a-fa93-4e28-9b96-800d81054de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-c9bdadee-25d5-4bd6-af33-25fc26f6f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-4d635054-f119-4ee0-860f-7dc405d4356e,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-eb2c2427-9d52-41ef-90eb-dce5f6ad5532,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-8ab7706b-84a4-4c7f-b638-a6e8e8f47b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-7c203b0c-f5c4-49e2-b4ca-f4d0e9bd7c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-9e995334-f2f3-4960-b40a-57b288f93047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945379985-172.17.0.21-1595583724367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40213,DS-bb8135dd-72d0-47af-9f26-783bcb1c969f,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-6a3e4bf9-a1c8-4f6a-bb7d-7c16c9837642,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-569bf5dd-e1ac-4ecd-812e-c43e685e6d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-e90d00d3-0e7a-450d-8f14-14a6b44a1c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-8f661bcf-d23e-4197-8575-4612f73f0849,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-e5631f48-4382-46f4-92fb-7b2298037cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-843cabda-fc37-4ae9-a1ea-380cb2d008de,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-fbc25065-cd3d-4a9b-902e-bab8a37000f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945379985-172.17.0.21-1595583724367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40213,DS-bb8135dd-72d0-47af-9f26-783bcb1c969f,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-6a3e4bf9-a1c8-4f6a-bb7d-7c16c9837642,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-569bf5dd-e1ac-4ecd-812e-c43e685e6d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-e90d00d3-0e7a-450d-8f14-14a6b44a1c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-8f661bcf-d23e-4197-8575-4612f73f0849,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-e5631f48-4382-46f4-92fb-7b2298037cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-843cabda-fc37-4ae9-a1ea-380cb2d008de,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-fbc25065-cd3d-4a9b-902e-bab8a37000f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702253757-172.17.0.21-1595583768027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-d779ebab-6c61-449d-937f-d2e1229f62a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-f38af91a-3398-4a22-a8af-f5d42e5331ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-0a36e0e0-38f2-4fed-9ee6-8cbd89fc66c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-a76eb67e-98b0-4b0d-a6b3-b72f14bc7cee,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-a90954e9-3056-45bf-8a0e-78cc11d4a2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-901cf936-b74a-4651-b33c-92e7f369ca87,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-2a6d1f00-8ec6-4e70-a3b3-54083634efca,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-828ec67e-b01f-4f4c-8a2e-222bf0620431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702253757-172.17.0.21-1595583768027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-d779ebab-6c61-449d-937f-d2e1229f62a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-f38af91a-3398-4a22-a8af-f5d42e5331ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-0a36e0e0-38f2-4fed-9ee6-8cbd89fc66c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-a76eb67e-98b0-4b0d-a6b3-b72f14bc7cee,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-a90954e9-3056-45bf-8a0e-78cc11d4a2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-901cf936-b74a-4651-b33c-92e7f369ca87,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-2a6d1f00-8ec6-4e70-a3b3-54083634efca,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-828ec67e-b01f-4f4c-8a2e-222bf0620431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635505572-172.17.0.21-1595583899369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-cf1f05f4-bbf5-4c07-92ad-57e39559d099,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-59244a1f-bcb9-4135-be7e-169a26ddb074,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-9e268f61-6f19-44b9-bb03-d48849258b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-fd764119-8f4d-40da-a0bc-b652d31d9d63,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-51e205b7-54b0-4525-8fe3-5d95a3e83aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-64801b8c-5c91-4b2e-accb-072b1361ac45,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-4104d8f0-5b1f-49d6-b69c-2bbc30a7ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-91af0291-ec96-4e12-a68b-68300302adfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635505572-172.17.0.21-1595583899369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-cf1f05f4-bbf5-4c07-92ad-57e39559d099,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-59244a1f-bcb9-4135-be7e-169a26ddb074,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-9e268f61-6f19-44b9-bb03-d48849258b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-fd764119-8f4d-40da-a0bc-b652d31d9d63,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-51e205b7-54b0-4525-8fe3-5d95a3e83aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-64801b8c-5c91-4b2e-accb-072b1361ac45,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-4104d8f0-5b1f-49d6-b69c-2bbc30a7ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-91af0291-ec96-4e12-a68b-68300302adfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649008108-172.17.0.21-1595584013824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45771,DS-e17b6a07-88e0-4b0b-9716-1a33dcc6fe27,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-04deabf1-8202-44cd-a7a9-096083b90d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-1838cbcf-c406-45d8-b6cf-83a239c2e21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-0b748449-f4ee-43ff-a750-80bb740e7bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-0d860555-5bdf-4cb7-ba4c-99bde8bb528d,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-85a6bc35-6742-4ec6-b692-ee08cd03169b,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-abc4d732-627b-4ad0-9123-d415d859f384,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-15522848-bb98-4a74-b53e-a2fae67f7565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649008108-172.17.0.21-1595584013824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45771,DS-e17b6a07-88e0-4b0b-9716-1a33dcc6fe27,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-04deabf1-8202-44cd-a7a9-096083b90d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-1838cbcf-c406-45d8-b6cf-83a239c2e21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-0b748449-f4ee-43ff-a750-80bb740e7bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-0d860555-5bdf-4cb7-ba4c-99bde8bb528d,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-85a6bc35-6742-4ec6-b692-ee08cd03169b,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-abc4d732-627b-4ad0-9123-d415d859f384,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-15522848-bb98-4a74-b53e-a2fae67f7565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580931631-172.17.0.21-1595584317527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-79cfb1bb-151c-4d7a-91e2-cdf7198447d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-e709a485-e5ad-49c9-b99c-f03b157d590b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-fd6a3c69-d38c-4f7b-89fc-1fc0d4300103,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-76226c60-34e2-4ff7-8493-1b8a80e9e21f,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-a0597c72-e154-461d-84fe-3068c4f0b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-dcfd50e1-c29a-44c3-9c7e-cd2015b78916,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-ffc10bb9-610b-4b80-a754-54d8b803bfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-c78f5a2f-2799-4353-8750-be7648a4b080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580931631-172.17.0.21-1595584317527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-79cfb1bb-151c-4d7a-91e2-cdf7198447d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-e709a485-e5ad-49c9-b99c-f03b157d590b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-fd6a3c69-d38c-4f7b-89fc-1fc0d4300103,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-76226c60-34e2-4ff7-8493-1b8a80e9e21f,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-a0597c72-e154-461d-84fe-3068c4f0b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-dcfd50e1-c29a-44c3-9c7e-cd2015b78916,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-ffc10bb9-610b-4b80-a754-54d8b803bfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-c78f5a2f-2799-4353-8750-be7648a4b080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111532351-172.17.0.21-1595584475030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-fce654de-4d2a-4c75-aad8-d51ad323b83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-eb9f3060-0848-407c-bc79-2967b91f9607,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-393329f1-fb91-48e3-ba85-132a383de8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-6cffe544-4124-4189-8d73-fd172fcd52a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-b3f41c5c-8ac6-454b-be6d-035b8c397382,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-1320e9fa-a233-47fd-b575-31aef728e4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-4f320799-8331-4f5e-9962-adc35ef479c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-e4dea4e4-9312-4d45-ad35-2b0a72b279bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111532351-172.17.0.21-1595584475030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-fce654de-4d2a-4c75-aad8-d51ad323b83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-eb9f3060-0848-407c-bc79-2967b91f9607,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-393329f1-fb91-48e3-ba85-132a383de8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-6cffe544-4124-4189-8d73-fd172fcd52a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-b3f41c5c-8ac6-454b-be6d-035b8c397382,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-1320e9fa-a233-47fd-b575-31aef728e4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-4f320799-8331-4f5e-9962-adc35ef479c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-e4dea4e4-9312-4d45-ad35-2b0a72b279bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917165620-172.17.0.21-1595584515524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-7fa7c09d-a88e-4500-b859-e8182c7dc404,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-284eb4ed-5b3d-42d4-b7b1-8849c9f9babb,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-641567ea-b4a4-4549-8af1-6336dcb6a9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-94fcfb70-85fa-4772-ba2e-1523131ebfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-11eec52d-be94-4b8c-80bc-a6f5ebf071f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-5a17c405-81c8-4bd0-9d93-337088ae7aad,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-2f219fb7-286c-4278-964e-3d16532fc8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-af081c6a-595c-453e-80e6-ecb958477a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917165620-172.17.0.21-1595584515524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-7fa7c09d-a88e-4500-b859-e8182c7dc404,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-284eb4ed-5b3d-42d4-b7b1-8849c9f9babb,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-641567ea-b4a4-4549-8af1-6336dcb6a9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-94fcfb70-85fa-4772-ba2e-1523131ebfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-11eec52d-be94-4b8c-80bc-a6f5ebf071f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-5a17c405-81c8-4bd0-9d93-337088ae7aad,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-2f219fb7-286c-4278-964e-3d16532fc8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-af081c6a-595c-453e-80e6-ecb958477a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5601
