reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997437086-172.17.0.14-1595938532143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44615,DS-9fc2283f-5f61-4bab-9842-c2b9c5f5b82c,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-3bb21aea-dd90-497d-9690-834cac34c70d,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-e8b656b8-dfbc-4475-9336-0f2c8e20407b,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-879ed812-c8a6-4906-9807-8889b951940e,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-b7c8decb-7798-4008-967e-9f95cb4f3104,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-8cf553fb-6de7-409e-9051-e107713d6eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-574c8c14-191c-43a2-9fbc-caf68ec677b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-1869419f-7406-412d-8804-e7abbf42da52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997437086-172.17.0.14-1595938532143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44615,DS-9fc2283f-5f61-4bab-9842-c2b9c5f5b82c,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-3bb21aea-dd90-497d-9690-834cac34c70d,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-e8b656b8-dfbc-4475-9336-0f2c8e20407b,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-879ed812-c8a6-4906-9807-8889b951940e,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-b7c8decb-7798-4008-967e-9f95cb4f3104,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-8cf553fb-6de7-409e-9051-e107713d6eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-574c8c14-191c-43a2-9fbc-caf68ec677b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-1869419f-7406-412d-8804-e7abbf42da52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460309013-172.17.0.14-1595939748973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45331,DS-cf039734-7cba-4b14-a5a4-a2c5eb97f585,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-cfc0dfaf-0c82-4f54-9820-5a3d35a4ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-c7db365a-e480-4436-8bfa-b71e673601e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-338825bb-bab5-4686-9bcd-dc61a8600674,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-2a36ddaf-3f0f-4901-9c99-1ad81a7ca072,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-59409240-d87a-4ddf-a9c6-7e964c6c0391,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-72b24700-fc99-4cd3-8e08-a5a7a5faa0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-609d0ae5-9521-431f-9f76-5b677baaf582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460309013-172.17.0.14-1595939748973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45331,DS-cf039734-7cba-4b14-a5a4-a2c5eb97f585,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-cfc0dfaf-0c82-4f54-9820-5a3d35a4ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-c7db365a-e480-4436-8bfa-b71e673601e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-338825bb-bab5-4686-9bcd-dc61a8600674,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-2a36ddaf-3f0f-4901-9c99-1ad81a7ca072,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-59409240-d87a-4ddf-a9c6-7e964c6c0391,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-72b24700-fc99-4cd3-8e08-a5a7a5faa0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-609d0ae5-9521-431f-9f76-5b677baaf582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210787996-172.17.0.14-1595940501763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-b7b4219a-2f41-412e-b1ff-389ca74b86b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-c89bad56-386d-419e-9a14-89d14d7620c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-e7600c39-60d5-4cfe-aba2-20bb3e8ae103,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-1c94c4f5-2ef9-4192-bfa7-9d66d3505255,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-bc039f09-21ac-471f-a8ce-7109af22accc,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-9f16aae8-8e52-4827-9a85-2dba75f31127,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-e244b9f2-0445-401c-bdd9-2fa1fd4154e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-dc00c810-f3bf-4fd1-bac1-a39d7bd478de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210787996-172.17.0.14-1595940501763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-b7b4219a-2f41-412e-b1ff-389ca74b86b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-c89bad56-386d-419e-9a14-89d14d7620c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-e7600c39-60d5-4cfe-aba2-20bb3e8ae103,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-1c94c4f5-2ef9-4192-bfa7-9d66d3505255,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-bc039f09-21ac-471f-a8ce-7109af22accc,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-9f16aae8-8e52-4827-9a85-2dba75f31127,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-e244b9f2-0445-401c-bdd9-2fa1fd4154e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-dc00c810-f3bf-4fd1-bac1-a39d7bd478de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925610261-172.17.0.14-1595940781699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-d4a73c14-d48d-4043-a129-6e3854299876,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-2d39bb82-f8aa-49ce-a8be-e619cee52f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-12543b67-480d-4719-b5d5-9e12fd53ae05,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-d1438bfe-1534-4265-bec2-4f267b10a4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-50b7d591-15c6-4a82-a505-4cce778bcb72,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-db31691e-fea1-44fb-927c-43362b18dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-7d468c2f-ee01-4c70-b110-d9ea9ea91f53,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-7b68ac0f-76fa-4aa2-ab20-37c8e609222e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925610261-172.17.0.14-1595940781699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-d4a73c14-d48d-4043-a129-6e3854299876,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-2d39bb82-f8aa-49ce-a8be-e619cee52f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-12543b67-480d-4719-b5d5-9e12fd53ae05,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-d1438bfe-1534-4265-bec2-4f267b10a4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-50b7d591-15c6-4a82-a505-4cce778bcb72,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-db31691e-fea1-44fb-927c-43362b18dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-7d468c2f-ee01-4c70-b110-d9ea9ea91f53,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-7b68ac0f-76fa-4aa2-ab20-37c8e609222e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688634426-172.17.0.14-1595941070711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-ade195e0-899f-4566-b986-50b69282c313,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-d44b9dde-04f1-4881-84b0-f2d97016897a,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-c3ca50ea-43f3-412f-8748-7ba5d41d28cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-7db802db-e676-4d80-b2ad-06e570652d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-1a250401-5188-478a-b647-7fedc6562c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1b7891a8-7328-4526-b8e4-ba1baf0218e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-d3cc8154-ff5d-49bd-8450-26f876530293,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-f4494f26-c744-472d-bc70-aea1ab4f0706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688634426-172.17.0.14-1595941070711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-ade195e0-899f-4566-b986-50b69282c313,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-d44b9dde-04f1-4881-84b0-f2d97016897a,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-c3ca50ea-43f3-412f-8748-7ba5d41d28cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-7db802db-e676-4d80-b2ad-06e570652d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-1a250401-5188-478a-b647-7fedc6562c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1b7891a8-7328-4526-b8e4-ba1baf0218e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-d3cc8154-ff5d-49bd-8450-26f876530293,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-f4494f26-c744-472d-bc70-aea1ab4f0706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224535288-172.17.0.14-1595941147908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44109,DS-a274c765-2fd0-42ab-a5b4-bc86d56b0720,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-a2eb2570-c1df-4a68-8765-195dde38c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-dbd275a1-4980-41cf-82af-3419456c42c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-df6b2d3f-08c5-4a61-9165-311b2872dc80,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-9dfc6f92-7c3f-4f22-80ef-721e89ff2a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-341a4dac-89ed-4710-92b9-56ddd942b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-31096c35-d40d-47e3-b493-fad149293d07,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-913fe67e-ac42-4017-af2e-180c701bf1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224535288-172.17.0.14-1595941147908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44109,DS-a274c765-2fd0-42ab-a5b4-bc86d56b0720,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-a2eb2570-c1df-4a68-8765-195dde38c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-dbd275a1-4980-41cf-82af-3419456c42c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-df6b2d3f-08c5-4a61-9165-311b2872dc80,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-9dfc6f92-7c3f-4f22-80ef-721e89ff2a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-341a4dac-89ed-4710-92b9-56ddd942b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-31096c35-d40d-47e3-b493-fad149293d07,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-913fe67e-ac42-4017-af2e-180c701bf1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053646216-172.17.0.14-1595941241101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38410,DS-602edcde-9291-4e36-b21f-ff511362e464,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-4250cafb-51b1-4914-84c0-836b6da7f1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-717ad48a-ba8c-432b-8d88-1ea1e2481e94,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-f1067569-ffa2-43fa-a63e-548635447702,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-4069c19f-6721-429d-b7b7-04dac30b25fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-0c22c8e6-6301-40a0-90aa-2944f20dd08e,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-6a30ac54-6fd9-42f0-bc34-07b7ac3b6d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-c18437b7-9af1-4553-9b67-d4c6a013c385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053646216-172.17.0.14-1595941241101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38410,DS-602edcde-9291-4e36-b21f-ff511362e464,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-4250cafb-51b1-4914-84c0-836b6da7f1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-717ad48a-ba8c-432b-8d88-1ea1e2481e94,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-f1067569-ffa2-43fa-a63e-548635447702,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-4069c19f-6721-429d-b7b7-04dac30b25fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-0c22c8e6-6301-40a0-90aa-2944f20dd08e,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-6a30ac54-6fd9-42f0-bc34-07b7ac3b6d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-c18437b7-9af1-4553-9b67-d4c6a013c385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839450380-172.17.0.14-1595941314948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-78390296-ed61-4149-b44d-aac743f06f17,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-5ba79777-620e-412b-abf3-2300eca48e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-08fbfa83-b76b-472c-9ed6-57dd08ed4760,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-a7dc0e6b-37a5-4911-8f52-baf8159f7e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-bfee166d-eb93-4d04-af4b-1aaa1bf6a173,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-166e9713-bb5d-4e51-a70a-0b56f8aca358,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-a8ae1a35-c3bd-4cf1-a5b9-7dfdd96387c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-409469d2-b6ec-4bb7-b7fc-c4008f8c637f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839450380-172.17.0.14-1595941314948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-78390296-ed61-4149-b44d-aac743f06f17,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-5ba79777-620e-412b-abf3-2300eca48e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-08fbfa83-b76b-472c-9ed6-57dd08ed4760,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-a7dc0e6b-37a5-4911-8f52-baf8159f7e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-bfee166d-eb93-4d04-af4b-1aaa1bf6a173,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-166e9713-bb5d-4e51-a70a-0b56f8aca358,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-a8ae1a35-c3bd-4cf1-a5b9-7dfdd96387c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-409469d2-b6ec-4bb7-b7fc-c4008f8c637f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226544290-172.17.0.14-1595941574563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37913,DS-0cfb9136-eb1c-4639-bbe8-d74bab3ea391,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-e5aef963-f146-4299-accd-d0a06e465ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-df2fdc65-25e9-4893-b77a-dcfd0c07802b,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-11738588-afa0-4570-b4a7-6309114251b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-0fb14932-c014-4996-8576-8f7aedce2788,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-0bfc3d5c-51ad-4c82-b701-059bd5636722,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-fd4758b0-dffe-41cf-88c2-fef5c182376b,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-08824a21-7260-4b91-a298-b2671336dbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226544290-172.17.0.14-1595941574563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37913,DS-0cfb9136-eb1c-4639-bbe8-d74bab3ea391,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-e5aef963-f146-4299-accd-d0a06e465ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-df2fdc65-25e9-4893-b77a-dcfd0c07802b,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-11738588-afa0-4570-b4a7-6309114251b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-0fb14932-c014-4996-8576-8f7aedce2788,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-0bfc3d5c-51ad-4c82-b701-059bd5636722,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-fd4758b0-dffe-41cf-88c2-fef5c182376b,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-08824a21-7260-4b91-a298-b2671336dbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628388236-172.17.0.14-1595941737451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32907,DS-a7ffa1de-fcd4-4633-9eea-c4e09afcb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-5cec212c-dfaa-4b1d-8973-d01d226ebe5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-01acb939-86ee-4a18-ae75-810d7f5b18d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-4415c3e0-ec0d-4f1d-a556-ee8ae7dfafad,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-7695fc9d-a04f-4afa-983f-e8abf043a9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-dc90d69a-f566-4d67-8bb4-cf42cd77678b,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-487a2b7e-7aaa-4502-89d6-ffc0730a6df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-2964b025-5d33-4fe7-b40a-444bae995386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628388236-172.17.0.14-1595941737451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32907,DS-a7ffa1de-fcd4-4633-9eea-c4e09afcb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-5cec212c-dfaa-4b1d-8973-d01d226ebe5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-01acb939-86ee-4a18-ae75-810d7f5b18d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-4415c3e0-ec0d-4f1d-a556-ee8ae7dfafad,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-7695fc9d-a04f-4afa-983f-e8abf043a9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-dc90d69a-f566-4d67-8bb4-cf42cd77678b,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-487a2b7e-7aaa-4502-89d6-ffc0730a6df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-2964b025-5d33-4fe7-b40a-444bae995386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46798556-172.17.0.14-1595941844259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44849,DS-ad143125-dfd9-4ad0-8bc6-b3187291ed99,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-f5544ddd-7494-4106-ba71-3bc2940a3e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-83b1cd1c-86ba-4799-94a8-5c37769cc7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-4ab4c2fa-6827-424f-821c-0196c3be0394,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-5028114b-bcfb-4ba5-9d32-0d6c30d6d701,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-590f3cb0-38b2-4583-bdd5-2d67db5bcab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-0e5f5e69-f39b-4e94-a7e6-12835b10efd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-488292b6-3800-448a-bafa-ab8beaff1217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46798556-172.17.0.14-1595941844259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44849,DS-ad143125-dfd9-4ad0-8bc6-b3187291ed99,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-f5544ddd-7494-4106-ba71-3bc2940a3e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-83b1cd1c-86ba-4799-94a8-5c37769cc7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-4ab4c2fa-6827-424f-821c-0196c3be0394,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-5028114b-bcfb-4ba5-9d32-0d6c30d6d701,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-590f3cb0-38b2-4583-bdd5-2d67db5bcab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-0e5f5e69-f39b-4e94-a7e6-12835b10efd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-488292b6-3800-448a-bafa-ab8beaff1217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233435847-172.17.0.14-1595942207138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43543,DS-4bdd348e-0c6e-4dcf-a820-20553dc09e25,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-1d82e02f-671a-4b46-a666-cbaebd8f4b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-a65428df-1e70-4157-9657-07e5aa7306bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-efadb97f-a02e-47f4-b289-1025608eed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-0f4d140c-9d5a-4293-9d60-3336f8c896d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-ab8f3777-604a-4759-85ec-330157c19598,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-fb4b61f7-d276-4884-9600-7a86c46ea2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-e1751459-1d31-4e0d-bdbf-26770a6d44ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233435847-172.17.0.14-1595942207138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43543,DS-4bdd348e-0c6e-4dcf-a820-20553dc09e25,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-1d82e02f-671a-4b46-a666-cbaebd8f4b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-a65428df-1e70-4157-9657-07e5aa7306bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-efadb97f-a02e-47f4-b289-1025608eed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-0f4d140c-9d5a-4293-9d60-3336f8c896d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-ab8f3777-604a-4759-85ec-330157c19598,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-fb4b61f7-d276-4884-9600-7a86c46ea2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-e1751459-1d31-4e0d-bdbf-26770a6d44ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773662572-172.17.0.14-1595942317079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34472,DS-3468212a-a5b3-4b55-9169-5affdf90ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-2f05aa03-989d-480b-a30f-c1db23b6799f,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-6dd6e91a-b0fa-41b1-8b9d-2d9d060a9b79,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-51bde02d-a0ea-41f6-a32d-5a653b5f31e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-f4726af5-1927-4250-a0c8-0a4a828d546c,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-b4279067-d217-4b87-8143-cc529c47ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-9ae400d0-317a-4c88-8000-419c1eb0c695,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-480ae21b-cbd6-4a72-a299-d083019e8214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773662572-172.17.0.14-1595942317079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34472,DS-3468212a-a5b3-4b55-9169-5affdf90ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-2f05aa03-989d-480b-a30f-c1db23b6799f,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-6dd6e91a-b0fa-41b1-8b9d-2d9d060a9b79,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-51bde02d-a0ea-41f6-a32d-5a653b5f31e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-f4726af5-1927-4250-a0c8-0a4a828d546c,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-b4279067-d217-4b87-8143-cc529c47ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-9ae400d0-317a-4c88-8000-419c1eb0c695,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-480ae21b-cbd6-4a72-a299-d083019e8214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293860597-172.17.0.14-1595942707204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-7222b34d-a84b-4d84-9e25-0c53483675a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-96f9b691-0185-4a55-b382-9267eb2cae64,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-05a78388-4be1-4ec1-8acc-533f56be076e,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-903a5a83-26c5-4e6a-9f67-5287aba7a5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-4014a147-d891-46c2-85b6-321a9ea0b90e,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-d50eb8e4-1e1d-46b2-ac9f-cbecd41ab079,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-39ec92c3-bf0b-4332-80e3-b139db13fc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c5e16871-4e31-457c-95af-ae11262fbf8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293860597-172.17.0.14-1595942707204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-7222b34d-a84b-4d84-9e25-0c53483675a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-96f9b691-0185-4a55-b382-9267eb2cae64,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-05a78388-4be1-4ec1-8acc-533f56be076e,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-903a5a83-26c5-4e6a-9f67-5287aba7a5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-4014a147-d891-46c2-85b6-321a9ea0b90e,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-d50eb8e4-1e1d-46b2-ac9f-cbecd41ab079,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-39ec92c3-bf0b-4332-80e3-b139db13fc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c5e16871-4e31-457c-95af-ae11262fbf8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455603367-172.17.0.14-1595942860441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-9c0ceb38-25bf-4d0b-af91-58db5feecb58,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-217fcbdd-ad5f-4aa6-86aa-c50a12d53ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-cfa9b87f-74e2-49e5-9647-69cda381e71a,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-1b61c1de-7802-435e-8cce-53f15628b028,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-cfb3021b-d061-4435-b833-33b2bc279a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-90040779-c7a1-4c11-b27f-c07c69113bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-1710a3cd-76c6-4982-8b88-1ffdd45939ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-498c836c-4207-43f8-9ba1-33ed55b7308a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455603367-172.17.0.14-1595942860441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-9c0ceb38-25bf-4d0b-af91-58db5feecb58,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-217fcbdd-ad5f-4aa6-86aa-c50a12d53ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-cfa9b87f-74e2-49e5-9647-69cda381e71a,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-1b61c1de-7802-435e-8cce-53f15628b028,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-cfb3021b-d061-4435-b833-33b2bc279a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-90040779-c7a1-4c11-b27f-c07c69113bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-1710a3cd-76c6-4982-8b88-1ffdd45939ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-498c836c-4207-43f8-9ba1-33ed55b7308a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017708552-172.17.0.14-1595943160197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-d24761bd-5bd9-488f-9653-3a3edacfd0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-0ceca7b7-4c72-4fe3-b498-3a6c0c90e297,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-09aae213-8d4e-4475-989b-21bf9e0b94ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-9fbd6b96-7672-4402-9e8c-692793033c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-fd9ccb73-ee19-465c-b5eb-eeac21dd49eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-87c3292c-d726-4009-9758-09f55ec43338,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-ab472322-5be6-4025-bbd9-c5df3b1faa02,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-76333a56-7c68-4647-a0e8-7a4fb7ec87a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017708552-172.17.0.14-1595943160197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-d24761bd-5bd9-488f-9653-3a3edacfd0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-0ceca7b7-4c72-4fe3-b498-3a6c0c90e297,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-09aae213-8d4e-4475-989b-21bf9e0b94ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-9fbd6b96-7672-4402-9e8c-692793033c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-fd9ccb73-ee19-465c-b5eb-eeac21dd49eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-87c3292c-d726-4009-9758-09f55ec43338,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-ab472322-5be6-4025-bbd9-c5df3b1faa02,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-76333a56-7c68-4647-a0e8-7a4fb7ec87a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341260398-172.17.0.14-1595943196107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-29819774-fbf5-4dfe-aa8f-5cd65aafca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-8f31cd8c-6679-41b1-b0fe-45803c7b1b95,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-45b1c199-f167-4687-8a41-2ad274318426,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-ee72231b-cb72-4b9e-8b86-6dc4af231ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-458f17d1-32f3-4e0b-add7-a28e56923496,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-c5c620f0-7ae2-44bf-8e52-ff0950dc77a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-894bdf7a-ee0d-4587-b5de-cf50692e76c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-55bcd545-1b51-4ba3-b5fc-205250400371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341260398-172.17.0.14-1595943196107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-29819774-fbf5-4dfe-aa8f-5cd65aafca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-8f31cd8c-6679-41b1-b0fe-45803c7b1b95,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-45b1c199-f167-4687-8a41-2ad274318426,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-ee72231b-cb72-4b9e-8b86-6dc4af231ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-458f17d1-32f3-4e0b-add7-a28e56923496,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-c5c620f0-7ae2-44bf-8e52-ff0950dc77a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-894bdf7a-ee0d-4587-b5de-cf50692e76c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-55bcd545-1b51-4ba3-b5fc-205250400371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714233476-172.17.0.14-1595943304136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-59465832-a728-4eb3-9bc4-45fe20bf9118,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-4ee32329-6a36-4523-bb46-14e83ee6fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-5822b5f3-b3dd-41a7-aabc-4836d69134ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-df18122a-239a-447e-900d-ecdc58f52b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-ad25dcea-4855-454d-b0d7-beb515152aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-20606fee-7815-4716-bc00-18e0062e3342,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-e15a9208-d585-4a2b-8093-6104657ec5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-4aa7eeb9-28e8-4b10-b450-8326df865abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714233476-172.17.0.14-1595943304136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-59465832-a728-4eb3-9bc4-45fe20bf9118,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-4ee32329-6a36-4523-bb46-14e83ee6fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-5822b5f3-b3dd-41a7-aabc-4836d69134ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-df18122a-239a-447e-900d-ecdc58f52b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-ad25dcea-4855-454d-b0d7-beb515152aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-20606fee-7815-4716-bc00-18e0062e3342,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-e15a9208-d585-4a2b-8093-6104657ec5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-4aa7eeb9-28e8-4b10-b450-8326df865abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5610
