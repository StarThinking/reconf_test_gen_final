reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857439696-172.17.0.16-1595842280191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34104,DS-73d5e70a-6d34-4c28-b465-ba36c8b02b59,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-90c529ce-7881-40d4-bb19-c1282c6d9f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-04f00be9-cb2a-4431-85e2-e553306dba36,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-46d62e9f-85ef-4c66-8d23-7cbaad4150e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-ae7c367f-b5f6-4031-a2e9-59fd7bcb3fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-af636a46-bff7-46d9-9a84-b79341fb41a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-9ca8c00f-557c-4fdd-82d8-42454d18eef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-d3514ccc-aa23-477d-9537-1505bebe7555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857439696-172.17.0.16-1595842280191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34104,DS-73d5e70a-6d34-4c28-b465-ba36c8b02b59,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-90c529ce-7881-40d4-bb19-c1282c6d9f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-04f00be9-cb2a-4431-85e2-e553306dba36,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-46d62e9f-85ef-4c66-8d23-7cbaad4150e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-ae7c367f-b5f6-4031-a2e9-59fd7bcb3fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-af636a46-bff7-46d9-9a84-b79341fb41a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-9ca8c00f-557c-4fdd-82d8-42454d18eef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-d3514ccc-aa23-477d-9537-1505bebe7555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648528065-172.17.0.16-1595842781210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-ccaa87bd-6f9f-4633-96dd-665774e79a86,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-e01e20e9-9e9b-478f-93ec-5da8f42b9a34,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-ef69325b-19cf-48c7-a912-9d4c5a56390d,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-391f352f-e577-4b25-a40f-6d2775868872,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-083e377e-af5e-40b7-9a56-e5ec304d3d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-da0e70c1-56d4-465a-9456-ad27f2e21fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-f353b341-4efd-485c-bacc-fb4768436def,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-9848887a-bae0-47c2-ac59-ab23cd8114c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648528065-172.17.0.16-1595842781210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-ccaa87bd-6f9f-4633-96dd-665774e79a86,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-e01e20e9-9e9b-478f-93ec-5da8f42b9a34,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-ef69325b-19cf-48c7-a912-9d4c5a56390d,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-391f352f-e577-4b25-a40f-6d2775868872,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-083e377e-af5e-40b7-9a56-e5ec304d3d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-da0e70c1-56d4-465a-9456-ad27f2e21fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-f353b341-4efd-485c-bacc-fb4768436def,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-9848887a-bae0-47c2-ac59-ab23cd8114c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766742579-172.17.0.16-1595842825813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45113,DS-df029a55-cffa-428a-ad4d-c50b58cee1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-ddafc5ba-21b7-4f0e-8338-278acdc32a11,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-40e817a6-8c29-46d0-8e1b-c8198411e199,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-fbb8edb5-5f41-4adf-b8ee-985716cd1697,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-117111dc-97e7-48a9-8ad9-32b899d54298,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-ec07436f-64da-481a-ad4b-91019810753a,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-d93ee06f-ff2a-4f50-9f90-c11116e16237,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-e3a9ce6e-9069-4651-bede-ed6f03c7c20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766742579-172.17.0.16-1595842825813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45113,DS-df029a55-cffa-428a-ad4d-c50b58cee1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-ddafc5ba-21b7-4f0e-8338-278acdc32a11,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-40e817a6-8c29-46d0-8e1b-c8198411e199,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-fbb8edb5-5f41-4adf-b8ee-985716cd1697,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-117111dc-97e7-48a9-8ad9-32b899d54298,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-ec07436f-64da-481a-ad4b-91019810753a,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-d93ee06f-ff2a-4f50-9f90-c11116e16237,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-e3a9ce6e-9069-4651-bede-ed6f03c7c20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119470152-172.17.0.16-1595843141023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44834,DS-9b66e93e-96f1-47dc-b3e1-5a9183f84438,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-bd1cfbc2-9419-4e12-9d25-3bbd49ba97bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-5354c459-91e2-4077-bec9-96a590e069dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-4dcb58f4-a68f-48af-9f05-cbb0c17992b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-93fb1fff-d02d-46b3-aeec-ac4d2664b51f,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-f0f7d85e-f11a-4233-a8ef-ccb6cb197955,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-6940145e-4809-4766-922b-0c11cdb347c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-9977257b-8056-4cd9-af97-65d3c77a5e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119470152-172.17.0.16-1595843141023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44834,DS-9b66e93e-96f1-47dc-b3e1-5a9183f84438,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-bd1cfbc2-9419-4e12-9d25-3bbd49ba97bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-5354c459-91e2-4077-bec9-96a590e069dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-4dcb58f4-a68f-48af-9f05-cbb0c17992b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-93fb1fff-d02d-46b3-aeec-ac4d2664b51f,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-f0f7d85e-f11a-4233-a8ef-ccb6cb197955,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-6940145e-4809-4766-922b-0c11cdb347c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-9977257b-8056-4cd9-af97-65d3c77a5e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549559578-172.17.0.16-1595844013508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-dbb97a16-faf6-4a17-9eaf-41e85950440d,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-8abaa409-ecc3-4f6e-8790-1e3ed0de017c,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-fe75a5fe-ee9d-4053-887c-18e9c84cc355,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-2a2a2fbd-87e3-48a6-b69e-05fac0a11798,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-2b473a0b-4d41-4c9a-82e5-cbc16b746e75,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-0577ac10-be69-4df9-a343-b2fd6b000c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-b99ab8b0-db53-42da-bce9-bda6f0c07319,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-adc5d847-8fb6-42d1-9219-2b18eb9d01fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549559578-172.17.0.16-1595844013508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-dbb97a16-faf6-4a17-9eaf-41e85950440d,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-8abaa409-ecc3-4f6e-8790-1e3ed0de017c,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-fe75a5fe-ee9d-4053-887c-18e9c84cc355,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-2a2a2fbd-87e3-48a6-b69e-05fac0a11798,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-2b473a0b-4d41-4c9a-82e5-cbc16b746e75,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-0577ac10-be69-4df9-a343-b2fd6b000c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-b99ab8b0-db53-42da-bce9-bda6f0c07319,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-adc5d847-8fb6-42d1-9219-2b18eb9d01fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645342503-172.17.0.16-1595844127262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43822,DS-e10b048f-0bb7-4327-84fe-9ea770406d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-f48289ba-0f1e-4d4a-b139-3eb71931b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-9dc838b8-44a7-4fab-a6c8-b95f18cb47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-6344f395-3c10-4686-b0e1-12b5325aa572,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-caa0c5c1-62e3-48df-9bb7-e606e0eaa80b,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-ed714360-568f-4d81-a263-e4417602e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-68a8e4a2-c20f-41c7-9450-9a538bdf9a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-9c510026-1f50-4e4a-be21-5fa550d630bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645342503-172.17.0.16-1595844127262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43822,DS-e10b048f-0bb7-4327-84fe-9ea770406d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-f48289ba-0f1e-4d4a-b139-3eb71931b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-9dc838b8-44a7-4fab-a6c8-b95f18cb47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-6344f395-3c10-4686-b0e1-12b5325aa572,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-caa0c5c1-62e3-48df-9bb7-e606e0eaa80b,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-ed714360-568f-4d81-a263-e4417602e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-68a8e4a2-c20f-41c7-9450-9a538bdf9a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-9c510026-1f50-4e4a-be21-5fa550d630bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901121038-172.17.0.16-1595844572388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-c1e44a81-0aa4-4d07-a5a6-4b7343fc1682,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-5e4aef04-e639-43f0-858e-12bdeaff9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-8f63a47f-e5b9-420c-bbe3-fa46040c4913,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-2288457b-fb07-444b-bd53-eebe03d08f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-67fa3395-11c5-4944-9b36-985c93bd214c,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-4a7afa78-1a52-44d2-91a6-75909a6eae44,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-52213bf5-8196-487d-b40c-a3aa36dfa31b,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-235c69f2-0d85-4a25-96ed-98236fc60119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901121038-172.17.0.16-1595844572388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-c1e44a81-0aa4-4d07-a5a6-4b7343fc1682,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-5e4aef04-e639-43f0-858e-12bdeaff9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-8f63a47f-e5b9-420c-bbe3-fa46040c4913,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-2288457b-fb07-444b-bd53-eebe03d08f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-67fa3395-11c5-4944-9b36-985c93bd214c,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-4a7afa78-1a52-44d2-91a6-75909a6eae44,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-52213bf5-8196-487d-b40c-a3aa36dfa31b,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-235c69f2-0d85-4a25-96ed-98236fc60119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111498601-172.17.0.16-1595844849881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-68224c21-7deb-49d6-ba79-d003314c885f,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-1f714a60-1545-41c0-869d-f5652ab09414,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-d540ce1e-4886-44fa-b8d0-a95051fc03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-bfbdc126-bae5-4cb2-a2ac-b7333dacd64f,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-6bf16ebf-2e72-4229-802f-29691e7496d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-93c713f6-81d2-4d8c-9892-b80bd69929ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-56b5774f-95a0-4cf0-97dd-21dc209b6472,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-c6328b1d-1f2a-4476-ad79-e3ea5eed0b84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111498601-172.17.0.16-1595844849881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-68224c21-7deb-49d6-ba79-d003314c885f,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-1f714a60-1545-41c0-869d-f5652ab09414,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-d540ce1e-4886-44fa-b8d0-a95051fc03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-bfbdc126-bae5-4cb2-a2ac-b7333dacd64f,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-6bf16ebf-2e72-4229-802f-29691e7496d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-93c713f6-81d2-4d8c-9892-b80bd69929ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-56b5774f-95a0-4cf0-97dd-21dc209b6472,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-c6328b1d-1f2a-4476-ad79-e3ea5eed0b84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781074221-172.17.0.16-1595844960397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35434,DS-7c1dbc6f-bf68-4aeb-b4f2-75cb1cc7255b,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-3ad4ff5d-2f9e-4afc-b117-a57d23fbc6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-7609ae29-ddaf-4396-80f0-74be5aa7673b,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-fc1ec1d5-3fcd-4a0f-9983-da9835a3c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-0d35ce6b-fa3f-457d-ae2d-4e0d7f501b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-1aa69a78-200d-4d18-97f5-43ed6f082032,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-e034f70c-56c6-431d-b83f-0387cbceb855,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-b5ad1d03-0817-44a2-ab0f-b9c27f85d602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781074221-172.17.0.16-1595844960397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35434,DS-7c1dbc6f-bf68-4aeb-b4f2-75cb1cc7255b,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-3ad4ff5d-2f9e-4afc-b117-a57d23fbc6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-7609ae29-ddaf-4396-80f0-74be5aa7673b,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-fc1ec1d5-3fcd-4a0f-9983-da9835a3c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-0d35ce6b-fa3f-457d-ae2d-4e0d7f501b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-1aa69a78-200d-4d18-97f5-43ed6f082032,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-e034f70c-56c6-431d-b83f-0387cbceb855,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-b5ad1d03-0817-44a2-ab0f-b9c27f85d602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340037874-172.17.0.16-1595845064553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-fb4944ab-9daa-43b6-a21a-b9fa817fa886,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-754a41bb-d202-49ca-a45a-fdf5e199b964,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-1ac47f86-888e-4b57-a627-b3da2edffeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-16532c27-f3fa-43c1-9214-a21cf1994141,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-c6e57953-c626-4e04-b76b-21de5a356373,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-10166100-4da5-4a94-a6a6-77ab1181676f,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-0bc7eabf-8bb6-400b-88b0-918c79ac54c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-b9c3992f-7a78-4661-9d41-ee98fdd2d378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340037874-172.17.0.16-1595845064553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-fb4944ab-9daa-43b6-a21a-b9fa817fa886,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-754a41bb-d202-49ca-a45a-fdf5e199b964,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-1ac47f86-888e-4b57-a627-b3da2edffeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-16532c27-f3fa-43c1-9214-a21cf1994141,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-c6e57953-c626-4e04-b76b-21de5a356373,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-10166100-4da5-4a94-a6a6-77ab1181676f,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-0bc7eabf-8bb6-400b-88b0-918c79ac54c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-b9c3992f-7a78-4661-9d41-ee98fdd2d378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849989109-172.17.0.16-1595845251049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-e4e4c88a-b82c-4374-b060-02bf6f082619,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-c1b30ee8-11d2-49a9-a07d-3b9f23e75a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-d4722f68-c0f7-495b-a7cf-b38bb05e0988,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-db51eb2c-5364-42b2-9f7c-bd8432c7ec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-1283d6b8-455d-45c3-a281-cfe702846fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-fd08989d-4dcd-400a-89aa-1dd9dd486aab,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-22bf9a94-923d-4228-988e-36756090e7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-3714bdef-1097-4cf3-b28e-f2c7807f35c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849989109-172.17.0.16-1595845251049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-e4e4c88a-b82c-4374-b060-02bf6f082619,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-c1b30ee8-11d2-49a9-a07d-3b9f23e75a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-d4722f68-c0f7-495b-a7cf-b38bb05e0988,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-db51eb2c-5364-42b2-9f7c-bd8432c7ec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-1283d6b8-455d-45c3-a281-cfe702846fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-fd08989d-4dcd-400a-89aa-1dd9dd486aab,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-22bf9a94-923d-4228-988e-36756090e7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-3714bdef-1097-4cf3-b28e-f2c7807f35c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315549989-172.17.0.16-1595845403047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-c9cdda62-98cc-4326-954c-39a12522f552,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-fcfd5435-a647-4c2e-a2a1-102041e454ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-be634f0b-aa8d-472d-b798-927eaef408db,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-1cf758c4-c312-42c7-aeda-5aaf17cbcf83,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-f98fc09c-9359-49a3-b16c-1e796aaa55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-fb9c838f-6a5b-4433-9aac-fb5fc4c76c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-637180c5-c294-451a-b0f6-aa739518062e,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-348b693d-f82c-4d2b-ad06-c952facdd3ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315549989-172.17.0.16-1595845403047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-c9cdda62-98cc-4326-954c-39a12522f552,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-fcfd5435-a647-4c2e-a2a1-102041e454ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-be634f0b-aa8d-472d-b798-927eaef408db,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-1cf758c4-c312-42c7-aeda-5aaf17cbcf83,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-f98fc09c-9359-49a3-b16c-1e796aaa55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-fb9c838f-6a5b-4433-9aac-fb5fc4c76c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-637180c5-c294-451a-b0f6-aa739518062e,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-348b693d-f82c-4d2b-ad06-c952facdd3ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798982952-172.17.0.16-1595845497732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-c415697f-a247-4bde-beea-4d392b42631d,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-e926465b-444e-4920-94e4-8043307f7a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-86ce3c32-abeb-45e0-86ba-8254a4ffa55f,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-57a4ab8b-2713-495a-8336-3ec4b14cd9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-ddd81e3a-5f25-4b3d-a4cd-1d870c60c475,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-5118c990-ef76-4f71-b4af-e14bec96ca41,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-5641b02e-7e26-40aa-8522-e87a6122e08c,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-9bc0f108-631a-4407-88a0-717c005b88fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798982952-172.17.0.16-1595845497732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-c415697f-a247-4bde-beea-4d392b42631d,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-e926465b-444e-4920-94e4-8043307f7a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-86ce3c32-abeb-45e0-86ba-8254a4ffa55f,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-57a4ab8b-2713-495a-8336-3ec4b14cd9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-ddd81e3a-5f25-4b3d-a4cd-1d870c60c475,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-5118c990-ef76-4f71-b4af-e14bec96ca41,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-5641b02e-7e26-40aa-8522-e87a6122e08c,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-9bc0f108-631a-4407-88a0-717c005b88fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096837197-172.17.0.16-1595845888402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38325,DS-d4d982c8-dacd-469c-bbde-cb6ef30bac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-c26cb641-e97a-4165-98bf-633b0dbf5e35,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-80a974d8-852f-452c-8254-a7e69cf7b54a,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-82ea6615-2235-4010-98d8-9414a1400ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-62e7a605-e3a6-4b8d-ab66-1bce77b8d83c,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-de6d74d8-72e3-44e5-9510-2547f705f436,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-167e448c-7327-4410-b20a-53f742ee0248,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-334038c7-9730-429a-ac28-8103bec906d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096837197-172.17.0.16-1595845888402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38325,DS-d4d982c8-dacd-469c-bbde-cb6ef30bac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-c26cb641-e97a-4165-98bf-633b0dbf5e35,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-80a974d8-852f-452c-8254-a7e69cf7b54a,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-82ea6615-2235-4010-98d8-9414a1400ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-62e7a605-e3a6-4b8d-ab66-1bce77b8d83c,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-de6d74d8-72e3-44e5-9510-2547f705f436,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-167e448c-7327-4410-b20a-53f742ee0248,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-334038c7-9730-429a-ac28-8103bec906d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868468452-172.17.0.16-1595846553063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40941,DS-99f9468e-8f24-457a-9fdb-61d27a8b5cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-29674b1d-5b5c-4dd1-8a48-2e121ac05195,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-d9e466bc-fd16-4857-b488-7ad60d2869da,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-0f5de5b1-478c-4447-8ffb-b27039308511,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-8f1725f5-58e0-4094-b871-8cd056617949,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-68aa1906-f4c7-4a9e-a522-116b8f299878,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-b29ce0cd-8d07-48d2-9788-41d7dbe2692d,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-7d648780-650a-4e89-a0ce-e3af34f05df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868468452-172.17.0.16-1595846553063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40941,DS-99f9468e-8f24-457a-9fdb-61d27a8b5cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-29674b1d-5b5c-4dd1-8a48-2e121ac05195,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-d9e466bc-fd16-4857-b488-7ad60d2869da,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-0f5de5b1-478c-4447-8ffb-b27039308511,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-8f1725f5-58e0-4094-b871-8cd056617949,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-68aa1906-f4c7-4a9e-a522-116b8f299878,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-b29ce0cd-8d07-48d2-9788-41d7dbe2692d,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-7d648780-650a-4e89-a0ce-e3af34f05df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5402
