reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787895332-172.17.0.20-1595623376081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34191,DS-c4e2ab8d-b201-4b5b-bb18-404bdf8562f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-4f793e3c-0f18-4d67-a62b-8523606b0175,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-6b475e9f-bf7f-492f-a7b6-6b29d8154719,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-e05c902b-750d-4b23-9bcb-281e326e06a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-a936952e-42c3-4396-998f-a5ccc743cf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-1d5b4a77-5f5b-4c57-b755-8eea5a680355,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-78512837-d916-44f7-953e-b6fc9bed587a,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-84474604-9dbd-47d0-a063-e3f4c3f442ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787895332-172.17.0.20-1595623376081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34191,DS-c4e2ab8d-b201-4b5b-bb18-404bdf8562f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-4f793e3c-0f18-4d67-a62b-8523606b0175,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-6b475e9f-bf7f-492f-a7b6-6b29d8154719,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-e05c902b-750d-4b23-9bcb-281e326e06a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-a936952e-42c3-4396-998f-a5ccc743cf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-1d5b4a77-5f5b-4c57-b755-8eea5a680355,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-78512837-d916-44f7-953e-b6fc9bed587a,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-84474604-9dbd-47d0-a063-e3f4c3f442ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792682288-172.17.0.20-1595625083563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-07bd2053-dc68-4d7b-9413-21afc696fa09,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-c6789d1f-7e0e-40da-a433-49b97880a80b,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-6a7f9c82-29f5-4c9a-926c-0376104b6c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-fb0dd920-f529-4789-bfca-d009dad1df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-94298f23-964f-484e-84a0-7cce2ce0a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-8bd07a5f-a160-4e39-8de8-cb1f83669a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-3c1dc81f-6400-4791-a11d-6bf875ca671c,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-0e238b60-a30d-4dea-ab0f-dbd96b4e9668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792682288-172.17.0.20-1595625083563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-07bd2053-dc68-4d7b-9413-21afc696fa09,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-c6789d1f-7e0e-40da-a433-49b97880a80b,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-6a7f9c82-29f5-4c9a-926c-0376104b6c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-fb0dd920-f529-4789-bfca-d009dad1df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-94298f23-964f-484e-84a0-7cce2ce0a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-8bd07a5f-a160-4e39-8de8-cb1f83669a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-3c1dc81f-6400-4791-a11d-6bf875ca671c,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-0e238b60-a30d-4dea-ab0f-dbd96b4e9668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525488692-172.17.0.20-1595625417445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45189,DS-37640270-735f-49ee-9d3a-feae543522e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-857d5dce-4b2b-4ba1-83ad-6150137810aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-2cb4c1e2-9448-4c0e-87c6-9c6743f2049f,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-d4984ee3-d60b-4988-b114-2295b96abf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-ad991cab-c88e-4335-af1e-a273ccbf90ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-2b5b3c37-0580-4400-ad85-35e66cb83d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-a176d09c-67e7-4e74-9691-2bc40a7352d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-e6f2f72e-b80e-49e6-addc-29e06c95d1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525488692-172.17.0.20-1595625417445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45189,DS-37640270-735f-49ee-9d3a-feae543522e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-857d5dce-4b2b-4ba1-83ad-6150137810aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-2cb4c1e2-9448-4c0e-87c6-9c6743f2049f,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-d4984ee3-d60b-4988-b114-2295b96abf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-ad991cab-c88e-4335-af1e-a273ccbf90ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-2b5b3c37-0580-4400-ad85-35e66cb83d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-a176d09c-67e7-4e74-9691-2bc40a7352d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-e6f2f72e-b80e-49e6-addc-29e06c95d1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715770733-172.17.0.20-1595625632771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-fd7b6b90-c059-4f9a-8c11-e33f904b97f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-9d032c24-eaf5-4d44-828a-250c8a3edce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-3adb4046-68c6-44cd-b7b2-6f3f98bea1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-83c47ce5-7a6e-42ab-b9aa-e35185069b15,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-3809cf01-99e5-4db4-9b3e-e42967664cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-d221fe84-be0a-4f89-91fc-fbed8b0a3895,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-95522777-8dc6-4ab8-95d1-e3b162fee564,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-78dd568d-8bd3-4dce-94a8-5926e2a4dd52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715770733-172.17.0.20-1595625632771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-fd7b6b90-c059-4f9a-8c11-e33f904b97f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-9d032c24-eaf5-4d44-828a-250c8a3edce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-3adb4046-68c6-44cd-b7b2-6f3f98bea1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-83c47ce5-7a6e-42ab-b9aa-e35185069b15,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-3809cf01-99e5-4db4-9b3e-e42967664cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-d221fe84-be0a-4f89-91fc-fbed8b0a3895,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-95522777-8dc6-4ab8-95d1-e3b162fee564,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-78dd568d-8bd3-4dce-94a8-5926e2a4dd52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560287085-172.17.0.20-1595625797573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-cefdb696-d7d4-421a-9dc9-fb0b51b8f1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-2e7e72f5-43bc-449a-8ddf-ca3ef69634e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-dcc4e72f-b226-47cb-b083-41f83449c348,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-60bebc11-5afa-4a56-b439-89bcbf6aa179,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-76d4aeb5-fd4c-47ae-bc5c-e8d5f5f7fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-cf8ae34c-b664-4c23-be0f-e003e9f7d621,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-8bc71d6b-3015-41c3-b450-e364ee764917,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-1284c1a7-568b-4313-affc-f1bd54c4d0a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560287085-172.17.0.20-1595625797573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-cefdb696-d7d4-421a-9dc9-fb0b51b8f1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-2e7e72f5-43bc-449a-8ddf-ca3ef69634e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-dcc4e72f-b226-47cb-b083-41f83449c348,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-60bebc11-5afa-4a56-b439-89bcbf6aa179,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-76d4aeb5-fd4c-47ae-bc5c-e8d5f5f7fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-cf8ae34c-b664-4c23-be0f-e003e9f7d621,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-8bc71d6b-3015-41c3-b450-e364ee764917,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-1284c1a7-568b-4313-affc-f1bd54c4d0a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194162083-172.17.0.20-1595625872095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35477,DS-0accfb25-cd2b-44e2-bc3b-25c5ff054053,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-a5923bba-f9f9-4496-b2b2-bcab806f1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-23196141-cb09-4aef-bab8-9b69b2f31494,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-1000a56e-606e-476a-be8d-ac8a285aaf03,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-4b8b5c4a-5433-4c65-b73e-1f8f44e06ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-a8a48746-9519-4002-8e08-6b7c828779a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-3a303f18-cba3-4a85-a234-726019f427cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-cc563f22-4e1c-43df-989e-9c707bd4fec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194162083-172.17.0.20-1595625872095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35477,DS-0accfb25-cd2b-44e2-bc3b-25c5ff054053,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-a5923bba-f9f9-4496-b2b2-bcab806f1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-23196141-cb09-4aef-bab8-9b69b2f31494,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-1000a56e-606e-476a-be8d-ac8a285aaf03,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-4b8b5c4a-5433-4c65-b73e-1f8f44e06ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-a8a48746-9519-4002-8e08-6b7c828779a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-3a303f18-cba3-4a85-a234-726019f427cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-cc563f22-4e1c-43df-989e-9c707bd4fec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016670770-172.17.0.20-1595626525416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45462,DS-7ee81f36-aab4-4497-a3bf-57239877a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-bf629b13-ce50-4648-a346-4cad3d3c89b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-fe47b9d8-73fb-4fdc-a596-7808ed2688d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-2c740861-0556-442f-8293-c4c29e22b40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-739194dd-0e3f-4192-9279-5ec580e50e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-91809749-e45e-49ea-a68e-880e25735a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-26b511a7-ae62-4a31-86de-e77ff56bbaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-5650be18-be72-4bfe-be71-e5c27eb1c04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016670770-172.17.0.20-1595626525416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45462,DS-7ee81f36-aab4-4497-a3bf-57239877a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-bf629b13-ce50-4648-a346-4cad3d3c89b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-fe47b9d8-73fb-4fdc-a596-7808ed2688d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-2c740861-0556-442f-8293-c4c29e22b40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-739194dd-0e3f-4192-9279-5ec580e50e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-91809749-e45e-49ea-a68e-880e25735a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-26b511a7-ae62-4a31-86de-e77ff56bbaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-5650be18-be72-4bfe-be71-e5c27eb1c04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330466577-172.17.0.20-1595627036957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-1507481d-30b1-436d-9f5d-0e1446020a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-adab44f3-3c03-4b7b-a488-58c46f250d01,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-632737d5-c099-4465-a269-8f9d874c2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-d56c51cb-761b-48fe-8a52-7868eb5a2d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-2fdd7429-bde6-4141-a54c-381d4d154e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-87e75bb5-9de7-4d00-851f-039b332d33bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-771649d9-83cc-4bec-b0e0-c7f404872519,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-492a0b52-1e42-4cbf-aa2f-013546686901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330466577-172.17.0.20-1595627036957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-1507481d-30b1-436d-9f5d-0e1446020a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-adab44f3-3c03-4b7b-a488-58c46f250d01,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-632737d5-c099-4465-a269-8f9d874c2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-d56c51cb-761b-48fe-8a52-7868eb5a2d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-2fdd7429-bde6-4141-a54c-381d4d154e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-87e75bb5-9de7-4d00-851f-039b332d33bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-771649d9-83cc-4bec-b0e0-c7f404872519,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-492a0b52-1e42-4cbf-aa2f-013546686901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648029176-172.17.0.20-1595627770164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33030,DS-d9577c33-a42f-4440-b71c-dd088cfe1fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-df5f9c77-6f2c-446c-a183-a253f89290cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-786da0ff-274b-41ad-b551-220f4f08b5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-0d5b2a86-4e10-4cf0-af0c-6aa636e6c313,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-d8368f89-61ef-42ef-88fd-9299f204500c,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1374ff14-3d88-41d2-8ad5-8c18db3155cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-5c9d726d-ff68-44d4-96b9-ff3c2bdfa679,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-14c97f41-d9ec-4e5b-8ff6-ec1117c7dbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648029176-172.17.0.20-1595627770164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33030,DS-d9577c33-a42f-4440-b71c-dd088cfe1fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-df5f9c77-6f2c-446c-a183-a253f89290cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-786da0ff-274b-41ad-b551-220f4f08b5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-0d5b2a86-4e10-4cf0-af0c-6aa636e6c313,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-d8368f89-61ef-42ef-88fd-9299f204500c,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1374ff14-3d88-41d2-8ad5-8c18db3155cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-5c9d726d-ff68-44d4-96b9-ff3c2bdfa679,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-14c97f41-d9ec-4e5b-8ff6-ec1117c7dbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5519
