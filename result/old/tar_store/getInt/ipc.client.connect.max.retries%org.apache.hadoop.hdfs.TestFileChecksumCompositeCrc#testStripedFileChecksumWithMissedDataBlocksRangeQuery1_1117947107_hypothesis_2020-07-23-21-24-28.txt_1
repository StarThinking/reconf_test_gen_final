reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249547493-172.17.0.21-1595539805582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-df08f695-a31e-467d-a3ed-e866d4e93128,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-f46d7f75-4d46-4611-b7dd-41bde73bc2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-01cde313-e599-4c8c-9395-25fba50d57d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-41e7109e-4e6e-48d3-8eaa-8142e5afc61d,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-c1eb160a-59f6-441d-b063-0ccc380e36ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-5d5375a8-b818-4e82-bad8-02c7e61bbbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-84bc67cd-1f74-4f34-b6df-a11e72b1be7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-e3531eef-79bf-44b1-a67d-529231102355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249547493-172.17.0.21-1595539805582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-df08f695-a31e-467d-a3ed-e866d4e93128,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-f46d7f75-4d46-4611-b7dd-41bde73bc2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-01cde313-e599-4c8c-9395-25fba50d57d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-41e7109e-4e6e-48d3-8eaa-8142e5afc61d,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-c1eb160a-59f6-441d-b063-0ccc380e36ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-5d5375a8-b818-4e82-bad8-02c7e61bbbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-84bc67cd-1f74-4f34-b6df-a11e72b1be7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-e3531eef-79bf-44b1-a67d-529231102355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939011977-172.17.0.21-1595540023518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39728,DS-63274195-41a0-4aec-af14-dd9665237ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-423d1bb2-6a5f-448e-882e-12f647ef73e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-e604b73f-e183-4c40-b05e-add7530d3e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-5bc6c98f-5204-4b51-8ff9-ad15a38a79ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-91da4cb2-b4be-4e91-8289-448ad2e7ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-0a0b7070-5be5-4ab2-89ba-903658792dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-87afd41a-1387-45ab-85f8-80f5be3d857b,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-b39df5d7-ade4-4346-9e70-ac55060a0e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939011977-172.17.0.21-1595540023518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39728,DS-63274195-41a0-4aec-af14-dd9665237ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-423d1bb2-6a5f-448e-882e-12f647ef73e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-e604b73f-e183-4c40-b05e-add7530d3e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-5bc6c98f-5204-4b51-8ff9-ad15a38a79ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-91da4cb2-b4be-4e91-8289-448ad2e7ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-0a0b7070-5be5-4ab2-89ba-903658792dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-87afd41a-1387-45ab-85f8-80f5be3d857b,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-b39df5d7-ade4-4346-9e70-ac55060a0e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987492311-172.17.0.21-1595541013453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36849,DS-600d551b-02f4-41d5-8da2-d27f4f424d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-01f929d7-8175-4b8e-b9ba-16eee23181da,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-693afab2-eb84-4523-920a-8d7fcbaf5c58,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-e90c143d-cb04-4cb0-93c2-9cde4fcfe293,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-a24ca967-a933-4629-a45f-3b6526ecec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-df957928-4d27-4b20-b164-b39f9a10b5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-e5db5b67-1502-49b0-b24c-99b3b1b3189c,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-425c3b3a-8cc2-4715-9dc3-ab69c95cd469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987492311-172.17.0.21-1595541013453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36849,DS-600d551b-02f4-41d5-8da2-d27f4f424d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-01f929d7-8175-4b8e-b9ba-16eee23181da,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-693afab2-eb84-4523-920a-8d7fcbaf5c58,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-e90c143d-cb04-4cb0-93c2-9cde4fcfe293,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-a24ca967-a933-4629-a45f-3b6526ecec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-df957928-4d27-4b20-b164-b39f9a10b5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-e5db5b67-1502-49b0-b24c-99b3b1b3189c,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-425c3b3a-8cc2-4715-9dc3-ab69c95cd469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589839092-172.17.0.21-1595541108192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42826,DS-244bc0ca-1bf4-459d-a9f9-952522e90cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-b851150f-79bb-4bb7-ac63-efd82ab5b97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-3c9921e7-5e18-40e1-91a5-b26dea0d5606,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-9f551d60-55d4-4ecf-b590-81e26db147d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-1d5cc912-5be1-401a-accd-29f9fc65ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-adbb2e35-bdbc-41f3-8d92-fd1a40e3808b,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-1ef80ffe-d134-4797-be66-c2706979ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-d27b93d6-ecc5-4e0a-b847-90a5d242f33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589839092-172.17.0.21-1595541108192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42826,DS-244bc0ca-1bf4-459d-a9f9-952522e90cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-b851150f-79bb-4bb7-ac63-efd82ab5b97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-3c9921e7-5e18-40e1-91a5-b26dea0d5606,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-9f551d60-55d4-4ecf-b590-81e26db147d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-1d5cc912-5be1-401a-accd-29f9fc65ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-adbb2e35-bdbc-41f3-8d92-fd1a40e3808b,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-1ef80ffe-d134-4797-be66-c2706979ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-d27b93d6-ecc5-4e0a-b847-90a5d242f33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338875708-172.17.0.21-1595541821608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45631,DS-02925de9-cae2-4324-9706-035856bba465,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-37d8db0d-a178-450c-bf30-c520e69776fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-71d93d95-53f6-4c5d-8f43-f2529fa1d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-9ba10445-d50e-4daf-a8cf-c021a7cab9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-1d4f07bc-b2f6-4c19-8ef9-b67e6c7bbdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-01c61bcc-e6d3-4a4b-9180-768e7d232e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-c08331b0-3bdb-4a65-b224-1522dfb75f38,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-3fa6d5bd-135f-4470-a604-6225783db7ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338875708-172.17.0.21-1595541821608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45631,DS-02925de9-cae2-4324-9706-035856bba465,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-37d8db0d-a178-450c-bf30-c520e69776fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-71d93d95-53f6-4c5d-8f43-f2529fa1d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-9ba10445-d50e-4daf-a8cf-c021a7cab9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-1d4f07bc-b2f6-4c19-8ef9-b67e6c7bbdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-01c61bcc-e6d3-4a4b-9180-768e7d232e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-c08331b0-3bdb-4a65-b224-1522dfb75f38,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-3fa6d5bd-135f-4470-a604-6225783db7ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331105668-172.17.0.21-1595541863243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34042,DS-c84864d8-37c8-4e56-8423-551d4d3b3688,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-f3e2c089-5a20-45b0-a5d3-1cfceaac9c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-07208d95-8dd9-4285-b572-8fd18ce21c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-c28c7f6e-c848-446f-bef2-f25a85ed1dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-8f8ea168-6514-4bac-9ea3-cf3c51810f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-5c343a0d-70af-4aef-b015-14e16f144f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-af121142-caa0-4ce1-b1dc-22d1adce0708,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-dba5c3c3-ddde-429e-ac43-f9d9c0ac9c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331105668-172.17.0.21-1595541863243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34042,DS-c84864d8-37c8-4e56-8423-551d4d3b3688,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-f3e2c089-5a20-45b0-a5d3-1cfceaac9c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-07208d95-8dd9-4285-b572-8fd18ce21c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-c28c7f6e-c848-446f-bef2-f25a85ed1dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-8f8ea168-6514-4bac-9ea3-cf3c51810f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-5c343a0d-70af-4aef-b015-14e16f144f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-af121142-caa0-4ce1-b1dc-22d1adce0708,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-dba5c3c3-ddde-429e-ac43-f9d9c0ac9c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977299889-172.17.0.21-1595541947730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34597,DS-6e35cf6c-7fb5-4ec6-ae6b-f86c08513004,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-2cf79f17-461d-4a9d-9cc6-f74cc7bfe043,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-e4088f34-6fed-45ac-87c2-aa904480bbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-dab3dcbb-f7bb-4b98-a5b5-61541794b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-c5ef0be7-81d2-4112-8977-ea65846a040f,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-de4823f3-00ee-4b9a-96eb-02aa0357e1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-5a183be3-7f83-4269-a5bf-0529bcf55550,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-86fb0699-d1fd-45a1-a58a-6a6450ec49bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977299889-172.17.0.21-1595541947730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34597,DS-6e35cf6c-7fb5-4ec6-ae6b-f86c08513004,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-2cf79f17-461d-4a9d-9cc6-f74cc7bfe043,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-e4088f34-6fed-45ac-87c2-aa904480bbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-dab3dcbb-f7bb-4b98-a5b5-61541794b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-c5ef0be7-81d2-4112-8977-ea65846a040f,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-de4823f3-00ee-4b9a-96eb-02aa0357e1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-5a183be3-7f83-4269-a5bf-0529bcf55550,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-86fb0699-d1fd-45a1-a58a-6a6450ec49bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457163959-172.17.0.21-1595542346197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-9fc006bc-9b40-413f-9afc-ce74adc78fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-049bbcb8-8481-4d8b-b396-013014b276ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-864eb196-9a42-4965-881d-0d670b0e4c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-7b82124f-494e-4f97-a1ec-4eb92679a492,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-49ae5b6b-e6bf-449d-9fce-22c8aa454acc,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-579a5b19-ecd6-4d9c-92c5-667ef5e99059,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-9657f960-b382-48e3-b28a-c53b7dc6989d,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-06f49489-dcbc-4428-aea4-c748b787d1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457163959-172.17.0.21-1595542346197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-9fc006bc-9b40-413f-9afc-ce74adc78fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-049bbcb8-8481-4d8b-b396-013014b276ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-864eb196-9a42-4965-881d-0d670b0e4c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-7b82124f-494e-4f97-a1ec-4eb92679a492,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-49ae5b6b-e6bf-449d-9fce-22c8aa454acc,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-579a5b19-ecd6-4d9c-92c5-667ef5e99059,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-9657f960-b382-48e3-b28a-c53b7dc6989d,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-06f49489-dcbc-4428-aea4-c748b787d1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060876615-172.17.0.21-1595542939433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42038,DS-e8f77434-2dec-4d17-b46d-7c911fba1764,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-4d08866a-4e2a-4ae0-984a-a5c46ee80515,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-b5f9a892-dff7-4035-a6fd-6ea4f046a180,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-06b5a018-f7a3-4846-b9d4-134208aaa44b,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-e54d5473-97cd-44ee-8c0f-31c5c38005c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-c609f48c-0d55-4196-977f-800fe62937ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-a7324ba9-02da-4587-8755-91ed9937d824,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-a604781f-fe3e-4528-8273-594dff791236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060876615-172.17.0.21-1595542939433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42038,DS-e8f77434-2dec-4d17-b46d-7c911fba1764,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-4d08866a-4e2a-4ae0-984a-a5c46ee80515,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-b5f9a892-dff7-4035-a6fd-6ea4f046a180,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-06b5a018-f7a3-4846-b9d4-134208aaa44b,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-e54d5473-97cd-44ee-8c0f-31c5c38005c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-c609f48c-0d55-4196-977f-800fe62937ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-a7324ba9-02da-4587-8755-91ed9937d824,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-a604781f-fe3e-4528-8273-594dff791236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836063497-172.17.0.21-1595544007350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46567,DS-6d31b8d8-4055-42eb-820e-d28be9152d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-59ecce49-9370-4e91-b99b-7a1730b14fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-767d1a30-579d-4b00-9a43-9f98df12a553,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-ff97184e-452f-4a35-a8ce-73c4cfbd60a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-2ed09fb4-8d46-40a0-ba82-f0d2d33fc88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-bfa6927e-4b0e-4a76-8207-34b20d9a1b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-48fc6128-3c8b-4c18-86c6-fa6dcaabdcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-0aff528b-601e-4fa3-86e9-3e305e237167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836063497-172.17.0.21-1595544007350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46567,DS-6d31b8d8-4055-42eb-820e-d28be9152d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-59ecce49-9370-4e91-b99b-7a1730b14fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-767d1a30-579d-4b00-9a43-9f98df12a553,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-ff97184e-452f-4a35-a8ce-73c4cfbd60a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-2ed09fb4-8d46-40a0-ba82-f0d2d33fc88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-bfa6927e-4b0e-4a76-8207-34b20d9a1b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-48fc6128-3c8b-4c18-86c6-fa6dcaabdcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-0aff528b-601e-4fa3-86e9-3e305e237167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090334283-172.17.0.21-1595544281646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-79065e2b-8f79-46dd-8339-843bfdec6b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-8bbc93ba-e8ba-4dac-95f1-a628f7cb33fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-a2a239d7-ca76-4cdf-9168-83fd71f50233,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-fce5e652-9a58-4cb5-8ac4-0bc2b4d562be,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-01ea5f87-fae1-43ea-aff3-d001d25323da,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-fa5be0ba-c6d7-49c7-9051-561e199dabb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-482d5013-6440-4db9-9857-448085870839,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-2b300c2e-d0ff-4f5d-8e18-0aa3700ae6cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090334283-172.17.0.21-1595544281646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-79065e2b-8f79-46dd-8339-843bfdec6b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-8bbc93ba-e8ba-4dac-95f1-a628f7cb33fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-a2a239d7-ca76-4cdf-9168-83fd71f50233,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-fce5e652-9a58-4cb5-8ac4-0bc2b4d562be,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-01ea5f87-fae1-43ea-aff3-d001d25323da,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-fa5be0ba-c6d7-49c7-9051-561e199dabb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-482d5013-6440-4db9-9857-448085870839,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-2b300c2e-d0ff-4f5d-8e18-0aa3700ae6cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995503222-172.17.0.21-1595544843409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-bb699cd5-e6e7-4e5b-9529-4964a29fbf58,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-f3162bb4-6ae4-428e-b7bf-ca6d3f88200e,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-9c29c3bc-6a2d-46b1-8b11-639ad176ef18,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-3c879aa3-8f94-4f35-88bf-6ec2095d1c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-03bbae0d-8b28-4565-9990-6071d2125fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-b09a25e0-52e5-455a-9aeb-bfd4d9d620f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-106ae3e9-cc7a-4299-a97f-4012feed828f,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-7ae34c9a-2419-4ff0-8f49-55fc362f67ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995503222-172.17.0.21-1595544843409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-bb699cd5-e6e7-4e5b-9529-4964a29fbf58,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-f3162bb4-6ae4-428e-b7bf-ca6d3f88200e,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-9c29c3bc-6a2d-46b1-8b11-639ad176ef18,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-3c879aa3-8f94-4f35-88bf-6ec2095d1c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-03bbae0d-8b28-4565-9990-6071d2125fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-b09a25e0-52e5-455a-9aeb-bfd4d9d620f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-106ae3e9-cc7a-4299-a97f-4012feed828f,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-7ae34c9a-2419-4ff0-8f49-55fc362f67ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798885743-172.17.0.21-1595545857302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33695,DS-584bb28f-d7e2-4bc5-b4e7-708bb7e06fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-437f338d-3b5d-4712-b1da-e7a8e5805680,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-18323fd9-c3b2-4c4d-99cd-2b414c4f2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-38cdb450-57fa-4368-9048-fb237204056c,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-2888d5ab-acaf-4329-b2ec-c05bf717d941,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-c49e82b1-6a70-422a-bec3-6a126fcc7c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-092066da-7217-4ce2-9a23-3da52e734ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-bc9367c3-25e2-48f0-9d7f-b1d70dbbb34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798885743-172.17.0.21-1595545857302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33695,DS-584bb28f-d7e2-4bc5-b4e7-708bb7e06fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-437f338d-3b5d-4712-b1da-e7a8e5805680,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-18323fd9-c3b2-4c4d-99cd-2b414c4f2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-38cdb450-57fa-4368-9048-fb237204056c,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-2888d5ab-acaf-4329-b2ec-c05bf717d941,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-c49e82b1-6a70-422a-bec3-6a126fcc7c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-092066da-7217-4ce2-9a23-3da52e734ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-bc9367c3-25e2-48f0-9d7f-b1d70dbbb34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885005313-172.17.0.21-1595545936363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-bf8508fb-73d7-4fab-8d75-19c6f1c89b45,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-fbb8f198-47be-4156-b27e-be2427a22e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-3702fa14-3e57-4742-b179-47c17a55f542,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-38971577-7bdb-4500-804b-9ec4de952abb,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-84411e00-964e-48c7-9a21-c37ccb34e3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-57680c0f-dc12-468a-b761-0072179d04df,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-ec60734d-5197-44af-ab4e-1432d0eea42d,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-516b39ea-6f7b-459a-b52e-264ca86475af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885005313-172.17.0.21-1595545936363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-bf8508fb-73d7-4fab-8d75-19c6f1c89b45,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-fbb8f198-47be-4156-b27e-be2427a22e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-3702fa14-3e57-4742-b179-47c17a55f542,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-38971577-7bdb-4500-804b-9ec4de952abb,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-84411e00-964e-48c7-9a21-c37ccb34e3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-57680c0f-dc12-468a-b761-0072179d04df,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-ec60734d-5197-44af-ab4e-1432d0eea42d,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-516b39ea-6f7b-459a-b52e-264ca86475af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6616
