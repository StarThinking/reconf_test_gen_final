reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668075295-172.17.0.11-1595589648588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39846,DS-3e866553-0481-4031-8f11-7fc2cc6b2736,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-a6a2ecdb-01ba-462c-99d8-349b92d755db,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-09778b91-8eb6-4ede-9871-76d4aaeb8efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-3c022d5f-e3ad-4d3f-98c7-f32bc8563573,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-261d73b4-bd90-4d13-b73c-f94daddd710a,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-4aa6dc54-2099-42c1-bddc-a876b4ac7ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-d216d1ce-c66c-49fb-9a08-26991ded7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-9d7d534f-d167-4f82-9f4d-0e0bdf0bb3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668075295-172.17.0.11-1595589648588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39846,DS-3e866553-0481-4031-8f11-7fc2cc6b2736,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-a6a2ecdb-01ba-462c-99d8-349b92d755db,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-09778b91-8eb6-4ede-9871-76d4aaeb8efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-3c022d5f-e3ad-4d3f-98c7-f32bc8563573,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-261d73b4-bd90-4d13-b73c-f94daddd710a,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-4aa6dc54-2099-42c1-bddc-a876b4ac7ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-d216d1ce-c66c-49fb-9a08-26991ded7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-9d7d534f-d167-4f82-9f4d-0e0bdf0bb3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816829397-172.17.0.11-1595589893615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-5c4400e2-c2c0-44d8-90ba-f06e86bce1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-93f2f9e5-ea16-4ecd-8e9d-03524ae46219,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-a889c1c7-d0df-41f5-94cc-64e504e0b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-d4df54ab-c9cd-46d4-af92-1d4ce10d8c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-ef58ccf3-2de4-4e4e-9788-e2378be36ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-a3df4e8e-01b9-4d45-b53a-e44368620cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-9414efc4-e179-453c-8e76-52c20c67b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-a4103baa-55a4-41ba-b0cd-0550b1ee56c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816829397-172.17.0.11-1595589893615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-5c4400e2-c2c0-44d8-90ba-f06e86bce1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-93f2f9e5-ea16-4ecd-8e9d-03524ae46219,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-a889c1c7-d0df-41f5-94cc-64e504e0b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-d4df54ab-c9cd-46d4-af92-1d4ce10d8c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-ef58ccf3-2de4-4e4e-9788-e2378be36ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-a3df4e8e-01b9-4d45-b53a-e44368620cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-9414efc4-e179-453c-8e76-52c20c67b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-a4103baa-55a4-41ba-b0cd-0550b1ee56c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074876140-172.17.0.11-1595590332062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-71c87433-f137-4c7d-b3d4-5361a5910d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-ee0d9f45-993f-40e1-b7ab-9c89b0e454bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-638a0284-a592-4317-807c-920c0821dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-9cbe0012-f968-4f46-a08f-f495191172d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-4a1cff08-458b-431d-92df-5ec1ad98d355,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-f91a12bd-7487-49ee-b9d1-368f2f762722,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-2ef0526d-ca4a-4914-b104-8d021ac35cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-804c3d8e-a021-4869-a919-f75d3ec6dc65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074876140-172.17.0.11-1595590332062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-71c87433-f137-4c7d-b3d4-5361a5910d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-ee0d9f45-993f-40e1-b7ab-9c89b0e454bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-638a0284-a592-4317-807c-920c0821dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-9cbe0012-f968-4f46-a08f-f495191172d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-4a1cff08-458b-431d-92df-5ec1ad98d355,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-f91a12bd-7487-49ee-b9d1-368f2f762722,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-2ef0526d-ca4a-4914-b104-8d021ac35cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-804c3d8e-a021-4869-a919-f75d3ec6dc65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873677413-172.17.0.11-1595590416862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-7190c268-c950-4bb6-8896-dee1ba686016,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-317451c6-733e-4447-a5fc-0323038edd92,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-6c50cd07-c29b-407e-83a3-2f15412376b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-196a2a1f-7ed7-4e23-9cf6-63ff316f92ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-7d4ad49a-1209-4b09-82d5-57571dd4c468,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-91c0bdac-df1a-4112-a741-5e73b86bc3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-22c3527f-747d-492e-aaac-185b6e143b32,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-4ad99f30-8166-4030-88ba-1077ac19127a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873677413-172.17.0.11-1595590416862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-7190c268-c950-4bb6-8896-dee1ba686016,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-317451c6-733e-4447-a5fc-0323038edd92,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-6c50cd07-c29b-407e-83a3-2f15412376b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-196a2a1f-7ed7-4e23-9cf6-63ff316f92ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-7d4ad49a-1209-4b09-82d5-57571dd4c468,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-91c0bdac-df1a-4112-a741-5e73b86bc3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-22c3527f-747d-492e-aaac-185b6e143b32,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-4ad99f30-8166-4030-88ba-1077ac19127a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318385082-172.17.0.11-1595591489989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44638,DS-9acf3a2d-0c6b-431f-b05d-2c594ee403ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-ccc04a92-742f-4061-9147-9ee084cba633,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-2336ae52-8278-496a-b2f7-7bd8a6d67890,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-1769ab4a-4e9e-4fec-b9f7-113f105f0af4,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-11a9f3ed-c885-449f-877a-81e67fcc34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-3d238d1b-6227-4ebc-92c8-d81aeb9b1ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-d8d0161b-264d-4871-ace0-9186dee28404,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-bddcac05-8d68-48f0-b84c-39d3d1f29d94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318385082-172.17.0.11-1595591489989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44638,DS-9acf3a2d-0c6b-431f-b05d-2c594ee403ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-ccc04a92-742f-4061-9147-9ee084cba633,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-2336ae52-8278-496a-b2f7-7bd8a6d67890,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-1769ab4a-4e9e-4fec-b9f7-113f105f0af4,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-11a9f3ed-c885-449f-877a-81e67fcc34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-3d238d1b-6227-4ebc-92c8-d81aeb9b1ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-d8d0161b-264d-4871-ace0-9186dee28404,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-bddcac05-8d68-48f0-b84c-39d3d1f29d94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882356738-172.17.0.11-1595591578947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-4e6a5d02-d18a-4df8-8995-859253e312d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-dac13b09-3462-49a3-942a-5b3ccc04020e,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-c3420180-a586-438f-9989-23085576caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-370c7e23-2680-4490-bb26-b2164ca02513,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-58bb8bfd-14ad-4815-8b65-49ba0a91e729,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-37957756-d686-4cdc-af35-3ed497cad3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-93d84a81-15cb-4233-8ff5-4084ed6908e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-6e2d72a1-c2b5-4c36-bc5f-ad57e0a39630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882356738-172.17.0.11-1595591578947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-4e6a5d02-d18a-4df8-8995-859253e312d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-dac13b09-3462-49a3-942a-5b3ccc04020e,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-c3420180-a586-438f-9989-23085576caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-370c7e23-2680-4490-bb26-b2164ca02513,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-58bb8bfd-14ad-4815-8b65-49ba0a91e729,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-37957756-d686-4cdc-af35-3ed497cad3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-93d84a81-15cb-4233-8ff5-4084ed6908e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-6e2d72a1-c2b5-4c36-bc5f-ad57e0a39630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663260065-172.17.0.11-1595592019883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-c4a0b619-a2a8-4826-84b5-bbed1e0f6d58,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-ece82419-4a35-4057-a8c0-d65819de3468,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-fbeedbd6-fff7-46d5-92d1-40d920fecd74,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-bb43cd98-7e48-4dcc-8ea2-a8c2b9b312e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-f9124e8c-066a-4cfe-9737-28127ca4a903,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-5ef9144f-4fe7-4d77-9291-006d2fb83385,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-7388dab0-3fff-4bc9-9134-575eaa9027e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-b63245c8-3dbf-4eae-b130-4f9aa387f046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663260065-172.17.0.11-1595592019883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-c4a0b619-a2a8-4826-84b5-bbed1e0f6d58,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-ece82419-4a35-4057-a8c0-d65819de3468,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-fbeedbd6-fff7-46d5-92d1-40d920fecd74,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-bb43cd98-7e48-4dcc-8ea2-a8c2b9b312e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-f9124e8c-066a-4cfe-9737-28127ca4a903,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-5ef9144f-4fe7-4d77-9291-006d2fb83385,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-7388dab0-3fff-4bc9-9134-575eaa9027e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-b63245c8-3dbf-4eae-b130-4f9aa387f046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519207348-172.17.0.11-1595592104988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-15a7cf67-e7d4-43a5-a1de-2d7a7c0a4936,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-21abd726-c03e-4f66-b17d-fb92b5acbbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-6f61e17a-7f0b-4e15-bf01-ac61b55a47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-e54070b8-c46b-4b3c-a998-ac732302b755,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-fd53e536-9a26-4db6-9723-645482f1a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-bc8456dd-7a84-4583-863a-332d0bb70cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-029e3700-2ad9-49a5-9856-3602b95687b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-d66da21c-02c3-409b-8183-c064e7be891d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519207348-172.17.0.11-1595592104988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-15a7cf67-e7d4-43a5-a1de-2d7a7c0a4936,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-21abd726-c03e-4f66-b17d-fb92b5acbbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-6f61e17a-7f0b-4e15-bf01-ac61b55a47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-e54070b8-c46b-4b3c-a998-ac732302b755,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-fd53e536-9a26-4db6-9723-645482f1a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-bc8456dd-7a84-4583-863a-332d0bb70cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-029e3700-2ad9-49a5-9856-3602b95687b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-d66da21c-02c3-409b-8183-c064e7be891d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480024892-172.17.0.11-1595592339124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44023,DS-b93670f6-7b12-47d1-a446-5495e340bb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-225f9df5-82cc-45c5-a7aa-f0b775485697,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-e64ef36c-eb3c-4dfd-80e9-b488de227036,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-ef77a02c-7083-432d-9fe5-cfaaaa171455,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-0e720e99-4912-4e93-b718-0fc10425cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-5906600f-fc47-44ff-a431-d1f96236be14,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-afefb60c-0d8a-414d-af09-315379bc49bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-6479b4f0-5305-489c-891d-37383cb2bdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480024892-172.17.0.11-1595592339124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44023,DS-b93670f6-7b12-47d1-a446-5495e340bb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-225f9df5-82cc-45c5-a7aa-f0b775485697,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-e64ef36c-eb3c-4dfd-80e9-b488de227036,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-ef77a02c-7083-432d-9fe5-cfaaaa171455,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-0e720e99-4912-4e93-b718-0fc10425cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-5906600f-fc47-44ff-a431-d1f96236be14,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-afefb60c-0d8a-414d-af09-315379bc49bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-6479b4f0-5305-489c-891d-37383cb2bdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137226380-172.17.0.11-1595593179648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-9507b3cc-5bf6-4542-9d6c-4bf4c19e0adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-11298a0b-abb4-4747-b94a-2064ca6a1892,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-2c6a8482-683f-4d59-9c41-7f664960a0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-5850a49a-91d7-4696-85f2-b04d41967622,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-92aae4d6-b2d1-4c93-9b6f-30306b1de9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-3483133c-76cd-4998-bb9e-dc12e2aaba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-63edb68d-188f-474e-9f58-ddf7604b3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-d0a5999c-d189-4193-9aa0-cf8b74601797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137226380-172.17.0.11-1595593179648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-9507b3cc-5bf6-4542-9d6c-4bf4c19e0adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-11298a0b-abb4-4747-b94a-2064ca6a1892,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-2c6a8482-683f-4d59-9c41-7f664960a0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-5850a49a-91d7-4696-85f2-b04d41967622,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-92aae4d6-b2d1-4c93-9b6f-30306b1de9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-3483133c-76cd-4998-bb9e-dc12e2aaba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-63edb68d-188f-474e-9f58-ddf7604b3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-d0a5999c-d189-4193-9aa0-cf8b74601797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056501799-172.17.0.11-1595593480860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41797,DS-59942a1d-23f2-4739-bc5e-189226b42838,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-b8aba0db-e59f-4dac-b0d3-90459d154d67,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-b7ed846f-837b-4f51-8e3c-ca43ea0382f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-370c2110-f283-4e57-b6fa-40c395245eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-ac4667ac-d29b-4ef7-93cb-a26c1c4787dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-1d6a3eb8-6553-43c6-ae78-c9b6b41776b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-7f5e58c0-f8c1-40d9-8881-64c210b82820,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-3382ecc2-7096-4733-bb5a-d9e02a25da64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056501799-172.17.0.11-1595593480860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41797,DS-59942a1d-23f2-4739-bc5e-189226b42838,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-b8aba0db-e59f-4dac-b0d3-90459d154d67,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-b7ed846f-837b-4f51-8e3c-ca43ea0382f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-370c2110-f283-4e57-b6fa-40c395245eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-ac4667ac-d29b-4ef7-93cb-a26c1c4787dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-1d6a3eb8-6553-43c6-ae78-c9b6b41776b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-7f5e58c0-f8c1-40d9-8881-64c210b82820,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-3382ecc2-7096-4733-bb5a-d9e02a25da64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248802552-172.17.0.11-1595594031273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39040,DS-a9572dd1-fa88-4f83-b375-a10f3ab42fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-1f790aad-aa57-44db-8697-0bfaa35a73ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-7eeafd8e-883c-4a3d-b2f2-c18f7b8dbc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-4c18d6ef-a9da-490d-8efa-e61ebf62deb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-1d67dbe6-0cf3-48e6-9db5-cd41f2d35713,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-34b1c327-ef5b-4740-9239-257f0f29f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-536a9a9c-9e35-4f6f-96d8-78b78a34c289,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-720caafb-f064-4b77-b15a-eeba881cfe6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248802552-172.17.0.11-1595594031273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39040,DS-a9572dd1-fa88-4f83-b375-a10f3ab42fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-1f790aad-aa57-44db-8697-0bfaa35a73ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-7eeafd8e-883c-4a3d-b2f2-c18f7b8dbc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-4c18d6ef-a9da-490d-8efa-e61ebf62deb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-1d67dbe6-0cf3-48e6-9db5-cd41f2d35713,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-34b1c327-ef5b-4740-9239-257f0f29f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-536a9a9c-9e35-4f6f-96d8-78b78a34c289,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-720caafb-f064-4b77-b15a-eeba881cfe6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048167956-172.17.0.11-1595594378668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-7fb650bc-7852-4444-9401-66e00130d416,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-818c93c9-80bc-4843-a37a-0ca0252654f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-5175cd57-130a-4383-9d0e-d59f88161f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-1c20713c-a59a-48e0-8991-a32da55f7b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-1f7336e4-ff0f-4672-ba4b-f7c8daa48731,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-e5ece154-5b85-4c7b-bec0-10a1dd1ee3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-3ac73e99-9f8b-48c3-9363-62e54b02a30f,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-c4c6a070-23af-4f49-b005-9f8e71e92e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048167956-172.17.0.11-1595594378668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-7fb650bc-7852-4444-9401-66e00130d416,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-818c93c9-80bc-4843-a37a-0ca0252654f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-5175cd57-130a-4383-9d0e-d59f88161f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-1c20713c-a59a-48e0-8991-a32da55f7b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-1f7336e4-ff0f-4672-ba4b-f7c8daa48731,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-e5ece154-5b85-4c7b-bec0-10a1dd1ee3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-3ac73e99-9f8b-48c3-9363-62e54b02a30f,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-c4c6a070-23af-4f49-b005-9f8e71e92e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568379549-172.17.0.11-1595594599882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-75380008-46d9-42db-987e-c32c5cc0985b,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-f2f165ae-5f3f-4963-922d-9ed27ef80c40,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-b077432e-af91-4135-aad6-d1c47fb34f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-ecab2e79-8dc3-4a5c-bc6b-a68afd964e42,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-c61be4a3-dc62-4acf-be14-02a93193c09a,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-3761f0ea-cc86-4198-b190-6051cfff9da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-aa22c066-9391-4444-8113-38c26050e80d,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-e54729b5-b322-415b-b76b-5d96b11fb84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568379549-172.17.0.11-1595594599882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-75380008-46d9-42db-987e-c32c5cc0985b,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-f2f165ae-5f3f-4963-922d-9ed27ef80c40,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-b077432e-af91-4135-aad6-d1c47fb34f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-ecab2e79-8dc3-4a5c-bc6b-a68afd964e42,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-c61be4a3-dc62-4acf-be14-02a93193c09a,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-3761f0ea-cc86-4198-b190-6051cfff9da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-aa22c066-9391-4444-8113-38c26050e80d,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-e54729b5-b322-415b-b76b-5d96b11fb84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445012843-172.17.0.11-1595595692439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-f0bb1401-2a21-4b2a-9ffa-92e075bdd931,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-cfcd52f0-4483-42c7-8af2-9224e996642b,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-2dec53cc-f126-4bc9-b2a6-202c4459dca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-46968523-72f9-4747-a4e6-b988f6104074,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-0937c623-332a-4fc0-aae9-a4b7331ea2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-1b37fd81-f855-4e83-ae14-e9df1694d4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ffab629a-2114-49be-a7aa-ddcf1349c398,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-7e3cb025-5a46-4f36-a290-be1ba5543f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445012843-172.17.0.11-1595595692439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-f0bb1401-2a21-4b2a-9ffa-92e075bdd931,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-cfcd52f0-4483-42c7-8af2-9224e996642b,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-2dec53cc-f126-4bc9-b2a6-202c4459dca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-46968523-72f9-4747-a4e6-b988f6104074,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-0937c623-332a-4fc0-aae9-a4b7331ea2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-1b37fd81-f855-4e83-ae14-e9df1694d4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ffab629a-2114-49be-a7aa-ddcf1349c398,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-7e3cb025-5a46-4f36-a290-be1ba5543f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6763
