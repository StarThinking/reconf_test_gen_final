reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887899709-172.17.0.21-1595615308411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-65d1e054-be9a-47f0-9914-b61c255d8549,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-7cca2498-ac08-4c82-9e7a-8502fe983514,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-f9a092d1-34e9-4c17-acc0-35d373cd6a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-82602112-a4a1-40b7-8706-a814dff79d63,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-a94ae962-827d-4df7-a1ff-99b116773085,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-0bec32dc-1211-4224-a2c9-d41e969960fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-cf7e873f-c746-47a1-97fa-03bfde13cbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-3a53247b-4cb3-48f3-b72f-33c499522566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887899709-172.17.0.21-1595615308411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-65d1e054-be9a-47f0-9914-b61c255d8549,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-7cca2498-ac08-4c82-9e7a-8502fe983514,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-f9a092d1-34e9-4c17-acc0-35d373cd6a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-82602112-a4a1-40b7-8706-a814dff79d63,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-a94ae962-827d-4df7-a1ff-99b116773085,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-0bec32dc-1211-4224-a2c9-d41e969960fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-cf7e873f-c746-47a1-97fa-03bfde13cbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-3a53247b-4cb3-48f3-b72f-33c499522566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873945733-172.17.0.21-1595615346125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38081,DS-51135889-1b78-4171-aba0-df2b88f893ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-5c53a27b-613f-4882-8457-833e9f037790,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-6b95014b-f647-4201-9033-1189274d65cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-7e363218-13c1-4e8b-b330-2ede64a6b0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-7a7e41b5-d64d-469a-a4dd-073b40d58248,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-2cf5a371-9173-44a9-aaad-f4b10684806f,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-2d4c1194-6694-4dbb-a558-2a2145b084b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-73ab168e-5ed4-4e2f-b656-37a31bc835fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873945733-172.17.0.21-1595615346125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38081,DS-51135889-1b78-4171-aba0-df2b88f893ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-5c53a27b-613f-4882-8457-833e9f037790,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-6b95014b-f647-4201-9033-1189274d65cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-7e363218-13c1-4e8b-b330-2ede64a6b0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-7a7e41b5-d64d-469a-a4dd-073b40d58248,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-2cf5a371-9173-44a9-aaad-f4b10684806f,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-2d4c1194-6694-4dbb-a558-2a2145b084b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-73ab168e-5ed4-4e2f-b656-37a31bc835fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223122105-172.17.0.21-1595615830548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-30e5397a-07c1-488c-b140-fdcee1d10355,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-9fc402ca-9cb9-4656-b902-41d6303c1246,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-b9506fc1-1cf5-4483-8158-03dfce4edf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-e60e7378-19f6-422d-a405-79c37b115dea,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-5f56083f-a2a8-4c37-a45f-110971262634,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-8b95c9fc-f1e7-49d3-b55e-ad5a6941cf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-46e6e1f1-46a1-42cd-bc99-cbdedf75bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-6f1fc7e9-b1ae-4512-98cb-129ca5474aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223122105-172.17.0.21-1595615830548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-30e5397a-07c1-488c-b140-fdcee1d10355,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-9fc402ca-9cb9-4656-b902-41d6303c1246,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-b9506fc1-1cf5-4483-8158-03dfce4edf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-e60e7378-19f6-422d-a405-79c37b115dea,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-5f56083f-a2a8-4c37-a45f-110971262634,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-8b95c9fc-f1e7-49d3-b55e-ad5a6941cf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-46e6e1f1-46a1-42cd-bc99-cbdedf75bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-6f1fc7e9-b1ae-4512-98cb-129ca5474aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542924814-172.17.0.21-1595616040755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38386,DS-7dbc9451-101a-4482-9621-f5751e4a334c,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-2e84b865-6691-4f08-be03-97a9ad12c958,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-4ef2a87c-40ab-4b0c-80f7-43151ad4c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-bec37a03-3450-42da-80e7-53219e18c1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-08fd2b38-85af-4570-bf7b-78760b749138,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-8f247f43-2786-461f-b00e-11039bffb484,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-51c2b872-77e5-4729-b140-3d1bf65f3834,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-a9ba218e-e9be-490d-8382-5ba1a8d584f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542924814-172.17.0.21-1595616040755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38386,DS-7dbc9451-101a-4482-9621-f5751e4a334c,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-2e84b865-6691-4f08-be03-97a9ad12c958,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-4ef2a87c-40ab-4b0c-80f7-43151ad4c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-bec37a03-3450-42da-80e7-53219e18c1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-08fd2b38-85af-4570-bf7b-78760b749138,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-8f247f43-2786-461f-b00e-11039bffb484,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-51c2b872-77e5-4729-b140-3d1bf65f3834,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-a9ba218e-e9be-490d-8382-5ba1a8d584f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781159289-172.17.0.21-1595616387995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33880,DS-2adf718e-b699-45e8-a892-6b7a87c8779b,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-3e3e0f51-5a53-4918-a76c-fb588d8f80c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-b43828eb-acbd-40d7-ad75-3b8d22816a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-6e3c9bed-c559-4121-8582-d6c4da79d811,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-c41adbfc-4759-4559-8fd0-92c29dac918d,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-066aa6fc-81d3-43a9-94f5-5279ec7cd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-4a60ae85-f6f8-412d-b155-c56dc9555b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-979943c3-3e81-4ad6-aca7-ea4c26df6350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781159289-172.17.0.21-1595616387995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33880,DS-2adf718e-b699-45e8-a892-6b7a87c8779b,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-3e3e0f51-5a53-4918-a76c-fb588d8f80c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-b43828eb-acbd-40d7-ad75-3b8d22816a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-6e3c9bed-c559-4121-8582-d6c4da79d811,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-c41adbfc-4759-4559-8fd0-92c29dac918d,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-066aa6fc-81d3-43a9-94f5-5279ec7cd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-4a60ae85-f6f8-412d-b155-c56dc9555b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-979943c3-3e81-4ad6-aca7-ea4c26df6350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502601214-172.17.0.21-1595616660417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-8b445dd8-bcb8-4a46-a1b2-fe4aaed2561f,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-ad2821aa-58f1-4057-87f1-fe135d2a00a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-0ff02299-cb40-46c0-b806-e95cd81d9784,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-e1d14647-dc58-4d98-b189-497f4737c08b,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-6c659490-6926-4425-8a3d-8977f898f413,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-446213d0-0178-451b-a635-e188ab41e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-890cf672-a127-4553-85ad-adae87bab229,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-f5882c91-3683-4cd5-b722-0478dad26039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502601214-172.17.0.21-1595616660417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-8b445dd8-bcb8-4a46-a1b2-fe4aaed2561f,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-ad2821aa-58f1-4057-87f1-fe135d2a00a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-0ff02299-cb40-46c0-b806-e95cd81d9784,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-e1d14647-dc58-4d98-b189-497f4737c08b,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-6c659490-6926-4425-8a3d-8977f898f413,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-446213d0-0178-451b-a635-e188ab41e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-890cf672-a127-4553-85ad-adae87bab229,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-f5882c91-3683-4cd5-b722-0478dad26039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761532298-172.17.0.21-1595616733484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-5adbccb5-133e-4c07-8e86-e8982816b8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-ddf219a9-50df-4cf8-b05e-add130cacf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-89c7045e-234b-4551-a33a-7f6378de11f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-57caf001-e090-4eba-b90b-81cd91330efe,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-93a24eb1-a8ef-45f8-85c8-042d06ab704b,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-58b7e637-e73d-40b5-9632-ff950229502c,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-f982351c-5bea-4b87-b688-b22908da4856,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-2b0d04ea-9d51-4e26-9c7e-eb487d0cba6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761532298-172.17.0.21-1595616733484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-5adbccb5-133e-4c07-8e86-e8982816b8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-ddf219a9-50df-4cf8-b05e-add130cacf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-89c7045e-234b-4551-a33a-7f6378de11f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-57caf001-e090-4eba-b90b-81cd91330efe,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-93a24eb1-a8ef-45f8-85c8-042d06ab704b,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-58b7e637-e73d-40b5-9632-ff950229502c,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-f982351c-5bea-4b87-b688-b22908da4856,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-2b0d04ea-9d51-4e26-9c7e-eb487d0cba6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953587994-172.17.0.21-1595616763967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-39b438ef-8b09-4d4d-b667-4c8beaa8e6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-b9b56673-155c-414f-8450-e309ee10a565,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-2e725790-3f25-403a-91f0-2cf2cc21fda5,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-44f77f74-bd5a-4418-bc91-229416260996,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-e9262e35-9bba-459f-91ac-68f421d0e3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-e4a22b1b-6dde-4bd9-b9c4-c03268be6d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-0c3340fd-c11e-495b-adad-a5327b4c61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-dcf912c2-76db-488f-a820-c3fc4e4c9777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953587994-172.17.0.21-1595616763967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-39b438ef-8b09-4d4d-b667-4c8beaa8e6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-b9b56673-155c-414f-8450-e309ee10a565,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-2e725790-3f25-403a-91f0-2cf2cc21fda5,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-44f77f74-bd5a-4418-bc91-229416260996,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-e9262e35-9bba-459f-91ac-68f421d0e3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-e4a22b1b-6dde-4bd9-b9c4-c03268be6d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-0c3340fd-c11e-495b-adad-a5327b4c61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-dcf912c2-76db-488f-a820-c3fc4e4c9777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459043214-172.17.0.21-1595617295539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-fde5d595-8d48-40ab-bc24-c5dec82a9a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-82221f7e-d6e6-4708-ba30-6f884539dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-f947a732-4aec-488b-9986-2d4604159fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-de792453-8d5a-4013-9cbc-e82e357e01f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-cd1dfca2-e68f-4f0a-b7be-023ecb41ff97,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-dbde726d-6562-46cb-a50c-0866b15df619,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-ba8b9364-94f5-4234-aa47-3df1116261f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-61e32839-dbf3-4573-aa06-5a2c4c3925ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459043214-172.17.0.21-1595617295539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-fde5d595-8d48-40ab-bc24-c5dec82a9a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-82221f7e-d6e6-4708-ba30-6f884539dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-f947a732-4aec-488b-9986-2d4604159fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-de792453-8d5a-4013-9cbc-e82e357e01f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-cd1dfca2-e68f-4f0a-b7be-023ecb41ff97,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-dbde726d-6562-46cb-a50c-0866b15df619,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-ba8b9364-94f5-4234-aa47-3df1116261f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-61e32839-dbf3-4573-aa06-5a2c4c3925ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940521857-172.17.0.21-1595617488355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-3ce5e5cb-f297-479b-abd5-4b2674280ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-30a03415-abcb-43ef-b5d3-f38ac8955a50,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-5c0b9df0-9ea4-4ec0-9765-a7e13476d598,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-b570374d-b64b-43d8-886e-2587ad5c3a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-b229abfb-9301-4472-b819-825263bf2133,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-95dcce4c-2cfb-49f5-952f-f6e7f9dd7a17,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-5c370612-7562-4b91-a063-2d4eda821006,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-53397a0e-c0e4-4e2f-8d51-3a7ec485c4a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940521857-172.17.0.21-1595617488355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-3ce5e5cb-f297-479b-abd5-4b2674280ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-30a03415-abcb-43ef-b5d3-f38ac8955a50,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-5c0b9df0-9ea4-4ec0-9765-a7e13476d598,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-b570374d-b64b-43d8-886e-2587ad5c3a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-b229abfb-9301-4472-b819-825263bf2133,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-95dcce4c-2cfb-49f5-952f-f6e7f9dd7a17,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-5c370612-7562-4b91-a063-2d4eda821006,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-53397a0e-c0e4-4e2f-8d51-3a7ec485c4a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940767389-172.17.0.21-1595617548616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-97388328-3482-45af-8e0f-c8dde0f03feb,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-6f65c394-bd14-4b93-9199-bc1b855a024a,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-e4468da1-7bef-49c0-b737-8db3d249abc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-b42c2fd3-c02f-43bb-8cbb-3c78ec14f5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-4c79190d-8477-460a-a0be-f9971e2efdba,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-2319dac2-e365-4bc0-9c1d-6d6b83f37e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-451bd6ad-fae7-429d-9942-5ee6d7b01238,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-2b35de01-154a-47e2-a94e-98875d09ef5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940767389-172.17.0.21-1595617548616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-97388328-3482-45af-8e0f-c8dde0f03feb,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-6f65c394-bd14-4b93-9199-bc1b855a024a,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-e4468da1-7bef-49c0-b737-8db3d249abc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-b42c2fd3-c02f-43bb-8cbb-3c78ec14f5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-4c79190d-8477-460a-a0be-f9971e2efdba,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-2319dac2-e365-4bc0-9c1d-6d6b83f37e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-451bd6ad-fae7-429d-9942-5ee6d7b01238,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-2b35de01-154a-47e2-a94e-98875d09ef5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912056590-172.17.0.21-1595617626826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-bd062383-cbbf-46ec-a695-4135763cbf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-4bac97f8-8b48-4a5f-8aff-c5fe05194a87,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-9bd7310c-dc2e-4b7e-9987-890cb319f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-74560bac-5bb9-43aa-a53a-fc24b7d03cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-1578f751-90f4-42b7-9b21-b97bacee47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-8e5ac029-b7cb-4343-8b23-300b4c94fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-89e238cf-ddc8-4107-a9c0-f4cfaf4c1a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-51c9ade1-ffd2-41de-969e-b70bbf93832f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912056590-172.17.0.21-1595617626826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-bd062383-cbbf-46ec-a695-4135763cbf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-4bac97f8-8b48-4a5f-8aff-c5fe05194a87,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-9bd7310c-dc2e-4b7e-9987-890cb319f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-74560bac-5bb9-43aa-a53a-fc24b7d03cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-1578f751-90f4-42b7-9b21-b97bacee47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-8e5ac029-b7cb-4343-8b23-300b4c94fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-89e238cf-ddc8-4107-a9c0-f4cfaf4c1a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-51c9ade1-ffd2-41de-969e-b70bbf93832f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750573808-172.17.0.21-1595618162235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-dd819cdc-2017-488c-ba23-7109c0484866,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-39736a5b-4000-4396-9435-fd98c4ac12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-0ff549eb-b68e-4e9b-9b4e-e22fb360b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-f0123f54-3da7-428d-b4fc-b5ac587d25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-c65f5fa3-34dc-45dc-aa6f-ab670b90e1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-aa498bb5-739e-43e6-8591-96e9ecc7fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-7f504c85-dad4-4ff7-a019-777bb9c6763c,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-c9722ac6-0a88-4228-88a2-f0d2ee19fa5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750573808-172.17.0.21-1595618162235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-dd819cdc-2017-488c-ba23-7109c0484866,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-39736a5b-4000-4396-9435-fd98c4ac12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-0ff549eb-b68e-4e9b-9b4e-e22fb360b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-f0123f54-3da7-428d-b4fc-b5ac587d25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-c65f5fa3-34dc-45dc-aa6f-ab670b90e1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-aa498bb5-739e-43e6-8591-96e9ecc7fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-7f504c85-dad4-4ff7-a019-777bb9c6763c,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-c9722ac6-0a88-4228-88a2-f0d2ee19fa5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538092393-172.17.0.21-1595618617792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38868,DS-44664430-e31f-44f7-865f-48c840492a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-1caa104a-3cc8-44f8-bdf4-544f06f61f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-1b26c6ef-2bd6-40a5-8260-d225466c8f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-6f170889-68ce-4c0d-84bc-8f2eb38dff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-e30a9272-a969-4ab9-8921-77d8f52a181a,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-baa5e87c-7bad-4f43-a82c-c7dc89bdb8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-d1358f9f-26fb-4b52-b130-fb58acd1fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-b693e5b2-d18e-4920-9e9d-82c539ba0d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538092393-172.17.0.21-1595618617792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38868,DS-44664430-e31f-44f7-865f-48c840492a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-1caa104a-3cc8-44f8-bdf4-544f06f61f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-1b26c6ef-2bd6-40a5-8260-d225466c8f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-6f170889-68ce-4c0d-84bc-8f2eb38dff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-e30a9272-a969-4ab9-8921-77d8f52a181a,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-baa5e87c-7bad-4f43-a82c-c7dc89bdb8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-d1358f9f-26fb-4b52-b130-fb58acd1fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-b693e5b2-d18e-4920-9e9d-82c539ba0d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511225822-172.17.0.21-1595618650262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40460,DS-abea7d0e-9e1b-498f-b298-b8095e51aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-aa03964f-7c5c-497e-9c2b-8f35b8bb532d,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-ded17300-bb7b-458e-9e88-ee6241bbd400,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-27892705-732e-46cf-84ff-4ded0c3c9ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-6f3ec5bc-1d2f-481a-a2cc-962fc94835b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-3b133a59-5c2c-48c8-9b2a-2250bbd776b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-1a987263-19c9-4e03-b1b7-db1fb1c2af54,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-78a84484-30dd-4b49-b1a6-a5b16d0f8139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511225822-172.17.0.21-1595618650262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40460,DS-abea7d0e-9e1b-498f-b298-b8095e51aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-aa03964f-7c5c-497e-9c2b-8f35b8bb532d,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-ded17300-bb7b-458e-9e88-ee6241bbd400,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-27892705-732e-46cf-84ff-4ded0c3c9ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-6f3ec5bc-1d2f-481a-a2cc-962fc94835b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-3b133a59-5c2c-48c8-9b2a-2250bbd776b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-1a987263-19c9-4e03-b1b7-db1fb1c2af54,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-78a84484-30dd-4b49-b1a6-a5b16d0f8139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201603119-172.17.0.21-1595618723790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-885a21c5-a0c5-42e7-ba61-5c5c5eb0a5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-88ac4bb8-4d80-49d2-9a36-e3cfcad55442,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-1b7762cf-f745-4eb7-89b9-9a4b55036000,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-6e1dd647-7cde-4a2f-95e8-b9c54ad622c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-9a6eed0c-d2ff-48be-aeaa-3533906140ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-0ff2df9e-899f-4698-abf9-e26f1d7d32f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-c9556d08-bb7d-4ed1-a5a0-6db2a2902ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-66cdcf7b-f6d6-4f59-ba62-e37b3fe33227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201603119-172.17.0.21-1595618723790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-885a21c5-a0c5-42e7-ba61-5c5c5eb0a5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-88ac4bb8-4d80-49d2-9a36-e3cfcad55442,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-1b7762cf-f745-4eb7-89b9-9a4b55036000,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-6e1dd647-7cde-4a2f-95e8-b9c54ad622c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-9a6eed0c-d2ff-48be-aeaa-3533906140ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-0ff2df9e-899f-4698-abf9-e26f1d7d32f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-c9556d08-bb7d-4ed1-a5a0-6db2a2902ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-66cdcf7b-f6d6-4f59-ba62-e37b3fe33227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461228295-172.17.0.21-1595618893177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33146,DS-1de6d264-9eab-40bf-b443-198cd7d5acf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-c38e4b72-7eb2-4215-9dc2-622c1935c31d,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-0c81eb82-1282-47a7-b90c-ea9275d345fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-3228cfd8-f3d2-4a34-ad1d-c797ad7c1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-3d3d2aa2-6833-43bf-bdec-9ce51f8bb3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-6fe5fa42-51f6-45f6-9d85-751c90af555a,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-20e7ef78-f005-43f8-beab-a91b06fb753e,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-b08c73f5-b899-44f9-8835-a117658dc974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461228295-172.17.0.21-1595618893177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33146,DS-1de6d264-9eab-40bf-b443-198cd7d5acf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-c38e4b72-7eb2-4215-9dc2-622c1935c31d,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-0c81eb82-1282-47a7-b90c-ea9275d345fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-3228cfd8-f3d2-4a34-ad1d-c797ad7c1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-3d3d2aa2-6833-43bf-bdec-9ce51f8bb3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-6fe5fa42-51f6-45f6-9d85-751c90af555a,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-20e7ef78-f005-43f8-beab-a91b06fb753e,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-b08c73f5-b899-44f9-8835-a117658dc974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146566248-172.17.0.21-1595619277225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40404,DS-b54a56da-8fd0-4658-9786-28a96b765b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-b2362461-50bd-4b11-8e71-c0d0cab8e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-5094e771-ee32-472e-a98e-b3bc51bf9249,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-0f785481-c696-4b5b-b27e-c36964eeaea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-281a2f2f-6a0f-478d-a04c-4166e10e8513,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-cf11e86e-fd9c-4b99-a281-e61377625664,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-18bd1dcd-d040-4689-9473-dbd44485db55,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-c6336afa-ca74-46f2-a336-01e26dc39b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146566248-172.17.0.21-1595619277225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40404,DS-b54a56da-8fd0-4658-9786-28a96b765b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-b2362461-50bd-4b11-8e71-c0d0cab8e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-5094e771-ee32-472e-a98e-b3bc51bf9249,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-0f785481-c696-4b5b-b27e-c36964eeaea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-281a2f2f-6a0f-478d-a04c-4166e10e8513,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-cf11e86e-fd9c-4b99-a281-e61377625664,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-18bd1dcd-d040-4689-9473-dbd44485db55,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-c6336afa-ca74-46f2-a336-01e26dc39b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220536543-172.17.0.21-1595619915402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-235b372f-76df-40f1-897b-da128a870ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-bdf3e211-2b43-48e0-88fd-0e8168d3f870,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-d7be9c1c-3910-413b-af93-4b851ddb65a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-c1ce76bc-390e-43c0-a68c-c19606dad671,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-bfdd4a51-6393-4a3e-ad55-f6d64c42c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-ca975857-2d4a-4484-acc6-c73c193fa6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-e500a25a-2117-447b-878f-d34a1122b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-e3960346-a22d-42aa-9983-ffa67f00aa12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220536543-172.17.0.21-1595619915402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-235b372f-76df-40f1-897b-da128a870ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-bdf3e211-2b43-48e0-88fd-0e8168d3f870,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-d7be9c1c-3910-413b-af93-4b851ddb65a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-c1ce76bc-390e-43c0-a68c-c19606dad671,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-bfdd4a51-6393-4a3e-ad55-f6d64c42c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-ca975857-2d4a-4484-acc6-c73c193fa6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-e500a25a-2117-447b-878f-d34a1122b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-e3960346-a22d-42aa-9983-ffa67f00aa12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5481
