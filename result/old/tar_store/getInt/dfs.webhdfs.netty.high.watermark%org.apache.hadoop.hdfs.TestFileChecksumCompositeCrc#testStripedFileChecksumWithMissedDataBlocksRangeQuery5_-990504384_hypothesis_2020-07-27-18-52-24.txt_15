reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676083664-172.17.0.6-1595875993949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37294,DS-729a936c-3fcf-41de-90a6-e95a25c17e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-8ff55634-80ab-49a8-845d-ba647230b8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-0e9abd66-6f74-4c52-812f-92e471fed38c,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-ed624873-c590-4e61-9a82-173834dd1296,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-5694677d-ee1f-4d72-9c0c-283ed3b1e8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-2e927398-ea1f-4079-8747-07bd3090c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-30517294-fb07-420c-9af2-a51338dc26d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-fa535bac-eefc-4c1b-b277-b56befdc61b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676083664-172.17.0.6-1595875993949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37294,DS-729a936c-3fcf-41de-90a6-e95a25c17e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-8ff55634-80ab-49a8-845d-ba647230b8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-0e9abd66-6f74-4c52-812f-92e471fed38c,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-ed624873-c590-4e61-9a82-173834dd1296,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-5694677d-ee1f-4d72-9c0c-283ed3b1e8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-2e927398-ea1f-4079-8747-07bd3090c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-30517294-fb07-420c-9af2-a51338dc26d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-fa535bac-eefc-4c1b-b277-b56befdc61b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071251115-172.17.0.6-1595876226594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-2c8e0100-3438-407a-8391-4ae58e7ec910,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-81d42a89-fe53-4845-8600-b18a36addb93,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-c4a4084b-1304-462d-89ee-ba62c722feec,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-abe73d87-74ef-4d12-971f-becc10801ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-98a0f48d-d2d1-4ebf-bcb7-200f68b937cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-57ffc4d1-443d-4e92-bc5a-abc16d95e6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-f6068f48-0b93-4740-aac9-97db93318517,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-80a35c56-5594-48bb-a269-8186500dac67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071251115-172.17.0.6-1595876226594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-2c8e0100-3438-407a-8391-4ae58e7ec910,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-81d42a89-fe53-4845-8600-b18a36addb93,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-c4a4084b-1304-462d-89ee-ba62c722feec,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-abe73d87-74ef-4d12-971f-becc10801ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-98a0f48d-d2d1-4ebf-bcb7-200f68b937cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-57ffc4d1-443d-4e92-bc5a-abc16d95e6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-f6068f48-0b93-4740-aac9-97db93318517,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-80a35c56-5594-48bb-a269-8186500dac67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223368587-172.17.0.6-1595876268304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34662,DS-f5c173e7-f653-442c-bb09-4d89f232a876,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-d5d2c37d-ab3e-4671-9787-33542a31a809,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-48438b78-0814-44c0-8445-c0827c71cb88,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-ab79a95a-d1b4-455b-9215-98385cde2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-7c41aa11-fb40-4806-b0f4-1500cca2d458,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-ab9c979d-02e8-4420-aa71-2482b30eb003,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-47488a9b-f3dd-418b-994d-1cac4194fdef,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-a8a664b2-2d75-4fd9-9b04-367d19554df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223368587-172.17.0.6-1595876268304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34662,DS-f5c173e7-f653-442c-bb09-4d89f232a876,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-d5d2c37d-ab3e-4671-9787-33542a31a809,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-48438b78-0814-44c0-8445-c0827c71cb88,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-ab79a95a-d1b4-455b-9215-98385cde2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-7c41aa11-fb40-4806-b0f4-1500cca2d458,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-ab9c979d-02e8-4420-aa71-2482b30eb003,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-47488a9b-f3dd-418b-994d-1cac4194fdef,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-a8a664b2-2d75-4fd9-9b04-367d19554df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566247229-172.17.0.6-1595876420099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39976,DS-da573023-a427-49d0-8dbb-b115aeb17f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-b340d81b-4415-4956-b1f2-68b584b8db24,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-042070b1-080f-4542-9dd0-e7d7bd47055a,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-64aeb583-6303-4f7e-9eb5-f5482ab38fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-d0555428-3d8c-4d5b-be4f-d4bbcf524037,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-4229ae14-80da-4cb4-8fd6-efd932d16950,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-8f693b06-ab49-43fc-9910-820124fc1e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-80c224bb-e152-4943-a60f-bd5ec03840de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566247229-172.17.0.6-1595876420099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39976,DS-da573023-a427-49d0-8dbb-b115aeb17f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-b340d81b-4415-4956-b1f2-68b584b8db24,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-042070b1-080f-4542-9dd0-e7d7bd47055a,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-64aeb583-6303-4f7e-9eb5-f5482ab38fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-d0555428-3d8c-4d5b-be4f-d4bbcf524037,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-4229ae14-80da-4cb4-8fd6-efd932d16950,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-8f693b06-ab49-43fc-9910-820124fc1e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-80c224bb-e152-4943-a60f-bd5ec03840de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295242790-172.17.0.6-1595876652629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-562ed267-5551-4cc1-a9ac-ffdda1200a85,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-d4e6a3d9-1cf0-4835-acb8-706430e7bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-e93dc26f-fabf-4a2c-af5e-9d20f2937cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-13296023-86d6-4978-9365-10b3334c1ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-35490b16-7516-42a0-a98a-1c249af6431b,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-c6baf6b7-8175-4942-99e6-fe718ea52221,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-e5f9c4c4-f653-4925-84cd-46d93a45bcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-1ef62ec0-d0b8-44ce-97ee-5dcb82c5fdde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295242790-172.17.0.6-1595876652629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-562ed267-5551-4cc1-a9ac-ffdda1200a85,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-d4e6a3d9-1cf0-4835-acb8-706430e7bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-e93dc26f-fabf-4a2c-af5e-9d20f2937cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-13296023-86d6-4978-9365-10b3334c1ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-35490b16-7516-42a0-a98a-1c249af6431b,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-c6baf6b7-8175-4942-99e6-fe718ea52221,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-e5f9c4c4-f653-4925-84cd-46d93a45bcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-1ef62ec0-d0b8-44ce-97ee-5dcb82c5fdde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413233211-172.17.0.6-1595877064966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-3f32b4b3-9584-4766-b5c8-f7c7e72df2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-7bc4ea02-465b-40b1-a6b1-00463aadde36,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-1ccd9229-ce25-4fed-8a17-165e95e6677b,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-1b534c63-72ba-4e0d-8156-2bc19d6fd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-4890fa6f-a19a-4a24-8645-7ad7bc5063d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-27e30e55-176b-41fc-abff-34875dc0c917,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-589477e4-ff2d-49ef-b73c-e8c070c6f729,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-af908323-9729-49c0-a645-d03c3b45dc0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413233211-172.17.0.6-1595877064966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-3f32b4b3-9584-4766-b5c8-f7c7e72df2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-7bc4ea02-465b-40b1-a6b1-00463aadde36,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-1ccd9229-ce25-4fed-8a17-165e95e6677b,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-1b534c63-72ba-4e0d-8156-2bc19d6fd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-4890fa6f-a19a-4a24-8645-7ad7bc5063d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-27e30e55-176b-41fc-abff-34875dc0c917,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-589477e4-ff2d-49ef-b73c-e8c070c6f729,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-af908323-9729-49c0-a645-d03c3b45dc0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587576104-172.17.0.6-1595877285189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-7c2d7715-9bd8-48e8-95e7-b01748c5a949,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-01d5888b-8d79-4f07-abc3-11d0a9aa687a,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-c2c4768f-b8a5-456b-8d68-393786e4ec89,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-d236f460-8e1f-4c9a-a390-864211102572,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-736147c4-f9a4-40ef-9dfc-d1a4da64d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-e4a070f7-d006-4dc0-92c6-b769227c483d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-3f94ed7d-3ca8-4bf1-a1ab-7ece685fd3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-441022dc-c254-4a83-bed1-efe0f6f2e8e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587576104-172.17.0.6-1595877285189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-7c2d7715-9bd8-48e8-95e7-b01748c5a949,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-01d5888b-8d79-4f07-abc3-11d0a9aa687a,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-c2c4768f-b8a5-456b-8d68-393786e4ec89,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-d236f460-8e1f-4c9a-a390-864211102572,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-736147c4-f9a4-40ef-9dfc-d1a4da64d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-e4a070f7-d006-4dc0-92c6-b769227c483d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-3f94ed7d-3ca8-4bf1-a1ab-7ece685fd3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-441022dc-c254-4a83-bed1-efe0f6f2e8e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138386898-172.17.0.6-1595877920243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-e847482c-ae0a-471b-820f-fd23aa1d129f,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-456e519c-1f8f-4ca0-a4ee-5ee12e02afd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-aec54f36-308a-4361-b181-31814335428d,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-8ef70160-1acb-4ed3-9665-d6185a0822ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-e02b2dd1-a52f-4e61-91df-f42dc1e0c467,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-d0d40f1f-a831-4bb2-917e-e752dcd14e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-7e4e0687-ffaa-49ee-8fa2-13ae6ccafe64,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-bd779fe7-ae89-4a81-a3c4-0ffd61ffa339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138386898-172.17.0.6-1595877920243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-e847482c-ae0a-471b-820f-fd23aa1d129f,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-456e519c-1f8f-4ca0-a4ee-5ee12e02afd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-aec54f36-308a-4361-b181-31814335428d,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-8ef70160-1acb-4ed3-9665-d6185a0822ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-e02b2dd1-a52f-4e61-91df-f42dc1e0c467,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-d0d40f1f-a831-4bb2-917e-e752dcd14e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-7e4e0687-ffaa-49ee-8fa2-13ae6ccafe64,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-bd779fe7-ae89-4a81-a3c4-0ffd61ffa339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924049787-172.17.0.6-1595878149493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-80107bbc-acf7-4972-b68e-09ca65d92d71,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-ec30d383-84ba-4672-8973-88f73e3172d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-4879f83f-ae05-4e15-bd17-053dad1b25d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-26dc9630-1e82-4f71-8c49-b9d84fa286b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-ad5eeca2-c1e2-4a56-ae5c-2a6f5074fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-37ebe204-cd4a-4b76-8f80-365f01494966,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-32d3ad1a-13a1-42f7-af82-327c551c887f,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-44d4488d-75ff-4c88-b3d6-9f8225903009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924049787-172.17.0.6-1595878149493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-80107bbc-acf7-4972-b68e-09ca65d92d71,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-ec30d383-84ba-4672-8973-88f73e3172d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-4879f83f-ae05-4e15-bd17-053dad1b25d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-26dc9630-1e82-4f71-8c49-b9d84fa286b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-ad5eeca2-c1e2-4a56-ae5c-2a6f5074fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-37ebe204-cd4a-4b76-8f80-365f01494966,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-32d3ad1a-13a1-42f7-af82-327c551c887f,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-44d4488d-75ff-4c88-b3d6-9f8225903009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702057657-172.17.0.6-1595878935043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35999,DS-2ec93f97-96ed-4ac1-998a-cd5c9384f217,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-d45427b4-f2c9-47aa-87a2-59057ef778dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-9a1daa19-4e82-4f98-a6ed-f1667520fb18,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-80e7eb6c-cfa3-4a9b-8ec2-5b2b78226f30,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-c558b2b2-a1b0-46c6-aca3-a2d8c066b0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-6c1c45b3-f181-4541-9935-d890a29425da,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-04d1e0b1-e11a-4d5d-ada9-5a976a2c1dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-da415399-0afb-41a5-b1dd-d99e1f03e3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702057657-172.17.0.6-1595878935043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35999,DS-2ec93f97-96ed-4ac1-998a-cd5c9384f217,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-d45427b4-f2c9-47aa-87a2-59057ef778dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-9a1daa19-4e82-4f98-a6ed-f1667520fb18,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-80e7eb6c-cfa3-4a9b-8ec2-5b2b78226f30,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-c558b2b2-a1b0-46c6-aca3-a2d8c066b0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-6c1c45b3-f181-4541-9935-d890a29425da,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-04d1e0b1-e11a-4d5d-ada9-5a976a2c1dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-da415399-0afb-41a5-b1dd-d99e1f03e3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887109211-172.17.0.6-1595879062455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45586,DS-ae97f1b2-3974-4856-a893-1a89afb53398,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-700ec8a3-075c-4a90-9341-8dcb8bdc469c,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-c11b08b0-8904-4edf-be15-033a26304ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-1b0d473c-be26-4271-9f0c-bb76f574e590,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-c07d7da5-5cba-444e-8f6b-78fa97c904bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-c81a29db-98df-43ed-abbe-678c5580fbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-3a588d5b-b971-4f0c-9878-6ceb961252c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-9a763816-6f6f-46e6-be52-bc76b3fb55fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887109211-172.17.0.6-1595879062455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45586,DS-ae97f1b2-3974-4856-a893-1a89afb53398,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-700ec8a3-075c-4a90-9341-8dcb8bdc469c,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-c11b08b0-8904-4edf-be15-033a26304ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-1b0d473c-be26-4271-9f0c-bb76f574e590,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-c07d7da5-5cba-444e-8f6b-78fa97c904bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-c81a29db-98df-43ed-abbe-678c5580fbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-3a588d5b-b971-4f0c-9878-6ceb961252c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-9a763816-6f6f-46e6-be52-bc76b3fb55fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575963421-172.17.0.6-1595879318142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45958,DS-d27e286d-71af-4ceb-ae1d-5feab8290564,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-1d8cebc0-5249-4727-9989-d8a3352c61ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-cc8d35dd-03b3-4266-9857-8464bcfdf154,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-8aff6aa0-6e71-42ab-93ec-eb67348070c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-c4bdbad8-67aa-4c6a-9379-86e2dda44a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-1dd8d56e-de93-422d-8c8f-d223c5a59c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-f453ac76-19ac-44f6-8243-fdf3020b5fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-2309a141-50d2-4ca7-8552-e46de9627851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575963421-172.17.0.6-1595879318142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45958,DS-d27e286d-71af-4ceb-ae1d-5feab8290564,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-1d8cebc0-5249-4727-9989-d8a3352c61ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-cc8d35dd-03b3-4266-9857-8464bcfdf154,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-8aff6aa0-6e71-42ab-93ec-eb67348070c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-c4bdbad8-67aa-4c6a-9379-86e2dda44a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-1dd8d56e-de93-422d-8c8f-d223c5a59c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-f453ac76-19ac-44f6-8243-fdf3020b5fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-2309a141-50d2-4ca7-8552-e46de9627851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058231593-172.17.0.6-1595879354220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-67378087-5e51-42a2-bd31-b6fb5f6751de,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-f5bc3fd5-49f5-445c-8505-0fc823f22658,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-b562c5a3-18e3-40a4-82e8-6a4e8a174363,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-320a170a-9820-4341-abfb-b5e7320c7e64,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-e6dc0dbf-b469-4f1c-adf2-f5568f383b25,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-ca7e8187-fdaa-42b8-8a6b-c8ba20916a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-4578cdd2-f248-490e-8c1e-862ea8e1eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-4375be57-fd83-4c2e-ba7d-54a228374cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058231593-172.17.0.6-1595879354220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-67378087-5e51-42a2-bd31-b6fb5f6751de,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-f5bc3fd5-49f5-445c-8505-0fc823f22658,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-b562c5a3-18e3-40a4-82e8-6a4e8a174363,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-320a170a-9820-4341-abfb-b5e7320c7e64,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-e6dc0dbf-b469-4f1c-adf2-f5568f383b25,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-ca7e8187-fdaa-42b8-8a6b-c8ba20916a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-4578cdd2-f248-490e-8c1e-862ea8e1eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-4375be57-fd83-4c2e-ba7d-54a228374cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458989409-172.17.0.6-1595879588510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41071,DS-55a6310f-6369-4e7a-90c1-53f5ca996a86,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-35dfcfe5-1d3e-445a-9c71-5b47c8f7cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-93c1db05-4d4a-4405-b6bb-67d962d1cb94,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7f379514-7402-4a53-b584-b8a6395443ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-590c506c-f290-4a25-ae6a-4221eb7c976a,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-423338fc-b851-478a-b658-ac7a7e3a4a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-caa77bb5-2974-44ef-9653-22fbe5243821,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-e0796218-f0d2-40f3-a2af-1d626d8a021e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458989409-172.17.0.6-1595879588510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41071,DS-55a6310f-6369-4e7a-90c1-53f5ca996a86,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-35dfcfe5-1d3e-445a-9c71-5b47c8f7cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-93c1db05-4d4a-4405-b6bb-67d962d1cb94,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7f379514-7402-4a53-b584-b8a6395443ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-590c506c-f290-4a25-ae6a-4221eb7c976a,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-423338fc-b851-478a-b658-ac7a7e3a4a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-caa77bb5-2974-44ef-9653-22fbe5243821,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-e0796218-f0d2-40f3-a2af-1d626d8a021e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003468730-172.17.0.6-1595880608743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38517,DS-7b930e8a-0bc0-4c74-98f0-f16dc06ed4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-620be5d8-9b3e-4f51-8840-923a8149a067,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-0c9d71e0-6e06-4ae8-82c6-ad491cb38165,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-20b923b2-f680-4abc-a3ac-18b1af22309f,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-c996b63f-5052-4a0a-9860-2ae3952ec81a,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-8fff927f-d8c0-4c48-8b79-d8b5426f87dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-d09da262-adf9-49e8-9e50-70d983a02ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-5c0276a4-7bb4-4b63-abb4-7d3d45038600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003468730-172.17.0.6-1595880608743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38517,DS-7b930e8a-0bc0-4c74-98f0-f16dc06ed4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-620be5d8-9b3e-4f51-8840-923a8149a067,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-0c9d71e0-6e06-4ae8-82c6-ad491cb38165,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-20b923b2-f680-4abc-a3ac-18b1af22309f,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-c996b63f-5052-4a0a-9860-2ae3952ec81a,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-8fff927f-d8c0-4c48-8b79-d8b5426f87dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-d09da262-adf9-49e8-9e50-70d983a02ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-5c0276a4-7bb4-4b63-abb4-7d3d45038600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663412954-172.17.0.6-1595880681541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-8e661779-9c9e-485d-a47b-f30a891a3fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-cadd215e-605b-425a-8f60-80a6efd57537,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-d0534e57-9f5a-4a5e-b0f5-40aab1b1300f,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-55dc0f82-09d7-41be-b2ca-2d6feb77e583,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-91fb1540-fad3-4bba-9a5d-07d2288e7162,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-71951d51-4435-436b-9b6f-3fc684ae2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-0475b7a8-0659-43c0-98f5-32430feb8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-ef29262b-c5fd-4d0b-945a-ff3c6c2023c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663412954-172.17.0.6-1595880681541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-8e661779-9c9e-485d-a47b-f30a891a3fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-cadd215e-605b-425a-8f60-80a6efd57537,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-d0534e57-9f5a-4a5e-b0f5-40aab1b1300f,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-55dc0f82-09d7-41be-b2ca-2d6feb77e583,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-91fb1540-fad3-4bba-9a5d-07d2288e7162,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-71951d51-4435-436b-9b6f-3fc684ae2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-0475b7a8-0659-43c0-98f5-32430feb8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-ef29262b-c5fd-4d0b-945a-ff3c6c2023c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619815034-172.17.0.6-1595881178941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-32d0d5ca-243a-4095-99c9-bcaa86bb99e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-e404ce84-1f01-45c2-970d-be45be7dca4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-c67e4d42-4179-4c7a-801b-4db96cb331db,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-e845e830-f5ff-4b16-9783-6d7abd6bbd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-a41f331e-5ece-4696-a14a-645b2d8016c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-14d3d2e8-47ea-4915-b90b-27b968904b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-ba55fca7-6a6c-43b7-8f09-076b5e3dac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-a7cf6026-2a96-475e-a44c-b0400fdfc1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619815034-172.17.0.6-1595881178941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-32d0d5ca-243a-4095-99c9-bcaa86bb99e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-e404ce84-1f01-45c2-970d-be45be7dca4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-c67e4d42-4179-4c7a-801b-4db96cb331db,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-e845e830-f5ff-4b16-9783-6d7abd6bbd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-a41f331e-5ece-4696-a14a-645b2d8016c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-14d3d2e8-47ea-4915-b90b-27b968904b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-ba55fca7-6a6c-43b7-8f09-076b5e3dac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-a7cf6026-2a96-475e-a44c-b0400fdfc1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251991797-172.17.0.6-1595881645236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-ef60e802-cd5e-4549-9fe1-5976bb29a1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-aac3a9df-69a9-47e5-8682-9ff303903b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-36211343-b817-4660-93be-62fed8721b94,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-dd441be7-e330-474e-9dbc-48c185bcaac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-6219cb47-6cd2-4526-a45d-ab6d64affa28,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-4cebc873-2e35-4c07-9d86-d2e74999b017,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-078d648b-f752-4c91-86a2-27333d832d75,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-9276179b-0a04-44f9-b4c1-caf0b05ab0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251991797-172.17.0.6-1595881645236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-ef60e802-cd5e-4549-9fe1-5976bb29a1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-aac3a9df-69a9-47e5-8682-9ff303903b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-36211343-b817-4660-93be-62fed8721b94,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-dd441be7-e330-474e-9dbc-48c185bcaac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-6219cb47-6cd2-4526-a45d-ab6d64affa28,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-4cebc873-2e35-4c07-9d86-d2e74999b017,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-078d648b-f752-4c91-86a2-27333d832d75,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-9276179b-0a04-44f9-b4c1-caf0b05ab0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5719
