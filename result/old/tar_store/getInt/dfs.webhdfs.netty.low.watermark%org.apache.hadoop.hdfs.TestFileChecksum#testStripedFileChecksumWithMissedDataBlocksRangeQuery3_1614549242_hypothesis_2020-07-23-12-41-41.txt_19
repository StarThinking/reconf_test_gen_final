reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712221976-172.17.0.13-1595508337929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-33c29ad3-9c18-4fb0-b7fa-8bfbe40baa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-8e992075-38ab-4199-8a94-ff7b9e2d3e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-b60ccb29-69a8-4242-b602-f5b6c417c64d,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-dbbc6097-b3b5-4c7b-b549-551aea895bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-5e1b1b9c-c2cd-4d79-8797-8bb23375a483,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-6a4351dd-66d2-4ea1-b79b-67c567c7df6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-8b0403ef-328c-4ed5-8c38-7f54b9c08640,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-962b440d-fce9-4081-bf2f-0b6e701f9a20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712221976-172.17.0.13-1595508337929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-33c29ad3-9c18-4fb0-b7fa-8bfbe40baa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-8e992075-38ab-4199-8a94-ff7b9e2d3e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-b60ccb29-69a8-4242-b602-f5b6c417c64d,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-dbbc6097-b3b5-4c7b-b549-551aea895bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-5e1b1b9c-c2cd-4d79-8797-8bb23375a483,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-6a4351dd-66d2-4ea1-b79b-67c567c7df6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-8b0403ef-328c-4ed5-8c38-7f54b9c08640,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-962b440d-fce9-4081-bf2f-0b6e701f9a20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16390710-172.17.0.13-1595508862511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40781,DS-e249d472-15e2-4855-b605-14b8d4ba1079,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-bbc88bae-1901-4abe-939e-425fcccc0345,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-aea9cc4a-a417-4d2d-95b5-06e4f4cb180e,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-0a21f019-ed31-4adb-af4a-7bfe55f5ba92,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-b9773094-8968-451a-91df-fa48fbbcae97,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-2a0dae4c-b2b1-4da8-b506-5a1c58d663dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-a49ef14e-9e92-46bb-ac8d-b1477619b9de,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-cdbc79a7-4eda-4cc1-8ba2-d1293d1be0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16390710-172.17.0.13-1595508862511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40781,DS-e249d472-15e2-4855-b605-14b8d4ba1079,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-bbc88bae-1901-4abe-939e-425fcccc0345,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-aea9cc4a-a417-4d2d-95b5-06e4f4cb180e,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-0a21f019-ed31-4adb-af4a-7bfe55f5ba92,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-b9773094-8968-451a-91df-fa48fbbcae97,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-2a0dae4c-b2b1-4da8-b506-5a1c58d663dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-a49ef14e-9e92-46bb-ac8d-b1477619b9de,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-cdbc79a7-4eda-4cc1-8ba2-d1293d1be0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279120624-172.17.0.13-1595509165259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-a2ba8d9f-f52c-4318-aaed-156e43ae8ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-357f5b95-ce31-444d-b63d-e0b05e18c628,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-ee979934-255e-46c9-b7ab-16293a541608,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-f9c9000f-849e-4ebd-8c3d-419b35765127,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-1dfb87ab-aea9-43a4-94d8-44d63f7b13fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-a6c97650-dd7c-4358-a980-1b1daf7bf034,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-751a6d83-406b-499d-a33f-c2306d1635e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-750494b4-5073-4c1e-9ee8-c10189aed868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279120624-172.17.0.13-1595509165259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-a2ba8d9f-f52c-4318-aaed-156e43ae8ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-357f5b95-ce31-444d-b63d-e0b05e18c628,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-ee979934-255e-46c9-b7ab-16293a541608,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-f9c9000f-849e-4ebd-8c3d-419b35765127,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-1dfb87ab-aea9-43a4-94d8-44d63f7b13fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-a6c97650-dd7c-4358-a980-1b1daf7bf034,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-751a6d83-406b-499d-a33f-c2306d1635e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-750494b4-5073-4c1e-9ee8-c10189aed868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418099456-172.17.0.13-1595510819555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45571,DS-3e6b91a4-2281-4300-889c-24d1162eeadb,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-3be0e18a-7a69-4458-a996-e92800fe3591,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-6533822e-7c94-418c-a77a-ba2933550260,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-d400c930-d36a-4cda-9569-e5212f2421b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-f01c7d64-839f-4b2b-b700-740b8e6afb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-007b902a-ac90-4ab3-b71d-1357ef9f0f55,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-e6312309-936a-43d4-8525-e78294f1d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-4b9ffa82-b0f2-42c0-b096-fa04ede9a9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418099456-172.17.0.13-1595510819555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45571,DS-3e6b91a4-2281-4300-889c-24d1162eeadb,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-3be0e18a-7a69-4458-a996-e92800fe3591,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-6533822e-7c94-418c-a77a-ba2933550260,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-d400c930-d36a-4cda-9569-e5212f2421b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-f01c7d64-839f-4b2b-b700-740b8e6afb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-007b902a-ac90-4ab3-b71d-1357ef9f0f55,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-e6312309-936a-43d4-8525-e78294f1d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-4b9ffa82-b0f2-42c0-b096-fa04ede9a9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100628215-172.17.0.13-1595511054659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35527,DS-d910d2e5-c7c1-4c52-94ce-78349402f117,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-6ce801d8-dca5-4043-857d-f5b36ed329e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-14834a87-26ac-4a46-bb77-60e92885f2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-dde288c7-d81d-440e-89d3-605046af3ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-1260bc8d-4530-4f74-8eff-427b7167c46d,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-6826de11-0aa6-4bab-8214-ddd2935bd82f,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-963e0f3a-456a-4218-b60f-7c20a32b9046,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-2f277931-406d-4dd1-854c-3485a54e0dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100628215-172.17.0.13-1595511054659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35527,DS-d910d2e5-c7c1-4c52-94ce-78349402f117,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-6ce801d8-dca5-4043-857d-f5b36ed329e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-14834a87-26ac-4a46-bb77-60e92885f2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-dde288c7-d81d-440e-89d3-605046af3ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-1260bc8d-4530-4f74-8eff-427b7167c46d,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-6826de11-0aa6-4bab-8214-ddd2935bd82f,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-963e0f3a-456a-4218-b60f-7c20a32b9046,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-2f277931-406d-4dd1-854c-3485a54e0dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126428137-172.17.0.13-1595511144170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-fc97f3bd-fed2-4dbd-882b-29055d6c88a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-3f86475b-a3bd-4219-bce8-f5699b733a01,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-3fe8739b-74e4-401f-8426-a63d7342943d,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-6372ade8-256b-464c-83c3-893efc18c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-067dab2d-87bb-4f72-b141-905968af726b,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-a697da0f-3e7c-41b3-b15a-d2d0d5c59007,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-bf5af0f7-92ef-463b-9d15-41596c4f39c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-499f2313-546c-4420-a90a-1713d7ff51f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126428137-172.17.0.13-1595511144170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-fc97f3bd-fed2-4dbd-882b-29055d6c88a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-3f86475b-a3bd-4219-bce8-f5699b733a01,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-3fe8739b-74e4-401f-8426-a63d7342943d,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-6372ade8-256b-464c-83c3-893efc18c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-067dab2d-87bb-4f72-b141-905968af726b,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-a697da0f-3e7c-41b3-b15a-d2d0d5c59007,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-bf5af0f7-92ef-463b-9d15-41596c4f39c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-499f2313-546c-4420-a90a-1713d7ff51f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617462289-172.17.0.13-1595511281136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34726,DS-9adb4a62-92e8-4c70-978e-42738de36234,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-49149cca-ef7b-4644-84a4-f2c49c705d09,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-803d8042-dd40-4d8a-a156-94bbd2273d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-912ecf31-5cd0-400f-a8f1-f1ad0df95c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-3c13b8f1-0a31-4c06-baf4-c1ca0cc90dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-117b27aa-3522-4987-964c-247d731ee2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-eaa5ba0f-5651-4e61-a0cc-5b509a41b62f,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-ea194bb4-10dc-4c7d-ac90-2b21ca5d37be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617462289-172.17.0.13-1595511281136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34726,DS-9adb4a62-92e8-4c70-978e-42738de36234,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-49149cca-ef7b-4644-84a4-f2c49c705d09,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-803d8042-dd40-4d8a-a156-94bbd2273d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-912ecf31-5cd0-400f-a8f1-f1ad0df95c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-3c13b8f1-0a31-4c06-baf4-c1ca0cc90dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-117b27aa-3522-4987-964c-247d731ee2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-eaa5ba0f-5651-4e61-a0cc-5b509a41b62f,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-ea194bb4-10dc-4c7d-ac90-2b21ca5d37be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814137209-172.17.0.13-1595511326223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40645,DS-16f273df-2008-4240-8fed-9b589f87adcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-df4e35ef-bcec-4f5f-abdd-e882fa7b7051,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-1829663d-6647-42ed-bfcc-31d2811bd933,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-81ebf8be-63e9-453f-b594-793b5139e0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-954cf37a-e881-4e27-b2a4-c431c13614ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-8999a825-4983-4a61-ac43-b321c63ea723,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-e5ff7b9b-5669-481c-823e-730ae9a95b17,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-ce43aebd-0b80-42e9-8e56-7d6cb6b19195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814137209-172.17.0.13-1595511326223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40645,DS-16f273df-2008-4240-8fed-9b589f87adcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-df4e35ef-bcec-4f5f-abdd-e882fa7b7051,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-1829663d-6647-42ed-bfcc-31d2811bd933,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-81ebf8be-63e9-453f-b594-793b5139e0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-954cf37a-e881-4e27-b2a4-c431c13614ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-8999a825-4983-4a61-ac43-b321c63ea723,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-e5ff7b9b-5669-481c-823e-730ae9a95b17,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-ce43aebd-0b80-42e9-8e56-7d6cb6b19195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567055743-172.17.0.13-1595511413743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-e0500015-77c3-4730-a6e6-c97e5fd40cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-4c34a3d9-589e-43ff-9fa2-3d931ba6b339,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-e808c28a-2059-4640-8b8e-1f81a3d8fa48,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-ff22b4e2-7a62-4ad9-ba43-f19e43c2ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-00005890-0a3a-43dc-ab4a-53374ca9b429,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-d4a9f6e5-1132-4d93-bc92-2b5963aa41a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-e8f581a0-befe-4691-9e8f-bd05a7838d05,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-2e3ae7ae-7197-4279-ad68-595f153dc8bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567055743-172.17.0.13-1595511413743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-e0500015-77c3-4730-a6e6-c97e5fd40cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-4c34a3d9-589e-43ff-9fa2-3d931ba6b339,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-e808c28a-2059-4640-8b8e-1f81a3d8fa48,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-ff22b4e2-7a62-4ad9-ba43-f19e43c2ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-00005890-0a3a-43dc-ab4a-53374ca9b429,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-d4a9f6e5-1132-4d93-bc92-2b5963aa41a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-e8f581a0-befe-4691-9e8f-bd05a7838d05,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-2e3ae7ae-7197-4279-ad68-595f153dc8bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311120578-172.17.0.13-1595512204339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39620,DS-ff24e4d4-d1e6-4a1f-ab9f-91306e9faa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-cb9d5853-1451-40bd-8542-5fcf037596e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-e3e664f9-e023-450e-a520-d6d58c6ef76d,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-c4afe7dc-575c-4299-8edb-cf269e35f529,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-f57686b0-117e-40ee-8f92-7a9e289ce950,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-7e6a82b0-91eb-4dc0-9697-0ce56344db9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-eb13225c-82ea-4423-b1a8-0a744abc1352,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-818b85c2-29bd-45f1-9bc5-e227076a6ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311120578-172.17.0.13-1595512204339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39620,DS-ff24e4d4-d1e6-4a1f-ab9f-91306e9faa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-cb9d5853-1451-40bd-8542-5fcf037596e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-e3e664f9-e023-450e-a520-d6d58c6ef76d,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-c4afe7dc-575c-4299-8edb-cf269e35f529,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-f57686b0-117e-40ee-8f92-7a9e289ce950,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-7e6a82b0-91eb-4dc0-9697-0ce56344db9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-eb13225c-82ea-4423-b1a8-0a744abc1352,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-818b85c2-29bd-45f1-9bc5-e227076a6ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330782228-172.17.0.13-1595512709051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-6a466b5a-02d1-468b-bbaf-1fa0cb04724a,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-c91021dd-fcb3-424b-90de-2cea715fd589,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-20c68430-aaf5-41a3-90f5-7e75ff35d079,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-ea1d2633-3642-4715-8644-151cf3cf580d,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-a0b2f82a-2d03-44dc-9b91-68466ba53e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-6ee6669b-01dc-45b1-a2ec-5b3aae416bff,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-bc260f90-e818-4258-99d2-8611768b6c06,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-4995eddf-fff1-49ac-8fe0-cff314d333c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330782228-172.17.0.13-1595512709051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-6a466b5a-02d1-468b-bbaf-1fa0cb04724a,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-c91021dd-fcb3-424b-90de-2cea715fd589,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-20c68430-aaf5-41a3-90f5-7e75ff35d079,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-ea1d2633-3642-4715-8644-151cf3cf580d,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-a0b2f82a-2d03-44dc-9b91-68466ba53e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-6ee6669b-01dc-45b1-a2ec-5b3aae416bff,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-bc260f90-e818-4258-99d2-8611768b6c06,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-4995eddf-fff1-49ac-8fe0-cff314d333c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20716554-172.17.0.13-1595513067247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-c3933841-4972-4afc-af62-217927b05a48,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-66da4ee5-1d7d-45f7-a316-b4e64424bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-e2fc0ab2-5a50-4587-8682-28b69638caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-4d59b1ab-aa35-490d-b334-81912548bc84,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-1357907a-e089-4f8d-93cc-e3fec5e94eef,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-dbed6acf-10eb-45cd-b944-6725d9411aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-73a312e3-d2da-4b78-a033-c7d8dbb61b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-0edfb66d-b59b-4704-8a6c-90dd8bd58491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20716554-172.17.0.13-1595513067247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-c3933841-4972-4afc-af62-217927b05a48,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-66da4ee5-1d7d-45f7-a316-b4e64424bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-e2fc0ab2-5a50-4587-8682-28b69638caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-4d59b1ab-aa35-490d-b334-81912548bc84,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-1357907a-e089-4f8d-93cc-e3fec5e94eef,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-dbed6acf-10eb-45cd-b944-6725d9411aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-73a312e3-d2da-4b78-a033-c7d8dbb61b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-0edfb66d-b59b-4704-8a6c-90dd8bd58491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618696445-172.17.0.13-1595513646339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35480,DS-cba049a9-fc7c-4852-bbc2-2d7870a540bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-6ab47002-8bc9-4094-af24-dcf302a82570,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-c6325ec1-1786-4b12-8c64-6347e252a9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-df504464-6771-43a6-be73-4b092a10bbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-9512cb64-485b-40aa-8a19-839117be61ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-0221a7cc-5dd3-4129-a490-dc4d03547cac,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-9a1b6580-2c77-4316-b346-460cdf0439d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-3eab49d5-b511-4f03-9722-ce6d35fcfe40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618696445-172.17.0.13-1595513646339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35480,DS-cba049a9-fc7c-4852-bbc2-2d7870a540bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-6ab47002-8bc9-4094-af24-dcf302a82570,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-c6325ec1-1786-4b12-8c64-6347e252a9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-df504464-6771-43a6-be73-4b092a10bbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-9512cb64-485b-40aa-8a19-839117be61ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-0221a7cc-5dd3-4129-a490-dc4d03547cac,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-9a1b6580-2c77-4316-b346-460cdf0439d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-3eab49d5-b511-4f03-9722-ce6d35fcfe40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120019229-172.17.0.13-1595513857633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41058,DS-3cbd1398-4e18-4121-9ad8-9e1545865d71,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-14762d8d-922f-4791-911d-e574dfe8720a,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-37c19783-a087-4631-955d-0aa04bb16cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-7b704888-cb18-43d5-9641-967523b13b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-ef4f17a5-df4b-49b9-853b-13e9a85adc06,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-44df63c3-f668-4b73-8783-854d034dd31f,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-1d90c7e5-1580-446f-9e1c-fc0db11962f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-eb4b7bdc-83d1-4188-af95-50f9cfa44c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120019229-172.17.0.13-1595513857633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41058,DS-3cbd1398-4e18-4121-9ad8-9e1545865d71,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-14762d8d-922f-4791-911d-e574dfe8720a,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-37c19783-a087-4631-955d-0aa04bb16cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-7b704888-cb18-43d5-9641-967523b13b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-ef4f17a5-df4b-49b9-853b-13e9a85adc06,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-44df63c3-f668-4b73-8783-854d034dd31f,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-1d90c7e5-1580-446f-9e1c-fc0db11962f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-eb4b7bdc-83d1-4188-af95-50f9cfa44c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145960111-172.17.0.13-1595513896710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46487,DS-a57622c5-74b6-4b9f-a97a-914671edb566,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-9a6cb2ea-b9de-418f-9a67-98c7748526f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-dd94a7d5-be74-4c7d-8466-70e9ea8a2c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-fdc96a01-253b-4ba2-848e-02bbf4ca9a68,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-b6c86eb1-a0be-4603-81fd-6f934eada1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-95198486-f418-4382-a880-1a33b775a0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-2c6205ce-7077-4a6e-b2da-786fd21c45f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-62c7b223-9bc6-44a8-9632-5fc3403396e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145960111-172.17.0.13-1595513896710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46487,DS-a57622c5-74b6-4b9f-a97a-914671edb566,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-9a6cb2ea-b9de-418f-9a67-98c7748526f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-dd94a7d5-be74-4c7d-8466-70e9ea8a2c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-fdc96a01-253b-4ba2-848e-02bbf4ca9a68,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-b6c86eb1-a0be-4603-81fd-6f934eada1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-95198486-f418-4382-a880-1a33b775a0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-2c6205ce-7077-4a6e-b2da-786fd21c45f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-62c7b223-9bc6-44a8-9632-5fc3403396e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729360966-172.17.0.13-1595514032519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-37da8f35-e4e5-4fa0-a82c-5e4f687e0c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-918d8961-e537-4afc-802e-26e41af90e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-21e0930e-0dd5-4095-a96f-a5fc3ec30ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-3f0dc78e-60d9-4e0f-bffc-d594fc5ddba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-4d74070a-27eb-4b4a-8831-f52109919e41,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-553e61a6-58ac-4bb1-9a13-9d69841a820c,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-807a3f40-dc35-4386-9513-40f75c6bf1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-18b09fca-a69d-47c3-b52d-c5810c4bfdd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729360966-172.17.0.13-1595514032519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-37da8f35-e4e5-4fa0-a82c-5e4f687e0c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-918d8961-e537-4afc-802e-26e41af90e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-21e0930e-0dd5-4095-a96f-a5fc3ec30ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-3f0dc78e-60d9-4e0f-bffc-d594fc5ddba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-4d74070a-27eb-4b4a-8831-f52109919e41,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-553e61a6-58ac-4bb1-9a13-9d69841a820c,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-807a3f40-dc35-4386-9513-40f75c6bf1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-18b09fca-a69d-47c3-b52d-c5810c4bfdd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777209716-172.17.0.13-1595514242988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-9aa2e449-f04b-4e6a-b6db-d237fa3d64c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-a43810e1-5f41-46cf-95fe-f4febbe38ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-93202449-7f5f-4f7e-952b-b0674b71e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-f395456e-731f-4494-866a-6144a14f9e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-04e4cc9d-7b25-4d47-ae97-1ad047cb575b,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-1aea10e2-7a60-4e41-9b71-5cb33f9fd495,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-7a376a35-e686-40e7-aaf0-e4a88c382c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b06b28b0-72e4-45ab-abd0-9d9484bdcf99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777209716-172.17.0.13-1595514242988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-9aa2e449-f04b-4e6a-b6db-d237fa3d64c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-a43810e1-5f41-46cf-95fe-f4febbe38ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-93202449-7f5f-4f7e-952b-b0674b71e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-f395456e-731f-4494-866a-6144a14f9e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-04e4cc9d-7b25-4d47-ae97-1ad047cb575b,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-1aea10e2-7a60-4e41-9b71-5cb33f9fd495,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-7a376a35-e686-40e7-aaf0-e4a88c382c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b06b28b0-72e4-45ab-abd0-9d9484bdcf99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249002768-172.17.0.13-1595514459105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38855,DS-b43dd0a5-b127-4a55-876b-d2d893166571,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-2d0fdaa1-3cc2-4258-a531-c18cba0a5208,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-bfddd972-b31c-49ab-9ee3-1f2a1033e73e,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-ba7bf088-8cd1-45ae-84f8-07526b96e3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-fdfed75e-41e5-4b48-ae49-72c72b03887c,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-f406361b-5b1a-46d0-9a65-08b3624791ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-dfcef632-f4b1-427b-a16c-10f7fd8c45eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-64de7ab3-87b9-4902-b1a3-0c5e0797d06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249002768-172.17.0.13-1595514459105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38855,DS-b43dd0a5-b127-4a55-876b-d2d893166571,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-2d0fdaa1-3cc2-4258-a531-c18cba0a5208,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-bfddd972-b31c-49ab-9ee3-1f2a1033e73e,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-ba7bf088-8cd1-45ae-84f8-07526b96e3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-fdfed75e-41e5-4b48-ae49-72c72b03887c,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-f406361b-5b1a-46d0-9a65-08b3624791ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-dfcef632-f4b1-427b-a16c-10f7fd8c45eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-64de7ab3-87b9-4902-b1a3-0c5e0797d06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6751
