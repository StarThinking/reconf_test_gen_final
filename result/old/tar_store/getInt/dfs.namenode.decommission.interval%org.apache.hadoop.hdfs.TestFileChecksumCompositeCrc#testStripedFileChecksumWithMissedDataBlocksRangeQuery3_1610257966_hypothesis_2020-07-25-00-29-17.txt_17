reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033322480-172.17.0.20-1595637020812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-3f997127-2caa-49e8-854d-c6d26f84ef01,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-ebc0358b-f57b-45b0-9062-7822d12eccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-bffb9b76-0d73-45d5-b5df-bcef46aedacd,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-f6c417ae-caeb-45a9-a759-4118b1eb1dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-983c4cc5-379e-4ae7-b1a1-5d324f308215,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-0576c79a-6dce-4c6b-8f9d-ac53ee5c7c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-f63356b9-cb5a-45dd-bbb8-a8c5ca1a6225,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-be51e9c4-b0b3-464c-8197-5596c47ab300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033322480-172.17.0.20-1595637020812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-3f997127-2caa-49e8-854d-c6d26f84ef01,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-ebc0358b-f57b-45b0-9062-7822d12eccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-bffb9b76-0d73-45d5-b5df-bcef46aedacd,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-f6c417ae-caeb-45a9-a759-4118b1eb1dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-983c4cc5-379e-4ae7-b1a1-5d324f308215,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-0576c79a-6dce-4c6b-8f9d-ac53ee5c7c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-f63356b9-cb5a-45dd-bbb8-a8c5ca1a6225,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-be51e9c4-b0b3-464c-8197-5596c47ab300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182663222-172.17.0.20-1595637693105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-c6ac2eee-c79e-4977-8098-b725272e7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-a694be16-8f04-4ddf-8727-79cbc0b21657,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-a9ba2187-fd2b-4703-ac7d-cd682459705d,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-a671f6f6-21c7-4541-b755-0d8618549a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-b6fb36cf-86ed-4e52-844b-7fa54e05f437,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-0f41bb9b-6277-4385-a144-a9731c5f469c,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-b6570da3-57a1-4053-a5b2-ef9bd6450e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-2f4e0611-eeb5-4b66-b9d5-1bcb5214f585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182663222-172.17.0.20-1595637693105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-c6ac2eee-c79e-4977-8098-b725272e7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-a694be16-8f04-4ddf-8727-79cbc0b21657,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-a9ba2187-fd2b-4703-ac7d-cd682459705d,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-a671f6f6-21c7-4541-b755-0d8618549a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-b6fb36cf-86ed-4e52-844b-7fa54e05f437,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-0f41bb9b-6277-4385-a144-a9731c5f469c,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-b6570da3-57a1-4053-a5b2-ef9bd6450e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-2f4e0611-eeb5-4b66-b9d5-1bcb5214f585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584294978-172.17.0.20-1595638991243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44188,DS-efad4cd5-dd5f-462f-96d5-bd3967348668,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-b0e440cf-09bf-4ab6-917f-f3054b923b26,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-cd30041d-6342-4325-9dc4-27062204aadb,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-106e7352-2818-4e14-9b7b-8894bcd9691b,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-2a668f31-8aa0-47c3-9239-ea0da453b098,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-592abbb9-078e-495c-945a-c29958224934,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-54853795-5d5b-4564-9d86-253d45ad0f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-eb472856-4b9a-4ca0-92da-e816dac2b54b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584294978-172.17.0.20-1595638991243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44188,DS-efad4cd5-dd5f-462f-96d5-bd3967348668,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-b0e440cf-09bf-4ab6-917f-f3054b923b26,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-cd30041d-6342-4325-9dc4-27062204aadb,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-106e7352-2818-4e14-9b7b-8894bcd9691b,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-2a668f31-8aa0-47c3-9239-ea0da453b098,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-592abbb9-078e-495c-945a-c29958224934,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-54853795-5d5b-4564-9d86-253d45ad0f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-eb472856-4b9a-4ca0-92da-e816dac2b54b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773380961-172.17.0.20-1595639461029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41386,DS-6ba6ace8-9e50-473c-bc7c-2312a6bc060f,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-2a03b237-7b1d-41d7-9f2b-72ae9c8e9033,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-630876f9-625c-4afc-94bb-31f33ba504e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-2a952402-a0ee-4c6f-bdc0-66f2d5f93114,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-4f790d20-f336-4db7-8981-b4414af06278,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-378603b9-19d1-4286-8d87-a029776f3603,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-0a112edb-9136-4bac-9527-cf00f711bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-5d110756-f4ba-4593-ae00-a8178980b572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773380961-172.17.0.20-1595639461029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41386,DS-6ba6ace8-9e50-473c-bc7c-2312a6bc060f,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-2a03b237-7b1d-41d7-9f2b-72ae9c8e9033,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-630876f9-625c-4afc-94bb-31f33ba504e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-2a952402-a0ee-4c6f-bdc0-66f2d5f93114,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-4f790d20-f336-4db7-8981-b4414af06278,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-378603b9-19d1-4286-8d87-a029776f3603,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-0a112edb-9136-4bac-9527-cf00f711bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-5d110756-f4ba-4593-ae00-a8178980b572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861688883-172.17.0.20-1595639817571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-6b0e4973-4828-468e-a1e2-afffd485ff71,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-1d80f371-fa65-4086-9616-c5e63552555b,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-6833122c-4a63-4328-b5f1-58616091f706,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-4cbcff59-7c9c-46b8-8b56-990f20fa7864,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-71cd9326-cb68-4ce9-a451-9de87c870154,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-a2ee3b4e-fd1b-470a-862e-9f5910aaf1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-2db5f4ba-a320-4702-9d0e-6e0a66882d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-75a11305-1589-4a5a-b551-50fb3f2cbde7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861688883-172.17.0.20-1595639817571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-6b0e4973-4828-468e-a1e2-afffd485ff71,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-1d80f371-fa65-4086-9616-c5e63552555b,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-6833122c-4a63-4328-b5f1-58616091f706,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-4cbcff59-7c9c-46b8-8b56-990f20fa7864,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-71cd9326-cb68-4ce9-a451-9de87c870154,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-a2ee3b4e-fd1b-470a-862e-9f5910aaf1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-2db5f4ba-a320-4702-9d0e-6e0a66882d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-75a11305-1589-4a5a-b551-50fb3f2cbde7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317063828-172.17.0.20-1595640563752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35688,DS-e1c4a903-be4c-40a2-aa6f-8c0865e9331e,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-bd10e6d5-0595-4c4b-b0bf-1ca871e7db65,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-6ac64cf2-c2cc-40f0-be30-a46463697fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e696235a-2127-4169-895b-8e7a8ebe240c,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-cc04cab1-28a3-43df-89f7-fb849eb31107,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-2649f959-2f40-4e39-9012-10c63ac4c744,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-55bc04ce-3a0a-48bc-ae48-af7587bbbf74,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-d06b8bc3-a09e-4b54-8c97-b31a78e744d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317063828-172.17.0.20-1595640563752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35688,DS-e1c4a903-be4c-40a2-aa6f-8c0865e9331e,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-bd10e6d5-0595-4c4b-b0bf-1ca871e7db65,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-6ac64cf2-c2cc-40f0-be30-a46463697fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e696235a-2127-4169-895b-8e7a8ebe240c,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-cc04cab1-28a3-43df-89f7-fb849eb31107,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-2649f959-2f40-4e39-9012-10c63ac4c744,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-55bc04ce-3a0a-48bc-ae48-af7587bbbf74,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-d06b8bc3-a09e-4b54-8c97-b31a78e744d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003180739-172.17.0.20-1595640737414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42529,DS-c5022826-5899-4943-b76b-33ee14a550a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-e687dda7-58c8-4792-b2f5-0611a0b62d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-9e311f89-7b4e-475d-ad72-00616187bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1e8c0e49-40bf-4493-84b0-c76232ed127d,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-d3e3ef6f-889f-4152-a36d-76aa235f4d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-ba72622c-2c5f-4f39-b2ec-572f2d127885,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-ac4ea8be-fbe1-4d69-9579-2d586e369cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-479ca3ff-32ae-4735-840a-1710ff04ad0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003180739-172.17.0.20-1595640737414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42529,DS-c5022826-5899-4943-b76b-33ee14a550a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-e687dda7-58c8-4792-b2f5-0611a0b62d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-9e311f89-7b4e-475d-ad72-00616187bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1e8c0e49-40bf-4493-84b0-c76232ed127d,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-d3e3ef6f-889f-4152-a36d-76aa235f4d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-ba72622c-2c5f-4f39-b2ec-572f2d127885,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-ac4ea8be-fbe1-4d69-9579-2d586e369cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-479ca3ff-32ae-4735-840a-1710ff04ad0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580371695-172.17.0.20-1595640824988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-44e66f2e-c1f2-4951-aa8b-4526462c5a14,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-57ed24b3-584d-42f6-96b5-cfd6493987ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-86960085-2752-43e8-baa7-a00005b51669,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-cdb576d1-d3e1-4863-997a-6c79e500f329,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-b5ae583d-b6f7-4297-97b2-4c7ce40f304a,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-e6922eb0-4692-47f7-bcbb-74eed3c7ba36,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-7ef88544-c641-4764-bd90-3655bd866e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-58b1dbdb-b8ad-49dc-902a-399a51667fa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580371695-172.17.0.20-1595640824988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-44e66f2e-c1f2-4951-aa8b-4526462c5a14,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-57ed24b3-584d-42f6-96b5-cfd6493987ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-86960085-2752-43e8-baa7-a00005b51669,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-cdb576d1-d3e1-4863-997a-6c79e500f329,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-b5ae583d-b6f7-4297-97b2-4c7ce40f304a,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-e6922eb0-4692-47f7-bcbb-74eed3c7ba36,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-7ef88544-c641-4764-bd90-3655bd866e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-58b1dbdb-b8ad-49dc-902a-399a51667fa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297115266-172.17.0.20-1595641594704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41045,DS-35eee223-20e0-441e-87e8-fdc9f8eda5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-692c1ca5-6557-4efc-886e-e14c06be2984,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-23aa14f6-da61-4b1d-b846-3c74d6e4d2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-07ed3acf-b389-48ac-9c13-0e5ba82b0732,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-74dc4188-2c80-4417-aab4-3e03883bc177,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-fc733f09-7aa3-4f3d-854d-c233e9697a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-f31b7cf4-38ab-4ff8-86d2-96f2158e93f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-c49d57bb-cd6f-4781-921f-b3148d581568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297115266-172.17.0.20-1595641594704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41045,DS-35eee223-20e0-441e-87e8-fdc9f8eda5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-692c1ca5-6557-4efc-886e-e14c06be2984,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-23aa14f6-da61-4b1d-b846-3c74d6e4d2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-07ed3acf-b389-48ac-9c13-0e5ba82b0732,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-74dc4188-2c80-4417-aab4-3e03883bc177,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-fc733f09-7aa3-4f3d-854d-c233e9697a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-f31b7cf4-38ab-4ff8-86d2-96f2158e93f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-c49d57bb-cd6f-4781-921f-b3148d581568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489562737-172.17.0.20-1595641812998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-ceea1270-0501-4470-a997-78ffbf240edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-08e1bc46-3044-4078-9daa-82fe6e1c1ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-17ea1d51-245f-44ef-9996-69ca3af3215d,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-95f3659b-f2cf-4210-8236-e215207403f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-96741c0a-d290-447f-987f-3c9c105a3871,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-aa402f73-f915-4cd7-885b-75236b701c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-a19cf414-2301-4061-8479-9bdca8f09ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-07cfb5f8-ed08-48a5-aa45-8cebdf7b0e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489562737-172.17.0.20-1595641812998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-ceea1270-0501-4470-a997-78ffbf240edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-08e1bc46-3044-4078-9daa-82fe6e1c1ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-17ea1d51-245f-44ef-9996-69ca3af3215d,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-95f3659b-f2cf-4210-8236-e215207403f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-96741c0a-d290-447f-987f-3c9c105a3871,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-aa402f73-f915-4cd7-885b-75236b701c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-a19cf414-2301-4061-8479-9bdca8f09ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-07cfb5f8-ed08-48a5-aa45-8cebdf7b0e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361278712-172.17.0.20-1595641900908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-b8c3f748-420d-44dc-be2c-ee68fb617e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-16c0a87b-0401-4c20-b4f8-5da33d96d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-30485d8d-c7ff-42f2-a50e-fa5a061ca128,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-10f0a8f2-087b-4dea-b6c8-310858969a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-36a882e7-4d73-4ea7-8d7d-017707387d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-76ffd2c9-5502-482b-9427-7cdb4651c825,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-c59ea1ee-620e-402c-a9e6-a7f3c3a9b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-9fb7e7d1-560f-4cc0-912a-bf6a03897e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361278712-172.17.0.20-1595641900908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-b8c3f748-420d-44dc-be2c-ee68fb617e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-16c0a87b-0401-4c20-b4f8-5da33d96d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-30485d8d-c7ff-42f2-a50e-fa5a061ca128,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-10f0a8f2-087b-4dea-b6c8-310858969a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-36a882e7-4d73-4ea7-8d7d-017707387d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-76ffd2c9-5502-482b-9427-7cdb4651c825,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-c59ea1ee-620e-402c-a9e6-a7f3c3a9b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-9fb7e7d1-560f-4cc0-912a-bf6a03897e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161386699-172.17.0.20-1595642038377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36245,DS-c89c406f-6255-4514-bbfa-618d2e413bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ca590730-e028-4fc6-b982-5bda4cbcf4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-294506f2-8363-4ce2-8c4e-2323d212ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-27303bc9-7ebf-4fae-a04e-8026194aefcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-39f39778-09c9-41cc-b83f-51dfe599af16,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-8379feb6-cb03-477c-9f5c-6d8fadbef06c,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-cc5dbd1e-9340-4d6c-b352-3697ce5a87ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-3edf2ab7-5b2b-4285-bbe5-b611574a938d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161386699-172.17.0.20-1595642038377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36245,DS-c89c406f-6255-4514-bbfa-618d2e413bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ca590730-e028-4fc6-b982-5bda4cbcf4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-294506f2-8363-4ce2-8c4e-2323d212ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-27303bc9-7ebf-4fae-a04e-8026194aefcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-39f39778-09c9-41cc-b83f-51dfe599af16,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-8379feb6-cb03-477c-9f5c-6d8fadbef06c,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-cc5dbd1e-9340-4d6c-b352-3697ce5a87ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-3edf2ab7-5b2b-4285-bbe5-b611574a938d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524032129-172.17.0.20-1595642131637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33990,DS-bdfe5af4-d5d9-4d76-9739-9cba3125daa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-2e729f5b-0915-4bfa-9bdb-d518ca6af95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-b2f2c9f3-960e-4242-8849-47dec7ba35b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-534a435e-1015-4f4a-b57d-10ce7428e1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-2285f278-11a8-4161-9a9c-35df86c2efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-4de246a3-3e48-47a3-810e-e38ce683b40c,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-bf70a0df-8362-4e1e-bc8b-85cc62276d43,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-6caa64e3-49d0-48f9-b447-fffdad5ea99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524032129-172.17.0.20-1595642131637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33990,DS-bdfe5af4-d5d9-4d76-9739-9cba3125daa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-2e729f5b-0915-4bfa-9bdb-d518ca6af95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-b2f2c9f3-960e-4242-8849-47dec7ba35b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-534a435e-1015-4f4a-b57d-10ce7428e1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-2285f278-11a8-4161-9a9c-35df86c2efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-4de246a3-3e48-47a3-810e-e38ce683b40c,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-bf70a0df-8362-4e1e-bc8b-85cc62276d43,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-6caa64e3-49d0-48f9-b447-fffdad5ea99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274999919-172.17.0.20-1595643202000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46005,DS-3e1818b3-7aaa-490c-9e48-a5760d69c758,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-5e1f089a-643e-44cc-96b0-64be824a57d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-4321fd05-d674-4e5c-85c9-985f7a84cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-193eb3bf-bf72-4102-b8da-92bd1008fd24,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-0a5129dd-118b-48fc-a9bd-4e446b20c69c,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-ef405bec-7bda-4681-bf2e-d4dd19b84131,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-24ed59a7-4f72-43e7-b15c-a61a9af9d582,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-d7b7d6fb-5668-43de-b5c7-77666ac7f972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274999919-172.17.0.20-1595643202000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46005,DS-3e1818b3-7aaa-490c-9e48-a5760d69c758,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-5e1f089a-643e-44cc-96b0-64be824a57d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-4321fd05-d674-4e5c-85c9-985f7a84cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-193eb3bf-bf72-4102-b8da-92bd1008fd24,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-0a5129dd-118b-48fc-a9bd-4e446b20c69c,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-ef405bec-7bda-4681-bf2e-d4dd19b84131,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-24ed59a7-4f72-43e7-b15c-a61a9af9d582,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-d7b7d6fb-5668-43de-b5c7-77666ac7f972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270430871-172.17.0.20-1595643645216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-3459d228-d696-4c58-8d9e-007f96234a75,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-9669d7f8-78f9-4d16-81c3-49bfb595a863,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-42b3177a-a24d-44a4-90ce-4d4a4917dd08,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-63efbd42-8e0a-4e11-8eba-5c9aaa66750c,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-92771b24-a450-4bc2-a52e-5146f599cb45,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-c6cc400d-d192-434a-b704-ec1cb169df26,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-c491ff8e-6df3-45a4-bdf3-438be7d065ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-d9c12718-3afb-418c-907b-5505d9a294a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270430871-172.17.0.20-1595643645216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-3459d228-d696-4c58-8d9e-007f96234a75,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-9669d7f8-78f9-4d16-81c3-49bfb595a863,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-42b3177a-a24d-44a4-90ce-4d4a4917dd08,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-63efbd42-8e0a-4e11-8eba-5c9aaa66750c,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-92771b24-a450-4bc2-a52e-5146f599cb45,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-c6cc400d-d192-434a-b704-ec1cb169df26,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-c491ff8e-6df3-45a4-bdf3-438be7d065ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-d9c12718-3afb-418c-907b-5505d9a294a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6713
