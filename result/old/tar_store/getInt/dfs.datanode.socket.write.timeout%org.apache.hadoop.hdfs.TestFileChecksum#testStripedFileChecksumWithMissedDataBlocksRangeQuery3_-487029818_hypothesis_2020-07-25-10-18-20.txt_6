reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624736585-172.17.0.19-1595673278660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42749,DS-5f99ce47-399e-441d-a3df-7c1eb9e33c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-91100b94-5369-4bdf-acff-1fb3ad9aba72,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-dcc522e4-e6f4-4c0d-a135-3d217c178d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-4e1dea39-62e0-4f28-b274-3e1cf46e24ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-da1d8f00-1c73-49f9-90e2-5cf26f6f4e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-e83075d8-d4c9-42d0-ae24-d9d9dbed4f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-bc302c4a-02a4-43af-9565-dd966fe4f646,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-96333ad9-fd2b-48fb-ac61-4ab6254ed95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624736585-172.17.0.19-1595673278660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42749,DS-5f99ce47-399e-441d-a3df-7c1eb9e33c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-91100b94-5369-4bdf-acff-1fb3ad9aba72,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-dcc522e4-e6f4-4c0d-a135-3d217c178d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-4e1dea39-62e0-4f28-b274-3e1cf46e24ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-da1d8f00-1c73-49f9-90e2-5cf26f6f4e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-e83075d8-d4c9-42d0-ae24-d9d9dbed4f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-bc302c4a-02a4-43af-9565-dd966fe4f646,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-96333ad9-fd2b-48fb-ac61-4ab6254ed95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760631601-172.17.0.19-1595673331354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-f94c1422-88ee-4b2f-befb-20fba5344931,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-c95a8879-feda-44ce-abbb-b3d1a51a46ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-e20a5bf6-3301-4591-8941-44d9486af906,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-60d1006e-43a1-48da-8cde-fc15d8a440b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-53960679-36e5-47d4-8768-a1d16932e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-6b2aefbc-b9a3-4be8-b7cf-f3dbf58d9bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-83f5b521-fe6d-431b-be5d-52c4fa4bdc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-f9b29ee9-b512-43d8-86f2-261ecff17864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760631601-172.17.0.19-1595673331354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-f94c1422-88ee-4b2f-befb-20fba5344931,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-c95a8879-feda-44ce-abbb-b3d1a51a46ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-e20a5bf6-3301-4591-8941-44d9486af906,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-60d1006e-43a1-48da-8cde-fc15d8a440b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-53960679-36e5-47d4-8768-a1d16932e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-6b2aefbc-b9a3-4be8-b7cf-f3dbf58d9bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-83f5b521-fe6d-431b-be5d-52c4fa4bdc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-f9b29ee9-b512-43d8-86f2-261ecff17864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285365167-172.17.0.19-1595673418102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34436,DS-ffd22da0-6a29-4d1d-b953-ccbb3e7fa980,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-48149cee-7a50-47e2-b951-5a6e4e5a1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-a934ae0b-44e6-431c-8208-26b6ad7b96f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-18fc8c21-7895-4300-8031-6fd796129a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-2ceb4f49-a5e1-4b9f-a700-fbc1c922feb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-eae70f30-ad97-4300-80d2-a9156efa8e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-2cc90f0c-1b17-47cd-a62e-ca31801da6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-1dae809a-ff09-42a7-996c-f95884e5f979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285365167-172.17.0.19-1595673418102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34436,DS-ffd22da0-6a29-4d1d-b953-ccbb3e7fa980,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-48149cee-7a50-47e2-b951-5a6e4e5a1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-a934ae0b-44e6-431c-8208-26b6ad7b96f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-18fc8c21-7895-4300-8031-6fd796129a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-2ceb4f49-a5e1-4b9f-a700-fbc1c922feb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-eae70f30-ad97-4300-80d2-a9156efa8e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-2cc90f0c-1b17-47cd-a62e-ca31801da6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-1dae809a-ff09-42a7-996c-f95884e5f979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704490512-172.17.0.19-1595674777845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32950,DS-e2aabfd1-c713-4155-b694-1899ccd8e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-559e98fa-afaa-4aa9-b689-b36eed5252df,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-ceb32b53-8905-43a3-8bde-27b383ac0ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-f0a67c9e-f185-4b4a-810a-a5cd5c9ffbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-6aa1f32f-b65d-4e55-9a17-213c922671e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-af828890-d6dd-499a-bf4d-0656f16fe758,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-0820a8af-4c44-4c62-a89b-6ee08867bb37,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-d8c712d7-8c3d-4497-97c5-14f52126c106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704490512-172.17.0.19-1595674777845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32950,DS-e2aabfd1-c713-4155-b694-1899ccd8e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-559e98fa-afaa-4aa9-b689-b36eed5252df,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-ceb32b53-8905-43a3-8bde-27b383ac0ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-f0a67c9e-f185-4b4a-810a-a5cd5c9ffbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-6aa1f32f-b65d-4e55-9a17-213c922671e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-af828890-d6dd-499a-bf4d-0656f16fe758,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-0820a8af-4c44-4c62-a89b-6ee08867bb37,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-d8c712d7-8c3d-4497-97c5-14f52126c106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466161861-172.17.0.19-1595674819818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45992,DS-a2c69d91-9586-41f6-bdfa-963f039ba757,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-12c6503c-a9c3-4649-8b26-1be76be50f04,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-5c3cbd52-270e-47bb-8715-851146909834,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-af46ed5b-0066-4d13-be57-59a02c25c707,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-8a6c07da-4817-432f-888b-45986a062b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-b72baada-7a52-4afd-908c-045454af149c,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-e319ae8d-c03c-440a-a76c-9d13538521a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-eeac1a54-4a3f-40fd-87f6-409a3ef9c8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466161861-172.17.0.19-1595674819818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45992,DS-a2c69d91-9586-41f6-bdfa-963f039ba757,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-12c6503c-a9c3-4649-8b26-1be76be50f04,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-5c3cbd52-270e-47bb-8715-851146909834,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-af46ed5b-0066-4d13-be57-59a02c25c707,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-8a6c07da-4817-432f-888b-45986a062b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-b72baada-7a52-4afd-908c-045454af149c,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-e319ae8d-c03c-440a-a76c-9d13538521a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-eeac1a54-4a3f-40fd-87f6-409a3ef9c8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407053612-172.17.0.19-1595674865678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42046,DS-1daad17e-4378-4cb0-9ffd-f690b001f902,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-ffe7a37e-d46c-4330-82d6-a3551dadd604,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-362513e3-49cf-43e3-bfb7-34d82493612f,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-dd536625-3a7d-479c-923d-c195d39eecec,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-46f1447e-ced4-4d76-9701-1db9af89121e,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-01ff29ee-59cd-4487-b404-e7db2226c1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-23603698-df4b-4bdf-8b38-1fbb8f8ae77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-16f5d18b-283e-4a64-884c-cb798ed75ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407053612-172.17.0.19-1595674865678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42046,DS-1daad17e-4378-4cb0-9ffd-f690b001f902,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-ffe7a37e-d46c-4330-82d6-a3551dadd604,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-362513e3-49cf-43e3-bfb7-34d82493612f,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-dd536625-3a7d-479c-923d-c195d39eecec,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-46f1447e-ced4-4d76-9701-1db9af89121e,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-01ff29ee-59cd-4487-b404-e7db2226c1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-23603698-df4b-4bdf-8b38-1fbb8f8ae77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-16f5d18b-283e-4a64-884c-cb798ed75ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968012239-172.17.0.19-1595674918587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40902,DS-b3406cca-f79b-4bc8-961f-96e9081004bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-334ed70b-d92b-4dd5-b75b-6b9055b6d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-71610138-8ece-4463-af84-c5ca0e7adf53,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-d5b66060-7faf-4658-8af7-5ee1d76405f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-20f3b6cc-abda-4350-996d-88f7fec50066,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-cd068b4c-9a84-4764-a35b-ab7b2eeb14c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-8ff229c1-db25-4a3d-9a51-e73ee4e71252,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-f82cbd6b-55d1-4b42-ae5a-814f2f75ff2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968012239-172.17.0.19-1595674918587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40902,DS-b3406cca-f79b-4bc8-961f-96e9081004bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-334ed70b-d92b-4dd5-b75b-6b9055b6d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-71610138-8ece-4463-af84-c5ca0e7adf53,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-d5b66060-7faf-4658-8af7-5ee1d76405f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-20f3b6cc-abda-4350-996d-88f7fec50066,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-cd068b4c-9a84-4764-a35b-ab7b2eeb14c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-8ff229c1-db25-4a3d-9a51-e73ee4e71252,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-f82cbd6b-55d1-4b42-ae5a-814f2f75ff2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738814558-172.17.0.19-1595675405801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-1f8c34cb-1622-43f8-8488-475cf0becf42,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-94d9d5b7-3b2b-4048-afb3-42fa548cbb81,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-2798cde7-2d80-441f-b9d2-d9bffdfa172c,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-70674d3f-bf3b-4128-8ec7-0acf618b0fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-9f51a3e0-cf2a-4938-b3ab-acc2664f8f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-2a3387f4-3d98-48a6-ae9d-c0400e79b7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-29c017c7-6f74-45fd-b092-6e717be29419,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-5f2d16ed-2274-4639-93c6-15ce825f5e77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738814558-172.17.0.19-1595675405801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-1f8c34cb-1622-43f8-8488-475cf0becf42,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-94d9d5b7-3b2b-4048-afb3-42fa548cbb81,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-2798cde7-2d80-441f-b9d2-d9bffdfa172c,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-70674d3f-bf3b-4128-8ec7-0acf618b0fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-9f51a3e0-cf2a-4938-b3ab-acc2664f8f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-2a3387f4-3d98-48a6-ae9d-c0400e79b7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-29c017c7-6f74-45fd-b092-6e717be29419,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-5f2d16ed-2274-4639-93c6-15ce825f5e77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927153340-172.17.0.19-1595675833134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-301e7260-16b8-48c5-b60d-20c02c2a0014,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-3b1b0796-840c-4cc7-b062-b8b7a7afe1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-d9d2984a-2af7-4230-8775-c34230ef2190,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-c518ecda-2312-47c6-b6e9-77f3de6ccc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-ee0bf315-8569-4c8a-a7be-172dbc0411bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-67801cb8-350d-49cf-bb06-c8cc0ecf31f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-2ff421f8-59f6-49ad-9b55-991de188670b,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-8854ca8f-ab90-4c8e-8e43-9c0f2ea9f154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927153340-172.17.0.19-1595675833134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-301e7260-16b8-48c5-b60d-20c02c2a0014,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-3b1b0796-840c-4cc7-b062-b8b7a7afe1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-d9d2984a-2af7-4230-8775-c34230ef2190,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-c518ecda-2312-47c6-b6e9-77f3de6ccc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-ee0bf315-8569-4c8a-a7be-172dbc0411bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-67801cb8-350d-49cf-bb06-c8cc0ecf31f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-2ff421f8-59f6-49ad-9b55-991de188670b,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-8854ca8f-ab90-4c8e-8e43-9c0f2ea9f154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146397797-172.17.0.19-1595676117073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-c61f6c4b-5cd6-4cab-af96-ec5c50cb5b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-6cafec44-3f3c-447d-b93c-4fe6510ce1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-0375a812-a098-4e6d-80a8-276b09259c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-f25b103b-fc51-40ea-905e-9cdde51ad4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-a8c7253f-9191-4030-8d4d-b3071b08426a,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-2e59e758-4872-48c4-b27f-2b7c87afc432,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-309a1b78-cb04-4da8-aa3a-49da690a9cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-6e819387-022c-43a4-bc5b-2d1dcee4c823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146397797-172.17.0.19-1595676117073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-c61f6c4b-5cd6-4cab-af96-ec5c50cb5b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-6cafec44-3f3c-447d-b93c-4fe6510ce1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-0375a812-a098-4e6d-80a8-276b09259c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-f25b103b-fc51-40ea-905e-9cdde51ad4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-a8c7253f-9191-4030-8d4d-b3071b08426a,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-2e59e758-4872-48c4-b27f-2b7c87afc432,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-309a1b78-cb04-4da8-aa3a-49da690a9cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-6e819387-022c-43a4-bc5b-2d1dcee4c823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333065133-172.17.0.19-1595676327007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42417,DS-a27a0618-b35e-48f1-bdff-763b30de220d,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-23ec2fe4-bfaa-4b04-86fc-08a8fa8dcecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-39f2f2cf-ff10-4ff7-b88d-81082b7ae6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-2b3c41f1-d28c-482d-8b88-f56af7e89ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-c3309ffe-739c-46d4-b8e1-90df38b9cab3,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-1ad5c16a-5c10-4abf-9597-2d6075a210f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-8d24f6ca-5d76-49d0-98c3-0fba12b8c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-7588fe75-0e58-4d86-83b1-53fc71ec48cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333065133-172.17.0.19-1595676327007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42417,DS-a27a0618-b35e-48f1-bdff-763b30de220d,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-23ec2fe4-bfaa-4b04-86fc-08a8fa8dcecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-39f2f2cf-ff10-4ff7-b88d-81082b7ae6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-2b3c41f1-d28c-482d-8b88-f56af7e89ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-c3309ffe-739c-46d4-b8e1-90df38b9cab3,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-1ad5c16a-5c10-4abf-9597-2d6075a210f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-8d24f6ca-5d76-49d0-98c3-0fba12b8c1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-7588fe75-0e58-4d86-83b1-53fc71ec48cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715818749-172.17.0.19-1595676722266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-e14584e2-1c90-4c59-bb36-6d683571bbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-af8ef1c8-ddd8-4642-919e-653a9a12d648,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-687089e0-5c5f-49c6-abf4-012580478cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-94f1efdd-c689-4472-9090-5b7b076f6f27,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-b92507b2-8aa2-46fe-b23b-f66f4cc95086,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-4d06b359-b8b2-4498-9d1a-5720e80d8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-dc206325-b500-433f-a798-1c46f61829da,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-dd0635c0-cbbd-4c0e-aaa5-4ddfaa4bfed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715818749-172.17.0.19-1595676722266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-e14584e2-1c90-4c59-bb36-6d683571bbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-af8ef1c8-ddd8-4642-919e-653a9a12d648,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-687089e0-5c5f-49c6-abf4-012580478cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-94f1efdd-c689-4472-9090-5b7b076f6f27,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-b92507b2-8aa2-46fe-b23b-f66f4cc95086,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-4d06b359-b8b2-4498-9d1a-5720e80d8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-dc206325-b500-433f-a798-1c46f61829da,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-dd0635c0-cbbd-4c0e-aaa5-4ddfaa4bfed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375392654-172.17.0.19-1595677122530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36478,DS-7f36b785-081a-4d71-becd-fe942848aadb,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-5a171a43-587e-486b-ae92-ffdd351bea19,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-cb1b6d86-28fc-4bc1-ac34-2143e359744a,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-6be3f2ee-531b-40f5-8a0e-5d51c047636c,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-08fb4114-8a8b-4f01-819f-9962164bc215,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d8e3b13d-f400-4bc3-bc24-7c91bbdd7351,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-be34c5eb-a91f-48c0-a12d-bd3465043128,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-048538d5-e60b-4865-b386-d7fa98a678d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375392654-172.17.0.19-1595677122530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36478,DS-7f36b785-081a-4d71-becd-fe942848aadb,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-5a171a43-587e-486b-ae92-ffdd351bea19,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-cb1b6d86-28fc-4bc1-ac34-2143e359744a,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-6be3f2ee-531b-40f5-8a0e-5d51c047636c,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-08fb4114-8a8b-4f01-819f-9962164bc215,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d8e3b13d-f400-4bc3-bc24-7c91bbdd7351,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-be34c5eb-a91f-48c0-a12d-bd3465043128,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-048538d5-e60b-4865-b386-d7fa98a678d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763850788-172.17.0.19-1595677208341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38776,DS-3825f806-4819-4018-ae83-3e6bd75ad2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-be62b24a-8595-446e-9eac-0e98b6f68f85,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-9275979e-00f8-4548-be0d-f4a9da10bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-78722081-d0d7-4f20-9fe0-b0241c2ef5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-ef004caf-99ae-4871-ba68-f9bb90c6ecb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-e8431b95-86ef-4500-a38a-f782f0e3ed11,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-bec15b2d-a666-4023-a319-6a73402e0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-abd223c0-85db-4005-befe-600f241ca641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763850788-172.17.0.19-1595677208341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38776,DS-3825f806-4819-4018-ae83-3e6bd75ad2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-be62b24a-8595-446e-9eac-0e98b6f68f85,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-9275979e-00f8-4548-be0d-f4a9da10bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-78722081-d0d7-4f20-9fe0-b0241c2ef5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-ef004caf-99ae-4871-ba68-f9bb90c6ecb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-e8431b95-86ef-4500-a38a-f782f0e3ed11,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-bec15b2d-a666-4023-a319-6a73402e0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-abd223c0-85db-4005-befe-600f241ca641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424949113-172.17.0.19-1595677472821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42943,DS-5ffb22cc-0b44-463e-86ca-b4e53758076f,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-1c4b2ff8-b049-4fdf-8cc7-fceaa0e9c47d,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-a7b8e933-f4cf-4e5b-b36a-97bcf5bf125d,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-b98f480f-0607-4ea5-9962-bd730bcb55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-67a2d004-53a3-49f9-9302-fbbde0084885,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-347e530c-d30b-4516-adf6-2eebc96bf7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-63cc4087-b5f8-48dd-a498-1a0528fdc034,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-8ccf4839-60f1-4be4-84cb-310fc816d860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424949113-172.17.0.19-1595677472821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42943,DS-5ffb22cc-0b44-463e-86ca-b4e53758076f,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-1c4b2ff8-b049-4fdf-8cc7-fceaa0e9c47d,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-a7b8e933-f4cf-4e5b-b36a-97bcf5bf125d,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-b98f480f-0607-4ea5-9962-bd730bcb55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-67a2d004-53a3-49f9-9302-fbbde0084885,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-347e530c-d30b-4516-adf6-2eebc96bf7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-63cc4087-b5f8-48dd-a498-1a0528fdc034,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-8ccf4839-60f1-4be4-84cb-310fc816d860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018375995-172.17.0.19-1595677595457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34248,DS-9a12ac32-b207-4906-b913-8603203bc784,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-9b34aa3a-9dfc-4c9a-a21a-e61354f63c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-c564906f-370d-4be2-a285-056311fab384,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-36e7fd20-fb5a-42be-af6e-79d6a9226b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-61dbc1e4-0fce-44fc-9e94-8105ecea0290,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-16c08a31-1614-4ac7-803c-6c0bf2f5007d,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-6895f48c-5454-4f3f-af8d-ccf609e1cb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-5c71f9f5-a79b-4fe6-a804-a449ecddba6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018375995-172.17.0.19-1595677595457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34248,DS-9a12ac32-b207-4906-b913-8603203bc784,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-9b34aa3a-9dfc-4c9a-a21a-e61354f63c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-c564906f-370d-4be2-a285-056311fab384,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-36e7fd20-fb5a-42be-af6e-79d6a9226b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-61dbc1e4-0fce-44fc-9e94-8105ecea0290,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-16c08a31-1614-4ac7-803c-6c0bf2f5007d,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-6895f48c-5454-4f3f-af8d-ccf609e1cb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-5c71f9f5-a79b-4fe6-a804-a449ecddba6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804815994-172.17.0.19-1595678477205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-470b1e09-5e3a-4743-b4ae-e582900fdbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-4a39948a-4ef3-4540-967f-b9ef2df57083,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-0b8d1a94-b674-4679-9a7b-52fa97f65652,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-a984ba16-974a-48d7-9943-43ccdd490e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-1613dd3a-1d3e-49b4-b525-f1fc84ee4b46,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-3695d3fb-741e-4179-9706-705bcfdc33f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-87aab61c-03e0-4d06-ae0a-cbc7ed516d09,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-e037f168-9f60-452a-9ec0-e7ef99900df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804815994-172.17.0.19-1595678477205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-470b1e09-5e3a-4743-b4ae-e582900fdbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-4a39948a-4ef3-4540-967f-b9ef2df57083,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-0b8d1a94-b674-4679-9a7b-52fa97f65652,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-a984ba16-974a-48d7-9943-43ccdd490e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-1613dd3a-1d3e-49b4-b525-f1fc84ee4b46,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-3695d3fb-741e-4179-9706-705bcfdc33f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-87aab61c-03e0-4d06-ae0a-cbc7ed516d09,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-e037f168-9f60-452a-9ec0-e7ef99900df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6563
