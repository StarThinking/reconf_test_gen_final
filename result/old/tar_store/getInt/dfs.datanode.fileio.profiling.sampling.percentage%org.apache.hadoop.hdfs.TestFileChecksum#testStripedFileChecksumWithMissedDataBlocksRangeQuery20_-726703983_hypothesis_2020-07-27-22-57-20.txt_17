reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878445130-172.17.0.11-1595890785534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35324,DS-7d04dcd0-5903-41f3-865b-10b755d032e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-5e9ebda1-6fd7-43e9-b751-afef50d7177d,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-4a85f7d3-cb05-4e51-8d47-e442e0c241cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-de6fff67-0917-453a-b931-6a75dfa48460,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-e71cf419-af8c-4f8c-b123-1348c3bf2217,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-225a1047-2f54-4bd9-b16c-ac6bbd051346,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-8e9ca0db-6b3a-42aa-a90f-49d694d761fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-7ee3e5ed-9c63-4768-a2d4-c527e1704da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878445130-172.17.0.11-1595890785534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35324,DS-7d04dcd0-5903-41f3-865b-10b755d032e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-5e9ebda1-6fd7-43e9-b751-afef50d7177d,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-4a85f7d3-cb05-4e51-8d47-e442e0c241cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-de6fff67-0917-453a-b931-6a75dfa48460,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-e71cf419-af8c-4f8c-b123-1348c3bf2217,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-225a1047-2f54-4bd9-b16c-ac6bbd051346,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-8e9ca0db-6b3a-42aa-a90f-49d694d761fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-7ee3e5ed-9c63-4768-a2d4-c527e1704da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993427643-172.17.0.11-1595891071947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-5106862e-cc96-454a-b5bf-52d26c59acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-bffc5961-0274-4cbe-9c88-c8e79bef1608,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-4fbd17dc-e249-41b1-8eef-9ffc906436ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-446a5f80-7f84-464e-95ef-99688c11f873,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-1c181159-68c7-451d-a1a7-cf8c095a3b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-d6e118b3-c83f-459e-af12-f99917bf5db5,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-6fc35b84-ae54-4e83-b5a9-67152576d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-8dbe9800-5fc2-419b-9797-68d2cea7198c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993427643-172.17.0.11-1595891071947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-5106862e-cc96-454a-b5bf-52d26c59acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-bffc5961-0274-4cbe-9c88-c8e79bef1608,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-4fbd17dc-e249-41b1-8eef-9ffc906436ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-446a5f80-7f84-464e-95ef-99688c11f873,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-1c181159-68c7-451d-a1a7-cf8c095a3b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-d6e118b3-c83f-459e-af12-f99917bf5db5,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-6fc35b84-ae54-4e83-b5a9-67152576d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-8dbe9800-5fc2-419b-9797-68d2cea7198c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727510663-172.17.0.11-1595891245105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-41bc5dd2-e593-445b-89cf-3a44562667ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-65da8034-bb0a-4f22-ba17-ef777eba15aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-966c3201-cdca-4193-9f8a-fd44014f3519,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-eac666d5-2cb2-4413-8dd1-b8d92dd5dc16,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-d407c538-bd3f-4fb0-b0c9-7df34b17a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-1f93cee2-5850-4a8c-b2b3-173b814ea6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-6bc63b50-4c67-4a82-8865-4ccd9cc0a7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-13ada2e4-f549-49d0-8933-694184eb18fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727510663-172.17.0.11-1595891245105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-41bc5dd2-e593-445b-89cf-3a44562667ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-65da8034-bb0a-4f22-ba17-ef777eba15aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-966c3201-cdca-4193-9f8a-fd44014f3519,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-eac666d5-2cb2-4413-8dd1-b8d92dd5dc16,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-d407c538-bd3f-4fb0-b0c9-7df34b17a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-1f93cee2-5850-4a8c-b2b3-173b814ea6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-6bc63b50-4c67-4a82-8865-4ccd9cc0a7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-13ada2e4-f549-49d0-8933-694184eb18fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372347252-172.17.0.11-1595891351661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-8ebaf0f2-2e00-4c12-babf-90b864863aed,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-eb225423-27be-4a3d-ba81-1553d1ff2db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-db2849c8-fcfc-4959-9b48-bed50a58d151,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-6befb537-9267-4e88-bb53-bcb07b4dcaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-93e9ec57-2804-4bf5-a34b-022c80599b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-6ec18e30-c4ed-4124-acf1-b6abfbffedf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-1bfd812f-3bfa-46d7-bb07-3564a97fd010,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-61f2208c-b40a-47ee-ac95-b413cf8067fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372347252-172.17.0.11-1595891351661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-8ebaf0f2-2e00-4c12-babf-90b864863aed,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-eb225423-27be-4a3d-ba81-1553d1ff2db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-db2849c8-fcfc-4959-9b48-bed50a58d151,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-6befb537-9267-4e88-bb53-bcb07b4dcaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-93e9ec57-2804-4bf5-a34b-022c80599b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-6ec18e30-c4ed-4124-acf1-b6abfbffedf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-1bfd812f-3bfa-46d7-bb07-3564a97fd010,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-61f2208c-b40a-47ee-ac95-b413cf8067fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454176846-172.17.0.11-1595891494332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41094,DS-ae96242b-5c2b-4d0d-b595-69328548eaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-d4451797-0f48-488f-80ff-6f9ffa7beca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-967f16e6-a268-4021-9edc-09aaf8f9f68d,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-bc3e3d00-53e0-41a2-b493-bffb952d0a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-3e0a5abd-db46-4254-a5f5-82d5280f4fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-cac2d6ae-bff8-478f-942e-16d9cd14d204,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-bff320ab-d32f-47d0-953f-771e7739169f,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-afb139e0-9010-40cf-9101-34be43b7f7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454176846-172.17.0.11-1595891494332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41094,DS-ae96242b-5c2b-4d0d-b595-69328548eaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-d4451797-0f48-488f-80ff-6f9ffa7beca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-967f16e6-a268-4021-9edc-09aaf8f9f68d,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-bc3e3d00-53e0-41a2-b493-bffb952d0a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-3e0a5abd-db46-4254-a5f5-82d5280f4fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-cac2d6ae-bff8-478f-942e-16d9cd14d204,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-bff320ab-d32f-47d0-953f-771e7739169f,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-afb139e0-9010-40cf-9101-34be43b7f7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-843296848-172.17.0.11-1595892238921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43065,DS-37940cf3-0178-47cd-8645-097e1dc39a46,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-d556269b-79cf-4222-a79f-6991afeb11ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-c61e3305-dd2e-4cdd-b944-336ec5344df3,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-6f571e32-8269-4a02-85c6-2f5207d6d655,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-bb4a532f-9225-4e73-aabb-e91ba24c2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-6cd81ebe-87fc-4dfb-bf20-41105595d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-cfbd8f19-67a7-47b7-b356-de3fe3bf1cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-f81202bb-5849-4ef0-9ada-a9c28e596fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-843296848-172.17.0.11-1595892238921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43065,DS-37940cf3-0178-47cd-8645-097e1dc39a46,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-d556269b-79cf-4222-a79f-6991afeb11ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-c61e3305-dd2e-4cdd-b944-336ec5344df3,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-6f571e32-8269-4a02-85c6-2f5207d6d655,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-bb4a532f-9225-4e73-aabb-e91ba24c2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-6cd81ebe-87fc-4dfb-bf20-41105595d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-cfbd8f19-67a7-47b7-b356-de3fe3bf1cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-f81202bb-5849-4ef0-9ada-a9c28e596fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328211648-172.17.0.11-1595892478501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39249,DS-b24f6816-337e-4b4b-a146-dc1c976d9e11,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-8acb775d-ab30-41fe-afb3-02fc5efd1638,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-8cfb5132-21aa-4a46-a673-6e2f47a39344,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-f2d3561b-d004-4472-89fb-405554ab4214,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-e1aaea1c-a7f5-4ac8-9888-9a0b7f6c4f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-6977c581-caee-4547-b347-6f4a132d2099,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-20cfd15c-03da-4c30-8536-52bbfb09c532,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-8739e735-c22c-41cc-8b6a-88d33ab54894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328211648-172.17.0.11-1595892478501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39249,DS-b24f6816-337e-4b4b-a146-dc1c976d9e11,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-8acb775d-ab30-41fe-afb3-02fc5efd1638,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-8cfb5132-21aa-4a46-a673-6e2f47a39344,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-f2d3561b-d004-4472-89fb-405554ab4214,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-e1aaea1c-a7f5-4ac8-9888-9a0b7f6c4f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-6977c581-caee-4547-b347-6f4a132d2099,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-20cfd15c-03da-4c30-8536-52bbfb09c532,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-8739e735-c22c-41cc-8b6a-88d33ab54894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707031117-172.17.0.11-1595893193646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46399,DS-a215888d-ec6e-48b2-8179-61ff554844ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-47a8626d-4739-45f6-b3f0-16e5469ace8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-3f2cca5a-e5f1-4c0f-806f-3a6ea5f475c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-6dcf4359-a929-4cfa-84ac-9a26da00c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-aa0a19d9-ad60-45c3-999e-54d1fa1cd7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-a7722280-9011-4ff0-a7e5-a266f682efb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-3f026531-b271-4980-9546-4334ad15d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-f42d5613-c7b0-4b78-9dc7-e8c44a731b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707031117-172.17.0.11-1595893193646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46399,DS-a215888d-ec6e-48b2-8179-61ff554844ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-47a8626d-4739-45f6-b3f0-16e5469ace8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-3f2cca5a-e5f1-4c0f-806f-3a6ea5f475c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-6dcf4359-a929-4cfa-84ac-9a26da00c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-aa0a19d9-ad60-45c3-999e-54d1fa1cd7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-a7722280-9011-4ff0-a7e5-a266f682efb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-3f026531-b271-4980-9546-4334ad15d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-f42d5613-c7b0-4b78-9dc7-e8c44a731b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344620443-172.17.0.11-1595893583829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-0ebddadf-046d-4e78-9e93-9146c1dcfe16,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-bfdcf1db-f96e-4172-a64e-f8f84f7408d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-096d1441-3bac-4c9e-854c-b5ace2ab9cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-a1962763-4940-4825-8b11-279a99e2a4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-c49faa0a-8197-4283-b06d-8f8cb0655f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-8578a122-a5f1-4e79-8f03-baf664142662,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-b4b9aef5-32b1-4120-bddf-f05d8c6893fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-8f130f7b-71a8-4b0b-9f0f-f3e94250da27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344620443-172.17.0.11-1595893583829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-0ebddadf-046d-4e78-9e93-9146c1dcfe16,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-bfdcf1db-f96e-4172-a64e-f8f84f7408d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-096d1441-3bac-4c9e-854c-b5ace2ab9cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-a1962763-4940-4825-8b11-279a99e2a4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-c49faa0a-8197-4283-b06d-8f8cb0655f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-8578a122-a5f1-4e79-8f03-baf664142662,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-b4b9aef5-32b1-4120-bddf-f05d8c6893fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-8f130f7b-71a8-4b0b-9f0f-f3e94250da27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034783007-172.17.0.11-1595894019744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-dbadcbe2-051d-46bb-9db7-341756288a42,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-2cc387a5-f6e3-47b3-b0f0-b1e62034ff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-16f29f39-7624-48f3-8b2c-d48e6344fd49,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-1fbbbfa3-6e94-4be7-b898-be489a5832c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-d327a90c-5877-4545-8632-0e98f6667d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-a0b4e5ec-9145-4639-b60d-9fb278b22ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-334013d7-5e17-4839-86a5-9154fa668ace,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-c3012f24-c06c-47e5-882e-ef20ae67ab8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034783007-172.17.0.11-1595894019744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-dbadcbe2-051d-46bb-9db7-341756288a42,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-2cc387a5-f6e3-47b3-b0f0-b1e62034ff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-16f29f39-7624-48f3-8b2c-d48e6344fd49,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-1fbbbfa3-6e94-4be7-b898-be489a5832c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-d327a90c-5877-4545-8632-0e98f6667d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-a0b4e5ec-9145-4639-b60d-9fb278b22ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-334013d7-5e17-4839-86a5-9154fa668ace,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-c3012f24-c06c-47e5-882e-ef20ae67ab8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858779664-172.17.0.11-1595894143730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-053d7f0b-0fc5-4abb-9d5e-a11fb499ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-db3d0e4f-0e7f-412a-b474-3acbdc241890,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-ae7d1c22-e94a-4dfe-a915-d2fb042ab0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-0dd7b7c2-6491-4676-9982-20ae09b47e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-e7130b8b-5ad1-4b00-8504-e16623bcc3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-e8a5d8f4-312b-4da1-9c9b-d38720b9961f,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-3f12bc54-13c8-4acf-8cf0-f19f8faf6925,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-fc992da6-2037-47cc-aa44-823b8e23649a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858779664-172.17.0.11-1595894143730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-053d7f0b-0fc5-4abb-9d5e-a11fb499ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-db3d0e4f-0e7f-412a-b474-3acbdc241890,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-ae7d1c22-e94a-4dfe-a915-d2fb042ab0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-0dd7b7c2-6491-4676-9982-20ae09b47e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-e7130b8b-5ad1-4b00-8504-e16623bcc3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-e8a5d8f4-312b-4da1-9c9b-d38720b9961f,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-3f12bc54-13c8-4acf-8cf0-f19f8faf6925,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-fc992da6-2037-47cc-aa44-823b8e23649a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675521338-172.17.0.11-1595894185090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44123,DS-4406c97e-e91b-4b8a-b72c-1df1fbe3d863,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-ceaf5405-1aec-4c78-98e7-a60e6c740b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-18e8c886-ab33-499b-bf99-d06f6b4e44ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-51b5d5a2-eacf-46e4-89f4-9173ee23683a,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-8ffec303-8fcf-4e89-be71-8f61309fd3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-ee64dbed-c1de-42aa-86cc-da7a95a230e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-6da555ef-4bee-4e7e-8e47-ca5b603bac05,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-2f82213b-1fba-4d44-b082-9b9c6d78942d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675521338-172.17.0.11-1595894185090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44123,DS-4406c97e-e91b-4b8a-b72c-1df1fbe3d863,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-ceaf5405-1aec-4c78-98e7-a60e6c740b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-18e8c886-ab33-499b-bf99-d06f6b4e44ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-51b5d5a2-eacf-46e4-89f4-9173ee23683a,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-8ffec303-8fcf-4e89-be71-8f61309fd3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-ee64dbed-c1de-42aa-86cc-da7a95a230e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-6da555ef-4bee-4e7e-8e47-ca5b603bac05,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-2f82213b-1fba-4d44-b082-9b9c6d78942d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255373849-172.17.0.11-1595894333436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-8c917311-c2b9-4e74-b5b2-d498d71d28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-ff7cb24d-f9a9-4d88-a6d4-e1a2cb599e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-42aae53d-0a58-44a6-a843-73d871b4ca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-e9116b8f-08e3-45d2-a3be-cceafd71e11c,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-9216bece-486c-4a7c-b837-3f5d6d5cadf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-afd67458-f804-45ba-be11-a0a5e05e9810,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-c47ac069-2e8d-4078-a180-c5801e609187,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-d92bee0e-9a4f-4e5f-bbbd-b37ebe74e311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255373849-172.17.0.11-1595894333436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-8c917311-c2b9-4e74-b5b2-d498d71d28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-ff7cb24d-f9a9-4d88-a6d4-e1a2cb599e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-42aae53d-0a58-44a6-a843-73d871b4ca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-e9116b8f-08e3-45d2-a3be-cceafd71e11c,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-9216bece-486c-4a7c-b837-3f5d6d5cadf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-afd67458-f804-45ba-be11-a0a5e05e9810,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-c47ac069-2e8d-4078-a180-c5801e609187,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-d92bee0e-9a4f-4e5f-bbbd-b37ebe74e311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757860579-172.17.0.11-1595894454385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-1d3603a4-f89a-4ffb-b344-e3d625ef0aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-187fd93c-1b2b-46a7-8c0e-4379ac110857,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-9b986b77-20c8-428f-a344-53da0740af4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-37b81d8f-a427-41f4-b290-5239aaf1033c,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-6f116c16-56a9-4d68-818d-bf7726a217fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-dabfd75c-fd09-4682-953e-f781fc1a174d,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-11c8755d-abe3-4631-8a22-9e8439b02229,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-774a321d-7637-48dd-a8c0-86505126e3c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757860579-172.17.0.11-1595894454385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-1d3603a4-f89a-4ffb-b344-e3d625ef0aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-187fd93c-1b2b-46a7-8c0e-4379ac110857,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-9b986b77-20c8-428f-a344-53da0740af4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-37b81d8f-a427-41f4-b290-5239aaf1033c,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-6f116c16-56a9-4d68-818d-bf7726a217fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-dabfd75c-fd09-4682-953e-f781fc1a174d,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-11c8755d-abe3-4631-8a22-9e8439b02229,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-774a321d-7637-48dd-a8c0-86505126e3c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130132435-172.17.0.11-1595894629543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44976,DS-8306dab4-d69d-4c1f-8eee-852e3cebe0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-6f3f98b1-92b4-4ce9-9a56-0c43e9923aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-afb5cba1-9e05-4f45-bb2b-3a0ad08f3ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-02026541-3f22-4d3a-9ef5-2f17f709cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-a12ad9ec-e578-4b0d-9458-adda656ac92b,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-3ce17cc0-e1e7-4112-b7f5-7c7ebd8acde9,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-af3346c8-f0dc-4bf1-93a4-c7ecb0e3edda,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-d4198fd2-fda0-4ca0-9f4b-072f55865189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130132435-172.17.0.11-1595894629543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44976,DS-8306dab4-d69d-4c1f-8eee-852e3cebe0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-6f3f98b1-92b4-4ce9-9a56-0c43e9923aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-afb5cba1-9e05-4f45-bb2b-3a0ad08f3ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-02026541-3f22-4d3a-9ef5-2f17f709cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-a12ad9ec-e578-4b0d-9458-adda656ac92b,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-3ce17cc0-e1e7-4112-b7f5-7c7ebd8acde9,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-af3346c8-f0dc-4bf1-93a4-c7ecb0e3edda,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-d4198fd2-fda0-4ca0-9f4b-072f55865189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891274188-172.17.0.11-1595895187831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41058,DS-8cd257f1-477a-43ec-b2ef-63233088a468,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-6d19aba2-4fef-44a2-b039-5809cba92029,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-19bf0d9f-c059-4a75-b507-09b6f60eade9,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-9c9f6fb4-09bb-4cd6-ad3e-1c729c66ea38,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-57fff19d-62eb-4dba-8816-30e47b719aba,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-939742fe-e716-4a97-b6d0-aea8c6703269,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-eb6a15cb-eea4-441a-9d61-05d6dc29d677,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-4eb84f0a-5489-498c-b843-767459149f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891274188-172.17.0.11-1595895187831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41058,DS-8cd257f1-477a-43ec-b2ef-63233088a468,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-6d19aba2-4fef-44a2-b039-5809cba92029,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-19bf0d9f-c059-4a75-b507-09b6f60eade9,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-9c9f6fb4-09bb-4cd6-ad3e-1c729c66ea38,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-57fff19d-62eb-4dba-8816-30e47b719aba,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-939742fe-e716-4a97-b6d0-aea8c6703269,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-eb6a15cb-eea4-441a-9d61-05d6dc29d677,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-4eb84f0a-5489-498c-b843-767459149f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037656358-172.17.0.11-1595896120065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39190,DS-02de34b2-ee69-4fee-8919-3bc7d1923c69,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-e99abc26-a296-4537-be75-fc5d322f2767,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-4976e382-1a3a-4761-91d9-a836db2b5661,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-d6129822-63ef-4f85-8f9a-11f0ddb224ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-508501a5-d494-412b-9617-301f3076045d,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-754032de-83b7-4834-8098-7b2b251c445f,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-f626c87e-de83-4c5a-b2cf-c2442c479af3,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-b5a23b0f-6d84-4a51-8a5a-0adb562185ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037656358-172.17.0.11-1595896120065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39190,DS-02de34b2-ee69-4fee-8919-3bc7d1923c69,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-e99abc26-a296-4537-be75-fc5d322f2767,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-4976e382-1a3a-4761-91d9-a836db2b5661,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-d6129822-63ef-4f85-8f9a-11f0ddb224ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-508501a5-d494-412b-9617-301f3076045d,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-754032de-83b7-4834-8098-7b2b251c445f,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-f626c87e-de83-4c5a-b2cf-c2442c479af3,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-b5a23b0f-6d84-4a51-8a5a-0adb562185ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239825143-172.17.0.11-1595896243897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40515,DS-976589fe-9b02-4674-bae9-1e7632f51202,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-7010ef6f-94b1-4224-bfa0-3c5ba4f515b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-81c1fceb-1600-43d6-a14d-adf5a53045ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-848cd33f-4211-460f-82b3-84b6c37e8ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-6fb2927a-fbb6-44a3-9e31-bb2f0fcef553,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-5ea29053-2edc-4481-ba2f-98555ead68fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-f8c53b9d-f64e-43d1-9848-f5ce2fb111d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-1234ec43-3e39-4f21-80a6-4b9d26d800bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239825143-172.17.0.11-1595896243897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40515,DS-976589fe-9b02-4674-bae9-1e7632f51202,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-7010ef6f-94b1-4224-bfa0-3c5ba4f515b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-81c1fceb-1600-43d6-a14d-adf5a53045ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-848cd33f-4211-460f-82b3-84b6c37e8ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-6fb2927a-fbb6-44a3-9e31-bb2f0fcef553,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-5ea29053-2edc-4481-ba2f-98555ead68fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-f8c53b9d-f64e-43d1-9848-f5ce2fb111d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-1234ec43-3e39-4f21-80a6-4b9d26d800bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541177724-172.17.0.11-1595896511453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46042,DS-27747384-3270-4d82-9e8b-3a7689292328,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-bc3d14b5-bce5-44bc-b966-e90d1da81cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f7997cb9-2e81-4a65-ac69-9fea3442e63e,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-df6a45dd-2ff8-4582-8eba-c269e3c437b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-df6f4ed1-b2b4-4e77-9884-03490e971ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-bd06b3d4-0cb6-4feb-be89-0f6680e038f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-732b4fa9-f1c1-4189-a43b-97cb74f99277,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-926b3161-6ed6-417e-b0e3-f73c8f10a0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541177724-172.17.0.11-1595896511453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46042,DS-27747384-3270-4d82-9e8b-3a7689292328,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-bc3d14b5-bce5-44bc-b966-e90d1da81cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f7997cb9-2e81-4a65-ac69-9fea3442e63e,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-df6a45dd-2ff8-4582-8eba-c269e3c437b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-df6f4ed1-b2b4-4e77-9884-03490e971ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-bd06b3d4-0cb6-4feb-be89-0f6680e038f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-732b4fa9-f1c1-4189-a43b-97cb74f99277,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-926b3161-6ed6-417e-b0e3-f73c8f10a0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190780014-172.17.0.11-1595896653715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38595,DS-84afec62-49d8-4e66-99bb-626443a7d019,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-b34b8dfa-5520-4766-849d-611570308ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-e8f60d9d-7cb0-4f7e-92ed-abc07deed295,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-059cd68e-2340-4886-a41b-fa1c7f604a66,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-cc9c09b0-e520-4345-aa05-18abb4b6c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-9ce7cdcf-dad1-467a-8f6b-da3f77788b01,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-6ec1b944-33dc-4518-a575-949b9c3d01ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-84f3ebc1-912f-4af6-b05f-0940f51f30df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190780014-172.17.0.11-1595896653715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38595,DS-84afec62-49d8-4e66-99bb-626443a7d019,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-b34b8dfa-5520-4766-849d-611570308ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-e8f60d9d-7cb0-4f7e-92ed-abc07deed295,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-059cd68e-2340-4886-a41b-fa1c7f604a66,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-cc9c09b0-e520-4345-aa05-18abb4b6c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-9ce7cdcf-dad1-467a-8f6b-da3f77788b01,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-6ec1b944-33dc-4518-a575-949b9c3d01ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-84f3ebc1-912f-4af6-b05f-0940f51f30df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584975882-172.17.0.11-1595896877026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-1483120e-8575-456d-a7ff-d89e34b79ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-9b97d23a-f201-4d56-bf34-bdb87f5ecb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-0d244f37-e222-4273-9c1c-d159460b965a,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-9b341e18-9e52-42d8-8614-d7533f14297d,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-d211067a-6633-4194-be92-db223251db54,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-0d2cbc94-6a37-457c-9e38-4cf429e44fad,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-a3d69507-62a9-46e1-8aac-b21accc52e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-8276a2d0-dd35-47fc-b038-62f94d71477b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584975882-172.17.0.11-1595896877026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-1483120e-8575-456d-a7ff-d89e34b79ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-9b97d23a-f201-4d56-bf34-bdb87f5ecb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-0d244f37-e222-4273-9c1c-d159460b965a,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-9b341e18-9e52-42d8-8614-d7533f14297d,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-d211067a-6633-4194-be92-db223251db54,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-0d2cbc94-6a37-457c-9e38-4cf429e44fad,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-a3d69507-62a9-46e1-8aac-b21accc52e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-8276a2d0-dd35-47fc-b038-62f94d71477b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6561
