reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150165969-172.17.0.15-1595954105965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-d7759fd5-d18b-4e37-beae-3753e38571c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-920b8143-d184-4ca4-a6c0-c95a6d777b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-d8ca563b-5017-4368-8bce-668ee4bbc9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-6b9ff76d-3c4b-43f7-ac1e-8e8028d96de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-4546b143-c316-4276-b3e7-1806b205a5da,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-093a3a6c-4f2c-48b2-9fab-17b9c19e2918,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-1e91c385-4d70-4960-864c-4b86b828cc78,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-9f3ac2c0-deb6-48b6-99b1-a7dbfb295185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150165969-172.17.0.15-1595954105965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-d7759fd5-d18b-4e37-beae-3753e38571c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-920b8143-d184-4ca4-a6c0-c95a6d777b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-d8ca563b-5017-4368-8bce-668ee4bbc9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-6b9ff76d-3c4b-43f7-ac1e-8e8028d96de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-4546b143-c316-4276-b3e7-1806b205a5da,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-093a3a6c-4f2c-48b2-9fab-17b9c19e2918,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-1e91c385-4d70-4960-864c-4b86b828cc78,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-9f3ac2c0-deb6-48b6-99b1-a7dbfb295185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055660418-172.17.0.15-1595954494005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41077,DS-bf4fea6f-0016-4c49-aa0c-0820e5789149,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-9752e883-8bba-4b12-ab68-280e19a02aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-a7b01260-3210-449e-8804-a5e1e2111d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-8971d08b-d322-4acd-83d6-3d35d8eb0aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-4f104924-bc2a-41d3-b349-fcc4bfee4f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-e9477b46-4f79-4e49-93e2-3562850f5bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-cdcbbcf2-aa48-439d-944d-19b9f4c92619,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-fcacbf0b-1a78-4934-bc0b-237252fc9281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055660418-172.17.0.15-1595954494005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41077,DS-bf4fea6f-0016-4c49-aa0c-0820e5789149,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-9752e883-8bba-4b12-ab68-280e19a02aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-a7b01260-3210-449e-8804-a5e1e2111d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-8971d08b-d322-4acd-83d6-3d35d8eb0aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-4f104924-bc2a-41d3-b349-fcc4bfee4f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-e9477b46-4f79-4e49-93e2-3562850f5bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-cdcbbcf2-aa48-439d-944d-19b9f4c92619,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-fcacbf0b-1a78-4934-bc0b-237252fc9281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804263873-172.17.0.15-1595955316717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40223,DS-1c86619d-02c4-411a-83ca-0cfb4453af0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-e31bc97e-4a51-48ca-aee0-52193851e0af,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-0c3b1920-5235-4891-873c-0b952bf306be,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-f07bb912-09d7-4a87-a5c2-0e0bf87ef338,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-e1f083dd-ae4e-468f-87ca-028f85e22db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-213c96ec-d7ba-461d-babb-3b8c7a8dbe57,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-a50093ad-7d0e-41c6-b8ec-c14622522d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-0ee22a71-8714-4b65-8b1e-1c73fba85769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804263873-172.17.0.15-1595955316717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40223,DS-1c86619d-02c4-411a-83ca-0cfb4453af0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-e31bc97e-4a51-48ca-aee0-52193851e0af,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-0c3b1920-5235-4891-873c-0b952bf306be,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-f07bb912-09d7-4a87-a5c2-0e0bf87ef338,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-e1f083dd-ae4e-468f-87ca-028f85e22db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-213c96ec-d7ba-461d-babb-3b8c7a8dbe57,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-a50093ad-7d0e-41c6-b8ec-c14622522d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-0ee22a71-8714-4b65-8b1e-1c73fba85769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477341266-172.17.0.15-1595955357268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35340,DS-e678dea4-4201-4844-888c-da99a083c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-ae252704-fe72-4ae9-a8d1-9559d6381079,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-1404e65f-bc8b-4790-8b3b-af385b0dff69,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-87f4427c-e575-42b9-9d19-28a1d3c36739,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-dfd6e273-9939-4604-9f42-44e869b0770c,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-7c311034-8b7c-432b-8259-b409cca703d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-fb554096-e26d-47dc-9432-28c99355fb81,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-d26d776d-6037-4a5d-875f-860c029a0f2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477341266-172.17.0.15-1595955357268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35340,DS-e678dea4-4201-4844-888c-da99a083c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-ae252704-fe72-4ae9-a8d1-9559d6381079,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-1404e65f-bc8b-4790-8b3b-af385b0dff69,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-87f4427c-e575-42b9-9d19-28a1d3c36739,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-dfd6e273-9939-4604-9f42-44e869b0770c,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-7c311034-8b7c-432b-8259-b409cca703d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-fb554096-e26d-47dc-9432-28c99355fb81,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-d26d776d-6037-4a5d-875f-860c029a0f2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35771369-172.17.0.15-1595955862602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34600,DS-15d2f852-5f9d-4658-9bcd-c9b8984f0670,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-bd9315bc-28fb-422d-b2e0-ae5e3c5215c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-f060b886-af0e-4b9b-b88f-6b13a74f3015,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-515e5f7e-7667-4305-814e-997d6c9544af,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-38b8d016-65ad-4763-8c36-9ced424b951a,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-7077574a-443e-4564-81ef-359dec811ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-67197e00-de74-4513-99a2-faa47e969fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-e3820a7d-c136-413a-a153-7c0fd61f5279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35771369-172.17.0.15-1595955862602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34600,DS-15d2f852-5f9d-4658-9bcd-c9b8984f0670,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-bd9315bc-28fb-422d-b2e0-ae5e3c5215c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-f060b886-af0e-4b9b-b88f-6b13a74f3015,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-515e5f7e-7667-4305-814e-997d6c9544af,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-38b8d016-65ad-4763-8c36-9ced424b951a,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-7077574a-443e-4564-81ef-359dec811ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-67197e00-de74-4513-99a2-faa47e969fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-e3820a7d-c136-413a-a153-7c0fd61f5279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366930059-172.17.0.15-1595955906321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-e4e73aef-2581-4728-a20e-e863d28de5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-81f3f4ad-8c75-48cf-8216-12531e1063ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-b54b356a-d19b-49ca-9885-9cd64cea1df9,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-917f3925-516d-48d8-b69d-e8a23fd9a582,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-44b9f95e-8d8c-4b2f-baac-800502156536,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-1a32bcc8-65bb-49bc-86d2-19a1e9137be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-da0bb42f-ac23-455c-ac56-efe27f79791d,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-7a8055f8-9d04-4be6-8d79-ef02f86a3a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366930059-172.17.0.15-1595955906321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-e4e73aef-2581-4728-a20e-e863d28de5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-81f3f4ad-8c75-48cf-8216-12531e1063ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-b54b356a-d19b-49ca-9885-9cd64cea1df9,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-917f3925-516d-48d8-b69d-e8a23fd9a582,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-44b9f95e-8d8c-4b2f-baac-800502156536,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-1a32bcc8-65bb-49bc-86d2-19a1e9137be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-da0bb42f-ac23-455c-ac56-efe27f79791d,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-7a8055f8-9d04-4be6-8d79-ef02f86a3a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313743803-172.17.0.15-1595955943517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37758,DS-1c11ffa5-13a2-4f52-a828-fd69cef2f444,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-84463243-36f2-4a45-a9f1-21478356cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-49e514da-bb23-4cf7-8462-c20f1c01c379,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-e2dadd58-e63a-4edc-ad04-da1b670e052b,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-7e5d493f-9490-4c42-a522-38bf3c62ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-41d411fa-1399-427c-bf8d-c8163433f615,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-4761aefe-7b36-4560-b0ff-26be928ab9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-34265beb-5dc6-4fa6-86e0-edaef8616770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313743803-172.17.0.15-1595955943517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37758,DS-1c11ffa5-13a2-4f52-a828-fd69cef2f444,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-84463243-36f2-4a45-a9f1-21478356cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-49e514da-bb23-4cf7-8462-c20f1c01c379,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-e2dadd58-e63a-4edc-ad04-da1b670e052b,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-7e5d493f-9490-4c42-a522-38bf3c62ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-41d411fa-1399-427c-bf8d-c8163433f615,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-4761aefe-7b36-4560-b0ff-26be928ab9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-34265beb-5dc6-4fa6-86e0-edaef8616770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119347305-172.17.0.15-1595956750026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-ce711473-7002-4fe0-b3ba-de83e42092d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-29239267-eb2a-431d-9df0-1a30abff9ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-25478bac-5179-4cfd-b764-c4ecda1237cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-e5f36c00-0b91-4c64-bb66-ebad9ea0e05a,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-1f8fd030-591d-4cc3-80fd-5d444ee7ed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-02262ce0-de43-40ef-bbf4-50f4c49b9335,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-873e609e-d7d2-40fc-b829-53790f7b127e,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-fd3b744c-e615-4054-aca1-fb05f3942b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119347305-172.17.0.15-1595956750026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-ce711473-7002-4fe0-b3ba-de83e42092d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-29239267-eb2a-431d-9df0-1a30abff9ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-25478bac-5179-4cfd-b764-c4ecda1237cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-e5f36c00-0b91-4c64-bb66-ebad9ea0e05a,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-1f8fd030-591d-4cc3-80fd-5d444ee7ed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-02262ce0-de43-40ef-bbf4-50f4c49b9335,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-873e609e-d7d2-40fc-b829-53790f7b127e,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-fd3b744c-e615-4054-aca1-fb05f3942b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402544764-172.17.0.15-1595957019787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-4c800d8b-f858-4b17-abb2-14bd0622867d,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-e0aa21be-c76e-43b9-a728-aac293b8a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-aa1eaa20-71d6-441c-8dfa-7c40eed2bcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-2fa4c1ca-6371-4f03-a641-daedc142984b,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-c3a897fa-0621-4684-825e-fcf600945448,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-0ebb3324-25f4-4de9-9000-663c29856bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-23104927-3d13-49b1-919f-705c6ec81244,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-03105b07-9dd2-4836-b94e-678522ca25a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402544764-172.17.0.15-1595957019787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-4c800d8b-f858-4b17-abb2-14bd0622867d,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-e0aa21be-c76e-43b9-a728-aac293b8a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-aa1eaa20-71d6-441c-8dfa-7c40eed2bcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-2fa4c1ca-6371-4f03-a641-daedc142984b,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-c3a897fa-0621-4684-825e-fcf600945448,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-0ebb3324-25f4-4de9-9000-663c29856bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-23104927-3d13-49b1-919f-705c6ec81244,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-03105b07-9dd2-4836-b94e-678522ca25a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528137769-172.17.0.15-1595957352796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-8561590d-2a26-4963-9925-bab51457064e,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-67d0270f-318a-4932-9e60-ed4e63d1e360,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-f8470797-e4ca-4365-b62a-a8a7780c8689,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-923b6c81-0cdf-4d24-b915-cdc63602294b,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-344c3eea-b283-4413-ac4b-272cbe7e7af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-e907b5fa-0c4d-4f43-a5cd-dd5962539f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-fe2afeb1-8c84-4e0e-929e-a1fab6847ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-3ddb90f8-870b-40f8-a8ba-06310584d201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528137769-172.17.0.15-1595957352796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-8561590d-2a26-4963-9925-bab51457064e,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-67d0270f-318a-4932-9e60-ed4e63d1e360,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-f8470797-e4ca-4365-b62a-a8a7780c8689,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-923b6c81-0cdf-4d24-b915-cdc63602294b,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-344c3eea-b283-4413-ac4b-272cbe7e7af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-e907b5fa-0c4d-4f43-a5cd-dd5962539f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-fe2afeb1-8c84-4e0e-929e-a1fab6847ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-3ddb90f8-870b-40f8-a8ba-06310584d201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685685410-172.17.0.15-1595957622969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36816,DS-c97b62da-af3f-4576-be34-5a98d10c092a,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-d16788d5-f8e0-444b-9782-7658633e6f20,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-0d29b6fb-6123-41bc-af2c-040c7ecd280d,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-953e3509-f628-4de7-8ea7-010b57568632,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-d0ea7110-e196-47f5-a4c6-8070a50a3b96,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-b255b8aa-061b-464e-813a-f0dab8252185,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-378bb615-11ee-4cf8-a97d-79175a4b0c39,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-69cc24c3-2225-4209-a9ca-dcab28490f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685685410-172.17.0.15-1595957622969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36816,DS-c97b62da-af3f-4576-be34-5a98d10c092a,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-d16788d5-f8e0-444b-9782-7658633e6f20,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-0d29b6fb-6123-41bc-af2c-040c7ecd280d,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-953e3509-f628-4de7-8ea7-010b57568632,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-d0ea7110-e196-47f5-a4c6-8070a50a3b96,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-b255b8aa-061b-464e-813a-f0dab8252185,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-378bb615-11ee-4cf8-a97d-79175a4b0c39,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-69cc24c3-2225-4209-a9ca-dcab28490f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756397732-172.17.0.15-1595957884920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38939,DS-ffb18cd1-c956-4bc5-a66c-c4b89bf50a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-28e9b0ab-e0db-4d28-95c8-9a25c0fb29b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-afb9c03c-6dcc-4643-9b67-1ac4cb1e2877,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-5f310843-7f04-42f0-a9bb-2bed8583aead,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-918f586d-4ef2-40c0-b005-a74f54da9a63,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-0211181a-661d-4bb0-880d-3b3da53d16cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-6673f3ea-1820-42dc-83f2-327e3978cbed,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-5344184e-e068-4e1a-90d2-e259c3206dce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756397732-172.17.0.15-1595957884920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38939,DS-ffb18cd1-c956-4bc5-a66c-c4b89bf50a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-28e9b0ab-e0db-4d28-95c8-9a25c0fb29b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-afb9c03c-6dcc-4643-9b67-1ac4cb1e2877,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-5f310843-7f04-42f0-a9bb-2bed8583aead,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-918f586d-4ef2-40c0-b005-a74f54da9a63,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-0211181a-661d-4bb0-880d-3b3da53d16cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-6673f3ea-1820-42dc-83f2-327e3978cbed,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-5344184e-e068-4e1a-90d2-e259c3206dce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335521721-172.17.0.15-1595958144887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37147,DS-487ebcb0-1eec-49f3-b523-5383ff91203f,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-09b03ad6-6e5f-421a-a32c-787b7c7ae810,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-48ea1c3f-2f22-47c1-815a-a874c705ec1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-d30370e0-66fc-4293-9976-b67f22e34e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-8f6d7386-5913-4636-bd48-d62a23e66f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-673b9480-604a-41d8-bcc0-00dd2c5686d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-3e460318-09af-4a38-9f31-cccfb309a575,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-bb268d35-2310-4a93-b5c1-4284d3dba4b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335521721-172.17.0.15-1595958144887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37147,DS-487ebcb0-1eec-49f3-b523-5383ff91203f,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-09b03ad6-6e5f-421a-a32c-787b7c7ae810,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-48ea1c3f-2f22-47c1-815a-a874c705ec1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-d30370e0-66fc-4293-9976-b67f22e34e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-8f6d7386-5913-4636-bd48-d62a23e66f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-673b9480-604a-41d8-bcc0-00dd2c5686d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-3e460318-09af-4a38-9f31-cccfb309a575,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-bb268d35-2310-4a93-b5c1-4284d3dba4b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852329996-172.17.0.15-1595958212130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-66a2169e-09c2-4be6-bc8f-d91a2202cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-c558c7a3-b03f-48e2-9960-cc6ccec42b46,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-213242d4-3aee-47fd-b549-b4cb26b17b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-3541e184-d2bc-4a04-8157-ad11bc0d1549,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-023add45-a492-46fc-b14c-80b6f87ae7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-a51fb8e4-f92f-4dca-b321-1b2597be1c82,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-ece3aa03-f2c5-4eca-9a70-8b0707e1db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-66c7dc87-1ab0-47a7-949d-1001fc72c36c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852329996-172.17.0.15-1595958212130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-66a2169e-09c2-4be6-bc8f-d91a2202cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-c558c7a3-b03f-48e2-9960-cc6ccec42b46,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-213242d4-3aee-47fd-b549-b4cb26b17b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-3541e184-d2bc-4a04-8157-ad11bc0d1549,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-023add45-a492-46fc-b14c-80b6f87ae7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-a51fb8e4-f92f-4dca-b321-1b2597be1c82,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-ece3aa03-f2c5-4eca-9a70-8b0707e1db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-66c7dc87-1ab0-47a7-949d-1001fc72c36c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147270552-172.17.0.15-1595958461104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41514,DS-d733349a-ce86-4dbc-bdcb-8f1634b97baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-dd14e0d1-4390-489a-ba1f-d472a48e2e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-e1bc7bfa-83f1-4a2c-a88f-c40d9f900422,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-1e8fbd1b-0762-49ed-ae56-22db5d59df50,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-2191c861-e2a1-4be1-800a-e59c5553b5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-83e365c6-4b57-4e40-8fb0-4d4fdcaa549f,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-033b9048-eae9-4910-96d4-2a8b3f57db11,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-c9a421c3-0f14-49cd-af66-2ef8303322dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147270552-172.17.0.15-1595958461104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41514,DS-d733349a-ce86-4dbc-bdcb-8f1634b97baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-dd14e0d1-4390-489a-ba1f-d472a48e2e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-e1bc7bfa-83f1-4a2c-a88f-c40d9f900422,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-1e8fbd1b-0762-49ed-ae56-22db5d59df50,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-2191c861-e2a1-4be1-800a-e59c5553b5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-83e365c6-4b57-4e40-8fb0-4d4fdcaa549f,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-033b9048-eae9-4910-96d4-2a8b3f57db11,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-c9a421c3-0f14-49cd-af66-2ef8303322dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474274797-172.17.0.15-1595958504213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41138,DS-90cac170-f567-4c94-a448-b222de35e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-187f0953-dacc-48c2-9fb0-1f929c5d320f,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-6dcf7841-93c4-42bf-aa4e-afe47ee5cd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-019532fb-aeba-4ecc-9e2e-acfb45cba161,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-b2ff1659-42e6-4745-a334-6051079d3cee,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-b7b53d15-9188-4062-a9bd-f9c37ad3a649,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-03fceeff-5e35-4a12-bbe6-15d3c1c891c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-a5e53e76-97b0-4e60-9a05-eec3998e34d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474274797-172.17.0.15-1595958504213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41138,DS-90cac170-f567-4c94-a448-b222de35e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-187f0953-dacc-48c2-9fb0-1f929c5d320f,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-6dcf7841-93c4-42bf-aa4e-afe47ee5cd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-019532fb-aeba-4ecc-9e2e-acfb45cba161,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-b2ff1659-42e6-4745-a334-6051079d3cee,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-b7b53d15-9188-4062-a9bd-f9c37ad3a649,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-03fceeff-5e35-4a12-bbe6-15d3c1c891c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-a5e53e76-97b0-4e60-9a05-eec3998e34d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561615085-172.17.0.15-1595958736351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46155,DS-fe7939f3-6a89-4468-b598-147c232d9d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-0a43e3c3-bcc8-4300-b344-a22e6128a983,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-ecb3a4a2-3523-4b7e-baac-5bb6b47ab798,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-e237f0cc-cba1-400d-906a-923ea46772ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-8a41d912-29cb-4cb7-8b27-1d5e462728cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-4eff2254-3eb0-41d2-a9c4-aa57dcd31cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-cbde8ab1-9f44-463e-9388-21f3670aa484,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-38cc1d1b-4692-42dc-8192-4ea869a9dcd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561615085-172.17.0.15-1595958736351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46155,DS-fe7939f3-6a89-4468-b598-147c232d9d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-0a43e3c3-bcc8-4300-b344-a22e6128a983,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-ecb3a4a2-3523-4b7e-baac-5bb6b47ab798,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-e237f0cc-cba1-400d-906a-923ea46772ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-8a41d912-29cb-4cb7-8b27-1d5e462728cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-4eff2254-3eb0-41d2-a9c4-aa57dcd31cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-cbde8ab1-9f44-463e-9388-21f3670aa484,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-38cc1d1b-4692-42dc-8192-4ea869a9dcd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394314157-172.17.0.15-1595959280220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-147716c3-fa09-43d3-a957-4c00c5ad87bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-9a558a58-a55b-481f-ba0f-fd6ef466bb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-7ac674bc-bfc4-4b29-8fc5-d64abf1c8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-a9beba2e-0755-4e48-9f63-9abd5b2d4c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-7780a632-9c0e-4717-a1d2-79ed3f9baf42,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-b96a2153-3f7f-48f3-b58c-5e1a764884bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-52df4eca-8c09-4644-a4a8-e45d01736dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-21ea0875-d9f2-4aad-b576-d3af0ac54aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394314157-172.17.0.15-1595959280220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-147716c3-fa09-43d3-a957-4c00c5ad87bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-9a558a58-a55b-481f-ba0f-fd6ef466bb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-7ac674bc-bfc4-4b29-8fc5-d64abf1c8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-a9beba2e-0755-4e48-9f63-9abd5b2d4c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-7780a632-9c0e-4717-a1d2-79ed3f9baf42,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-b96a2153-3f7f-48f3-b58c-5e1a764884bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-52df4eca-8c09-4644-a4a8-e45d01736dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-21ea0875-d9f2-4aad-b576-d3af0ac54aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145365509-172.17.0.15-1595959319699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37074,DS-eb5f4da9-9b33-4b92-b7fb-20ad65c6b503,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-b7cc9b8d-aa08-424d-8773-3351d1900c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-7ef7d7eb-21dc-411f-96e3-e6effb42b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-2a028a7d-87be-45c6-bdf5-08683bccc9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-dabcae3a-6a9d-4cbf-ae94-80e0b71f6caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-782a7ca3-f5d6-4632-9e2b-8b74a1f68ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-5b349743-3269-4edd-b657-63ee95c2bcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-4eafe54c-8c61-42ec-a5b0-ba832366c209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145365509-172.17.0.15-1595959319699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37074,DS-eb5f4da9-9b33-4b92-b7fb-20ad65c6b503,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-b7cc9b8d-aa08-424d-8773-3351d1900c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-7ef7d7eb-21dc-411f-96e3-e6effb42b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-2a028a7d-87be-45c6-bdf5-08683bccc9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-dabcae3a-6a9d-4cbf-ae94-80e0b71f6caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-782a7ca3-f5d6-4632-9e2b-8b74a1f68ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-5b349743-3269-4edd-b657-63ee95c2bcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-4eafe54c-8c61-42ec-a5b0-ba832366c209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5529
