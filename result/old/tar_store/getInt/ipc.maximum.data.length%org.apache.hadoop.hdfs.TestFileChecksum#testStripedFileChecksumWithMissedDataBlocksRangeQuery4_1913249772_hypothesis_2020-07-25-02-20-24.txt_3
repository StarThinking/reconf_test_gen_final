reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649880141-172.17.0.10-1595643888566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-73dd321c-4872-4821-b2fe-90ff5303c503,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-1293ffb0-3022-46f5-a057-77cb30335bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-4dcd7399-c29b-4f89-b179-241f526e63e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-da1f260f-516e-4fc4-a980-71773ce0f0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-1778de31-ff29-4baa-bb3e-6085f7b9b976,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-91ed7b53-7737-4e7b-b5b7-3137697530d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-91e9f07d-2967-4065-8588-d5ae97e84aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-89c48ca4-7e48-42e2-b14e-3a863cd6bf35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649880141-172.17.0.10-1595643888566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-73dd321c-4872-4821-b2fe-90ff5303c503,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-1293ffb0-3022-46f5-a057-77cb30335bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-4dcd7399-c29b-4f89-b179-241f526e63e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-da1f260f-516e-4fc4-a980-71773ce0f0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-1778de31-ff29-4baa-bb3e-6085f7b9b976,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-91ed7b53-7737-4e7b-b5b7-3137697530d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-91e9f07d-2967-4065-8588-d5ae97e84aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-89c48ca4-7e48-42e2-b14e-3a863cd6bf35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928905540-172.17.0.10-1595644112968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37846,DS-a7de0ba1-c9fc-468a-9bff-01272c70f155,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-9d26d583-5c8b-432c-81d0-fb1fa7ad77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-d7782f4f-4932-4849-b34e-04b504763bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-b406e077-b9d8-4aef-8b49-8badb67d01e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-c4f0f760-4263-439d-8db9-5ad83dcb3736,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-c211681d-2921-4b18-b5fd-52609c8c877b,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-3a312b84-602b-4a39-8e13-a59705131760,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-210ec716-77c1-44b6-b054-34f13bb5edcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928905540-172.17.0.10-1595644112968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37846,DS-a7de0ba1-c9fc-468a-9bff-01272c70f155,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-9d26d583-5c8b-432c-81d0-fb1fa7ad77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-d7782f4f-4932-4849-b34e-04b504763bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-b406e077-b9d8-4aef-8b49-8badb67d01e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-c4f0f760-4263-439d-8db9-5ad83dcb3736,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-c211681d-2921-4b18-b5fd-52609c8c877b,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-3a312b84-602b-4a39-8e13-a59705131760,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-210ec716-77c1-44b6-b054-34f13bb5edcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111666340-172.17.0.10-1595645059039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-e403d509-56c9-46ae-97a0-046b69584967,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-806d53b1-5621-4f66-954a-04e98914e778,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-d138d314-bf95-4bb3-b143-860c45e1a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-bbfc3ee4-f4fc-472d-994e-07ad6e207c64,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-05622a98-bddd-4c2e-a371-bf1711c068ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-3a29d178-35b3-4f29-8069-1a4b119afc12,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-8bb72fb0-812f-4aed-b111-90e8eedd475d,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-bb9a16b7-d00c-4fdb-980a-57fc2fdc31a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111666340-172.17.0.10-1595645059039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-e403d509-56c9-46ae-97a0-046b69584967,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-806d53b1-5621-4f66-954a-04e98914e778,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-d138d314-bf95-4bb3-b143-860c45e1a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-bbfc3ee4-f4fc-472d-994e-07ad6e207c64,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-05622a98-bddd-4c2e-a371-bf1711c068ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-3a29d178-35b3-4f29-8069-1a4b119afc12,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-8bb72fb0-812f-4aed-b111-90e8eedd475d,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-bb9a16b7-d00c-4fdb-980a-57fc2fdc31a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771309457-172.17.0.10-1595645096491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42134,DS-a3d2482c-183a-4714-8286-8b3e7c7c142e,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-62dbd95f-e6ad-439c-a5f3-aec280d8089d,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-8fd2bb7f-f35d-45bc-9842-502994937045,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-0285b719-2e4f-4f01-a906-73a1255bcab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-ea3f1759-d60d-4ad4-b37d-3b7f9be700fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-688df4be-6e2b-41c7-822c-fea1b8c375a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-d5f3f8e6-3c12-4c4e-acf8-8c445e759422,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-a3aaafb8-2f8b-497c-9c03-2ee6579ec5c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771309457-172.17.0.10-1595645096491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42134,DS-a3d2482c-183a-4714-8286-8b3e7c7c142e,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-62dbd95f-e6ad-439c-a5f3-aec280d8089d,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-8fd2bb7f-f35d-45bc-9842-502994937045,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-0285b719-2e4f-4f01-a906-73a1255bcab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-ea3f1759-d60d-4ad4-b37d-3b7f9be700fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-688df4be-6e2b-41c7-822c-fea1b8c375a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-d5f3f8e6-3c12-4c4e-acf8-8c445e759422,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-a3aaafb8-2f8b-497c-9c03-2ee6579ec5c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248859993-172.17.0.10-1595645431980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40684,DS-f3bf9348-f49b-40b7-b891-d05eda5310fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-2d8de4c4-394f-433b-81d9-d91515ebd5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-6c3eac9f-b67b-4028-b924-69ac98cd04c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1bb9f57e-4976-4be2-8175-858eb16a16b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-9e5646d5-7565-4a9b-b1a0-3e749276f7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-6ae9dd3e-a3bb-4608-be6a-99a1a90c12d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-4d72afa2-9e49-4150-ad0c-5844a465a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-5361ead2-955b-4e09-b6ec-128e24434e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248859993-172.17.0.10-1595645431980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40684,DS-f3bf9348-f49b-40b7-b891-d05eda5310fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-2d8de4c4-394f-433b-81d9-d91515ebd5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-6c3eac9f-b67b-4028-b924-69ac98cd04c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1bb9f57e-4976-4be2-8175-858eb16a16b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-9e5646d5-7565-4a9b-b1a0-3e749276f7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-6ae9dd3e-a3bb-4608-be6a-99a1a90c12d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-4d72afa2-9e49-4150-ad0c-5844a465a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-5361ead2-955b-4e09-b6ec-128e24434e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589356142-172.17.0.10-1595645595204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43944,DS-8f7758d0-ab7c-42f1-a030-4f8901c86fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-8729293d-9398-49f0-bdcb-c3b68ff41558,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-55141f53-ea1f-4023-8065-0a2d79214805,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-fb6c35fd-36c1-4c03-8e06-02d1fdd9a93a,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-1f125857-edc8-430d-abab-d7a9c85684a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-faf675af-66a4-48cb-866e-5c7c74d10cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-5c2fb47a-8b2d-4f16-bddf-f11a6354694f,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-15854158-2284-49c7-83c6-d95de7c5d2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589356142-172.17.0.10-1595645595204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43944,DS-8f7758d0-ab7c-42f1-a030-4f8901c86fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-8729293d-9398-49f0-bdcb-c3b68ff41558,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-55141f53-ea1f-4023-8065-0a2d79214805,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-fb6c35fd-36c1-4c03-8e06-02d1fdd9a93a,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-1f125857-edc8-430d-abab-d7a9c85684a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-faf675af-66a4-48cb-866e-5c7c74d10cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-5c2fb47a-8b2d-4f16-bddf-f11a6354694f,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-15854158-2284-49c7-83c6-d95de7c5d2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291626909-172.17.0.10-1595645768101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-30fd4995-8067-4186-aa3b-706f758568fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-8230abd8-e2df-41bf-bc17-2931fd91101e,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-269b70a7-dc1b-4918-9ca4-7b47cd632195,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-019f825e-a6c6-41c0-a317-4a1d3db191c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-7ff45b61-f8d4-4cda-afe4-2050b6c54a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-89743b98-c4d4-411d-87a5-b3dd3ab039ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-8aadeba7-5a7d-405e-a2f3-e28d9d9f7bde,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-a4167858-4957-47e6-823c-26d1c3f9b0c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291626909-172.17.0.10-1595645768101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-30fd4995-8067-4186-aa3b-706f758568fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-8230abd8-e2df-41bf-bc17-2931fd91101e,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-269b70a7-dc1b-4918-9ca4-7b47cd632195,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-019f825e-a6c6-41c0-a317-4a1d3db191c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-7ff45b61-f8d4-4cda-afe4-2050b6c54a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-89743b98-c4d4-411d-87a5-b3dd3ab039ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-8aadeba7-5a7d-405e-a2f3-e28d9d9f7bde,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-a4167858-4957-47e6-823c-26d1c3f9b0c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998168156-172.17.0.10-1595645923075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-eaaa8b81-1f02-4c7b-b906-1717ee2a0e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-37febcc4-8ffb-4cdd-9ce8-287120c90c86,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-8b246a8d-68a3-4f04-9114-0588c68b5978,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b60e816e-10ba-46ca-9176-e931aca27eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-8c9d48ef-13f8-4181-bc4f-811db69fab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-0113abfd-246b-4a71-97de-d638ff7c0b31,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-69f4155e-ff47-41da-8731-37e9181215b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-fd46b334-cc26-40d8-a8a9-a0996f0d93d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998168156-172.17.0.10-1595645923075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-eaaa8b81-1f02-4c7b-b906-1717ee2a0e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-37febcc4-8ffb-4cdd-9ce8-287120c90c86,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-8b246a8d-68a3-4f04-9114-0588c68b5978,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b60e816e-10ba-46ca-9176-e931aca27eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-8c9d48ef-13f8-4181-bc4f-811db69fab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-0113abfd-246b-4a71-97de-d638ff7c0b31,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-69f4155e-ff47-41da-8731-37e9181215b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-fd46b334-cc26-40d8-a8a9-a0996f0d93d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151585878-172.17.0.10-1595646692991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38797,DS-79bd3c1c-ce97-4408-be92-a44a58f03ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-40e6a172-8c1c-4d03-86ef-fc55b0463db6,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-60a282ac-0cfa-4082-9b8f-3cac6f2f088d,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-84929a8c-4b5c-4fbf-888d-f8a3eaa55b56,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-29014258-17b2-4b4d-b782-fb80d7ee86b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-c4b55920-789b-49a8-8c14-62d3c84441af,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-b2107f64-3a74-4163-af17-4df4a51a5281,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-987088cc-aea9-407d-a8eb-4afc3f90a91e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151585878-172.17.0.10-1595646692991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38797,DS-79bd3c1c-ce97-4408-be92-a44a58f03ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-40e6a172-8c1c-4d03-86ef-fc55b0463db6,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-60a282ac-0cfa-4082-9b8f-3cac6f2f088d,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-84929a8c-4b5c-4fbf-888d-f8a3eaa55b56,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-29014258-17b2-4b4d-b782-fb80d7ee86b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-c4b55920-789b-49a8-8c14-62d3c84441af,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-b2107f64-3a74-4163-af17-4df4a51a5281,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-987088cc-aea9-407d-a8eb-4afc3f90a91e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094790813-172.17.0.10-1595647147095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-509c8751-624c-4116-9e16-0108281c7499,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-b73f460f-3dce-44eb-bfab-98aac985901f,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-db22100d-3579-48c8-ad9e-bae27774b87d,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-8b8dd118-1f5f-406d-9e62-294cba3da95f,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-7340ad1f-db90-471c-9a77-91bf9cb0ada6,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-277af313-5d29-4fc2-ba32-02002e3ed055,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-64991741-ff3e-44b8-88ed-047c906e0eff,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-31501557-4147-4fdb-951e-37b1cc032221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094790813-172.17.0.10-1595647147095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-509c8751-624c-4116-9e16-0108281c7499,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-b73f460f-3dce-44eb-bfab-98aac985901f,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-db22100d-3579-48c8-ad9e-bae27774b87d,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-8b8dd118-1f5f-406d-9e62-294cba3da95f,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-7340ad1f-db90-471c-9a77-91bf9cb0ada6,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-277af313-5d29-4fc2-ba32-02002e3ed055,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-64991741-ff3e-44b8-88ed-047c906e0eff,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-31501557-4147-4fdb-951e-37b1cc032221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875029260-172.17.0.10-1595647599779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-637eaca8-d304-47e8-a459-f62f46dde168,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-2c23b67b-c075-4319-9702-3369cf022de1,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-c7da78d2-db6c-4e25-80af-ab320886f819,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-e9ce3e46-9025-42ee-aa07-91d0a34f27e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-3071e473-ee2b-4a7a-974e-6aa0c13c3138,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-ac34d110-5d08-4beb-867c-0da08991fc61,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-9c8e3f75-d714-45d7-8c04-ccefd69444ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-459bacf8-7bbc-421f-a65f-f0264fd336b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875029260-172.17.0.10-1595647599779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-637eaca8-d304-47e8-a459-f62f46dde168,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-2c23b67b-c075-4319-9702-3369cf022de1,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-c7da78d2-db6c-4e25-80af-ab320886f819,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-e9ce3e46-9025-42ee-aa07-91d0a34f27e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-3071e473-ee2b-4a7a-974e-6aa0c13c3138,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-ac34d110-5d08-4beb-867c-0da08991fc61,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-9c8e3f75-d714-45d7-8c04-ccefd69444ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-459bacf8-7bbc-421f-a65f-f0264fd336b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92773277-172.17.0.10-1595647631170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36120,DS-c46bfa34-263e-4742-bd0b-1ec5331021ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-7fd02be6-c8eb-490d-9fb8-269567529c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-8e05f0e5-e75d-4ae6-9232-f9f49d80f040,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-00a20ec7-49ac-4607-a82b-147a07070ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-2e0b8572-22ad-4b4c-aa25-66d53b4950df,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-8c8cf816-2758-436e-a1fb-5840aafb805f,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-cd6c8d91-6df1-4549-b81a-b33bb4ef4630,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-d5ae64a7-7564-4430-8907-787ee9f72e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92773277-172.17.0.10-1595647631170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36120,DS-c46bfa34-263e-4742-bd0b-1ec5331021ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-7fd02be6-c8eb-490d-9fb8-269567529c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-8e05f0e5-e75d-4ae6-9232-f9f49d80f040,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-00a20ec7-49ac-4607-a82b-147a07070ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-2e0b8572-22ad-4b4c-aa25-66d53b4950df,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-8c8cf816-2758-436e-a1fb-5840aafb805f,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-cd6c8d91-6df1-4549-b81a-b33bb4ef4630,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-d5ae64a7-7564-4430-8907-787ee9f72e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109438281-172.17.0.10-1595647753297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33141,DS-6dfd6890-ac69-4453-b836-346e1a016348,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-e871713b-208d-4758-8e9b-447ed87d1913,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-f587a55e-aef1-4791-851e-a3013de925ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-f000713b-950e-4170-89e1-07c929c8fa88,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-a0392f49-f364-455a-be5b-a30dfb13027d,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-3047c4bb-631c-4dff-bfe5-3163ddc49d67,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-154708c9-7be5-4ac0-87a0-457d1cf20af1,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-8a43031e-5151-458d-a52d-4c7b5ea70a67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109438281-172.17.0.10-1595647753297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33141,DS-6dfd6890-ac69-4453-b836-346e1a016348,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-e871713b-208d-4758-8e9b-447ed87d1913,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-f587a55e-aef1-4791-851e-a3013de925ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-f000713b-950e-4170-89e1-07c929c8fa88,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-a0392f49-f364-455a-be5b-a30dfb13027d,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-3047c4bb-631c-4dff-bfe5-3163ddc49d67,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-154708c9-7be5-4ac0-87a0-457d1cf20af1,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-8a43031e-5151-458d-a52d-4c7b5ea70a67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729215595-172.17.0.10-1595648252096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44396,DS-6e2b1b01-315e-4ef3-9b52-68cf9b03a83f,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-b8da5020-25b9-4fcb-becc-5bb6c7dc55f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-2389989c-56cb-41a2-962d-576a29e63764,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-1b65c146-eefb-4d95-9a09-7289f81bcc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-2fdc6e1c-091f-474a-a2d4-6446ff660efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-949d12ce-5a72-41b9-8d14-fe506e21123d,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-15e8838b-6121-412e-9cd0-bd9e8af1ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-7d20b83a-6aef-4746-8a92-2dada9abdbdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729215595-172.17.0.10-1595648252096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44396,DS-6e2b1b01-315e-4ef3-9b52-68cf9b03a83f,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-b8da5020-25b9-4fcb-becc-5bb6c7dc55f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-2389989c-56cb-41a2-962d-576a29e63764,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-1b65c146-eefb-4d95-9a09-7289f81bcc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-2fdc6e1c-091f-474a-a2d4-6446ff660efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-949d12ce-5a72-41b9-8d14-fe506e21123d,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-15e8838b-6121-412e-9cd0-bd9e8af1ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-7d20b83a-6aef-4746-8a92-2dada9abdbdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804421442-172.17.0.10-1595648454522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-6dd8d66f-98f2-4ada-90ad-f4b22d75cd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-739689e0-ddb5-4a16-843a-245f95960923,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-6b4cf268-a360-403c-b450-838bd54a22a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-8f09870b-3bfa-47c5-a869-8582cc176982,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-2930b0e6-1c4c-401d-bc15-026ac2f9b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-7e209833-b545-4393-b026-ca078c25ae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-2b2775d8-c321-4835-a20c-1bc3f684631e,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-a88cc0d3-f719-47f7-8698-5e3087d1918a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804421442-172.17.0.10-1595648454522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-6dd8d66f-98f2-4ada-90ad-f4b22d75cd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-739689e0-ddb5-4a16-843a-245f95960923,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-6b4cf268-a360-403c-b450-838bd54a22a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-8f09870b-3bfa-47c5-a869-8582cc176982,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-2930b0e6-1c4c-401d-bc15-026ac2f9b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-7e209833-b545-4393-b026-ca078c25ae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-2b2775d8-c321-4835-a20c-1bc3f684631e,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-a88cc0d3-f719-47f7-8698-5e3087d1918a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727969863-172.17.0.10-1595649169201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37962,DS-f4b1c742-cbc8-4e0f-9f48-ed01ae8b5ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-774bbec9-6918-4d34-9076-136859fef171,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-33691490-db05-477b-a8c2-1fb6b9db57d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-673d963e-48fe-47bc-ba5f-ca9dd267dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-7bb88016-ee73-4b9f-87fc-4a7de5c28e53,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-9abd9b09-95b3-454a-bf41-08ed56ef4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-3bbbebcd-d2d0-4b5b-b6d2-6d9f0d87becf,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-c516023f-717d-4574-b11f-fff0c0811fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727969863-172.17.0.10-1595649169201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37962,DS-f4b1c742-cbc8-4e0f-9f48-ed01ae8b5ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-774bbec9-6918-4d34-9076-136859fef171,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-33691490-db05-477b-a8c2-1fb6b9db57d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-673d963e-48fe-47bc-ba5f-ca9dd267dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-7bb88016-ee73-4b9f-87fc-4a7de5c28e53,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-9abd9b09-95b3-454a-bf41-08ed56ef4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-3bbbebcd-d2d0-4b5b-b6d2-6d9f0d87becf,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-c516023f-717d-4574-b11f-fff0c0811fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077462700-172.17.0.10-1595649431364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39419,DS-cf4fd959-8b91-4005-bd8f-e71c8dd4caa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-33f49a66-cb72-4404-9415-762d3c0a2560,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-b6d8e493-8c3b-48d9-9d18-0d711d0a6303,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-f217df45-85d1-4fea-aba6-b26f8838cdae,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-062f55ed-63b3-4bd1-834f-a730b09872b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-90e1ecab-34c7-4ca0-9d15-721240fd29dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-2383355f-9cec-46fb-a628-886524f29aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-8c8f5db1-bca9-4013-b2f5-17933e15b937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077462700-172.17.0.10-1595649431364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39419,DS-cf4fd959-8b91-4005-bd8f-e71c8dd4caa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-33f49a66-cb72-4404-9415-762d3c0a2560,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-b6d8e493-8c3b-48d9-9d18-0d711d0a6303,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-f217df45-85d1-4fea-aba6-b26f8838cdae,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-062f55ed-63b3-4bd1-834f-a730b09872b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-90e1ecab-34c7-4ca0-9d15-721240fd29dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-2383355f-9cec-46fb-a628-886524f29aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-8c8f5db1-bca9-4013-b2f5-17933e15b937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6418
