reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323805992-172.17.0.17-1595875924543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-7ed0ff2e-499a-4e3f-8968-9b2182034eac,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-00a6c907-4912-4068-8ab1-c5d7bf59225f,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-b0bcfae3-292a-441d-b800-2ba6887ba54b,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-ad628c14-eaea-4a83-838d-beb1e9b36b83,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-172f9b88-0599-45fd-9dbb-805a96a6eaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-358eab72-fcc0-46aa-a1ab-4d13eb79da81,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-b2f765a9-ba01-4403-b7d6-fa23db58941b,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-e48f8efe-1529-42a4-b714-233ce20ee87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323805992-172.17.0.17-1595875924543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-7ed0ff2e-499a-4e3f-8968-9b2182034eac,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-00a6c907-4912-4068-8ab1-c5d7bf59225f,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-b0bcfae3-292a-441d-b800-2ba6887ba54b,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-ad628c14-eaea-4a83-838d-beb1e9b36b83,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-172f9b88-0599-45fd-9dbb-805a96a6eaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-358eab72-fcc0-46aa-a1ab-4d13eb79da81,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-b2f765a9-ba01-4403-b7d6-fa23db58941b,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-e48f8efe-1529-42a4-b714-233ce20ee87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329367288-172.17.0.17-1595875967577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-c113146b-b929-4d2b-ae14-167f07780ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-c928d004-d257-4ddc-b3f8-5612612b7aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-ddbba6e4-3acc-4007-9297-97050410bc24,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-db8d7556-f52c-41eb-984b-0d26f7e8b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-a65b7b37-81a5-4460-877b-0c0a2385d50f,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-d73a3e77-5af5-4943-8fd9-8c6b811f1007,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-dfeede07-8ed1-4bee-aa58-3a3f5e39bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-5e35849f-520d-46f1-9039-c219e8ffeb9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329367288-172.17.0.17-1595875967577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-c113146b-b929-4d2b-ae14-167f07780ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-c928d004-d257-4ddc-b3f8-5612612b7aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-ddbba6e4-3acc-4007-9297-97050410bc24,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-db8d7556-f52c-41eb-984b-0d26f7e8b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-a65b7b37-81a5-4460-877b-0c0a2385d50f,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-d73a3e77-5af5-4943-8fd9-8c6b811f1007,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-dfeede07-8ed1-4bee-aa58-3a3f5e39bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-5e35849f-520d-46f1-9039-c219e8ffeb9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001635251-172.17.0.17-1595876374417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38471,DS-43468d32-a8c4-48fd-aba1-97c4f7599c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-605e4fef-434c-4d9e-83d1-e42a68d895b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-83591482-abad-4601-a2b5-716f7103a1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-413a9e80-ea50-4af7-bbaa-1b6c619caff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-798aea33-7b46-4f56-b4d2-efa2c8057cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-56dd6446-be7d-4fbb-af04-ce5804f52c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-a959978b-1de5-4751-a0e4-6b027b8d810f,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-91b60dec-9559-4940-87df-6c2bb1415b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001635251-172.17.0.17-1595876374417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38471,DS-43468d32-a8c4-48fd-aba1-97c4f7599c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-605e4fef-434c-4d9e-83d1-e42a68d895b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-83591482-abad-4601-a2b5-716f7103a1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-413a9e80-ea50-4af7-bbaa-1b6c619caff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-798aea33-7b46-4f56-b4d2-efa2c8057cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-56dd6446-be7d-4fbb-af04-ce5804f52c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-a959978b-1de5-4751-a0e4-6b027b8d810f,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-91b60dec-9559-4940-87df-6c2bb1415b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774407499-172.17.0.17-1595876406166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-b6fb2489-6f2a-46b4-b131-e255be001072,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-cf98a619-c813-41f5-9808-a5ebdd55b07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-c5155a80-d111-4f07-be92-569d79752bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-678d9f07-8bcb-44d7-b237-e2632137dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-4f03e55c-6d70-4c62-9899-ea765a16e2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-3ef5d6dc-41cc-425f-9f62-328c0b09d9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-3826f8e2-b06b-4371-8a63-07ebfa00e655,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-6f891f26-75e6-48a0-ad8f-d96b7184388d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774407499-172.17.0.17-1595876406166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-b6fb2489-6f2a-46b4-b131-e255be001072,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-cf98a619-c813-41f5-9808-a5ebdd55b07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-c5155a80-d111-4f07-be92-569d79752bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-678d9f07-8bcb-44d7-b237-e2632137dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-4f03e55c-6d70-4c62-9899-ea765a16e2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-3ef5d6dc-41cc-425f-9f62-328c0b09d9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-3826f8e2-b06b-4371-8a63-07ebfa00e655,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-6f891f26-75e6-48a0-ad8f-d96b7184388d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417227207-172.17.0.17-1595876631438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-d9b8bb5b-ca3c-41b6-8e01-2907182b8ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-84394b5d-8ea0-46ab-98bf-74f1006787d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-62d12d3f-ba99-4785-b3d8-ec830ff72bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-119d27ce-9d0b-4f59-8b12-25037f8b1aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-c8b0d4cf-be16-44a8-98fa-b181c0476b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-fea5e92c-7925-47d8-96fc-5125e39f83c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-1cfe4980-9b2e-4ba7-b096-9587bb6219e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-3ac40f94-8e8f-440e-b585-d8d3d869b980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417227207-172.17.0.17-1595876631438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-d9b8bb5b-ca3c-41b6-8e01-2907182b8ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-84394b5d-8ea0-46ab-98bf-74f1006787d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-62d12d3f-ba99-4785-b3d8-ec830ff72bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-119d27ce-9d0b-4f59-8b12-25037f8b1aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-c8b0d4cf-be16-44a8-98fa-b181c0476b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-fea5e92c-7925-47d8-96fc-5125e39f83c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-1cfe4980-9b2e-4ba7-b096-9587bb6219e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-3ac40f94-8e8f-440e-b585-d8d3d869b980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148956945-172.17.0.17-1595876965711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-73e6dbff-83cf-4b09-a288-15e5db19f324,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-c781df83-9f33-4e90-a334-0d53614e9652,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-fdb92326-6243-4ea3-bc69-b8e59f313d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-c6f992be-3c14-4195-94b5-c8fd772123ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-6ec00b92-a7ec-41b2-a2fb-b65c30fde582,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-3696109b-1216-4ea2-993e-a766ce6a4215,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-48335916-a520-47e6-99e5-6e83fbd3eb98,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-941f6a81-90f9-4c37-b351-34d72bbf9a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148956945-172.17.0.17-1595876965711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-73e6dbff-83cf-4b09-a288-15e5db19f324,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-c781df83-9f33-4e90-a334-0d53614e9652,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-fdb92326-6243-4ea3-bc69-b8e59f313d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-c6f992be-3c14-4195-94b5-c8fd772123ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-6ec00b92-a7ec-41b2-a2fb-b65c30fde582,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-3696109b-1216-4ea2-993e-a766ce6a4215,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-48335916-a520-47e6-99e5-6e83fbd3eb98,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-941f6a81-90f9-4c37-b351-34d72bbf9a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91359043-172.17.0.17-1595877249792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40646,DS-4b058c11-8186-4657-bc7a-f17aa781b5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-8f11f480-b647-43d4-ae36-8bf9a4c33c85,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-73354720-96c9-4337-89b7-822d75cc42ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-e59ef57d-6650-47ee-aa4c-b7ed4279c371,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-1a99cb06-9a8a-4762-84be-2446bab23569,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-4bb99735-4a7e-4b37-9ecf-1d1d07394873,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-2dbde3e1-4968-4dd4-b70e-874efcc30d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-a4b89581-0162-4fd8-bf17-e994cda3a4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91359043-172.17.0.17-1595877249792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40646,DS-4b058c11-8186-4657-bc7a-f17aa781b5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-8f11f480-b647-43d4-ae36-8bf9a4c33c85,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-73354720-96c9-4337-89b7-822d75cc42ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-e59ef57d-6650-47ee-aa4c-b7ed4279c371,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-1a99cb06-9a8a-4762-84be-2446bab23569,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-4bb99735-4a7e-4b37-9ecf-1d1d07394873,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-2dbde3e1-4968-4dd4-b70e-874efcc30d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-a4b89581-0162-4fd8-bf17-e994cda3a4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659983120-172.17.0.17-1595877503108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-e8f0a1b6-4971-4835-b36b-d883dff7f591,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-1c6396c2-6028-47dd-9c4d-caa4a983ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-efb39e97-0baf-429c-ad14-b8c244e57331,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-e3297707-29ad-432f-8a6f-55c24ef2bed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-3ef2c90d-4160-4c64-afa5-25525e3fa88c,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-0c9a6dc0-3f57-43c8-8034-17172948bfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-786fe8d4-90a5-404c-8f1c-00be64f53915,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-ac9da9c4-03f6-4dd1-a311-ae9e5edf9f8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659983120-172.17.0.17-1595877503108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-e8f0a1b6-4971-4835-b36b-d883dff7f591,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-1c6396c2-6028-47dd-9c4d-caa4a983ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-efb39e97-0baf-429c-ad14-b8c244e57331,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-e3297707-29ad-432f-8a6f-55c24ef2bed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-3ef2c90d-4160-4c64-afa5-25525e3fa88c,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-0c9a6dc0-3f57-43c8-8034-17172948bfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-786fe8d4-90a5-404c-8f1c-00be64f53915,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-ac9da9c4-03f6-4dd1-a311-ae9e5edf9f8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939817703-172.17.0.17-1595877657329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-a3ccb562-5091-4ce0-b2b2-ba671324167e,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-820e1cc4-6de4-4023-9f71-6a2d7f68f1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-f90fc53d-ffba-4390-a575-88f5418c049a,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4ff5f759-8e5c-4646-be11-db3114dd32a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-caa6e4e8-e9f5-4224-9f70-3b9b96dc4490,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-280fb755-57c2-4ce9-8336-a91002cfe87c,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-ccaa0bc6-50cc-4129-9b6b-c8b101a3c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-6e862c85-596e-45d0-80d5-e0753f96bf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939817703-172.17.0.17-1595877657329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-a3ccb562-5091-4ce0-b2b2-ba671324167e,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-820e1cc4-6de4-4023-9f71-6a2d7f68f1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-f90fc53d-ffba-4390-a575-88f5418c049a,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4ff5f759-8e5c-4646-be11-db3114dd32a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-caa6e4e8-e9f5-4224-9f70-3b9b96dc4490,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-280fb755-57c2-4ce9-8336-a91002cfe87c,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-ccaa0bc6-50cc-4129-9b6b-c8b101a3c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-6e862c85-596e-45d0-80d5-e0753f96bf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879936251-172.17.0.17-1595877727207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-0cfe5533-6ed0-4d27-b72b-0c68cb1ceec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-b8b68e8a-c550-4c1c-add3-ab78252b884d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-f4863254-4eda-4f56-b3ac-fedce8a22e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-1c545a75-d376-4c00-9c46-de360f5d2f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-7070ca0e-491d-4d9f-9534-bc03a626432c,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-49b710ba-5a65-49d5-87ad-67b632cf9169,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-ad4363ef-f685-4517-b2d6-fc6bf245d4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-c91c3636-1d65-4ff3-bf41-2cc602de447b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879936251-172.17.0.17-1595877727207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-0cfe5533-6ed0-4d27-b72b-0c68cb1ceec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-b8b68e8a-c550-4c1c-add3-ab78252b884d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-f4863254-4eda-4f56-b3ac-fedce8a22e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-1c545a75-d376-4c00-9c46-de360f5d2f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-7070ca0e-491d-4d9f-9534-bc03a626432c,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-49b710ba-5a65-49d5-87ad-67b632cf9169,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-ad4363ef-f685-4517-b2d6-fc6bf245d4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-c91c3636-1d65-4ff3-bf41-2cc602de447b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219529208-172.17.0.17-1595878107166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-055146fe-b8b5-4d8e-899a-19806bd586ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-92947f6b-bda6-4764-b2a2-1a52f5123a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-86c93a46-a35c-4f56-91b7-9b914f97b26e,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-e326b257-173c-4569-85c5-74c6754c3e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-242c80ef-9233-429b-aa46-b06a72390869,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-715a4f37-d15c-44b1-8d3b-97904c36a273,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-75af0b00-9474-45a5-bcf6-6d2e8d777a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-49eb2bf7-d5c0-4fd9-becc-8a41f965b497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219529208-172.17.0.17-1595878107166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-055146fe-b8b5-4d8e-899a-19806bd586ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-92947f6b-bda6-4764-b2a2-1a52f5123a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-86c93a46-a35c-4f56-91b7-9b914f97b26e,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-e326b257-173c-4569-85c5-74c6754c3e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-242c80ef-9233-429b-aa46-b06a72390869,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-715a4f37-d15c-44b1-8d3b-97904c36a273,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-75af0b00-9474-45a5-bcf6-6d2e8d777a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-49eb2bf7-d5c0-4fd9-becc-8a41f965b497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888832018-172.17.0.17-1595878181128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-3b375527-a5d4-4ecc-b2d5-96f8fede1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-1c617071-08d6-41bd-a813-8fc481e0dd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-072d4e2d-289f-414a-97d2-6194bc7a9e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-5f2949db-726f-4b1d-b960-0530d5a2c5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-bf3cfec2-040a-4b9c-9910-0688d3343d02,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-d95a875a-0f66-46d1-9c08-bcfb220bec52,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-c1a24671-b5f3-47b4-93da-87d70551776e,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-0e93bc06-ab1e-44f4-a0af-619ea57c6c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888832018-172.17.0.17-1595878181128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-3b375527-a5d4-4ecc-b2d5-96f8fede1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-1c617071-08d6-41bd-a813-8fc481e0dd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-072d4e2d-289f-414a-97d2-6194bc7a9e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-5f2949db-726f-4b1d-b960-0530d5a2c5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-bf3cfec2-040a-4b9c-9910-0688d3343d02,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-d95a875a-0f66-46d1-9c08-bcfb220bec52,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-c1a24671-b5f3-47b4-93da-87d70551776e,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-0e93bc06-ab1e-44f4-a0af-619ea57c6c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378378733-172.17.0.17-1595879202565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34236,DS-5b5e3a75-e878-44aa-bf34-1e602340262d,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-11e14c1f-a99f-4489-8d7e-dde2d94fae18,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-5e7acfb2-9bde-43e5-9865-73b66f92deaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-8037db5e-3b4d-401c-8651-9e5b12874d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-63a179c4-670c-4ad6-90fa-1f472776072a,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-db470fc4-6d47-44d9-a4de-2e36e2ba0eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-f1bbbd8e-e869-4a82-849f-0f539752b408,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-306fbb15-b231-4cb5-9697-e36f3b41df19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378378733-172.17.0.17-1595879202565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34236,DS-5b5e3a75-e878-44aa-bf34-1e602340262d,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-11e14c1f-a99f-4489-8d7e-dde2d94fae18,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-5e7acfb2-9bde-43e5-9865-73b66f92deaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-8037db5e-3b4d-401c-8651-9e5b12874d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-63a179c4-670c-4ad6-90fa-1f472776072a,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-db470fc4-6d47-44d9-a4de-2e36e2ba0eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-f1bbbd8e-e869-4a82-849f-0f539752b408,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-306fbb15-b231-4cb5-9697-e36f3b41df19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261901272-172.17.0.17-1595879458803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-047a067a-2b9c-4e84-814c-a177a854503d,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-d26d58bd-a158-472c-97af-383b33bd218e,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-dfe3033a-e5a4-4c4c-91d9-699ab2ef2fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-5df56941-da68-4af0-92bf-b146a6527c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-c7ee0234-ed7e-4f4f-8377-0ada151f260a,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-853a83af-9d3c-44ae-b182-d5a30374bb42,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-8ecdd38c-9289-4de1-8c95-228c51972af6,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-911e9f27-6139-46bc-86fd-5a0b445e86ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261901272-172.17.0.17-1595879458803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-047a067a-2b9c-4e84-814c-a177a854503d,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-d26d58bd-a158-472c-97af-383b33bd218e,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-dfe3033a-e5a4-4c4c-91d9-699ab2ef2fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-5df56941-da68-4af0-92bf-b146a6527c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-c7ee0234-ed7e-4f4f-8377-0ada151f260a,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-853a83af-9d3c-44ae-b182-d5a30374bb42,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-8ecdd38c-9289-4de1-8c95-228c51972af6,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-911e9f27-6139-46bc-86fd-5a0b445e86ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533912505-172.17.0.17-1595879633257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39354,DS-e646f059-04f0-4efe-b0b4-2b1f14aec3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-b1706dba-bc7f-499a-befc-86f2b04af2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-4332d49c-1f06-4fe9-bb00-8846152e15cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-5d0e7881-2c14-49ca-8b5b-9ea59dde8344,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-a1adc18c-9195-4dd8-9a8c-697108d47d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-9b3f5c78-e1c6-4d91-bec6-6a0d93af0d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-61997b30-c654-4333-b6df-0fb1ee65b31c,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-a8c5bb00-62fd-403f-85e9-698f23d523f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533912505-172.17.0.17-1595879633257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39354,DS-e646f059-04f0-4efe-b0b4-2b1f14aec3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-b1706dba-bc7f-499a-befc-86f2b04af2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-4332d49c-1f06-4fe9-bb00-8846152e15cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-5d0e7881-2c14-49ca-8b5b-9ea59dde8344,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-a1adc18c-9195-4dd8-9a8c-697108d47d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-9b3f5c78-e1c6-4d91-bec6-6a0d93af0d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-61997b30-c654-4333-b6df-0fb1ee65b31c,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-a8c5bb00-62fd-403f-85e9-698f23d523f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505672937-172.17.0.17-1595880143141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45926,DS-46e79348-806e-46ea-b284-e696ad960e29,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-105f1c7f-5245-40c6-bad8-214275898084,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-5dd86e7b-e974-4909-abca-53520a0c3e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-175e1c1c-3316-4a5f-9b0c-5171e5b974da,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-191827bb-60e3-4bd7-8186-f611b87d106d,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-f929f200-3237-4796-adee-17091f781053,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-2449032b-6314-4fd0-a9f5-76ac73b3f488,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-ea800210-55c5-41a5-8e0c-14c338498a2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505672937-172.17.0.17-1595880143141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45926,DS-46e79348-806e-46ea-b284-e696ad960e29,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-105f1c7f-5245-40c6-bad8-214275898084,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-5dd86e7b-e974-4909-abca-53520a0c3e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-175e1c1c-3316-4a5f-9b0c-5171e5b974da,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-191827bb-60e3-4bd7-8186-f611b87d106d,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-f929f200-3237-4796-adee-17091f781053,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-2449032b-6314-4fd0-a9f5-76ac73b3f488,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-ea800210-55c5-41a5-8e0c-14c338498a2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5334
