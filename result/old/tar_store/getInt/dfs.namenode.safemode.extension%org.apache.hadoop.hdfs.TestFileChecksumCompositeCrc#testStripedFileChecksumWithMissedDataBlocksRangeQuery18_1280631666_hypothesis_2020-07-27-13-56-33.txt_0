reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31675014-172.17.0.13-1595858211057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36058,DS-2d9a917d-a745-4f53-991d-14e60ea904c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-5343d3b8-745d-4a56-b2b5-d3617510fca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-c8a07723-ffa5-49c7-b130-31939922045e,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-121eac69-bcdc-4490-8570-2d0bd14001e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-2ae74f29-21f9-43f4-816f-25e3d92cba23,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-5a25fee3-c391-4e5d-831b-c8e5c252ecae,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-631db681-df15-49c9-a6ac-6f83df91c3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-6c61736d-1722-4b0c-a424-084b9af5822a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31675014-172.17.0.13-1595858211057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36058,DS-2d9a917d-a745-4f53-991d-14e60ea904c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-5343d3b8-745d-4a56-b2b5-d3617510fca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-c8a07723-ffa5-49c7-b130-31939922045e,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-121eac69-bcdc-4490-8570-2d0bd14001e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-2ae74f29-21f9-43f4-816f-25e3d92cba23,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-5a25fee3-c391-4e5d-831b-c8e5c252ecae,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-631db681-df15-49c9-a6ac-6f83df91c3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-6c61736d-1722-4b0c-a424-084b9af5822a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546271694-172.17.0.13-1595858510394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-d7bc2aa4-664a-4e15-b73b-add8f9dc580e,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-9485d85d-a125-47f3-95be-cb42dd91382a,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-dcc119dd-1d89-4154-9816-d2d75a397eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-eda19ba0-0253-4887-a9e9-7518a47a4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-d0b90e63-641d-4f8f-82a1-eedc7b2e3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-f737f072-38d0-4410-aa3c-8310a2c8ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-8f9981a0-6a9d-4fee-bc2c-d8a2a275afcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-4e781eb9-3a0d-4b5a-93fc-2a0c9a15dfd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546271694-172.17.0.13-1595858510394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-d7bc2aa4-664a-4e15-b73b-add8f9dc580e,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-9485d85d-a125-47f3-95be-cb42dd91382a,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-dcc119dd-1d89-4154-9816-d2d75a397eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-eda19ba0-0253-4887-a9e9-7518a47a4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-d0b90e63-641d-4f8f-82a1-eedc7b2e3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-f737f072-38d0-4410-aa3c-8310a2c8ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-8f9981a0-6a9d-4fee-bc2c-d8a2a275afcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-4e781eb9-3a0d-4b5a-93fc-2a0c9a15dfd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116016496-172.17.0.13-1595858610320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-74c623fc-06f0-40d9-991c-a602e05f1867,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-4c694b1d-103e-4301-8e8e-e3f377a3fea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-f4e87e8a-418e-4853-b477-04ee342a36a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-eaa350b9-0da4-4f1b-a26b-a81513b4bd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-bbd27735-e003-46e9-9f59-fb33162ce029,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-6652ad8d-9aad-44cc-a8d9-9656d44a3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-6ac63381-b164-46e2-84cb-caf909eb1df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-da318cc6-8916-4d81-ab58-c66251d06cfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116016496-172.17.0.13-1595858610320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-74c623fc-06f0-40d9-991c-a602e05f1867,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-4c694b1d-103e-4301-8e8e-e3f377a3fea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-f4e87e8a-418e-4853-b477-04ee342a36a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-eaa350b9-0da4-4f1b-a26b-a81513b4bd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-bbd27735-e003-46e9-9f59-fb33162ce029,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-6652ad8d-9aad-44cc-a8d9-9656d44a3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-6ac63381-b164-46e2-84cb-caf909eb1df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-da318cc6-8916-4d81-ab58-c66251d06cfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364045832-172.17.0.13-1595858643229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-ea06d0fc-85ff-4f05-b577-e94e84b99457,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-f77abeb8-fea2-46a6-ad61-ff05d79b115b,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-546b8ac1-1d78-4c3b-839d-6530fd524299,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-0110120a-96e4-4cb5-bc42-0b7428d9a235,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-8ce0b0cb-a28c-449c-bc2b-7864cae43bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-88272cc3-beb3-4eb9-989f-aced4934455a,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-c563f13d-b388-425d-bb61-4e7fddd70ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-e2c78cc5-1502-41b2-9c8f-0acaa7d5f3e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364045832-172.17.0.13-1595858643229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-ea06d0fc-85ff-4f05-b577-e94e84b99457,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-f77abeb8-fea2-46a6-ad61-ff05d79b115b,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-546b8ac1-1d78-4c3b-839d-6530fd524299,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-0110120a-96e4-4cb5-bc42-0b7428d9a235,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-8ce0b0cb-a28c-449c-bc2b-7864cae43bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-88272cc3-beb3-4eb9-989f-aced4934455a,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-c563f13d-b388-425d-bb61-4e7fddd70ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-e2c78cc5-1502-41b2-9c8f-0acaa7d5f3e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278774304-172.17.0.13-1595859048686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33433,DS-f1c8369b-f511-4cec-8f1f-915a6fe2f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-46f7ba3a-9e8c-49b5-8d90-a7d4b177002b,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-8c1ffdd6-a7aa-44cf-b7d3-32d85440dc17,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-e3779f51-440b-4f36-954e-67a580f247d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-3a0549de-e32e-4a38-9362-0bf7e587cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-ed152d11-6c08-48f5-be29-9e6efdbe8dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-0af302ab-1e56-4099-a023-79e42f326741,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-8bc90d95-88da-4c64-836b-71bf2de8a2e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278774304-172.17.0.13-1595859048686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33433,DS-f1c8369b-f511-4cec-8f1f-915a6fe2f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-46f7ba3a-9e8c-49b5-8d90-a7d4b177002b,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-8c1ffdd6-a7aa-44cf-b7d3-32d85440dc17,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-e3779f51-440b-4f36-954e-67a580f247d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-3a0549de-e32e-4a38-9362-0bf7e587cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-ed152d11-6c08-48f5-be29-9e6efdbe8dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-0af302ab-1e56-4099-a023-79e42f326741,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-8bc90d95-88da-4c64-836b-71bf2de8a2e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735905470-172.17.0.13-1595859183877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41321,DS-d63f5bd2-c9a2-4505-b2c5-4f5159182cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-578d1e18-8202-4d95-a4c9-de54623702a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-4cccb986-97df-46c6-a1f4-d9d69a8dacc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-2e456fbb-5c64-4999-88b3-7b6ce0f157b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-fad97738-3872-47e1-91cf-0d58749dc301,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-141da4d4-ebdb-44b9-8fc7-fda147194747,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-0c9487ce-93f2-4a3d-a8c2-338fdf8cf303,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-49fc393a-e268-4512-ba7e-1859c0000535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735905470-172.17.0.13-1595859183877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41321,DS-d63f5bd2-c9a2-4505-b2c5-4f5159182cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-578d1e18-8202-4d95-a4c9-de54623702a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-4cccb986-97df-46c6-a1f4-d9d69a8dacc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-2e456fbb-5c64-4999-88b3-7b6ce0f157b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-fad97738-3872-47e1-91cf-0d58749dc301,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-141da4d4-ebdb-44b9-8fc7-fda147194747,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-0c9487ce-93f2-4a3d-a8c2-338fdf8cf303,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-49fc393a-e268-4512-ba7e-1859c0000535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433813506-172.17.0.13-1595859390509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39951,DS-67dab0d7-06e3-4428-8fe0-97703dd9c433,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-d6a6a99a-d381-40b1-acf2-b6bbbcd04a58,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-55c3c6a1-d7fa-4815-9bd7-6fd965b6b6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-de3d2001-53bc-4a7b-a849-a699fe1b7b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-271f9d79-4d2b-41a8-9696-5cd1d16bec30,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-28531e55-1d34-4c85-8461-60d4ec0307f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-956969d6-8631-48b8-9b84-469ee11feecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-7803194b-d904-4dba-a624-a8ca56202e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433813506-172.17.0.13-1595859390509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39951,DS-67dab0d7-06e3-4428-8fe0-97703dd9c433,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-d6a6a99a-d381-40b1-acf2-b6bbbcd04a58,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-55c3c6a1-d7fa-4815-9bd7-6fd965b6b6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-de3d2001-53bc-4a7b-a849-a699fe1b7b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-271f9d79-4d2b-41a8-9696-5cd1d16bec30,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-28531e55-1d34-4c85-8461-60d4ec0307f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-956969d6-8631-48b8-9b84-469ee11feecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-7803194b-d904-4dba-a624-a8ca56202e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088962514-172.17.0.13-1595859570638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41479,DS-91ce2681-4073-4d2f-93af-cedcd3a0fba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-714c546f-6dde-4399-95e2-c0685ce06a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-d3ef9d59-daef-4a3c-87fb-a370499740d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-04a5fd60-fa9f-41dc-9e7a-b1fb51c2f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-bc2fff20-937f-4d80-871d-f58a2f797889,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-45849ba7-726d-4051-823a-022e28050313,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-cbc5a677-079c-476c-80f8-1d4e9179bc06,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-8051c817-74a9-4600-8e4b-016dc733c150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088962514-172.17.0.13-1595859570638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41479,DS-91ce2681-4073-4d2f-93af-cedcd3a0fba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-714c546f-6dde-4399-95e2-c0685ce06a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-d3ef9d59-daef-4a3c-87fb-a370499740d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-04a5fd60-fa9f-41dc-9e7a-b1fb51c2f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-bc2fff20-937f-4d80-871d-f58a2f797889,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-45849ba7-726d-4051-823a-022e28050313,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-cbc5a677-079c-476c-80f8-1d4e9179bc06,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-8051c817-74a9-4600-8e4b-016dc733c150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207652618-172.17.0.13-1595860631275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-d6dc2280-4bec-4ef3-a320-f0088c5645db,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-2ed8de61-5819-492a-8c24-42e482977559,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-efa78a79-a481-43d9-a95a-0284f60c105a,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-eaeffd91-1471-44be-b786-985d8f043e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-904dbf02-dd9c-4f30-9b81-cbac5f3eff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-bfe9b363-aadb-453d-8eb1-b87799341c41,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-e35118a2-4add-4c8f-9542-e23feefda220,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-0fb9cef1-79bf-4f87-8d2e-2030c6955b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207652618-172.17.0.13-1595860631275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-d6dc2280-4bec-4ef3-a320-f0088c5645db,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-2ed8de61-5819-492a-8c24-42e482977559,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-efa78a79-a481-43d9-a95a-0284f60c105a,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-eaeffd91-1471-44be-b786-985d8f043e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-904dbf02-dd9c-4f30-9b81-cbac5f3eff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-bfe9b363-aadb-453d-8eb1-b87799341c41,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-e35118a2-4add-4c8f-9542-e23feefda220,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-0fb9cef1-79bf-4f87-8d2e-2030c6955b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518591536-172.17.0.13-1595860798532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-2a0bd6a6-061a-4c7d-8cb8-bbd3a69c6136,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-f42c37be-0c5c-4088-86f6-ac2c1dd749a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-b2b85969-b40f-4124-a05b-3974a1df6c44,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-34e8c443-ffca-44fb-8160-37d5ec00e039,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-7e8d38b6-0a08-434f-83d6-ebf80a8874af,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-71f62ed4-ebb0-435c-a673-e47c51b4494a,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-4c619797-5015-4ae8-99bc-eb299248025b,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-41dd4988-ce22-41d2-9887-cf191a9c57dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518591536-172.17.0.13-1595860798532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-2a0bd6a6-061a-4c7d-8cb8-bbd3a69c6136,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-f42c37be-0c5c-4088-86f6-ac2c1dd749a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-b2b85969-b40f-4124-a05b-3974a1df6c44,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-34e8c443-ffca-44fb-8160-37d5ec00e039,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-7e8d38b6-0a08-434f-83d6-ebf80a8874af,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-71f62ed4-ebb0-435c-a673-e47c51b4494a,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-4c619797-5015-4ae8-99bc-eb299248025b,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-41dd4988-ce22-41d2-9887-cf191a9c57dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848587435-172.17.0.13-1595861172045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43096,DS-f08377c3-7a1a-455c-9c5e-b2f3fad398e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-86395035-43e0-4393-a349-80911f5877f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-2a6be66d-ce58-4c80-b8db-e9eb3f2dc94d,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-3a6e51c6-bd6b-4fa6-968b-08e175784420,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-468139cc-b79b-4dc4-995a-be575be48de8,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-b3bdc3b6-2426-4e7f-845a-6aec5089b22a,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-b2b66107-6ed2-4304-a9cc-dfc14aed97bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-53b56629-496c-42b7-bad1-f2d575f008f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848587435-172.17.0.13-1595861172045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43096,DS-f08377c3-7a1a-455c-9c5e-b2f3fad398e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-86395035-43e0-4393-a349-80911f5877f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-2a6be66d-ce58-4c80-b8db-e9eb3f2dc94d,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-3a6e51c6-bd6b-4fa6-968b-08e175784420,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-468139cc-b79b-4dc4-995a-be575be48de8,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-b3bdc3b6-2426-4e7f-845a-6aec5089b22a,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-b2b66107-6ed2-4304-a9cc-dfc14aed97bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-53b56629-496c-42b7-bad1-f2d575f008f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988412550-172.17.0.13-1595861247250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32777,DS-8030ebe5-8592-48f6-9635-5e23acf7d88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-45d11c0d-6dbc-405b-8249-c44012557d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-934b59ac-3704-4f01-9453-08a2379d2f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-4ab2d441-940d-4018-9998-3165b86c4825,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-2d7c0769-1e23-4cfc-9008-eefe889109dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-e52f4995-d8f2-4c08-9848-b4e0513ff46a,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-834e2007-a3e4-4274-82fa-b5e98391121e,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-ba0e6be5-b078-47f8-a218-632ec15ac1c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988412550-172.17.0.13-1595861247250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32777,DS-8030ebe5-8592-48f6-9635-5e23acf7d88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-45d11c0d-6dbc-405b-8249-c44012557d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-934b59ac-3704-4f01-9453-08a2379d2f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-4ab2d441-940d-4018-9998-3165b86c4825,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-2d7c0769-1e23-4cfc-9008-eefe889109dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-e52f4995-d8f2-4c08-9848-b4e0513ff46a,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-834e2007-a3e4-4274-82fa-b5e98391121e,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-ba0e6be5-b078-47f8-a218-632ec15ac1c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313634271-172.17.0.13-1595861448843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-e668d21b-3e8a-4c75-90b5-7b1f21806f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-e7382173-66f7-457f-8f68-a83258e227be,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-682905ab-9d9d-49f3-b1b8-5af23c770fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-aa4e82bc-21b8-479a-8ce5-73d120832453,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-0b741c3a-083f-4699-be57-149208f7b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-62ff273d-4309-4892-a7b0-224bb4b77d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-431ca6d9-d6b9-4009-a279-a1e3ebbe19e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-ac0b4124-b374-41cb-9ffe-d046c671954f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313634271-172.17.0.13-1595861448843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-e668d21b-3e8a-4c75-90b5-7b1f21806f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-e7382173-66f7-457f-8f68-a83258e227be,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-682905ab-9d9d-49f3-b1b8-5af23c770fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-aa4e82bc-21b8-479a-8ce5-73d120832453,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-0b741c3a-083f-4699-be57-149208f7b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-62ff273d-4309-4892-a7b0-224bb4b77d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-431ca6d9-d6b9-4009-a279-a1e3ebbe19e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-ac0b4124-b374-41cb-9ffe-d046c671954f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085480434-172.17.0.13-1595861489037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43050,DS-6190db93-a2a1-46f0-bcff-26350a929273,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-d2461021-bc84-4a13-82d5-7b77047cd236,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-d07903b8-fa49-4cf1-9833-b7c0cb4327e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-90d11b59-3e65-48a5-87f4-6c1f88171766,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-a90283f8-7209-45fc-8075-9d77ac382369,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-3dfb075a-4e2f-4614-8d28-9947867a5fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-547a8a7c-91a7-40f0-ae78-49ae2244185c,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-89c3c434-833f-4f5d-ba9b-cc20cd74317f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085480434-172.17.0.13-1595861489037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43050,DS-6190db93-a2a1-46f0-bcff-26350a929273,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-d2461021-bc84-4a13-82d5-7b77047cd236,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-d07903b8-fa49-4cf1-9833-b7c0cb4327e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-90d11b59-3e65-48a5-87f4-6c1f88171766,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-a90283f8-7209-45fc-8075-9d77ac382369,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-3dfb075a-4e2f-4614-8d28-9947867a5fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-547a8a7c-91a7-40f0-ae78-49ae2244185c,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-89c3c434-833f-4f5d-ba9b-cc20cd74317f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070671499-172.17.0.13-1595862099423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44283,DS-39591e67-2e47-457a-87b9-7851908540df,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-7bb31987-720a-4641-9b77-24d609b04bea,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-a522b490-7663-444d-9d97-3ba1e628aeae,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-c9c9a3ee-94e2-4adc-b18e-5afab235def8,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-1f637f1e-692c-45d5-8f0e-623f478c3b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-f363b19d-b066-4781-9194-250c545a5575,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-2b2e1640-e82c-4dfe-b41f-66f306d7da0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-5477f07e-9b8a-436f-9482-106aad2ad7ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070671499-172.17.0.13-1595862099423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44283,DS-39591e67-2e47-457a-87b9-7851908540df,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-7bb31987-720a-4641-9b77-24d609b04bea,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-a522b490-7663-444d-9d97-3ba1e628aeae,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-c9c9a3ee-94e2-4adc-b18e-5afab235def8,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-1f637f1e-692c-45d5-8f0e-623f478c3b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-f363b19d-b066-4781-9194-250c545a5575,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-2b2e1640-e82c-4dfe-b41f-66f306d7da0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-5477f07e-9b8a-436f-9482-106aad2ad7ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506608696-172.17.0.13-1595862201066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33780,DS-f91d66a3-7668-4daf-97bc-d255e23b7b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-2003b293-2d62-494b-bfa2-1acc980644af,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-9b767d6e-4d2a-4947-b643-1060e49eb53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-f42cd046-acf8-4a91-a9e8-a79b1eb38f43,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-28400dd4-a169-47ec-ba6d-492bd361820b,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-3535bde1-a099-4e08-a514-46573f518c59,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-be47d42f-5865-45a9-8b5e-27a1716e00c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-29855e50-5dd2-42b4-9e6f-3296e0b16937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506608696-172.17.0.13-1595862201066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33780,DS-f91d66a3-7668-4daf-97bc-d255e23b7b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-2003b293-2d62-494b-bfa2-1acc980644af,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-9b767d6e-4d2a-4947-b643-1060e49eb53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-f42cd046-acf8-4a91-a9e8-a79b1eb38f43,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-28400dd4-a169-47ec-ba6d-492bd361820b,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-3535bde1-a099-4e08-a514-46573f518c59,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-be47d42f-5865-45a9-8b5e-27a1716e00c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-29855e50-5dd2-42b4-9e6f-3296e0b16937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428238265-172.17.0.13-1595862348608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-7a9ea172-507a-48c8-b9ef-7d657455fbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-acc1a80e-c516-45a9-a797-c6a9bbd5d058,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0b091e34-87f0-4a03-920e-53684355a558,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-5761cf52-4d9f-418e-ba64-ef6552cba221,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-5280a69e-8405-43ec-9bdc-a9f611c68206,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-f5f14d06-19bf-4e49-b9cb-aca4deb5465f,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-52b4bd2c-c3ec-4520-9e1f-9b7a62bf0c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-063770ae-d418-44d0-88f9-802e2acd7a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428238265-172.17.0.13-1595862348608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-7a9ea172-507a-48c8-b9ef-7d657455fbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-acc1a80e-c516-45a9-a797-c6a9bbd5d058,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0b091e34-87f0-4a03-920e-53684355a558,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-5761cf52-4d9f-418e-ba64-ef6552cba221,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-5280a69e-8405-43ec-9bdc-a9f611c68206,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-f5f14d06-19bf-4e49-b9cb-aca4deb5465f,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-52b4bd2c-c3ec-4520-9e1f-9b7a62bf0c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-063770ae-d418-44d0-88f9-802e2acd7a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881026033-172.17.0.13-1595862493802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40010,DS-671b7915-c8eb-4405-a5b8-967a3a12e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-7fda99c2-116c-4997-859f-4e6b8fc8796b,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-9464a7b2-981d-4a55-8023-acf869d75552,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-3c4fbcae-9060-4f88-8aee-d0849d03071c,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-af9122d9-dbf1-4696-86b4-f96d9f37c260,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-59179684-5b89-410c-abae-3abdda0827db,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-2e779efa-115a-4b0f-87d8-166cacb91b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-6a708afb-b77d-4c41-be6a-fd3df2f03660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881026033-172.17.0.13-1595862493802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40010,DS-671b7915-c8eb-4405-a5b8-967a3a12e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-7fda99c2-116c-4997-859f-4e6b8fc8796b,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-9464a7b2-981d-4a55-8023-acf869d75552,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-3c4fbcae-9060-4f88-8aee-d0849d03071c,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-af9122d9-dbf1-4696-86b4-f96d9f37c260,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-59179684-5b89-410c-abae-3abdda0827db,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-2e779efa-115a-4b0f-87d8-166cacb91b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-6a708afb-b77d-4c41-be6a-fd3df2f03660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288206176-172.17.0.13-1595862845481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-72cf2555-2f4f-4eb7-8bc3-91e7ae038d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-876b372f-14d7-4e27-92df-2482ea45d995,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-8072abee-1803-40f0-b131-00dc050e46f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-131877a3-cd1a-488f-9138-dcf574a405d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-18e077fd-217f-450c-bbd5-0e27b53b22a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-bc18da1d-e25e-4e11-ba94-48d9c359e630,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-0e13116d-5083-4418-bae0-487b89f606b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-de3ca894-23a6-4d92-b781-2b727377b4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288206176-172.17.0.13-1595862845481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-72cf2555-2f4f-4eb7-8bc3-91e7ae038d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-876b372f-14d7-4e27-92df-2482ea45d995,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-8072abee-1803-40f0-b131-00dc050e46f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-131877a3-cd1a-488f-9138-dcf574a405d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-18e077fd-217f-450c-bbd5-0e27b53b22a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-bc18da1d-e25e-4e11-ba94-48d9c359e630,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-0e13116d-5083-4418-bae0-487b89f606b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-de3ca894-23a6-4d92-b781-2b727377b4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5157
