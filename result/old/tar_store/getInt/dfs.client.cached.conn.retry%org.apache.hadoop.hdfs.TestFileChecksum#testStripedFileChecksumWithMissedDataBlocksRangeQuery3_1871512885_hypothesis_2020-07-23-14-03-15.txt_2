reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942051010-172.17.0.2-1595513218398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41783,DS-68580d3d-1771-4937-a3c7-7032888ad9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-ad904bb1-e928-4f0a-abc7-c0d1a4b2c766,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-4d5204ff-8c1c-4304-975d-277dfb442a77,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-c609f9f3-c8ab-4d40-9086-a84469abc995,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-89d07210-0224-41ac-9c0a-a7f008c3efc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-42bb947f-cc5d-4682-b62f-764889215b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-7e4ad56d-c216-40c7-97bf-de4c7442877d,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-b029ac41-75a3-4b51-8680-d470575a2e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942051010-172.17.0.2-1595513218398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41783,DS-68580d3d-1771-4937-a3c7-7032888ad9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-ad904bb1-e928-4f0a-abc7-c0d1a4b2c766,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-4d5204ff-8c1c-4304-975d-277dfb442a77,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-c609f9f3-c8ab-4d40-9086-a84469abc995,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-89d07210-0224-41ac-9c0a-a7f008c3efc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-42bb947f-cc5d-4682-b62f-764889215b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-7e4ad56d-c216-40c7-97bf-de4c7442877d,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-b029ac41-75a3-4b51-8680-d470575a2e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995676153-172.17.0.2-1595513326463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-b9f2807b-832e-413a-90b4-2d5680faaf94,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-b131ecce-d684-4d5e-b723-9250ad0096d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-7aa34654-42b3-475e-b426-53e5a9bc92f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-492ffaad-481a-45fa-8077-f87b73d35426,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-cf90bf26-dc9b-43d9-9608-82657e605d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-35f79b41-48e7-4a1c-ab0b-577d4cad54b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-683531b8-848e-4a3c-ae57-c63e250c900e,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-171b54af-99f8-44d3-b8c7-f313982bfc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995676153-172.17.0.2-1595513326463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-b9f2807b-832e-413a-90b4-2d5680faaf94,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-b131ecce-d684-4d5e-b723-9250ad0096d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-7aa34654-42b3-475e-b426-53e5a9bc92f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-492ffaad-481a-45fa-8077-f87b73d35426,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-cf90bf26-dc9b-43d9-9608-82657e605d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-35f79b41-48e7-4a1c-ab0b-577d4cad54b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-683531b8-848e-4a3c-ae57-c63e250c900e,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-171b54af-99f8-44d3-b8c7-f313982bfc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934039953-172.17.0.2-1595513471243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-1768abf9-8927-4abc-a610-19a2be0a6943,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-628b6d14-b39d-4e86-bfd8-1aeacac864c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-b4fc2444-09e7-4e7b-9f93-989577c949a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-d5a2c76b-626d-42af-9c91-b7e33dc64e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-a0813d64-f968-45d4-b9a8-fe4ff83097b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-0032fb88-0562-4b17-b250-62f2518aadb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-94139978-0851-4561-bd56-fb1cf167bb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-5ad5b0f7-404c-4b97-9727-3bb59cfd63d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934039953-172.17.0.2-1595513471243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-1768abf9-8927-4abc-a610-19a2be0a6943,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-628b6d14-b39d-4e86-bfd8-1aeacac864c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-b4fc2444-09e7-4e7b-9f93-989577c949a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-d5a2c76b-626d-42af-9c91-b7e33dc64e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-a0813d64-f968-45d4-b9a8-fe4ff83097b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-0032fb88-0562-4b17-b250-62f2518aadb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-94139978-0851-4561-bd56-fb1cf167bb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-5ad5b0f7-404c-4b97-9727-3bb59cfd63d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224699110-172.17.0.2-1595513574176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38744,DS-f54c4cf8-035d-4e97-a362-98745d5b3f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-06d68e0a-ce00-43a9-9e6f-324b5fd29edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-e88652c3-eade-4a95-9d36-7ecb6eeeafe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-bc396dba-995d-4ad4-a535-ee4d29673921,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-7d3d5293-474c-4f4c-acc7-1754a9626c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-5a87ba9a-fc14-429c-bb18-f271a96da8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-325872b7-1021-4e40-98f2-d1f36f328f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-ad3d2764-5b99-48b2-900a-ebe5be2a55a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224699110-172.17.0.2-1595513574176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38744,DS-f54c4cf8-035d-4e97-a362-98745d5b3f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-06d68e0a-ce00-43a9-9e6f-324b5fd29edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-e88652c3-eade-4a95-9d36-7ecb6eeeafe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-bc396dba-995d-4ad4-a535-ee4d29673921,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-7d3d5293-474c-4f4c-acc7-1754a9626c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-5a87ba9a-fc14-429c-bb18-f271a96da8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-325872b7-1021-4e40-98f2-d1f36f328f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-ad3d2764-5b99-48b2-900a-ebe5be2a55a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948319860-172.17.0.2-1595514129770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-9ecfc7e3-5cf2-4443-bfd3-bedac1320a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-315e1398-3364-475f-a55b-2e92663eceac,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-c2638e0f-15ff-4aa0-8d8f-91dffe029a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-71e138d3-da06-4e48-b5bc-bac40c91dae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-4ee1e3f8-b7cd-4659-8b3e-f03473496e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-14b235e4-1df8-41e0-9de2-a2b3ad9ee042,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-15ccc9b7-82df-4d73-81f9-a93b070a1f39,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-205eba50-c7de-4cc3-9ebb-966e5a3a8bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948319860-172.17.0.2-1595514129770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-9ecfc7e3-5cf2-4443-bfd3-bedac1320a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-315e1398-3364-475f-a55b-2e92663eceac,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-c2638e0f-15ff-4aa0-8d8f-91dffe029a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-71e138d3-da06-4e48-b5bc-bac40c91dae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-4ee1e3f8-b7cd-4659-8b3e-f03473496e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-14b235e4-1df8-41e0-9de2-a2b3ad9ee042,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-15ccc9b7-82df-4d73-81f9-a93b070a1f39,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-205eba50-c7de-4cc3-9ebb-966e5a3a8bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395886560-172.17.0.2-1595514209402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-78228c75-6d34-4569-b205-e37bb562696b,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-7680a61a-e113-4977-aa38-4e85bf185861,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-a15509c8-6726-438c-8603-da00a5aab928,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-133d8fe9-b08a-449b-94d5-87742853be7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-db2579e8-7dbf-4fed-8f4d-5341e9a7ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-9585fb71-bcc2-4ecc-812a-e5e973f89efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-37cedf8e-88e4-4758-b548-2f9e50961201,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-d022672d-57e6-4897-bb13-2ce6a14eb5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395886560-172.17.0.2-1595514209402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-78228c75-6d34-4569-b205-e37bb562696b,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-7680a61a-e113-4977-aa38-4e85bf185861,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-a15509c8-6726-438c-8603-da00a5aab928,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-133d8fe9-b08a-449b-94d5-87742853be7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-db2579e8-7dbf-4fed-8f4d-5341e9a7ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-9585fb71-bcc2-4ecc-812a-e5e973f89efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-37cedf8e-88e4-4758-b548-2f9e50961201,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-d022672d-57e6-4897-bb13-2ce6a14eb5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194657182-172.17.0.2-1595514478420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-32b8c037-bd50-4c35-8f2d-ff95fdf4841d,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-f4a79d53-b1bb-406b-826f-274707aaeade,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-099b7230-bd61-4632-b0d9-cd0946e35ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-bcee9421-56cc-4d68-9d3f-71fe7ea9f097,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-21121b35-1df2-47ac-9594-38cb705bf404,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-dbddfa36-312a-441a-8335-859f5123b134,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-f1accbf3-c45d-43dd-b7cc-eee497600b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-739fd26a-bd7d-4597-8a01-3eb855b9b83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194657182-172.17.0.2-1595514478420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-32b8c037-bd50-4c35-8f2d-ff95fdf4841d,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-f4a79d53-b1bb-406b-826f-274707aaeade,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-099b7230-bd61-4632-b0d9-cd0946e35ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-bcee9421-56cc-4d68-9d3f-71fe7ea9f097,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-21121b35-1df2-47ac-9594-38cb705bf404,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-dbddfa36-312a-441a-8335-859f5123b134,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-f1accbf3-c45d-43dd-b7cc-eee497600b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-739fd26a-bd7d-4597-8a01-3eb855b9b83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097196697-172.17.0.2-1595514805616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33876,DS-8af9feed-6313-4aa3-8cbf-7b421f849f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-d959f91b-4f3e-4fa8-abbd-92c8ef71cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-355b9669-0864-48c2-ae32-ec1b110752b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-1672e333-6a14-4329-baca-b47826379fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-b8d07bc6-98c2-425b-8cad-c2ecbb0eff00,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-5e3f56b4-ebb6-4eaf-a435-9a640e4e51ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-4095c3bc-91ac-4ede-aa61-03cf6c344643,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-cc98c473-86d7-41ea-afad-e1c211f81ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097196697-172.17.0.2-1595514805616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33876,DS-8af9feed-6313-4aa3-8cbf-7b421f849f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-d959f91b-4f3e-4fa8-abbd-92c8ef71cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-355b9669-0864-48c2-ae32-ec1b110752b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-1672e333-6a14-4329-baca-b47826379fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-b8d07bc6-98c2-425b-8cad-c2ecbb0eff00,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-5e3f56b4-ebb6-4eaf-a435-9a640e4e51ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-4095c3bc-91ac-4ede-aa61-03cf6c344643,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-cc98c473-86d7-41ea-afad-e1c211f81ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994634985-172.17.0.2-1595514845847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-a39fbaff-ba18-411b-8168-669d52b14b32,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-6facd7fe-18ee-4790-9e03-1610f242bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-4f6e3e23-38d6-402c-86fe-b0d0313a91b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-cb250629-87be-4a8f-9154-5c1e722d48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-8d9900df-80b5-4fa8-a135-35c33d661bed,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-d91e4f3e-a1a8-4aa0-907a-f4ebd58729a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-aefaaeb4-f052-491a-8504-959753d95e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-15db334a-0cf5-4fc7-a2f8-8b6999b6ee73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994634985-172.17.0.2-1595514845847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-a39fbaff-ba18-411b-8168-669d52b14b32,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-6facd7fe-18ee-4790-9e03-1610f242bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-4f6e3e23-38d6-402c-86fe-b0d0313a91b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-cb250629-87be-4a8f-9154-5c1e722d48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-8d9900df-80b5-4fa8-a135-35c33d661bed,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-d91e4f3e-a1a8-4aa0-907a-f4ebd58729a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-aefaaeb4-f052-491a-8504-959753d95e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-15db334a-0cf5-4fc7-a2f8-8b6999b6ee73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550068532-172.17.0.2-1595515225209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-9af94dc4-0d19-431c-bc79-45e1c6cf465c,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-a0c3d2d1-10ee-441c-b254-22bc514f7751,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-fca46cb5-8ec5-4bd8-ac29-6ef7e113aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-ba0f4a6d-604a-47f3-a7a9-8c6f5c20e053,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-3599e85e-5b8e-4909-965d-f555c4886974,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-7fe07485-779d-40a7-8e64-1a71bfacf7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-c65e4197-b826-478b-ad0b-8d2dc007b2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-f0fc3a14-0b47-4ed3-b756-a6681e0ff138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550068532-172.17.0.2-1595515225209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-9af94dc4-0d19-431c-bc79-45e1c6cf465c,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-a0c3d2d1-10ee-441c-b254-22bc514f7751,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-fca46cb5-8ec5-4bd8-ac29-6ef7e113aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-ba0f4a6d-604a-47f3-a7a9-8c6f5c20e053,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-3599e85e-5b8e-4909-965d-f555c4886974,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-7fe07485-779d-40a7-8e64-1a71bfacf7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-c65e4197-b826-478b-ad0b-8d2dc007b2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-f0fc3a14-0b47-4ed3-b756-a6681e0ff138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457593730-172.17.0.2-1595515524709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43585,DS-f8ebcc0c-1b78-4fef-8d77-27a4c2726992,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-c1f803e0-8623-4ec7-9728-7c62969251d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-18223b40-30d1-44d1-b5bc-b741996c5120,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-9ce36ac5-ff30-40d0-8f5c-fc14d2ade1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-97df6367-b660-4be8-bef3-d6b373b50ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-482202b1-3aa9-42b9-8fd9-9b6b1095217e,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-c65e61a7-425f-4c20-a0bb-b37642768431,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-d845f5d0-b852-459f-a964-afcf13800ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457593730-172.17.0.2-1595515524709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43585,DS-f8ebcc0c-1b78-4fef-8d77-27a4c2726992,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-c1f803e0-8623-4ec7-9728-7c62969251d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-18223b40-30d1-44d1-b5bc-b741996c5120,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-9ce36ac5-ff30-40d0-8f5c-fc14d2ade1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-97df6367-b660-4be8-bef3-d6b373b50ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-482202b1-3aa9-42b9-8fd9-9b6b1095217e,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-c65e61a7-425f-4c20-a0bb-b37642768431,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-d845f5d0-b852-459f-a964-afcf13800ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686272225-172.17.0.2-1595516318961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-e89adc8c-d0bf-4ceb-8e83-e950f6f00c60,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-0a92c79b-3c1c-499e-85c7-c2730e304674,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-48a098a9-0ee9-4e87-a989-808be77cf0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-5bfa3591-5e4b-4c6f-a302-59a52207ef82,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-d145acfc-f8e8-4466-822f-0559cfdf5f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-b80e2c31-4b3d-4084-8576-11d0f4bf7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-e3e5f3c5-efd7-46bf-9b58-42d3d5e2d049,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-27da0071-e58e-481f-bdc4-713c3cf72da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686272225-172.17.0.2-1595516318961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-e89adc8c-d0bf-4ceb-8e83-e950f6f00c60,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-0a92c79b-3c1c-499e-85c7-c2730e304674,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-48a098a9-0ee9-4e87-a989-808be77cf0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-5bfa3591-5e4b-4c6f-a302-59a52207ef82,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-d145acfc-f8e8-4466-822f-0559cfdf5f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-b80e2c31-4b3d-4084-8576-11d0f4bf7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-e3e5f3c5-efd7-46bf-9b58-42d3d5e2d049,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-27da0071-e58e-481f-bdc4-713c3cf72da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994708589-172.17.0.2-1595517420191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44704,DS-0542b305-39ec-4c79-a429-3b7add087f76,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-d9e104cd-ffc6-4999-b197-77260b51694b,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-01a78568-aa39-495f-a129-45c9d13e3f98,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-16c09274-04a1-460e-97ac-34b4f2397f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-425ddc22-6d62-437f-8c1d-d19f3ebddec4,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-7282f9d7-eedd-4663-ae86-bcb2a46d993e,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-33b31eb6-8784-478f-bf55-aa4113fc50a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-8b55368b-ddae-4650-9f84-c69b938811da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994708589-172.17.0.2-1595517420191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44704,DS-0542b305-39ec-4c79-a429-3b7add087f76,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-d9e104cd-ffc6-4999-b197-77260b51694b,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-01a78568-aa39-495f-a129-45c9d13e3f98,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-16c09274-04a1-460e-97ac-34b4f2397f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-425ddc22-6d62-437f-8c1d-d19f3ebddec4,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-7282f9d7-eedd-4663-ae86-bcb2a46d993e,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-33b31eb6-8784-478f-bf55-aa4113fc50a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-8b55368b-ddae-4650-9f84-c69b938811da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353790637-172.17.0.2-1595517566180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-17262e0b-ab4e-4aac-b717-b5e21db6ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-7333c6af-100d-4c82-9b96-c1fcf25e3c40,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-890da189-c1d4-4b88-a773-d8259a362f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-164ea6ab-8fcc-4742-a205-b5558898d2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-5a205fe3-e049-4eb4-bc3e-b4d551dad461,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-637187f2-d6c6-4b1a-bf3a-de59b027673a,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-0c1aaf09-1b18-467e-a9cc-f6db32d90dde,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-f1741f55-05e1-434b-8605-f836f5408f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353790637-172.17.0.2-1595517566180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-17262e0b-ab4e-4aac-b717-b5e21db6ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-7333c6af-100d-4c82-9b96-c1fcf25e3c40,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-890da189-c1d4-4b88-a773-d8259a362f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-164ea6ab-8fcc-4742-a205-b5558898d2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-5a205fe3-e049-4eb4-bc3e-b4d551dad461,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-637187f2-d6c6-4b1a-bf3a-de59b027673a,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-0c1aaf09-1b18-467e-a9cc-f6db32d90dde,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-f1741f55-05e1-434b-8605-f836f5408f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816056129-172.17.0.2-1595517724037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41607,DS-0cde67f4-162e-427e-b014-e370af7b7af0,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-10ba2d5c-3b5c-4243-92e7-aac569dd97e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-4337699f-583b-45fe-a242-2beac8026d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-1f297cd3-abb2-4521-b355-b750d2a46b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-87c5e058-8ae1-44b3-8756-8d10d8f0f77a,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-6007a72b-547e-4d85-9cf7-ddad75ff5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-71360696-d9e1-4feb-b67f-8de32e60e893,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-6177c79d-b780-4554-b03b-ddc0f2505034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816056129-172.17.0.2-1595517724037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41607,DS-0cde67f4-162e-427e-b014-e370af7b7af0,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-10ba2d5c-3b5c-4243-92e7-aac569dd97e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-4337699f-583b-45fe-a242-2beac8026d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-1f297cd3-abb2-4521-b355-b750d2a46b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-87c5e058-8ae1-44b3-8756-8d10d8f0f77a,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-6007a72b-547e-4d85-9cf7-ddad75ff5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-71360696-d9e1-4feb-b67f-8de32e60e893,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-6177c79d-b780-4554-b03b-ddc0f2505034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893579983-172.17.0.2-1595518249431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40027,DS-355b96db-8e98-4c09-88a9-adce0f53d7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-35392454-4e62-40ad-a67d-331b3726296a,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-de71c7dc-f0d7-468b-83ec-c65a6e80cfba,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-a51c30da-9d9e-41f8-ab8a-2a47eaba9775,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-67ddb346-876d-4f80-b9be-e3d76f5f0825,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-e3f95580-e223-4c2c-854a-08c50bfb6cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-98642609-35fd-48c7-a219-ccbf6b84bbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-5107db31-aeba-48d4-b209-cc27afbf897c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893579983-172.17.0.2-1595518249431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40027,DS-355b96db-8e98-4c09-88a9-adce0f53d7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-35392454-4e62-40ad-a67d-331b3726296a,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-de71c7dc-f0d7-468b-83ec-c65a6e80cfba,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-a51c30da-9d9e-41f8-ab8a-2a47eaba9775,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-67ddb346-876d-4f80-b9be-e3d76f5f0825,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-e3f95580-e223-4c2c-854a-08c50bfb6cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-98642609-35fd-48c7-a219-ccbf6b84bbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-5107db31-aeba-48d4-b209-cc27afbf897c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366048700-172.17.0.2-1595518324473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-23245899-32bd-4c89-8f43-7a8b7f6135fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-81084a38-5f0a-4b9f-a4d1-6ea0ebf11577,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-6b22de54-d447-461c-bad1-290d7767111d,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-9b6507fb-877d-4e83-a78c-bde698576001,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-a48abfee-5c86-4c27-af0a-7688c32cfbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-b4f73ca4-b1fe-4be8-ae33-52e1e57dfaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-c9e3affc-6137-4972-84ce-7b147cb873da,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-28a17d6e-1814-4432-9a7e-348b360bdf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366048700-172.17.0.2-1595518324473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-23245899-32bd-4c89-8f43-7a8b7f6135fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-81084a38-5f0a-4b9f-a4d1-6ea0ebf11577,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-6b22de54-d447-461c-bad1-290d7767111d,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-9b6507fb-877d-4e83-a78c-bde698576001,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-a48abfee-5c86-4c27-af0a-7688c32cfbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-b4f73ca4-b1fe-4be8-ae33-52e1e57dfaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-c9e3affc-6137-4972-84ce-7b147cb873da,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-28a17d6e-1814-4432-9a7e-348b360bdf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106684022-172.17.0.2-1595518430345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-a663bdd9-d41d-47d0-96fc-71e9c81c9eef,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-ca9dff35-69da-434e-9603-93c182ae3058,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-57891997-af43-4e47-bab5-019f47b14b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-106231a8-eb4b-4346-9fe9-f49875eb14e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-42c1924c-b524-4c2b-9e7e-080e38250151,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-b03c72ba-bd17-4ed6-b7e7-144da0d8f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-cb7935dd-2250-4c59-a8f1-d8b59f31c303,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-65f4d436-c1aa-4b72-be64-6b38b3225e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106684022-172.17.0.2-1595518430345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-a663bdd9-d41d-47d0-96fc-71e9c81c9eef,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-ca9dff35-69da-434e-9603-93c182ae3058,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-57891997-af43-4e47-bab5-019f47b14b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-106231a8-eb4b-4346-9fe9-f49875eb14e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-42c1924c-b524-4c2b-9e7e-080e38250151,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-b03c72ba-bd17-4ed6-b7e7-144da0d8f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-cb7935dd-2250-4c59-a8f1-d8b59f31c303,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-65f4d436-c1aa-4b72-be64-6b38b3225e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5676
