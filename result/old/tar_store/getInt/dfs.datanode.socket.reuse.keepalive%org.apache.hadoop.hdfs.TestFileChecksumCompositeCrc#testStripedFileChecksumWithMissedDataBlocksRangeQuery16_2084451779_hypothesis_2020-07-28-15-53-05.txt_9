reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999001301-172.17.0.21-1595951828022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-2f9dc9db-655c-4481-a030-c1763eb7cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-df1a16a2-ee40-48aa-a5a1-40a7cc500ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-d50b66ea-9002-49bb-ab97-a91426ce0a68,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-54bdaaa0-e244-4737-ac15-659f277738b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-f97621cb-61a1-4e82-b888-9b531b604828,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-ffd87e11-8db4-4662-a167-99ea2caeab10,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-5d265b3b-6860-47c5-8c94-5c084051009d,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-65ec919f-9fc3-4045-a727-a703ceeb5582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999001301-172.17.0.21-1595951828022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-2f9dc9db-655c-4481-a030-c1763eb7cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-df1a16a2-ee40-48aa-a5a1-40a7cc500ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-d50b66ea-9002-49bb-ab97-a91426ce0a68,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-54bdaaa0-e244-4737-ac15-659f277738b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-f97621cb-61a1-4e82-b888-9b531b604828,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-ffd87e11-8db4-4662-a167-99ea2caeab10,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-5d265b3b-6860-47c5-8c94-5c084051009d,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-65ec919f-9fc3-4045-a727-a703ceeb5582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866886596-172.17.0.21-1595952333687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37560,DS-44ae0774-e8d9-4f62-8b29-8ab38b08d2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-4a116b7f-d2e3-4a36-b7cb-606670ed0206,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e2dccd30-a8b3-4306-b6c4-206bad398f40,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-31cebc33-b602-4a8a-bdf2-e22f1c7f1676,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-b4882115-c7b5-486b-8c85-802d8cbed736,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-94cc99e2-e8e1-46eb-a2d4-903c9d704d34,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-93d9a18b-89de-4216-b763-053d0aa522d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-3230296a-3b42-488f-8983-7d00ffad4703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866886596-172.17.0.21-1595952333687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37560,DS-44ae0774-e8d9-4f62-8b29-8ab38b08d2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-4a116b7f-d2e3-4a36-b7cb-606670ed0206,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e2dccd30-a8b3-4306-b6c4-206bad398f40,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-31cebc33-b602-4a8a-bdf2-e22f1c7f1676,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-b4882115-c7b5-486b-8c85-802d8cbed736,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-94cc99e2-e8e1-46eb-a2d4-903c9d704d34,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-93d9a18b-89de-4216-b763-053d0aa522d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-3230296a-3b42-488f-8983-7d00ffad4703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447213273-172.17.0.21-1595952373233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35906,DS-2c4ee476-dff0-41ad-9520-11db2c2c9d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-800a0856-15c5-41ca-a8af-d56d7eb0766c,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-67cc95e9-50c4-4f28-8886-e18c6a5690cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-93869da9-2c51-4e14-aaae-e6c54453a068,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-cb2bb521-237c-4c42-986e-21600b9a3688,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-4ad8c396-6730-405c-b9f1-2748ae0635b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-f27e1905-46cf-4bd0-adfa-c363c3d14317,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-940e132d-3811-42e1-bf96-7a799ff4124c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447213273-172.17.0.21-1595952373233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35906,DS-2c4ee476-dff0-41ad-9520-11db2c2c9d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-800a0856-15c5-41ca-a8af-d56d7eb0766c,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-67cc95e9-50c4-4f28-8886-e18c6a5690cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-93869da9-2c51-4e14-aaae-e6c54453a068,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-cb2bb521-237c-4c42-986e-21600b9a3688,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-4ad8c396-6730-405c-b9f1-2748ae0635b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-f27e1905-46cf-4bd0-adfa-c363c3d14317,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-940e132d-3811-42e1-bf96-7a799ff4124c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491511173-172.17.0.21-1595952563701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-a6d685de-ad21-40ab-8aee-9d59ecb579b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-dc7d2317-c17b-48df-bc75-998e9794e96a,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-9e5a7668-1f07-4463-99bf-0b0ef336703b,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-61244268-f91d-4d45-b8ed-74c8f0c63c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-3477121d-d73a-4d6e-a3e9-e693dc8547de,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-e55556e3-d1e1-4e74-bb8a-3fcbc8f6233d,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-715ad2a6-c037-4ee3-9705-9ff05cfeffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-51364261-0cd2-470d-afc8-5178171569e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491511173-172.17.0.21-1595952563701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-a6d685de-ad21-40ab-8aee-9d59ecb579b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-dc7d2317-c17b-48df-bc75-998e9794e96a,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-9e5a7668-1f07-4463-99bf-0b0ef336703b,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-61244268-f91d-4d45-b8ed-74c8f0c63c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-3477121d-d73a-4d6e-a3e9-e693dc8547de,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-e55556e3-d1e1-4e74-bb8a-3fcbc8f6233d,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-715ad2a6-c037-4ee3-9705-9ff05cfeffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-51364261-0cd2-470d-afc8-5178171569e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627861864-172.17.0.21-1595953758665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-453fadcc-74a3-4876-a520-d80c824acd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-0cf832be-f6ef-452d-adb9-f2e297d2b000,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-a405d65e-ee40-4e80-b86f-72525d405dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-2540a214-9943-4baf-a63a-5cc7d2c36e50,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-3d4807a5-5fe9-4813-b8f8-87f3603fdd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-df55f172-b29f-40e0-ba1b-3daeaacf78d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-d62d3def-826e-4068-9777-d719e1d36b46,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-814ed35a-6e9e-4028-bfcf-54d2c65596db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627861864-172.17.0.21-1595953758665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-453fadcc-74a3-4876-a520-d80c824acd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-0cf832be-f6ef-452d-adb9-f2e297d2b000,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-a405d65e-ee40-4e80-b86f-72525d405dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-2540a214-9943-4baf-a63a-5cc7d2c36e50,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-3d4807a5-5fe9-4813-b8f8-87f3603fdd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-df55f172-b29f-40e0-ba1b-3daeaacf78d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-d62d3def-826e-4068-9777-d719e1d36b46,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-814ed35a-6e9e-4028-bfcf-54d2c65596db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209391703-172.17.0.21-1595953928382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-983c3703-eb09-465a-bad1-03b17046adae,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-74ae54db-ff42-4386-bad2-0033337b603b,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-24e02106-a484-457e-b550-c52e1add02a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-f6604307-ca53-4340-8b51-e1bd69e0d077,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-75059090-122c-47ae-aaaa-a5095c20ae9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-7266ba1f-68da-40a5-a1e9-133a1cb59f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-309543c0-5b0a-4f44-919c-605fb9a13c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-d8585e4c-ab05-4819-befa-f5e37c70c87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209391703-172.17.0.21-1595953928382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-983c3703-eb09-465a-bad1-03b17046adae,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-74ae54db-ff42-4386-bad2-0033337b603b,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-24e02106-a484-457e-b550-c52e1add02a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-f6604307-ca53-4340-8b51-e1bd69e0d077,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-75059090-122c-47ae-aaaa-a5095c20ae9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-7266ba1f-68da-40a5-a1e9-133a1cb59f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-309543c0-5b0a-4f44-919c-605fb9a13c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-d8585e4c-ab05-4819-befa-f5e37c70c87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352047800-172.17.0.21-1595954068185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41527,DS-4102fe45-0810-4bf7-91ff-a62d832e9101,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-55e46ad0-e1aa-4d25-9517-6e661a7a051a,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-237d0778-bfb5-443b-86f0-0245a055e92f,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-db83f82a-a1ef-4ee0-be44-19e56da8f521,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-8f4177bd-07cb-4a00-86de-f12eac470e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-abd8c35f-2afb-4ccb-a033-06ce39f784bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-1eb00c7d-9c4c-4747-adb0-5806ad9a09dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-85303fb0-607a-4062-a3d6-e673d31c6025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352047800-172.17.0.21-1595954068185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41527,DS-4102fe45-0810-4bf7-91ff-a62d832e9101,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-55e46ad0-e1aa-4d25-9517-6e661a7a051a,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-237d0778-bfb5-443b-86f0-0245a055e92f,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-db83f82a-a1ef-4ee0-be44-19e56da8f521,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-8f4177bd-07cb-4a00-86de-f12eac470e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-abd8c35f-2afb-4ccb-a033-06ce39f784bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-1eb00c7d-9c4c-4747-adb0-5806ad9a09dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-85303fb0-607a-4062-a3d6-e673d31c6025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120874285-172.17.0.21-1595954697415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-05de0410-a8fb-4d92-98d5-5cca14e722ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c3054a7c-f3b9-408f-8020-33c49409b1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-347a6add-ec8b-487c-bf43-e89ab9f6501f,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-cc399aeb-4da2-4f7c-bf97-03157a62d76f,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-5f83bafb-7098-4bfc-8fec-cefa688053ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-a305b447-428b-4016-8ecc-48bfa1cddf36,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-e90f756a-9baa-40dd-93b4-576c524f74e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-8dc6f2f8-cb3a-4e56-83a6-3af6203a8cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120874285-172.17.0.21-1595954697415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-05de0410-a8fb-4d92-98d5-5cca14e722ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c3054a7c-f3b9-408f-8020-33c49409b1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-347a6add-ec8b-487c-bf43-e89ab9f6501f,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-cc399aeb-4da2-4f7c-bf97-03157a62d76f,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-5f83bafb-7098-4bfc-8fec-cefa688053ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-a305b447-428b-4016-8ecc-48bfa1cddf36,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-e90f756a-9baa-40dd-93b4-576c524f74e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-8dc6f2f8-cb3a-4e56-83a6-3af6203a8cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872509117-172.17.0.21-1595954831031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-55e3fa97-1c62-410e-8aff-3556fe44c17e,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-bf3e70e8-a4ed-440c-a2a8-d0173887048e,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-d179d280-5b16-46e6-8a5c-0feef71926ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-ce42759c-56f2-4d2d-976a-1989653ae29a,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-488aa26f-feaa-4333-8d8b-0cdfdb001c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-317103a8-6886-42ec-a8ef-2bd5817680b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-d22cc7b3-e334-489a-93f8-177e5394def9,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-701fa756-2b1f-48bf-9196-5e8173857947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872509117-172.17.0.21-1595954831031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-55e3fa97-1c62-410e-8aff-3556fe44c17e,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-bf3e70e8-a4ed-440c-a2a8-d0173887048e,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-d179d280-5b16-46e6-8a5c-0feef71926ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-ce42759c-56f2-4d2d-976a-1989653ae29a,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-488aa26f-feaa-4333-8d8b-0cdfdb001c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-317103a8-6886-42ec-a8ef-2bd5817680b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-d22cc7b3-e334-489a-93f8-177e5394def9,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-701fa756-2b1f-48bf-9196-5e8173857947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723318904-172.17.0.21-1595954924276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36000,DS-741b2b4a-da9a-41d4-ab0b-94a75e26a2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-91155bcc-59ad-4ea3-a1a3-bb62bfb73f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-f8af2f6f-9ccd-451d-955b-c050056b7e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-6bc2d6c0-ac64-41b3-b640-a8810fb43d08,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-9935df3d-bcd7-442a-a9b0-6e636b41f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-632449be-1bdc-4f37-99c6-31e57edc60d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-6d7a57c6-b722-491c-994b-6c175c102297,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-33f600bc-3f89-47e2-b463-d9b395be81c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723318904-172.17.0.21-1595954924276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36000,DS-741b2b4a-da9a-41d4-ab0b-94a75e26a2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-91155bcc-59ad-4ea3-a1a3-bb62bfb73f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-f8af2f6f-9ccd-451d-955b-c050056b7e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-6bc2d6c0-ac64-41b3-b640-a8810fb43d08,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-9935df3d-bcd7-442a-a9b0-6e636b41f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-632449be-1bdc-4f37-99c6-31e57edc60d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-6d7a57c6-b722-491c-994b-6c175c102297,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-33f600bc-3f89-47e2-b463-d9b395be81c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193524828-172.17.0.21-1595955148702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36562,DS-22b7d17a-0949-408b-b51d-5a7869e46a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-80c01599-9314-4d61-845c-5b6ceb97f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-d5573130-85d5-41e2-be09-7c3f4ceb6f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-cfd16bdb-6f47-4ac8-b160-57cfaf6f2370,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-c386ff43-cbd7-40f3-bb49-0b4466f5e938,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-a3723809-5de1-480c-9e90-cfb21cb59d16,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-d4bb4ecd-ca30-495c-bd30-8d56f1f051b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-8c5794a7-928a-471d-a397-47bc4c3d73e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193524828-172.17.0.21-1595955148702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36562,DS-22b7d17a-0949-408b-b51d-5a7869e46a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-80c01599-9314-4d61-845c-5b6ceb97f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-d5573130-85d5-41e2-be09-7c3f4ceb6f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-cfd16bdb-6f47-4ac8-b160-57cfaf6f2370,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-c386ff43-cbd7-40f3-bb49-0b4466f5e938,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-a3723809-5de1-480c-9e90-cfb21cb59d16,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-d4bb4ecd-ca30-495c-bd30-8d56f1f051b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-8c5794a7-928a-471d-a397-47bc4c3d73e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979381563-172.17.0.21-1595955528614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-707130c2-94a7-4d48-8e87-0db70914258e,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-d993e659-c103-4e11-89da-d2f055057063,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-b3b2bf54-1472-452e-9dbc-cd1b75241e47,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-3f610a4b-e1d5-430b-8c7d-52eca02adc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-180ab48d-3138-4de3-aeca-8b2c0657a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-78b3521b-cfe7-4650-bde2-32f75d74684f,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-577b86bc-8011-475a-997d-290b8e578a47,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-e3a30737-880c-47b2-a68f-501f71b81843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979381563-172.17.0.21-1595955528614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-707130c2-94a7-4d48-8e87-0db70914258e,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-d993e659-c103-4e11-89da-d2f055057063,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-b3b2bf54-1472-452e-9dbc-cd1b75241e47,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-3f610a4b-e1d5-430b-8c7d-52eca02adc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-180ab48d-3138-4de3-aeca-8b2c0657a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-78b3521b-cfe7-4650-bde2-32f75d74684f,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-577b86bc-8011-475a-997d-290b8e578a47,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-e3a30737-880c-47b2-a68f-501f71b81843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687742000-172.17.0.21-1595955561683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34577,DS-5c5a359d-add6-4e3a-aeaa-6ad5396b7c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-b5ce77ff-d8d4-43cc-9d73-4c71bf48d9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-4d2df6c9-9b7d-43d1-85f5-7d715df469ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-85ff2b28-473a-41ac-aeee-d92fc6208e36,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-0ee25a59-553e-4409-b6db-49a0b1ca4169,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-25a1b610-a764-482b-886e-9514e0d79aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-a8646199-b897-415e-b75a-38cf0c0b98a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-f9a617cc-86cb-4430-bc66-0c8b7ca5b3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687742000-172.17.0.21-1595955561683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34577,DS-5c5a359d-add6-4e3a-aeaa-6ad5396b7c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-b5ce77ff-d8d4-43cc-9d73-4c71bf48d9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-4d2df6c9-9b7d-43d1-85f5-7d715df469ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-85ff2b28-473a-41ac-aeee-d92fc6208e36,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-0ee25a59-553e-4409-b6db-49a0b1ca4169,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-25a1b610-a764-482b-886e-9514e0d79aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-a8646199-b897-415e-b75a-38cf0c0b98a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-f9a617cc-86cb-4430-bc66-0c8b7ca5b3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309800587-172.17.0.21-1595955730334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-a5d89db4-b21f-4d21-879e-5c8ea58c7425,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-1f87ec77-fcf6-4f9b-bebc-1c4a5cec8431,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-1ad59d5b-189d-42b8-88cd-ae3b5af116cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-01038362-25c9-4fef-b909-9d56efacb1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-ada5ef9c-a135-4f67-aa9a-163ebf67061b,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-9552afa4-a39b-4633-a125-6b3529385f02,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-0f5460af-3f09-4778-9cd3-e8a0127b6a15,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-622fa779-5d6b-44ef-8c05-200f2a6cd2d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309800587-172.17.0.21-1595955730334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-a5d89db4-b21f-4d21-879e-5c8ea58c7425,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-1f87ec77-fcf6-4f9b-bebc-1c4a5cec8431,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-1ad59d5b-189d-42b8-88cd-ae3b5af116cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-01038362-25c9-4fef-b909-9d56efacb1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-ada5ef9c-a135-4f67-aa9a-163ebf67061b,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-9552afa4-a39b-4633-a125-6b3529385f02,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-0f5460af-3f09-4778-9cd3-e8a0127b6a15,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-622fa779-5d6b-44ef-8c05-200f2a6cd2d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427115607-172.17.0.21-1595955970427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-dae5a96e-b007-49a1-8c24-b10a5d16d2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-8bca0c01-0877-4afb-bab2-8c2d5fca770d,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-b86d1ee3-eb5c-44a9-a27f-4c84faea749b,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-9950782e-995e-4ec7-a763-0d5b224bc0af,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-7f1f60dd-d787-4d19-a366-31e437a1da29,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-cf65cbd5-1075-48fe-8ddb-36b642a5d5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-52a48b61-3fd3-4661-83f0-a4d8e1c7b1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-1537b7c3-20b1-469a-952a-705f0a08ed61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427115607-172.17.0.21-1595955970427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-dae5a96e-b007-49a1-8c24-b10a5d16d2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-8bca0c01-0877-4afb-bab2-8c2d5fca770d,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-b86d1ee3-eb5c-44a9-a27f-4c84faea749b,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-9950782e-995e-4ec7-a763-0d5b224bc0af,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-7f1f60dd-d787-4d19-a366-31e437a1da29,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-cf65cbd5-1075-48fe-8ddb-36b642a5d5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-52a48b61-3fd3-4661-83f0-a4d8e1c7b1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-1537b7c3-20b1-469a-952a-705f0a08ed61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702773928-172.17.0.21-1595956249989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43324,DS-2f51282d-0af6-484c-921c-8220dd78a238,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-fb561b64-e72b-461a-a49c-c09f9bd6dfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-37705dec-5b92-4a03-bca2-04403eb6f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-c9983e51-cfca-406d-9f90-d240accfa242,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-c1eef07d-4a5a-4bb5-a92c-a5ca22e925c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-953c256c-c972-4d35-a314-a44240ec9f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-efe1e65c-f1e1-49ce-9330-3ceb84d09cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-618343e8-ac9d-437a-8dda-a635843e1513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702773928-172.17.0.21-1595956249989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43324,DS-2f51282d-0af6-484c-921c-8220dd78a238,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-fb561b64-e72b-461a-a49c-c09f9bd6dfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-37705dec-5b92-4a03-bca2-04403eb6f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-c9983e51-cfca-406d-9f90-d240accfa242,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-c1eef07d-4a5a-4bb5-a92c-a5ca22e925c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-953c256c-c972-4d35-a314-a44240ec9f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-efe1e65c-f1e1-49ce-9330-3ceb84d09cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-618343e8-ac9d-437a-8dda-a635843e1513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203795308-172.17.0.21-1595956672338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37498,DS-9bd8ca67-9f1d-45a8-8c89-3354ceef0a71,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-f920ff0f-16fe-475e-8b43-1cc3de375a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-711a4e5f-c8cb-4713-b275-8bf7517abb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-76e23163-028d-43a2-8a1b-20275e4aad43,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-05356f6e-af88-4c47-b1ad-48c24f89a370,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-8a01c04d-008c-4a48-96d4-2a0c57336841,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-728f832e-80d5-48f6-8000-4929501d736d,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-97e76627-282b-4a9d-a13b-0e79d62a4e78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203795308-172.17.0.21-1595956672338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37498,DS-9bd8ca67-9f1d-45a8-8c89-3354ceef0a71,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-f920ff0f-16fe-475e-8b43-1cc3de375a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-711a4e5f-c8cb-4713-b275-8bf7517abb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-76e23163-028d-43a2-8a1b-20275e4aad43,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-05356f6e-af88-4c47-b1ad-48c24f89a370,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-8a01c04d-008c-4a48-96d4-2a0c57336841,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-728f832e-80d5-48f6-8000-4929501d736d,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-97e76627-282b-4a9d-a13b-0e79d62a4e78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5139
