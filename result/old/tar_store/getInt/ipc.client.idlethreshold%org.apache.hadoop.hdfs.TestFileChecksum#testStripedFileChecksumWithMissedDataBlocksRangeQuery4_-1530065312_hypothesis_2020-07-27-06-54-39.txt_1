reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786264544-172.17.0.6-1595833393112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-e0bb96c0-4515-4369-a3d2-85e949c8347b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e9e9c40d-b633-4b08-9734-ebaf2b80ed92,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-7bfb8853-069d-44a4-a62e-6c9248ce7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-700dea71-8902-4d17-8589-888aad9b75db,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-11aa047b-ce45-4c47-a671-3ae6d5b86587,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-9370b683-5848-4e98-b034-febb7ee38f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-01b48136-371a-4359-8e79-666bae92f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-e4b1d8ad-58d1-4ef8-b411-8553bda2649d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786264544-172.17.0.6-1595833393112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-e0bb96c0-4515-4369-a3d2-85e949c8347b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e9e9c40d-b633-4b08-9734-ebaf2b80ed92,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-7bfb8853-069d-44a4-a62e-6c9248ce7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-700dea71-8902-4d17-8589-888aad9b75db,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-11aa047b-ce45-4c47-a671-3ae6d5b86587,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-9370b683-5848-4e98-b034-febb7ee38f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-01b48136-371a-4359-8e79-666bae92f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-e4b1d8ad-58d1-4ef8-b411-8553bda2649d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128287616-172.17.0.6-1595833428498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46841,DS-b9a2d078-0647-4ded-bc5b-a4de99da5770,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-a75c770c-98ba-41f9-aa67-384e05fd7ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-da83c2f9-95df-44bc-a25a-1a0c1c2be23b,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-93ca4641-5f29-4d5a-bb7e-c657e220999e,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-ca2cd6dc-84bd-4250-ada1-c1652a55e1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-121e13c6-e75f-49c7-928d-afd7a85b4646,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-7f52f730-5c37-472a-8018-dfa41c151341,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-ed9008ab-3edd-456e-b27e-eac347176b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128287616-172.17.0.6-1595833428498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46841,DS-b9a2d078-0647-4ded-bc5b-a4de99da5770,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-a75c770c-98ba-41f9-aa67-384e05fd7ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-da83c2f9-95df-44bc-a25a-1a0c1c2be23b,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-93ca4641-5f29-4d5a-bb7e-c657e220999e,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-ca2cd6dc-84bd-4250-ada1-c1652a55e1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-121e13c6-e75f-49c7-928d-afd7a85b4646,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-7f52f730-5c37-472a-8018-dfa41c151341,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-ed9008ab-3edd-456e-b27e-eac347176b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249059590-172.17.0.6-1595833700293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41050,DS-d7b29eb0-a3d9-475e-af05-a0911753f2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-e322dfd4-4ba0-4b6b-9807-bd3d35e8f0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-2e4970cc-2443-4058-91e0-f82a1c878179,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-52b136ae-dcca-4ce5-b68e-62f56246bd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-39e2741f-849b-46c0-b332-749bbdf0adac,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-30bdf9ce-f735-48d4-b7b6-da288eaa0f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-8a885e04-b966-45aa-982c-f50839ad3193,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-66f603c2-8f02-48a4-88a9-c576e0f6a6e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249059590-172.17.0.6-1595833700293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41050,DS-d7b29eb0-a3d9-475e-af05-a0911753f2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-e322dfd4-4ba0-4b6b-9807-bd3d35e8f0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-2e4970cc-2443-4058-91e0-f82a1c878179,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-52b136ae-dcca-4ce5-b68e-62f56246bd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-39e2741f-849b-46c0-b332-749bbdf0adac,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-30bdf9ce-f735-48d4-b7b6-da288eaa0f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-8a885e04-b966-45aa-982c-f50839ad3193,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-66f603c2-8f02-48a4-88a9-c576e0f6a6e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192793072-172.17.0.6-1595834184214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33544,DS-1fffc9c5-556a-46e2-8ea2-bc421ed8b26f,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-acd0a61b-72df-408e-b454-53b12fb29f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-924ddc55-799b-4d82-bfe5-bc1c31b55d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-65301463-532c-4a40-b401-15e19572b764,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-3fd6dbf8-1672-4b01-945a-568587a8bcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-c023f91c-955f-4515-8e91-20cd540003dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-3fc386d0-c9ed-4b5e-93f2-5fee6a368d43,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-1b4b5e66-03a2-4e6c-97ac-1a929d65ad6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192793072-172.17.0.6-1595834184214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33544,DS-1fffc9c5-556a-46e2-8ea2-bc421ed8b26f,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-acd0a61b-72df-408e-b454-53b12fb29f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-924ddc55-799b-4d82-bfe5-bc1c31b55d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-65301463-532c-4a40-b401-15e19572b764,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-3fd6dbf8-1672-4b01-945a-568587a8bcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-c023f91c-955f-4515-8e91-20cd540003dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-3fc386d0-c9ed-4b5e-93f2-5fee6a368d43,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-1b4b5e66-03a2-4e6c-97ac-1a929d65ad6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155052001-172.17.0.6-1595834266216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45186,DS-ceb707e0-94c1-428d-ac8f-782ce37d7884,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-983a0e07-ece5-43f6-9321-891a723c4ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-6c2ac29d-5434-4194-bbe2-b5f5f99bab85,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-b23b091f-aa81-43fc-877b-4062a6085ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-135b850f-f34b-4ce5-9ac3-8d12b2c38e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-165f9a25-7cc9-4b2d-b7fe-ca7b9e21318e,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-e8d9729c-d0a6-4af8-a6f8-3b6ee5c6eed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-8b01a3db-75d0-45ed-b3a1-ff9477587e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155052001-172.17.0.6-1595834266216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45186,DS-ceb707e0-94c1-428d-ac8f-782ce37d7884,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-983a0e07-ece5-43f6-9321-891a723c4ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-6c2ac29d-5434-4194-bbe2-b5f5f99bab85,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-b23b091f-aa81-43fc-877b-4062a6085ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-135b850f-f34b-4ce5-9ac3-8d12b2c38e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-165f9a25-7cc9-4b2d-b7fe-ca7b9e21318e,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-e8d9729c-d0a6-4af8-a6f8-3b6ee5c6eed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-8b01a3db-75d0-45ed-b3a1-ff9477587e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58587316-172.17.0.6-1595834985184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35131,DS-5f4dec11-5343-48e8-92eb-8edf2fdd100a,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-26a98c94-d181-4cae-8ccf-b9a16e09ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-217e3d27-b422-4dfd-bfd7-95652fe12c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-9aa22877-f6fb-4b55-9e84-6ee7a245ac0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-34d01452-c0cd-46bc-bc26-de5942eea53f,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-735c29bb-ada5-455c-801f-88a6fbe70ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-d7e04e31-6a72-42b1-9a13-f6a55d06a213,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-fda22ae5-2b1d-49a3-8df6-863df18b0cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58587316-172.17.0.6-1595834985184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35131,DS-5f4dec11-5343-48e8-92eb-8edf2fdd100a,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-26a98c94-d181-4cae-8ccf-b9a16e09ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-217e3d27-b422-4dfd-bfd7-95652fe12c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-9aa22877-f6fb-4b55-9e84-6ee7a245ac0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-34d01452-c0cd-46bc-bc26-de5942eea53f,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-735c29bb-ada5-455c-801f-88a6fbe70ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-d7e04e31-6a72-42b1-9a13-f6a55d06a213,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-fda22ae5-2b1d-49a3-8df6-863df18b0cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174529130-172.17.0.6-1595835124312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-a7913a5e-572c-4e5d-b584-4846df7c6888,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-9dc4b085-4b51-4398-b60f-6071fb403b85,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-434f6b54-22e6-4383-9966-0d262eb03ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-bd7085bf-edb0-4beb-9d71-fa90c239bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-49b753d3-cede-4836-8cae-b0b531cb0e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-fa94e8d9-5a55-4572-a9cb-49cfe5fe7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-9057a364-f020-404c-8c55-3781baf78ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-4e28be1e-5f05-4d79-a258-5aec2da49b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174529130-172.17.0.6-1595835124312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-a7913a5e-572c-4e5d-b584-4846df7c6888,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-9dc4b085-4b51-4398-b60f-6071fb403b85,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-434f6b54-22e6-4383-9966-0d262eb03ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-bd7085bf-edb0-4beb-9d71-fa90c239bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-49b753d3-cede-4836-8cae-b0b531cb0e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-fa94e8d9-5a55-4572-a9cb-49cfe5fe7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-9057a364-f020-404c-8c55-3781baf78ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-4e28be1e-5f05-4d79-a258-5aec2da49b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492913059-172.17.0.6-1595835246871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43115,DS-fbd65c87-d410-4d24-a916-70fdad4d57fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-0f163f84-5977-4100-b7bd-6b64a000ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-f86c6e83-e70c-4d80-9e43-565135968228,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-da0a152a-6266-4b6a-8bff-f41933e74b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5bf02805-797c-48c2-a3fe-144116239a06,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-5a7b0578-e7c5-4340-80c4-06a9c827a8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-95ff6c24-752b-4601-9809-e79c77c7c990,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-bc8068c4-17d4-4483-9911-1b2cc0348cc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492913059-172.17.0.6-1595835246871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43115,DS-fbd65c87-d410-4d24-a916-70fdad4d57fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-0f163f84-5977-4100-b7bd-6b64a000ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-f86c6e83-e70c-4d80-9e43-565135968228,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-da0a152a-6266-4b6a-8bff-f41933e74b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5bf02805-797c-48c2-a3fe-144116239a06,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-5a7b0578-e7c5-4340-80c4-06a9c827a8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-95ff6c24-752b-4601-9809-e79c77c7c990,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-bc8068c4-17d4-4483-9911-1b2cc0348cc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035084552-172.17.0.6-1595835512180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-ba3d58c5-914e-4efc-ba47-7e364471a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-cf29f020-9b94-474d-aa01-9f595da0379e,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-f8e1bd42-39ad-4225-9918-caadda456541,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-34d9000b-ead3-4860-9643-6b76a3396635,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-66fb3683-67f4-4961-a8ca-f04f54a6167f,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-6a97aabd-fba8-4e95-a219-1eee9883b8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-edcc4afc-3f7c-40f7-beb2-5f1f153f76f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-f1325007-8f7d-4eb6-970a-a70f159635ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035084552-172.17.0.6-1595835512180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-ba3d58c5-914e-4efc-ba47-7e364471a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-cf29f020-9b94-474d-aa01-9f595da0379e,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-f8e1bd42-39ad-4225-9918-caadda456541,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-34d9000b-ead3-4860-9643-6b76a3396635,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-66fb3683-67f4-4961-a8ca-f04f54a6167f,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-6a97aabd-fba8-4e95-a219-1eee9883b8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-edcc4afc-3f7c-40f7-beb2-5f1f153f76f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-f1325007-8f7d-4eb6-970a-a70f159635ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641869249-172.17.0.6-1595835611925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-0759527e-d08a-4eb9-ba0e-973d667e02b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-ab7bd170-a132-4760-986e-7855cfe78596,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-d16f3126-8284-43f8-97a7-5f7962be291b,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-42067f20-b0b5-4344-98bf-8c91ff2ae17d,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-51833202-5f15-4c26-8181-ed7121a86097,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-bb00095b-20fe-433a-994f-b702332fbe24,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-b83914c8-b581-45e8-8808-9b930498c4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-69df764b-1dd7-4dd7-adc6-0256dc614a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641869249-172.17.0.6-1595835611925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-0759527e-d08a-4eb9-ba0e-973d667e02b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-ab7bd170-a132-4760-986e-7855cfe78596,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-d16f3126-8284-43f8-97a7-5f7962be291b,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-42067f20-b0b5-4344-98bf-8c91ff2ae17d,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-51833202-5f15-4c26-8181-ed7121a86097,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-bb00095b-20fe-433a-994f-b702332fbe24,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-b83914c8-b581-45e8-8808-9b930498c4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-69df764b-1dd7-4dd7-adc6-0256dc614a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268404007-172.17.0.6-1595835783263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35727,DS-674b8d14-590b-4771-aec7-fd495a589d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-1cd9383d-785b-4e2e-8254-d296c2a64fae,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-e8de9ddd-7e49-4eb3-b269-72686b94c4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-94756443-d7d5-4b7e-b8e5-d45168a6eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-72332da6-a3ef-4412-be7d-729c3226c4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-8c84bbea-5b4a-457a-9c49-7f53ac70feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-2fc78650-d7db-4b66-892b-4b9997858b87,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-d7d93be8-5fe1-499e-b81c-1b9b5f1e07b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268404007-172.17.0.6-1595835783263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35727,DS-674b8d14-590b-4771-aec7-fd495a589d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-1cd9383d-785b-4e2e-8254-d296c2a64fae,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-e8de9ddd-7e49-4eb3-b269-72686b94c4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-94756443-d7d5-4b7e-b8e5-d45168a6eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-72332da6-a3ef-4412-be7d-729c3226c4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-8c84bbea-5b4a-457a-9c49-7f53ac70feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-2fc78650-d7db-4b66-892b-4b9997858b87,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-d7d93be8-5fe1-499e-b81c-1b9b5f1e07b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052075185-172.17.0.6-1595835919094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39287,DS-f568ca11-71de-42d4-baad-cb0101345a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-3a9ffc80-cc57-474f-a88f-a9424e7e31b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-2da34dbf-10b4-430b-9159-f79e2bbaaa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-440c42b6-3608-40db-bc17-df684cfcb282,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-802e5ffc-bd21-4e71-8c1d-20f7da253c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-38a8791d-6b7b-4a8c-9fa8-9cfee0aa257a,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-59fdefa0-22fc-4828-a955-c794fbc8fcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-bae1159c-5860-4424-97ea-413b2bc25d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052075185-172.17.0.6-1595835919094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39287,DS-f568ca11-71de-42d4-baad-cb0101345a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-3a9ffc80-cc57-474f-a88f-a9424e7e31b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-2da34dbf-10b4-430b-9159-f79e2bbaaa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-440c42b6-3608-40db-bc17-df684cfcb282,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-802e5ffc-bd21-4e71-8c1d-20f7da253c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-38a8791d-6b7b-4a8c-9fa8-9cfee0aa257a,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-59fdefa0-22fc-4828-a955-c794fbc8fcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-bae1159c-5860-4424-97ea-413b2bc25d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629234190-172.17.0.6-1595836153220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-35cee523-a434-4084-a877-fabf8b8247a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-8624910c-e0b9-4f7d-8c5a-9df72f725f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-471e209d-7600-485c-afb8-511d1372deb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-81f1940f-28e3-4509-8c33-f23fa3fbf1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-c29ce06d-0b22-46c7-ab53-e5a63c30895a,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-4b3f4bbf-f908-4de8-b5b6-2bd3cf50b94c,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-388b6bf9-8a4e-42ee-9766-4fb1a6921836,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-5ba4e8a3-f698-44ef-8820-0312e4260793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629234190-172.17.0.6-1595836153220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-35cee523-a434-4084-a877-fabf8b8247a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-8624910c-e0b9-4f7d-8c5a-9df72f725f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-471e209d-7600-485c-afb8-511d1372deb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-81f1940f-28e3-4509-8c33-f23fa3fbf1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-c29ce06d-0b22-46c7-ab53-e5a63c30895a,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-4b3f4bbf-f908-4de8-b5b6-2bd3cf50b94c,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-388b6bf9-8a4e-42ee-9766-4fb1a6921836,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-5ba4e8a3-f698-44ef-8820-0312e4260793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624094763-172.17.0.6-1595836340052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-1d73f9c3-ed64-4693-9842-42ab14a55015,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-0d902f7a-412b-472f-91e9-7e823f16c6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-a957109f-5016-4d9c-9d26-054088a05945,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-1c02ea86-c4dc-48ed-8a3c-3c4f98fe59f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-a3669774-2093-424c-a865-48b885e73760,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-f0e62267-268d-4c1a-ad20-9af2fc6d77be,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-421d6187-f826-4112-ae96-a43d27d53c95,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-a0e53888-2b65-407f-9265-d49fca077a8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624094763-172.17.0.6-1595836340052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-1d73f9c3-ed64-4693-9842-42ab14a55015,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-0d902f7a-412b-472f-91e9-7e823f16c6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-a957109f-5016-4d9c-9d26-054088a05945,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-1c02ea86-c4dc-48ed-8a3c-3c4f98fe59f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-a3669774-2093-424c-a865-48b885e73760,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-f0e62267-268d-4c1a-ad20-9af2fc6d77be,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-421d6187-f826-4112-ae96-a43d27d53c95,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-a0e53888-2b65-407f-9265-d49fca077a8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647506387-172.17.0.6-1595837008765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-4d000a95-bf7a-46a7-88c4-b1527019db77,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-be82d300-e0bf-4cdf-b219-ca77da2d4e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-3af57eab-3353-4671-b7df-2c963ce30649,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-592cff54-266f-4c91-afe4-901cd2bffa63,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-973982c5-8f3d-4f3c-823e-b7c5e1e40e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-932c1949-08f7-48c8-918a-e5d5b4ffc586,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-45413729-1c17-4257-b6c6-1bfa872afae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-63f9352a-ea12-4e55-a4be-8d12779d6b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647506387-172.17.0.6-1595837008765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-4d000a95-bf7a-46a7-88c4-b1527019db77,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-be82d300-e0bf-4cdf-b219-ca77da2d4e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-3af57eab-3353-4671-b7df-2c963ce30649,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-592cff54-266f-4c91-afe4-901cd2bffa63,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-973982c5-8f3d-4f3c-823e-b7c5e1e40e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-932c1949-08f7-48c8-918a-e5d5b4ffc586,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-45413729-1c17-4257-b6c6-1bfa872afae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-63f9352a-ea12-4e55-a4be-8d12779d6b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791947656-172.17.0.6-1595837044554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-dd67d17c-ee77-4758-94f9-2a8477349dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-38ceda31-9c1c-423d-bd94-efada06ddad9,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-4658788e-a107-4309-b667-d6332f3227ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-66172b5a-634b-44d1-b9ec-2d6ab3f74c52,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-bd6af554-1d83-40de-90a2-7e0cd540a641,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-981f8ae1-fb34-4fd0-8770-b799f830c37e,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-6d50e494-e698-403d-a33f-cd68ecedf865,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-b45aba31-1c4c-48a0-b50c-f47ec222aae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791947656-172.17.0.6-1595837044554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-dd67d17c-ee77-4758-94f9-2a8477349dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-38ceda31-9c1c-423d-bd94-efada06ddad9,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-4658788e-a107-4309-b667-d6332f3227ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-66172b5a-634b-44d1-b9ec-2d6ab3f74c52,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-bd6af554-1d83-40de-90a2-7e0cd540a641,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-981f8ae1-fb34-4fd0-8770-b799f830c37e,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-6d50e494-e698-403d-a33f-cd68ecedf865,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-b45aba31-1c4c-48a0-b50c-f47ec222aae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333093352-172.17.0.6-1595837454938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39726,DS-5463faac-0dac-4cd1-99c6-ffe57b3820cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-061a39f4-b7e9-4d33-81d9-ea494560da65,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-08b53851-7ccf-4e5f-85a7-80e2345ae2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-ebc2627e-ebd1-4901-a822-470f5543ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-0d7e7f3f-f0cf-46b1-91d4-891077b8f099,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-345bac50-5c2c-4889-8607-d18b2abc9c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-5f24c363-b6de-4919-a50a-ee05d3538d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-269a3bf1-90c0-4e62-b95c-ea154f06b35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333093352-172.17.0.6-1595837454938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39726,DS-5463faac-0dac-4cd1-99c6-ffe57b3820cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-061a39f4-b7e9-4d33-81d9-ea494560da65,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-08b53851-7ccf-4e5f-85a7-80e2345ae2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-ebc2627e-ebd1-4901-a822-470f5543ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-0d7e7f3f-f0cf-46b1-91d4-891077b8f099,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-345bac50-5c2c-4889-8607-d18b2abc9c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-5f24c363-b6de-4919-a50a-ee05d3538d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-269a3bf1-90c0-4e62-b95c-ea154f06b35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367483778-172.17.0.6-1595837740449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41596,DS-7dadde85-99c9-4546-9585-3f1d34dfa013,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-7f305dc9-3720-4bc2-9000-5ae0de467fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-55c29410-5730-4e97-a726-b72335b04c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-e4493571-21f9-4f5e-9ea0-63e433a99951,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-c731ddad-4c40-451e-87c7-b0e0e178a083,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-f1730137-d0d5-4e36-a733-85b66f607d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-a258d50a-0454-4655-8bb7-d489a99b2966,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-58575766-337c-4f5e-b7a4-08fa797e0f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367483778-172.17.0.6-1595837740449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41596,DS-7dadde85-99c9-4546-9585-3f1d34dfa013,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-7f305dc9-3720-4bc2-9000-5ae0de467fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-55c29410-5730-4e97-a726-b72335b04c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-e4493571-21f9-4f5e-9ea0-63e433a99951,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-c731ddad-4c40-451e-87c7-b0e0e178a083,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-f1730137-d0d5-4e36-a733-85b66f607d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-a258d50a-0454-4655-8bb7-d489a99b2966,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-58575766-337c-4f5e-b7a4-08fa797e0f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872366751-172.17.0.6-1595837928115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34548,DS-eaed0f4c-120d-418b-a889-1b587e4dd9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-a0ceaf49-9bd6-4fa1-ab25-afc025df3a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-2aaaded5-106d-48d4-bdf9-a2277831ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-f8787be7-9ae5-4015-940f-e8b4052490cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-ac82ee11-b86b-42cb-a7ed-30f19179463e,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-cfb3bb41-698f-4a49-bab5-cd1b0e859d76,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-c40ac8a1-65b5-4c77-a2b5-243e2c4cb7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-983f2293-7ff3-47cc-b6d8-b45587808b67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872366751-172.17.0.6-1595837928115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34548,DS-eaed0f4c-120d-418b-a889-1b587e4dd9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-a0ceaf49-9bd6-4fa1-ab25-afc025df3a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-2aaaded5-106d-48d4-bdf9-a2277831ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-f8787be7-9ae5-4015-940f-e8b4052490cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-ac82ee11-b86b-42cb-a7ed-30f19179463e,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-cfb3bb41-698f-4a49-bab5-cd1b0e859d76,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-c40ac8a1-65b5-4c77-a2b5-243e2c4cb7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-983f2293-7ff3-47cc-b6d8-b45587808b67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953170424-172.17.0.6-1595838107975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-a53306ed-f00c-4c9e-9a5e-dc792aae9d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-eb59a369-98b2-4052-82d4-67082e1cfe61,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-e2c0727a-94ae-4859-aae3-835fdcc224f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-9b620e2a-7038-4ed6-a2c9-b4720fb2cdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-9822640a-ff4a-4db3-8880-2d870a9f0efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-4e70ec7b-ed70-4bf3-800c-ad68df98e7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-9c6f15e9-e535-4f5a-a0df-345e569f68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-b061b31f-08c2-468e-8a00-217555832208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953170424-172.17.0.6-1595838107975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-a53306ed-f00c-4c9e-9a5e-dc792aae9d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-eb59a369-98b2-4052-82d4-67082e1cfe61,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-e2c0727a-94ae-4859-aae3-835fdcc224f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-9b620e2a-7038-4ed6-a2c9-b4720fb2cdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-9822640a-ff4a-4db3-8880-2d870a9f0efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-4e70ec7b-ed70-4bf3-800c-ad68df98e7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-9c6f15e9-e535-4f5a-a0df-345e569f68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-b061b31f-08c2-468e-8a00-217555832208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5361
