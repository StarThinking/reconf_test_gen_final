reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920574665-172.17.0.9-1595986199067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41812,DS-99c837fc-2e17-4780-b2b2-946e1bf505a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-b8dc3d5a-9d17-40fc-914e-4435af68b74f,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-136ca205-532d-4900-8666-6e8461660e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-91eefa6a-8603-4a49-8dc2-8216f0bb8d91,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-092a3329-6c67-4ee7-9a1d-e26d500531ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-069f7f52-db4a-4187-9738-733646fce882,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-913d6b30-d4a8-4634-96a1-b4e8cd77415b,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-67b92814-4369-46a0-90ad-a706a0a31c72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920574665-172.17.0.9-1595986199067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41812,DS-99c837fc-2e17-4780-b2b2-946e1bf505a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-b8dc3d5a-9d17-40fc-914e-4435af68b74f,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-136ca205-532d-4900-8666-6e8461660e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-91eefa6a-8603-4a49-8dc2-8216f0bb8d91,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-092a3329-6c67-4ee7-9a1d-e26d500531ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-069f7f52-db4a-4187-9738-733646fce882,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-913d6b30-d4a8-4634-96a1-b4e8cd77415b,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-67b92814-4369-46a0-90ad-a706a0a31c72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220095580-172.17.0.9-1595986463975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46407,DS-64c6c86c-1a3c-45a5-ae45-6d4f55d5bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-df6bdef1-0a8f-4020-bbde-d4ed54322b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-b515579e-c28b-4db2-a0fc-bc6dc0fab51f,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-1c12b668-9b95-433e-b82d-b6ac3491fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b06af3b0-ea99-4dca-a383-db521dc564bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-0ad51549-6632-4766-a75c-24e0f421e4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-97c92c02-9427-4679-87b7-a2ed693a6201,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-5888d5c9-cbe6-4472-b56b-db1d57495566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220095580-172.17.0.9-1595986463975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46407,DS-64c6c86c-1a3c-45a5-ae45-6d4f55d5bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-df6bdef1-0a8f-4020-bbde-d4ed54322b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-b515579e-c28b-4db2-a0fc-bc6dc0fab51f,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-1c12b668-9b95-433e-b82d-b6ac3491fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b06af3b0-ea99-4dca-a383-db521dc564bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-0ad51549-6632-4766-a75c-24e0f421e4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-97c92c02-9427-4679-87b7-a2ed693a6201,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-5888d5c9-cbe6-4472-b56b-db1d57495566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507987573-172.17.0.9-1595986869103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44807,DS-07bd7070-6ccd-48bd-8c62-38612c046296,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-d09c3bac-12f4-4a4a-8610-4c567e66ec14,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-d941e081-7229-4883-8096-693243d049f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-2a5039dc-3e07-4758-bc86-6a3fa40e6024,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-4e477a7e-d053-4990-a533-f037697dfbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-75a7bba3-a700-4abc-9f81-57cdc85a3c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-0b1b35cf-121e-4058-8c0b-73360e7a619a,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-5278670c-3150-4c0f-bb77-839c1fc628d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507987573-172.17.0.9-1595986869103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44807,DS-07bd7070-6ccd-48bd-8c62-38612c046296,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-d09c3bac-12f4-4a4a-8610-4c567e66ec14,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-d941e081-7229-4883-8096-693243d049f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-2a5039dc-3e07-4758-bc86-6a3fa40e6024,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-4e477a7e-d053-4990-a533-f037697dfbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-75a7bba3-a700-4abc-9f81-57cdc85a3c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-0b1b35cf-121e-4058-8c0b-73360e7a619a,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-5278670c-3150-4c0f-bb77-839c1fc628d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032683239-172.17.0.9-1595987104766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-915f0b10-4b87-402c-9915-3e35e5dccfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-470f5376-64ad-43e8-adbe-b94b2e25cd10,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-8c5979f7-d8a8-40e9-b082-3813f4a59f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-a8f7330f-38af-443d-ad14-c6986bb73cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-4508fdb2-1657-451c-a060-1637679b931b,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-59581734-49fc-42b3-95a6-bff578b382f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-c59f1222-68e4-4b28-9969-fae7e7cfb306,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-cd3653ab-d0bd-4db6-9628-0fef65a94ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032683239-172.17.0.9-1595987104766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-915f0b10-4b87-402c-9915-3e35e5dccfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-470f5376-64ad-43e8-adbe-b94b2e25cd10,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-8c5979f7-d8a8-40e9-b082-3813f4a59f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-a8f7330f-38af-443d-ad14-c6986bb73cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-4508fdb2-1657-451c-a060-1637679b931b,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-59581734-49fc-42b3-95a6-bff578b382f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-c59f1222-68e4-4b28-9969-fae7e7cfb306,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-cd3653ab-d0bd-4db6-9628-0fef65a94ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957236104-172.17.0.9-1595987911443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45554,DS-15104c49-1a9c-4c77-b61a-05d08acdddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-f795f420-d6c6-4738-8798-243388822b19,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-c118ebec-e327-4663-bbd0-6084d0b103f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-38f34030-36b6-4617-84f8-e9448ce2f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-be958303-6085-4f86-a342-830795b31e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-1c8d3cec-7e30-40b1-99d9-d254577ae338,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-b326b65e-89e8-4eff-b09e-5e63d64a82f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-2a1374f1-6f06-4885-8863-2de3099f0f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957236104-172.17.0.9-1595987911443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45554,DS-15104c49-1a9c-4c77-b61a-05d08acdddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-f795f420-d6c6-4738-8798-243388822b19,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-c118ebec-e327-4663-bbd0-6084d0b103f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-38f34030-36b6-4617-84f8-e9448ce2f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-be958303-6085-4f86-a342-830795b31e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-1c8d3cec-7e30-40b1-99d9-d254577ae338,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-b326b65e-89e8-4eff-b09e-5e63d64a82f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-2a1374f1-6f06-4885-8863-2de3099f0f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203918652-172.17.0.9-1595988000289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-8f658220-76d9-40b2-81c5-9913dd580112,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-ab0d3fff-cadd-4075-a62c-a565502fdb03,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-5c8adacd-a6bc-468a-bcc8-cbf6e65fe5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-39392bd8-64df-4cd1-9469-123f2263aee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-452f80f5-0605-427e-b3a0-1c5254331848,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-77644aeb-6dbe-4456-8776-fe34b4144eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-67c0eeca-185a-4a39-bcdb-923ec1449cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-113f9909-8df2-4f6d-ad26-7d1468930029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203918652-172.17.0.9-1595988000289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-8f658220-76d9-40b2-81c5-9913dd580112,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-ab0d3fff-cadd-4075-a62c-a565502fdb03,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-5c8adacd-a6bc-468a-bcc8-cbf6e65fe5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-39392bd8-64df-4cd1-9469-123f2263aee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-452f80f5-0605-427e-b3a0-1c5254331848,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-77644aeb-6dbe-4456-8776-fe34b4144eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-67c0eeca-185a-4a39-bcdb-923ec1449cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-113f9909-8df2-4f6d-ad26-7d1468930029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442624673-172.17.0.9-1595988099261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-e1983d51-0031-4645-b791-016a78f89283,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-4f05d44c-055f-4f61-9a8e-c27a469a3bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-f8401ecb-a314-4dd8-ae40-9cbfc6c58587,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-ecde6067-1718-4686-9f9b-25c59686887f,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-03a64e39-48ca-48ff-89b5-a7b3cd22301c,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-eba9f2dc-feaf-4846-a5d6-a73b27c8c991,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-2c9c19a2-b6a1-4e09-8dcd-86fb9ee08548,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-cd50dc99-0a38-4dbb-a9d5-f68b58a699e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442624673-172.17.0.9-1595988099261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-e1983d51-0031-4645-b791-016a78f89283,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-4f05d44c-055f-4f61-9a8e-c27a469a3bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-f8401ecb-a314-4dd8-ae40-9cbfc6c58587,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-ecde6067-1718-4686-9f9b-25c59686887f,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-03a64e39-48ca-48ff-89b5-a7b3cd22301c,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-eba9f2dc-feaf-4846-a5d6-a73b27c8c991,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-2c9c19a2-b6a1-4e09-8dcd-86fb9ee08548,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-cd50dc99-0a38-4dbb-a9d5-f68b58a699e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565632740-172.17.0.9-1595988568317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42309,DS-1387d9cc-0ed9-4502-b609-ea0b81388b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-655e0dad-ecca-47a7-b20e-947fb4a5b4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-e89608b4-47f3-45b3-9079-88cc47f82d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-979993d2-c083-4ea1-95cb-9cd0e7af14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-466ad9bf-a3f8-4b4d-b5e9-2af3928ae1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-05a2c60c-cb31-499c-93ba-8b463a61c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-e2abea0c-d13c-4980-aec1-d97caa4e9792,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-71291675-2d3a-4a10-993c-a864ce4eb13c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565632740-172.17.0.9-1595988568317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42309,DS-1387d9cc-0ed9-4502-b609-ea0b81388b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-655e0dad-ecca-47a7-b20e-947fb4a5b4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-e89608b4-47f3-45b3-9079-88cc47f82d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-979993d2-c083-4ea1-95cb-9cd0e7af14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-466ad9bf-a3f8-4b4d-b5e9-2af3928ae1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-05a2c60c-cb31-499c-93ba-8b463a61c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-e2abea0c-d13c-4980-aec1-d97caa4e9792,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-71291675-2d3a-4a10-993c-a864ce4eb13c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619326942-172.17.0.9-1595988699597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41045,DS-5107e616-6867-4761-adcb-ab3437c6ac18,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-591f7bd9-472b-4818-8c45-5e8c95b8be39,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-ce967fbd-6281-4957-9842-3745f3ab98af,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-ceaa0a01-7ba9-4111-938e-eba59fd0a2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-6dda8a25-4bd5-41e1-83ef-64cf8eddd10d,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-b3cac095-362f-4abc-9901-508dfa63c831,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-0aac10d3-e62c-495f-ba60-08e48e74bd16,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-24a9d7b6-5dbb-4098-ae31-9cc6376b07cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619326942-172.17.0.9-1595988699597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41045,DS-5107e616-6867-4761-adcb-ab3437c6ac18,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-591f7bd9-472b-4818-8c45-5e8c95b8be39,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-ce967fbd-6281-4957-9842-3745f3ab98af,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-ceaa0a01-7ba9-4111-938e-eba59fd0a2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-6dda8a25-4bd5-41e1-83ef-64cf8eddd10d,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-b3cac095-362f-4abc-9901-508dfa63c831,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-0aac10d3-e62c-495f-ba60-08e48e74bd16,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-24a9d7b6-5dbb-4098-ae31-9cc6376b07cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283676635-172.17.0.9-1595988772679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-14ae8b56-de4a-4a4e-8034-9c1f487b8186,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-5c38fe4c-2ea6-4357-b5e6-e4b9c61f2817,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-f6bb7228-aba1-4a7e-abf2-7dbbfd42031f,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-c2aa4bd3-8eca-49b9-825f-a1435a2457a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-8fef31c0-582b-4b76-a0e0-b03dafa1baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-e90ae3f2-17d1-45a7-911c-2837790208e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-bc5bf573-58e0-49c5-8540-dc79d20872b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-e1961402-4e84-49b8-b6ef-165bf36054bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283676635-172.17.0.9-1595988772679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-14ae8b56-de4a-4a4e-8034-9c1f487b8186,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-5c38fe4c-2ea6-4357-b5e6-e4b9c61f2817,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-f6bb7228-aba1-4a7e-abf2-7dbbfd42031f,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-c2aa4bd3-8eca-49b9-825f-a1435a2457a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-8fef31c0-582b-4b76-a0e0-b03dafa1baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-e90ae3f2-17d1-45a7-911c-2837790208e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-bc5bf573-58e0-49c5-8540-dc79d20872b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-e1961402-4e84-49b8-b6ef-165bf36054bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077049585-172.17.0.9-1595989242896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42586,DS-84856873-7642-43c8-82b2-957c0168c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-68eb2529-412d-4d4f-9329-f8a5df525ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-1d61c418-da1c-442b-a49c-ce6f1ec7e719,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-55db67b9-fe47-4e18-bc6c-a5d5799ef63b,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-0953af0a-ce1f-4fdd-8c79-4fded527e1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-37e322db-ef9e-4732-97b5-78de1dbf770c,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-180ceae9-056e-469f-a979-a66128ed0194,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-89224b3b-0c97-471a-b0e7-601609c4e567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077049585-172.17.0.9-1595989242896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42586,DS-84856873-7642-43c8-82b2-957c0168c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-68eb2529-412d-4d4f-9329-f8a5df525ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-1d61c418-da1c-442b-a49c-ce6f1ec7e719,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-55db67b9-fe47-4e18-bc6c-a5d5799ef63b,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-0953af0a-ce1f-4fdd-8c79-4fded527e1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-37e322db-ef9e-4732-97b5-78de1dbf770c,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-180ceae9-056e-469f-a979-a66128ed0194,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-89224b3b-0c97-471a-b0e7-601609c4e567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265060902-172.17.0.9-1595989521996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43576,DS-30b598e8-94d6-4db8-b30e-1c91a340eb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-ceafa55e-c959-4b8e-b966-b272a26e493c,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-cae446fd-044c-4fe7-b4aa-fa0ce764de4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-06c3a154-59aa-4b8d-b525-4eb90481e3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-d1f3ba61-d292-4e5a-8455-d34344b304fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-fcee6d07-d53e-42af-a590-6c3edfa8108d,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-968a6dd9-5668-4e6e-9188-21c40bd7773c,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-d74eec33-6754-4d44-9e05-9fb3687fd766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265060902-172.17.0.9-1595989521996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43576,DS-30b598e8-94d6-4db8-b30e-1c91a340eb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-ceafa55e-c959-4b8e-b966-b272a26e493c,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-cae446fd-044c-4fe7-b4aa-fa0ce764de4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-06c3a154-59aa-4b8d-b525-4eb90481e3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-d1f3ba61-d292-4e5a-8455-d34344b304fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-fcee6d07-d53e-42af-a590-6c3edfa8108d,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-968a6dd9-5668-4e6e-9188-21c40bd7773c,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-d74eec33-6754-4d44-9e05-9fb3687fd766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143691133-172.17.0.9-1595990139840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41192,DS-b9de5e0d-cb67-436d-855f-efd435d012fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-f2c641d1-9d5a-4eb2-8616-69ab2a410ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-c2bbfed1-8dfc-4a21-a45f-fcae703edb12,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-a0954288-4532-42b2-a418-31f39089f33b,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-023056e7-a8d0-424f-99bf-1af6bf71a72e,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-f1a00084-659c-45cf-9b3c-c11bdd1aa69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-a8001a07-5106-4ca2-a800-cd8e4b769d10,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-833a7f5e-3f3f-48dc-bb97-31aaa7740250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143691133-172.17.0.9-1595990139840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41192,DS-b9de5e0d-cb67-436d-855f-efd435d012fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-f2c641d1-9d5a-4eb2-8616-69ab2a410ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-c2bbfed1-8dfc-4a21-a45f-fcae703edb12,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-a0954288-4532-42b2-a418-31f39089f33b,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-023056e7-a8d0-424f-99bf-1af6bf71a72e,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-f1a00084-659c-45cf-9b3c-c11bdd1aa69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-a8001a07-5106-4ca2-a800-cd8e4b769d10,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-833a7f5e-3f3f-48dc-bb97-31aaa7740250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747489864-172.17.0.9-1595990642346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-3de69193-f6f4-4953-a484-81d9176adf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-f762a811-e03c-4857-a3cd-0e60c21eba72,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-057ab53b-af04-4b67-b166-8d3e3306ddba,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-c4dd22eb-18d8-441c-9281-292fbbcaef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-962fe66b-f818-4bc7-b442-0cc53c8c9fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-108c8a62-07ab-4da3-9896-971f58c60631,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-2d6f1f45-b8f7-4309-a177-89ea812253fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-e6a97d53-1b53-4a69-b074-48636252e967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747489864-172.17.0.9-1595990642346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-3de69193-f6f4-4953-a484-81d9176adf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-f762a811-e03c-4857-a3cd-0e60c21eba72,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-057ab53b-af04-4b67-b166-8d3e3306ddba,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-c4dd22eb-18d8-441c-9281-292fbbcaef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-962fe66b-f818-4bc7-b442-0cc53c8c9fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-108c8a62-07ab-4da3-9896-971f58c60631,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-2d6f1f45-b8f7-4309-a177-89ea812253fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-e6a97d53-1b53-4a69-b074-48636252e967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879842292-172.17.0.9-1595990672996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-d80c2273-5c50-4e2f-8252-adb71cc38562,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-490a3a44-9c84-4628-a592-c794f1ad47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-9fab69a5-5811-4d11-b0a7-e8886bbac982,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-dbbc3e15-5955-491a-a6dd-b26577ee6251,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-2c7478f1-8f74-467c-bc80-c9bed10a2274,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-842ca845-83bd-4cd0-a480-d7f19e26085f,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-bc0774c4-41d2-42a0-87b6-3507c8f5c554,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-0a00c489-4d37-4ba4-86ff-847ecc6b9baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879842292-172.17.0.9-1595990672996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-d80c2273-5c50-4e2f-8252-adb71cc38562,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-490a3a44-9c84-4628-a592-c794f1ad47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-9fab69a5-5811-4d11-b0a7-e8886bbac982,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-dbbc3e15-5955-491a-a6dd-b26577ee6251,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-2c7478f1-8f74-467c-bc80-c9bed10a2274,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-842ca845-83bd-4cd0-a480-d7f19e26085f,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-bc0774c4-41d2-42a0-87b6-3507c8f5c554,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-0a00c489-4d37-4ba4-86ff-847ecc6b9baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442795474-172.17.0.9-1595990816164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-c45ae4e8-dc9e-403f-9177-0f076a1a1a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-5ed19f8d-c1f7-47d4-b67d-db5a1dadfc79,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-f73bc78a-221a-4594-9650-da934419ae82,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-dad45b6b-acfa-4c10-953d-2320e711e36f,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-6bfad694-cc4c-478d-9139-a12b014355bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-7baeedf3-1ce4-441a-82f3-626b71c63b46,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-f0ad9971-4756-401e-b8ab-a70e6d95aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-6e185045-dd56-4adb-b783-88dca8fc75d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442795474-172.17.0.9-1595990816164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-c45ae4e8-dc9e-403f-9177-0f076a1a1a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-5ed19f8d-c1f7-47d4-b67d-db5a1dadfc79,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-f73bc78a-221a-4594-9650-da934419ae82,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-dad45b6b-acfa-4c10-953d-2320e711e36f,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-6bfad694-cc4c-478d-9139-a12b014355bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-7baeedf3-1ce4-441a-82f3-626b71c63b46,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-f0ad9971-4756-401e-b8ab-a70e6d95aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-6e185045-dd56-4adb-b783-88dca8fc75d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208961718-172.17.0.9-1595991078943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-cc1807e3-6adb-4c45-a264-7a7f03a15827,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-7d41ee79-11c7-4114-83bd-b8efc8c626d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-defe3ca2-bcc8-48c6-bfe2-46a1afa2b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-e9f935c6-6409-449c-b83a-f1a1b03399f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-19309166-2ee2-460c-9c0f-305c27952f57,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-c6fc22c7-86e1-42e8-bd1b-23cc94b50858,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-d1d26e2a-3713-42e8-9894-30729becf78d,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-8e0453b0-54c5-482e-be80-1a4a1aa92b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208961718-172.17.0.9-1595991078943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-cc1807e3-6adb-4c45-a264-7a7f03a15827,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-7d41ee79-11c7-4114-83bd-b8efc8c626d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-defe3ca2-bcc8-48c6-bfe2-46a1afa2b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-e9f935c6-6409-449c-b83a-f1a1b03399f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-19309166-2ee2-460c-9c0f-305c27952f57,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-c6fc22c7-86e1-42e8-bd1b-23cc94b50858,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-d1d26e2a-3713-42e8-9894-30729becf78d,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-8e0453b0-54c5-482e-be80-1a4a1aa92b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5179
