reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234339977-172.17.0.11-1596003252202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39989,DS-dfba9df1-3207-4c71-8868-483361d11be7,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-15e03c3c-b561-408f-9f04-b84f60459fee,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-e64323da-0b82-405d-9d8f-40dab6f9157d,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-74522d77-afec-41b3-b07b-191644c004a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-5da80aa0-b8f6-474e-b2bd-97bbed695bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-30c68fbe-2d57-4a5c-8fae-965efd206c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9f10e046-d47c-4e02-bf8b-7624dbfcf3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-a5904ea2-2009-48e2-9cf2-82e36cfd95a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234339977-172.17.0.11-1596003252202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39989,DS-dfba9df1-3207-4c71-8868-483361d11be7,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-15e03c3c-b561-408f-9f04-b84f60459fee,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-e64323da-0b82-405d-9d8f-40dab6f9157d,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-74522d77-afec-41b3-b07b-191644c004a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-5da80aa0-b8f6-474e-b2bd-97bbed695bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-30c68fbe-2d57-4a5c-8fae-965efd206c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9f10e046-d47c-4e02-bf8b-7624dbfcf3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-a5904ea2-2009-48e2-9cf2-82e36cfd95a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324800133-172.17.0.11-1596003393355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37753,DS-3dc56f66-ca5b-4579-af89-99ce9ef831ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-adedaa48-6917-4a84-9305-3c0a88b54e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-49bc3efa-4acf-4466-8be1-a6450fb547a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-534d6379-5303-4804-af01-15e98ff36f83,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-2e79e849-4d87-41c4-a1af-1991175c8c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-2ea7f064-9150-4f19-94b1-ee3ee9829421,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-a26166dc-f2c9-428d-943d-27d912131fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-fba9a89c-9b5d-41c5-9928-002d7bea42e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324800133-172.17.0.11-1596003393355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37753,DS-3dc56f66-ca5b-4579-af89-99ce9ef831ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-adedaa48-6917-4a84-9305-3c0a88b54e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-49bc3efa-4acf-4466-8be1-a6450fb547a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-534d6379-5303-4804-af01-15e98ff36f83,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-2e79e849-4d87-41c4-a1af-1991175c8c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-2ea7f064-9150-4f19-94b1-ee3ee9829421,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-a26166dc-f2c9-428d-943d-27d912131fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-fba9a89c-9b5d-41c5-9928-002d7bea42e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629058801-172.17.0.11-1596003683889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37686,DS-3cb99e2e-a557-4bc9-8e91-dd48183c8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-4ae834aa-6451-4bb4-a4dc-fd7d819961c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-500f8989-f139-434e-b201-116a699abdee,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-a336adf4-ca64-4e59-a141-1f4aafa6ddee,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-de54e260-814a-414d-a695-90ba9d4b8a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-b5e5767c-5947-4411-a52c-7485649756ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-10670222-5b15-4bfd-9068-c63cf59ec86f,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-6deb7b03-7410-4089-b965-5f6267aa4e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629058801-172.17.0.11-1596003683889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37686,DS-3cb99e2e-a557-4bc9-8e91-dd48183c8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-4ae834aa-6451-4bb4-a4dc-fd7d819961c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-500f8989-f139-434e-b201-116a699abdee,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-a336adf4-ca64-4e59-a141-1f4aafa6ddee,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-de54e260-814a-414d-a695-90ba9d4b8a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-b5e5767c-5947-4411-a52c-7485649756ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-10670222-5b15-4bfd-9068-c63cf59ec86f,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-6deb7b03-7410-4089-b965-5f6267aa4e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865190789-172.17.0.11-1596004319282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-c8d0b516-a39a-4031-abd3-7242b5ace203,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-d7e81117-f104-45fe-a8a2-023579d06bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-e599c046-815d-4c85-9e44-a64eb57ad8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-14641ef5-7e74-43e0-8cc5-f2aec0f49282,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-5a3ba0b5-a5ed-45aa-ab7b-4c42258704d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-89436e28-ed7a-460c-a76e-31cebfcaa1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-1e364430-533d-4ba7-9f29-0aec90fad8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-78bc361f-137f-4f9c-aa92-5b376ad5d743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865190789-172.17.0.11-1596004319282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-c8d0b516-a39a-4031-abd3-7242b5ace203,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-d7e81117-f104-45fe-a8a2-023579d06bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-e599c046-815d-4c85-9e44-a64eb57ad8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-14641ef5-7e74-43e0-8cc5-f2aec0f49282,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-5a3ba0b5-a5ed-45aa-ab7b-4c42258704d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-89436e28-ed7a-460c-a76e-31cebfcaa1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-1e364430-533d-4ba7-9f29-0aec90fad8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-78bc361f-137f-4f9c-aa92-5b376ad5d743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755400809-172.17.0.11-1596004433278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-8aa200ba-5d83-4a6c-9926-8cb9a20cfa01,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-fee0379d-7704-4d42-bc0e-f7d6edc908a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-56f326b4-65d8-44ed-a010-fbfbbd71cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-26f279ba-9b52-493c-9a10-8c6139f8da33,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-368259fb-6145-41cc-9ccb-5ece0dc31add,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-c944b2b8-1824-4488-b990-c459668eb60b,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-0daf8642-c27f-4e80-9e97-e35596799eca,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-857f75ae-bc4f-45da-9af9-7696c0c88705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755400809-172.17.0.11-1596004433278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-8aa200ba-5d83-4a6c-9926-8cb9a20cfa01,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-fee0379d-7704-4d42-bc0e-f7d6edc908a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-56f326b4-65d8-44ed-a010-fbfbbd71cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-26f279ba-9b52-493c-9a10-8c6139f8da33,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-368259fb-6145-41cc-9ccb-5ece0dc31add,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-c944b2b8-1824-4488-b990-c459668eb60b,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-0daf8642-c27f-4e80-9e97-e35596799eca,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-857f75ae-bc4f-45da-9af9-7696c0c88705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215031137-172.17.0.11-1596004501644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46245,DS-e652d349-9655-400d-a6ce-9331c456280e,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-8d0a01d7-44d9-460e-9a5a-60b289f45357,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-4991a37f-891e-46cb-a288-3d83ca7aad28,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-80d31024-707c-4aef-becc-3fd334308e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-5a0e0f54-6ded-458e-9665-1b2b7fe29294,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-0786baf1-cbb4-4572-ad51-08f35c74d615,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-ef2dfd89-2ad5-4522-832a-dbe41aae4db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-0b657021-d6b0-4d0f-8559-b374a5c19030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215031137-172.17.0.11-1596004501644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46245,DS-e652d349-9655-400d-a6ce-9331c456280e,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-8d0a01d7-44d9-460e-9a5a-60b289f45357,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-4991a37f-891e-46cb-a288-3d83ca7aad28,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-80d31024-707c-4aef-becc-3fd334308e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-5a0e0f54-6ded-458e-9665-1b2b7fe29294,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-0786baf1-cbb4-4572-ad51-08f35c74d615,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-ef2dfd89-2ad5-4522-832a-dbe41aae4db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-0b657021-d6b0-4d0f-8559-b374a5c19030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445875196-172.17.0.11-1596004606120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-11e8374a-5d6c-408e-87c0-ff3d56d34920,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-2621c8ca-0efa-4479-b022-55f933afec57,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-9d31c8c9-00b6-4221-9669-cd2ed32886ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-09c78209-e6e9-4cad-83f6-c34bf089659b,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-eccefd11-c3e2-4879-b674-be71c1222c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-49e99d97-b647-4bd9-9c07-8e2ab8b23279,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-bf666e20-d201-4c9b-abd1-0c22a11e86c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-5bab5fe6-8cd8-4e83-b13a-af6fccd4ead5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445875196-172.17.0.11-1596004606120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-11e8374a-5d6c-408e-87c0-ff3d56d34920,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-2621c8ca-0efa-4479-b022-55f933afec57,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-9d31c8c9-00b6-4221-9669-cd2ed32886ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-09c78209-e6e9-4cad-83f6-c34bf089659b,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-eccefd11-c3e2-4879-b674-be71c1222c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-49e99d97-b647-4bd9-9c07-8e2ab8b23279,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-bf666e20-d201-4c9b-abd1-0c22a11e86c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-5bab5fe6-8cd8-4e83-b13a-af6fccd4ead5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412768963-172.17.0.11-1596004719873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-1ba52a14-2478-49e7-94d5-023e1fdde63f,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-c65555b5-780c-44f5-89e0-e731a4715a72,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-42fa90dc-7019-4db3-83b3-0db443c7d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-6bcc9771-e22e-4967-9257-a6b2b1cb009a,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-0c10593d-d014-4b01-b1dc-9cba38d51128,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-8031a7a7-d783-438b-be33-ea10665ce5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-5ec86d3c-5c86-44ad-ae72-3e1aa55a747a,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-9d23e2f1-1038-4165-93c4-22d42f6b1b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412768963-172.17.0.11-1596004719873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-1ba52a14-2478-49e7-94d5-023e1fdde63f,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-c65555b5-780c-44f5-89e0-e731a4715a72,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-42fa90dc-7019-4db3-83b3-0db443c7d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-6bcc9771-e22e-4967-9257-a6b2b1cb009a,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-0c10593d-d014-4b01-b1dc-9cba38d51128,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-8031a7a7-d783-438b-be33-ea10665ce5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-5ec86d3c-5c86-44ad-ae72-3e1aa55a747a,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-9d23e2f1-1038-4165-93c4-22d42f6b1b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585150078-172.17.0.11-1596005120602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39283,DS-d2b3b67c-e061-4bba-b843-4c26f31f8c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-5b67bfd3-7c97-4e4d-bfcf-bdd004d84d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-864191f8-5b8c-4a3e-8caf-378bfcddef83,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-3a12dbfa-e7bb-4f3d-bd53-85c03f871101,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-949356f2-dcb6-4ad6-86bd-7722e9c4c62a,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-0a1be617-6d19-4720-9000-2e45aeb05fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-21f9a619-22d4-4e9f-8be0-c4489182a928,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-c52690b4-d6d3-4e16-a2aa-68c173e2ba31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585150078-172.17.0.11-1596005120602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39283,DS-d2b3b67c-e061-4bba-b843-4c26f31f8c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-5b67bfd3-7c97-4e4d-bfcf-bdd004d84d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-864191f8-5b8c-4a3e-8caf-378bfcddef83,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-3a12dbfa-e7bb-4f3d-bd53-85c03f871101,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-949356f2-dcb6-4ad6-86bd-7722e9c4c62a,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-0a1be617-6d19-4720-9000-2e45aeb05fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-21f9a619-22d4-4e9f-8be0-c4489182a928,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-c52690b4-d6d3-4e16-a2aa-68c173e2ba31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915292635-172.17.0.11-1596005597633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-bef86bc6-6ebc-4067-a9b0-a1a27865eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-cbbc0ad5-ad65-42c4-bfbf-b9864a77eeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-9c58aec3-7a00-4751-a494-944796a6caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-2dc75e06-0c08-4c0e-ab13-6cb2179fafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-d497dd0e-ef2f-407b-bbdf-8c9b2d5ea812,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-e6e623b7-380c-4729-9d2f-250c6797a54d,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-487502c4-8823-40d4-8c6d-fd8b87128351,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-c87e685e-8341-4be1-88fc-6e478fd75e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915292635-172.17.0.11-1596005597633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-bef86bc6-6ebc-4067-a9b0-a1a27865eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-cbbc0ad5-ad65-42c4-bfbf-b9864a77eeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-9c58aec3-7a00-4751-a494-944796a6caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-2dc75e06-0c08-4c0e-ab13-6cb2179fafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-d497dd0e-ef2f-407b-bbdf-8c9b2d5ea812,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-e6e623b7-380c-4729-9d2f-250c6797a54d,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-487502c4-8823-40d4-8c6d-fd8b87128351,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-c87e685e-8341-4be1-88fc-6e478fd75e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657926200-172.17.0.11-1596005706237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42721,DS-acf86959-ffce-4d8f-9a3e-96470f4e4cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-c60e5ceb-2f88-49a7-97f3-627bbd6614a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-04fda4f8-8ee0-42ff-be49-ba43e3a76575,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-db9cdcab-3593-4349-a567-7013d9c4380d,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-557b8393-9ec9-409c-b338-2393c3eee8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-3ab1c424-efb9-4d16-beab-7bbc661ad501,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-be024b0a-a4f1-4319-be7f-d418f80c3c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-7e54c37f-9953-49eb-a889-db7c0a1e4eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657926200-172.17.0.11-1596005706237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42721,DS-acf86959-ffce-4d8f-9a3e-96470f4e4cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-c60e5ceb-2f88-49a7-97f3-627bbd6614a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-04fda4f8-8ee0-42ff-be49-ba43e3a76575,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-db9cdcab-3593-4349-a567-7013d9c4380d,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-557b8393-9ec9-409c-b338-2393c3eee8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-3ab1c424-efb9-4d16-beab-7bbc661ad501,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-be024b0a-a4f1-4319-be7f-d418f80c3c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-7e54c37f-9953-49eb-a889-db7c0a1e4eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611088472-172.17.0.11-1596005861952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37191,DS-dc3e3068-98fb-4d6c-a11b-c41b385304cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-b7882b2d-8097-462e-9785-8126ee2b3785,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-fc0d3905-3ba9-40b9-87f8-167edc85a776,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-a2287b8c-5b31-40b3-94b4-39b896652ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-d701dc3b-4b27-4145-838e-a055e7db4c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-54caac25-d160-4be6-93b1-b976b73f153c,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-8fdb806c-fcde-4246-b10c-17a71b608d90,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-5476ac22-c11c-4bb5-98eb-4fc7ac99b752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611088472-172.17.0.11-1596005861952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37191,DS-dc3e3068-98fb-4d6c-a11b-c41b385304cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-b7882b2d-8097-462e-9785-8126ee2b3785,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-fc0d3905-3ba9-40b9-87f8-167edc85a776,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-a2287b8c-5b31-40b3-94b4-39b896652ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-d701dc3b-4b27-4145-838e-a055e7db4c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-54caac25-d160-4be6-93b1-b976b73f153c,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-8fdb806c-fcde-4246-b10c-17a71b608d90,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-5476ac22-c11c-4bb5-98eb-4fc7ac99b752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405107680-172.17.0.11-1596007413015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40414,DS-0e10fd38-8932-4358-a799-c850a0859477,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-3b42782a-568d-4b52-83cf-1a8a5913149d,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-36e8e425-6099-429d-8bba-90fac31325ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-b9ea9f0c-4188-44ac-8798-064931370428,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-6266d91e-e731-41b0-8a3c-9c0abfebc877,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-5625be1c-c586-413d-bb09-9b2619724ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-5ece1080-e0b3-47ec-93b1-f647731c641e,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-06cb21fd-456a-4d94-8e4f-af2e5b8f126e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405107680-172.17.0.11-1596007413015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40414,DS-0e10fd38-8932-4358-a799-c850a0859477,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-3b42782a-568d-4b52-83cf-1a8a5913149d,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-36e8e425-6099-429d-8bba-90fac31325ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-b9ea9f0c-4188-44ac-8798-064931370428,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-6266d91e-e731-41b0-8a3c-9c0abfebc877,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-5625be1c-c586-413d-bb09-9b2619724ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-5ece1080-e0b3-47ec-93b1-f647731c641e,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-06cb21fd-456a-4d94-8e4f-af2e5b8f126e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721450618-172.17.0.11-1596007596331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-26f87888-ac3d-465b-993f-f2fd95338009,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-91fd7b83-5e38-48d4-ad5b-4b2df129e0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-e4a67dd3-4a88-4d60-8ca2-b3b756b7ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-450ceb99-88b4-4e0f-9f8d-b71084641eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-b0d96a61-b037-4dfe-89e1-09e209c5ea51,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-84101898-99bd-415d-a7b0-ffe62b1049b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-9720a304-5635-40b0-aef5-b7784e58eca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-ea549485-68ed-4ee0-ab8b-e704bcdcb833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721450618-172.17.0.11-1596007596331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-26f87888-ac3d-465b-993f-f2fd95338009,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-91fd7b83-5e38-48d4-ad5b-4b2df129e0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-e4a67dd3-4a88-4d60-8ca2-b3b756b7ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-450ceb99-88b4-4e0f-9f8d-b71084641eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-b0d96a61-b037-4dfe-89e1-09e209c5ea51,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-84101898-99bd-415d-a7b0-ffe62b1049b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-9720a304-5635-40b0-aef5-b7784e58eca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-ea549485-68ed-4ee0-ab8b-e704bcdcb833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601108635-172.17.0.11-1596008047626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34387,DS-e58a079c-39e5-4557-ad11-16219cb31b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-49c5fae9-a9bd-4362-b2e8-95874490dbae,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-a5e7093d-73fe-4859-ab3d-298fecb8b5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-6f81af0c-941a-4316-8739-a010e364e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-777c2d13-65ca-4229-b78c-1861bcd90a92,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-d8c67412-6c55-42db-81d5-1bea26cc1664,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-d73866d6-04c9-4390-94f2-c0853ad3111e,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-b8b73873-a7ff-41dd-8ca1-144db2adb9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601108635-172.17.0.11-1596008047626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34387,DS-e58a079c-39e5-4557-ad11-16219cb31b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-49c5fae9-a9bd-4362-b2e8-95874490dbae,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-a5e7093d-73fe-4859-ab3d-298fecb8b5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-6f81af0c-941a-4316-8739-a010e364e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-777c2d13-65ca-4229-b78c-1861bcd90a92,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-d8c67412-6c55-42db-81d5-1bea26cc1664,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-d73866d6-04c9-4390-94f2-c0853ad3111e,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-b8b73873-a7ff-41dd-8ca1-144db2adb9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710985344-172.17.0.11-1596008355877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34978,DS-e78b1f3c-33c3-405a-b1d7-51d2b82f926e,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-b1876f62-d3ea-4513-bf08-3d50441fa920,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-a89a26d0-cec9-4d01-a61b-6732e42b367b,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-8e807785-744d-4e2d-8b92-a14811ad7660,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-97e08cc2-bfb6-457e-80e3-951f1eec2ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-b28221e3-05a2-4e76-89f8-2a42195523cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-616f0aaf-3055-4c6d-b3c3-f7b7e4499237,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-a9dfe780-078a-44cf-a87a-4c9c38841094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710985344-172.17.0.11-1596008355877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34978,DS-e78b1f3c-33c3-405a-b1d7-51d2b82f926e,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-b1876f62-d3ea-4513-bf08-3d50441fa920,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-a89a26d0-cec9-4d01-a61b-6732e42b367b,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-8e807785-744d-4e2d-8b92-a14811ad7660,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-97e08cc2-bfb6-457e-80e3-951f1eec2ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-b28221e3-05a2-4e76-89f8-2a42195523cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-616f0aaf-3055-4c6d-b3c3-f7b7e4499237,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-a9dfe780-078a-44cf-a87a-4c9c38841094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833511097-172.17.0.11-1596008390489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-ff468b0b-72a4-40af-ac01-8d27bce33d44,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-9c9bb2ae-0c4e-4b09-a6e0-4ab6a3c0598c,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-fad021cb-ae13-447d-9c14-497070982c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-819430c2-67e1-446c-bfaa-b8a7c0348e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-b98e5c4f-c41f-4e9d-b00a-e70f35daa293,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-490e00d0-8989-42af-b8ee-93f33da6b661,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-ca5fc6a0-3d55-4b34-9572-89eb1e51f51d,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-b8855bec-86d5-46a0-b997-b003baa7d3bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833511097-172.17.0.11-1596008390489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-ff468b0b-72a4-40af-ac01-8d27bce33d44,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-9c9bb2ae-0c4e-4b09-a6e0-4ab6a3c0598c,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-fad021cb-ae13-447d-9c14-497070982c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-819430c2-67e1-446c-bfaa-b8a7c0348e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-b98e5c4f-c41f-4e9d-b00a-e70f35daa293,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-490e00d0-8989-42af-b8ee-93f33da6b661,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-ca5fc6a0-3d55-4b34-9572-89eb1e51f51d,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-b8855bec-86d5-46a0-b997-b003baa7d3bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5577
