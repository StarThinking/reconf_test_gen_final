reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990293634-172.17.0.4-1595971707391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-a981261d-ab13-4222-8b99-b7386be5553b,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-304cebd0-c777-463b-a1c2-fa77575e3264,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-473fb5e5-5430-40f0-99cd-08982bf03fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-e94ecacb-f91b-4081-862e-d6fb585e1e79,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-9c455624-c08a-45b1-9bc7-f3db9f12f305,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-ecac1d96-e0f5-46c3-81fa-1023579e3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-2f14117e-476b-4cbb-a387-a4d9fb884954,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-be830a97-6550-4573-9761-c851465766a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990293634-172.17.0.4-1595971707391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-a981261d-ab13-4222-8b99-b7386be5553b,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-304cebd0-c777-463b-a1c2-fa77575e3264,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-473fb5e5-5430-40f0-99cd-08982bf03fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-e94ecacb-f91b-4081-862e-d6fb585e1e79,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-9c455624-c08a-45b1-9bc7-f3db9f12f305,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-ecac1d96-e0f5-46c3-81fa-1023579e3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-2f14117e-476b-4cbb-a387-a4d9fb884954,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-be830a97-6550-4573-9761-c851465766a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685375725-172.17.0.4-1595972627976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-dcd31bb3-bc95-46b9-8888-807e69a41f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-d7f87f5a-928a-4178-b411-c648becb5067,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-d6d2acc9-80b5-4038-aaa7-33fad837b00b,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-2c7d3e25-7b4d-4334-bf4c-b2310a9cdd70,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-18c00196-75e5-46f8-82aa-ebc747c62992,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-a2be2d36-b39a-4ae6-ad7f-53c762f2808f,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-70c7b5b8-7aa3-41fe-9a95-2a9790b02d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-b32f34c6-2e4f-4bff-8935-59083ce05509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685375725-172.17.0.4-1595972627976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-dcd31bb3-bc95-46b9-8888-807e69a41f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-d7f87f5a-928a-4178-b411-c648becb5067,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-d6d2acc9-80b5-4038-aaa7-33fad837b00b,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-2c7d3e25-7b4d-4334-bf4c-b2310a9cdd70,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-18c00196-75e5-46f8-82aa-ebc747c62992,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-a2be2d36-b39a-4ae6-ad7f-53c762f2808f,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-70c7b5b8-7aa3-41fe-9a95-2a9790b02d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-b32f34c6-2e4f-4bff-8935-59083ce05509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103816855-172.17.0.4-1595973395343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40755,DS-9d418018-9f4b-4e06-b852-e1217abe2cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-98501b8d-416a-4261-8616-de2e34b7d4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-53f9d196-6469-4e63-946e-169a4b3cf0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-0695bc69-4faf-492c-82dd-48c40d544d88,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-7fe2f6af-be87-4111-b33c-4b2aca71a49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-c7d6ebe7-e4fd-4def-9e12-411e1d6ebdba,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-41fdeb04-4ff7-483f-8668-27375f44b064,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-c5c19aff-7024-4da2-a09e-80baada7bfab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103816855-172.17.0.4-1595973395343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40755,DS-9d418018-9f4b-4e06-b852-e1217abe2cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-98501b8d-416a-4261-8616-de2e34b7d4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-53f9d196-6469-4e63-946e-169a4b3cf0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-0695bc69-4faf-492c-82dd-48c40d544d88,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-7fe2f6af-be87-4111-b33c-4b2aca71a49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-c7d6ebe7-e4fd-4def-9e12-411e1d6ebdba,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-41fdeb04-4ff7-483f-8668-27375f44b064,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-c5c19aff-7024-4da2-a09e-80baada7bfab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137418343-172.17.0.4-1595973465450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-626dc7c7-08b2-4c88-8579-712bdd09797f,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-a010157a-7486-459a-8811-9eda904dcfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-202431d3-7c3b-4521-8321-f002acf9b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-12205962-7e6e-488f-91b3-4a26b32ef9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-69bdafee-6b01-494f-9d45-b706214837fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-c20dd197-329b-4be9-8142-992d4e1cf567,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-dffe6217-4cd0-4a49-9c23-17d259778b54,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-855e4792-d9a1-4cdb-8d20-cfe137742a25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137418343-172.17.0.4-1595973465450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-626dc7c7-08b2-4c88-8579-712bdd09797f,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-a010157a-7486-459a-8811-9eda904dcfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-202431d3-7c3b-4521-8321-f002acf9b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-12205962-7e6e-488f-91b3-4a26b32ef9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-69bdafee-6b01-494f-9d45-b706214837fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-c20dd197-329b-4be9-8142-992d4e1cf567,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-dffe6217-4cd0-4a49-9c23-17d259778b54,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-855e4792-d9a1-4cdb-8d20-cfe137742a25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726759764-172.17.0.4-1595973544925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40662,DS-0ffa6b52-f57c-4e6a-b745-6477f91ddcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-282ed259-ff43-4ae3-b6e3-b6f184f34840,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-978a0d64-a2fb-424b-b232-884b9c9f68a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-4c5d5cd8-a26a-41bd-9477-9ae679551547,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-bf5847b5-e199-4175-8de5-44399e7a2814,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-880edbe7-c5c1-4006-a93f-e8a84b3d685e,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-9ed43357-2385-48f7-abf6-6071e1d73fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-927966ad-d96a-4af6-bb91-a3c0755f8014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726759764-172.17.0.4-1595973544925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40662,DS-0ffa6b52-f57c-4e6a-b745-6477f91ddcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-282ed259-ff43-4ae3-b6e3-b6f184f34840,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-978a0d64-a2fb-424b-b232-884b9c9f68a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-4c5d5cd8-a26a-41bd-9477-9ae679551547,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-bf5847b5-e199-4175-8de5-44399e7a2814,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-880edbe7-c5c1-4006-a93f-e8a84b3d685e,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-9ed43357-2385-48f7-abf6-6071e1d73fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-927966ad-d96a-4af6-bb91-a3c0755f8014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855020097-172.17.0.4-1595973809348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-f9ab4052-3b2c-4be4-b40e-e158493b6537,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-946a4dfb-9a76-4013-9333-d9bea704c647,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-10002281-716a-49d4-ab44-aae03534dbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-ac17d776-82f8-4378-ad05-418790c5c6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-cd1a2c12-cf9e-4a50-bd71-dc9b22ea52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-1c60ea17-ab9a-4f7d-aee0-2171bd44cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-a2bafeef-6605-47ac-a382-6684847915e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-6567f097-0fb5-4ed9-a86a-358054f0e973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855020097-172.17.0.4-1595973809348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-f9ab4052-3b2c-4be4-b40e-e158493b6537,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-946a4dfb-9a76-4013-9333-d9bea704c647,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-10002281-716a-49d4-ab44-aae03534dbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-ac17d776-82f8-4378-ad05-418790c5c6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-cd1a2c12-cf9e-4a50-bd71-dc9b22ea52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-1c60ea17-ab9a-4f7d-aee0-2171bd44cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-a2bafeef-6605-47ac-a382-6684847915e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-6567f097-0fb5-4ed9-a86a-358054f0e973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416954057-172.17.0.4-1595973965761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41354,DS-19c8b413-078c-45ab-be1e-751ec7815aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-308ac84b-0048-483d-9942-4ccd49f45aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-fa98fb3c-bbcf-48e9-8ca7-8b6426882827,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-19dcfe4c-ad77-4620-b815-fa8da34ff48b,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-64a9bcbd-46d6-4ab5-aa90-c4a7001dfce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-ce3a97d2-cdef-40d3-b17b-97d3094eeac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-54192af0-8de0-404c-b0b8-5d5ed08fcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-63aa7c7f-7433-4ffb-a512-d948013ed286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416954057-172.17.0.4-1595973965761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41354,DS-19c8b413-078c-45ab-be1e-751ec7815aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-308ac84b-0048-483d-9942-4ccd49f45aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-fa98fb3c-bbcf-48e9-8ca7-8b6426882827,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-19dcfe4c-ad77-4620-b815-fa8da34ff48b,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-64a9bcbd-46d6-4ab5-aa90-c4a7001dfce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-ce3a97d2-cdef-40d3-b17b-97d3094eeac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-54192af0-8de0-404c-b0b8-5d5ed08fcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-63aa7c7f-7433-4ffb-a512-d948013ed286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674880309-172.17.0.4-1595974757606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-5632133d-2512-4e2e-a124-671388637f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-c1335943-734f-4fd8-a69f-3d4e95bf41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-1d3c09fd-5e9b-4de9-8f52-352b30d4c6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-2997688f-c665-4970-91a0-1c6c6be157bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-55803fcd-dd4b-47ab-9767-ed432e4c3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-5e34827e-d0a9-4654-b08b-1fbd656f683e,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-8559fb35-f694-4f97-9a48-32673d4cddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-32d9a989-e0f9-4859-8227-5a256273b264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674880309-172.17.0.4-1595974757606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-5632133d-2512-4e2e-a124-671388637f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-c1335943-734f-4fd8-a69f-3d4e95bf41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-1d3c09fd-5e9b-4de9-8f52-352b30d4c6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-2997688f-c665-4970-91a0-1c6c6be157bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-55803fcd-dd4b-47ab-9767-ed432e4c3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-5e34827e-d0a9-4654-b08b-1fbd656f683e,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-8559fb35-f694-4f97-9a48-32673d4cddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-32d9a989-e0f9-4859-8227-5a256273b264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823048723-172.17.0.4-1595975246408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-7f9ffaa5-048e-485c-8442-087f7f6c9552,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-0a22168c-9f01-4f56-be87-3a13586ce422,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-1c84985c-82f8-4bca-93bc-b202453a3954,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-f04ff8ab-5ff8-4053-8c33-cb2100cba41a,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-7f036835-5e7f-45af-93c9-8cd0894f43b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-0e924192-396e-4c47-b163-e9aa2494c9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-b5094bb2-5888-4fbe-b2e9-f7ca5a2036f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-5f857456-6b84-43ec-905c-bf754e6320fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823048723-172.17.0.4-1595975246408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-7f9ffaa5-048e-485c-8442-087f7f6c9552,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-0a22168c-9f01-4f56-be87-3a13586ce422,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-1c84985c-82f8-4bca-93bc-b202453a3954,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-f04ff8ab-5ff8-4053-8c33-cb2100cba41a,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-7f036835-5e7f-45af-93c9-8cd0894f43b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-0e924192-396e-4c47-b163-e9aa2494c9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-b5094bb2-5888-4fbe-b2e9-f7ca5a2036f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-5f857456-6b84-43ec-905c-bf754e6320fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906868078-172.17.0.4-1595975284206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35617,DS-5a2e88a2-bfba-4134-b135-0311f34bec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-30b2cc6f-064c-4462-86cc-21399edce409,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-479fd834-cad4-4b63-9f3b-db7a3f9e83b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-f101fd89-0681-4432-854a-64594e6c1e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-95867cd9-c4bd-4c4b-934e-d548aafd1954,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-7b58434f-c3f4-4b8c-aec6-e0ee56efaf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-03420170-47c7-42d3-bc3e-4f59d8885323,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-55208b29-3742-48b1-9056-d1109d4310bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906868078-172.17.0.4-1595975284206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35617,DS-5a2e88a2-bfba-4134-b135-0311f34bec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-30b2cc6f-064c-4462-86cc-21399edce409,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-479fd834-cad4-4b63-9f3b-db7a3f9e83b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-f101fd89-0681-4432-854a-64594e6c1e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-95867cd9-c4bd-4c4b-934e-d548aafd1954,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-7b58434f-c3f4-4b8c-aec6-e0ee56efaf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-03420170-47c7-42d3-bc3e-4f59d8885323,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-55208b29-3742-48b1-9056-d1109d4310bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346788141-172.17.0.4-1595975359610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35168,DS-87e24df1-0310-43a1-b9d9-112098021e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-b92aa680-dc0c-44c1-ab5a-04372938240b,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-4efd6391-2f01-4aed-a318-7729eccf40f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-f9fc8460-3b7c-4c6e-a8c5-079825e81d05,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-860bc403-cd54-4aec-aba0-8ea53da0b227,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-d319f5cc-19aa-446a-b91e-10dc6919dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-bfb086fc-fade-4e27-9f35-0431c45aba75,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-ccb7f4f5-bc6c-4a31-8ec2-aa77d7e49078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346788141-172.17.0.4-1595975359610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35168,DS-87e24df1-0310-43a1-b9d9-112098021e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-b92aa680-dc0c-44c1-ab5a-04372938240b,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-4efd6391-2f01-4aed-a318-7729eccf40f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-f9fc8460-3b7c-4c6e-a8c5-079825e81d05,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-860bc403-cd54-4aec-aba0-8ea53da0b227,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-d319f5cc-19aa-446a-b91e-10dc6919dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-bfb086fc-fade-4e27-9f35-0431c45aba75,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-ccb7f4f5-bc6c-4a31-8ec2-aa77d7e49078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261974019-172.17.0.4-1595975501843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-165c0f18-4b7f-49d1-9c36-a7285dab23c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-3e693bd2-d4f1-4f8d-af13-096397ac3866,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-7352318f-9e4d-4b9a-af6c-8f24bde48e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-856b059c-4216-43c4-8068-b3e4975a943b,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-0a1d992e-1a2c-4873-9183-f73742a298f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-a22460dd-a7de-45d6-897f-1d5875134360,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-f1c2b3b2-31ab-4134-b888-26eed565c078,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-23fb7a95-a7b6-44cb-8745-ab1bbbf34caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261974019-172.17.0.4-1595975501843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-165c0f18-4b7f-49d1-9c36-a7285dab23c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-3e693bd2-d4f1-4f8d-af13-096397ac3866,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-7352318f-9e4d-4b9a-af6c-8f24bde48e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-856b059c-4216-43c4-8068-b3e4975a943b,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-0a1d992e-1a2c-4873-9183-f73742a298f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-a22460dd-a7de-45d6-897f-1d5875134360,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-f1c2b3b2-31ab-4134-b888-26eed565c078,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-23fb7a95-a7b6-44cb-8745-ab1bbbf34caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123580973-172.17.0.4-1595975691813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-82542bbe-1229-46c9-9745-48fedf8a6bff,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-7fc9f8a4-c1a0-4a8d-bdb9-2ac27e9c5039,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-1cb73651-6562-4bd3-be18-3b85fb54413c,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-9cd58b3b-cd55-411c-8513-2df0cd1e23e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4d0947bc-942c-458f-a8f7-9710c503f2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-2f263ed6-9f9d-450e-8beb-64d41881bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-c0f3703b-b04c-4fb0-8b68-c08dc4eb5313,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-22792a04-26ce-4f34-bd8a-392252c668d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123580973-172.17.0.4-1595975691813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-82542bbe-1229-46c9-9745-48fedf8a6bff,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-7fc9f8a4-c1a0-4a8d-bdb9-2ac27e9c5039,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-1cb73651-6562-4bd3-be18-3b85fb54413c,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-9cd58b3b-cd55-411c-8513-2df0cd1e23e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4d0947bc-942c-458f-a8f7-9710c503f2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-2f263ed6-9f9d-450e-8beb-64d41881bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-c0f3703b-b04c-4fb0-8b68-c08dc4eb5313,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-22792a04-26ce-4f34-bd8a-392252c668d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338950600-172.17.0.4-1595975798260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38157,DS-fddeca44-a971-4e07-9e0a-bab7fa570e17,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-883c8890-25ea-4d49-976f-a18d5c2db31a,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-678b716f-9038-4608-8148-9d31b8cc5609,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-63f81e5b-8b24-479a-9685-86aedbabb50d,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-98ed3922-520e-4665-991d-8bf2dd98ec07,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-0e8d4a54-2c10-4614-ac5c-fca17c719e24,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-cd1f7b10-f5f5-4768-97d2-4e5e69e18137,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-3bc8e9e2-1d51-4714-9f6e-699938844f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338950600-172.17.0.4-1595975798260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38157,DS-fddeca44-a971-4e07-9e0a-bab7fa570e17,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-883c8890-25ea-4d49-976f-a18d5c2db31a,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-678b716f-9038-4608-8148-9d31b8cc5609,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-63f81e5b-8b24-479a-9685-86aedbabb50d,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-98ed3922-520e-4665-991d-8bf2dd98ec07,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-0e8d4a54-2c10-4614-ac5c-fca17c719e24,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-cd1f7b10-f5f5-4768-97d2-4e5e69e18137,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-3bc8e9e2-1d51-4714-9f6e-699938844f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010294083-172.17.0.4-1595975910847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-eb183e4b-6d69-4024-b0ee-c46252add539,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-28e67bc0-3818-42eb-a2d9-7c5e429fbb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-73b401aa-37cb-425f-b3bd-8bf0633a36c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-e7f888b2-74f2-4a06-884f-c2c756fe4d34,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-9920b621-d32c-4e22-ae89-832bf310f586,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-3d281b15-259e-4ca1-92f1-5901957bb092,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-2e4250c1-a4a2-4200-8a13-cc7557577383,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-64c37874-6025-4a75-9372-b36fe08d2ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010294083-172.17.0.4-1595975910847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-eb183e4b-6d69-4024-b0ee-c46252add539,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-28e67bc0-3818-42eb-a2d9-7c5e429fbb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-73b401aa-37cb-425f-b3bd-8bf0633a36c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-e7f888b2-74f2-4a06-884f-c2c756fe4d34,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-9920b621-d32c-4e22-ae89-832bf310f586,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-3d281b15-259e-4ca1-92f1-5901957bb092,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-2e4250c1-a4a2-4200-8a13-cc7557577383,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-64c37874-6025-4a75-9372-b36fe08d2ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150964434-172.17.0.4-1595976168762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37189,DS-eda0157c-9d49-431d-a594-fb913e3b2c35,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-a002f4e3-70d2-4ede-82ff-6b317c970fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-0eb08695-1d17-4010-9d16-17c58191ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-3a77cc38-303a-4710-89aa-ffca03925b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-3834efd4-46cb-4a33-bbb5-f780a63fa980,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-5bab1b88-c5c5-496e-9b31-0fd072acb5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-b7fba3b2-aaef-4203-bf26-c1aa82b58868,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-5b7965fb-8782-4845-ac36-2c52eef5a425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150964434-172.17.0.4-1595976168762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37189,DS-eda0157c-9d49-431d-a594-fb913e3b2c35,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-a002f4e3-70d2-4ede-82ff-6b317c970fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-0eb08695-1d17-4010-9d16-17c58191ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-3a77cc38-303a-4710-89aa-ffca03925b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-3834efd4-46cb-4a33-bbb5-f780a63fa980,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-5bab1b88-c5c5-496e-9b31-0fd072acb5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-b7fba3b2-aaef-4203-bf26-c1aa82b58868,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-5b7965fb-8782-4845-ac36-2c52eef5a425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020617221-172.17.0.4-1595976583299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-83ec581a-f7b1-4f34-b6fc-8b461f527893,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-b84000e2-a9c2-4d7f-96b5-892da8c11ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-8cd7a2ee-62a3-4d3c-a48a-7f57ae05262c,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-f30dc91f-db0e-4fea-8a4f-98ead37f551d,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-ea8fbf23-0cda-4da3-949e-1576411c2af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-1bf8c51a-ae11-4311-82ce-1d2ba1866518,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-4b181aee-dca1-4e33-b437-52c99683388d,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-142083c3-bd48-428a-b9b2-8e0f6c8107b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020617221-172.17.0.4-1595976583299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-83ec581a-f7b1-4f34-b6fc-8b461f527893,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-b84000e2-a9c2-4d7f-96b5-892da8c11ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-8cd7a2ee-62a3-4d3c-a48a-7f57ae05262c,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-f30dc91f-db0e-4fea-8a4f-98ead37f551d,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-ea8fbf23-0cda-4da3-949e-1576411c2af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-1bf8c51a-ae11-4311-82ce-1d2ba1866518,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-4b181aee-dca1-4e33-b437-52c99683388d,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-142083c3-bd48-428a-b9b2-8e0f6c8107b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271459618-172.17.0.4-1595976777031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46033,DS-c140af46-7f36-4515-b062-5f7d08d0b39d,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-84705662-29da-4d43-a468-81d9a69e37be,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-0bfd5ef5-1ad2-4307-b816-96326e724b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-199bfea3-af59-4660-a62b-9f7f9a90ba22,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-12d6a730-b1e4-4599-8afc-deaaf7c63b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-5aa51f29-c53b-4560-8bcc-153d06bcb257,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-67bd0ff7-c730-4f25-b1a7-37c52473960a,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-f2b1a29d-f120-46df-b05a-35e2db3e405e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271459618-172.17.0.4-1595976777031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46033,DS-c140af46-7f36-4515-b062-5f7d08d0b39d,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-84705662-29da-4d43-a468-81d9a69e37be,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-0bfd5ef5-1ad2-4307-b816-96326e724b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-199bfea3-af59-4660-a62b-9f7f9a90ba22,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-12d6a730-b1e4-4599-8afc-deaaf7c63b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-5aa51f29-c53b-4560-8bcc-153d06bcb257,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-67bd0ff7-c730-4f25-b1a7-37c52473960a,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-f2b1a29d-f120-46df-b05a-35e2db3e405e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5552
