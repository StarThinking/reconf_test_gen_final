reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240842139-172.17.0.10-1595928432892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40198,DS-0306bb2f-400c-48d6-b0ab-0dcce2fcd7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-4ec5122e-5f41-4164-8532-267379c1c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-70391254-7572-42de-94ec-b41557eb7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-153b5f35-60ed-4dc5-8baa-581434d01879,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-f37a1387-c785-4943-8fa2-7375cca37b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-34a6ebe4-eac5-4325-9b44-a6b00f272b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4ab005c4-a03d-440a-bd20-4c23af0bc037,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-33257271-dc82-4615-9b1e-540e0dcd363a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240842139-172.17.0.10-1595928432892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40198,DS-0306bb2f-400c-48d6-b0ab-0dcce2fcd7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-4ec5122e-5f41-4164-8532-267379c1c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-70391254-7572-42de-94ec-b41557eb7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-153b5f35-60ed-4dc5-8baa-581434d01879,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-f37a1387-c785-4943-8fa2-7375cca37b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-34a6ebe4-eac5-4325-9b44-a6b00f272b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4ab005c4-a03d-440a-bd20-4c23af0bc037,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-33257271-dc82-4615-9b1e-540e0dcd363a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345807747-172.17.0.10-1595929088882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-d285b575-ec89-4893-80fa-7341281e36dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-56e9a3a2-4b2e-410f-aebb-8c272d594316,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-0bb0c9db-5573-487e-80d9-8365dace7295,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-8050dfa7-b389-41cf-adec-7103b62ccaba,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-d5ebcd51-0c39-432d-bcc3-e75fb597534c,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-1c8248b6-93a4-40de-b195-4c95866ffc83,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-7851aff9-ea6b-4679-83c7-575cde65bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-f3687e4d-d097-44e4-85f5-47fac5d71a9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345807747-172.17.0.10-1595929088882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-d285b575-ec89-4893-80fa-7341281e36dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-56e9a3a2-4b2e-410f-aebb-8c272d594316,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-0bb0c9db-5573-487e-80d9-8365dace7295,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-8050dfa7-b389-41cf-adec-7103b62ccaba,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-d5ebcd51-0c39-432d-bcc3-e75fb597534c,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-1c8248b6-93a4-40de-b195-4c95866ffc83,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-7851aff9-ea6b-4679-83c7-575cde65bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-f3687e4d-d097-44e4-85f5-47fac5d71a9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007422506-172.17.0.10-1595929567409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46358,DS-982dd85c-8293-42b5-b88e-03d9a58d11c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-2ece0835-3a9c-45d3-a55a-20feac6ae61c,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-e8888f63-6b0b-41de-b15f-eb6e19cead7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-9a4aa43d-ca13-4695-b5e2-e029a481c09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-d1e3a4fd-9e48-4436-b4ec-68bdc2d18305,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-c97c9e33-c1e3-4e93-afb3-778ad0ff889b,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-aca7a7a1-68e2-46e9-b604-f13b31f33af6,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-c4554440-f386-41c3-b63a-35d7e57ddceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007422506-172.17.0.10-1595929567409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46358,DS-982dd85c-8293-42b5-b88e-03d9a58d11c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-2ece0835-3a9c-45d3-a55a-20feac6ae61c,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-e8888f63-6b0b-41de-b15f-eb6e19cead7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-9a4aa43d-ca13-4695-b5e2-e029a481c09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-d1e3a4fd-9e48-4436-b4ec-68bdc2d18305,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-c97c9e33-c1e3-4e93-afb3-778ad0ff889b,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-aca7a7a1-68e2-46e9-b604-f13b31f33af6,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-c4554440-f386-41c3-b63a-35d7e57ddceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545991558-172.17.0.10-1595929671317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41769,DS-c064ef1a-e94f-48f5-bae8-61ccf341dfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-6fdec109-2804-49e5-a45f-72b8e6659e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-020acc97-7395-445c-a9ab-288d73614f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-714fb5a6-fd08-4473-89ee-667daad6160e,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-08c199ec-1a67-4166-9e6e-bab2d35bacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-e444ecbc-eecc-4f12-8155-73ff5b776f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-45c009e9-c422-4c36-a349-8fc9a2c63033,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-8dc3a969-4efc-4cbc-93ea-52a5f3774f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545991558-172.17.0.10-1595929671317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41769,DS-c064ef1a-e94f-48f5-bae8-61ccf341dfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-6fdec109-2804-49e5-a45f-72b8e6659e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-020acc97-7395-445c-a9ab-288d73614f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-714fb5a6-fd08-4473-89ee-667daad6160e,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-08c199ec-1a67-4166-9e6e-bab2d35bacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-e444ecbc-eecc-4f12-8155-73ff5b776f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-45c009e9-c422-4c36-a349-8fc9a2c63033,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-8dc3a969-4efc-4cbc-93ea-52a5f3774f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890023383-172.17.0.10-1595930712594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-c484b25c-8d80-4f5f-bcbd-52a85e01d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-6e69029c-2590-4baf-ac37-ad428a117322,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-0e84ffda-53a4-4fa7-aafb-307fc93f9e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-9cf2f690-b00e-43d0-911e-92b08c683260,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-7e8ee577-d2ec-4869-b691-61e40b98d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-15362c0c-05cf-443a-96f2-843c9102b954,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-38ea3b3c-c4ea-4035-8cca-55a524bd5d68,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-663670c0-9dac-4238-8fe6-b40db69fc7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890023383-172.17.0.10-1595930712594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-c484b25c-8d80-4f5f-bcbd-52a85e01d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-6e69029c-2590-4baf-ac37-ad428a117322,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-0e84ffda-53a4-4fa7-aafb-307fc93f9e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-9cf2f690-b00e-43d0-911e-92b08c683260,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-7e8ee577-d2ec-4869-b691-61e40b98d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-15362c0c-05cf-443a-96f2-843c9102b954,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-38ea3b3c-c4ea-4035-8cca-55a524bd5d68,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-663670c0-9dac-4238-8fe6-b40db69fc7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371442391-172.17.0.10-1595930830380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32907,DS-b49b4357-ecd0-4f05-8fb8-f2fed54431ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-5281459e-2261-4169-951d-b853b08050cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-c1f50dfe-2d58-4978-8425-a86b984b6250,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-3946a676-7c89-4707-b5b6-11fecbadb6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-5c0ca759-7f32-4526-87fb-e029be87c290,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-a1dca82b-8fdc-4c81-9027-a38c83985442,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-dd508ebb-d091-4022-9436-2b8e53c912bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-7b453232-3661-4dfb-8f63-869e9aa8e3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371442391-172.17.0.10-1595930830380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32907,DS-b49b4357-ecd0-4f05-8fb8-f2fed54431ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-5281459e-2261-4169-951d-b853b08050cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-c1f50dfe-2d58-4978-8425-a86b984b6250,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-3946a676-7c89-4707-b5b6-11fecbadb6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-5c0ca759-7f32-4526-87fb-e029be87c290,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-a1dca82b-8fdc-4c81-9027-a38c83985442,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-dd508ebb-d091-4022-9436-2b8e53c912bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-7b453232-3661-4dfb-8f63-869e9aa8e3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3726791-172.17.0.10-1595931399334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-13b0fa3b-1374-449b-962d-6fe997388c66,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-c3cb06ac-157a-4d97-8aa2-fe79abfe4afb,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-d2874bdc-7186-4fb9-9320-bc1dc38f963b,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-3c9a0013-cd19-43a7-ba74-0733c5f7551e,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a5a14df4-d9da-43a5-a7fe-43b8df0c4819,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-2b780eb9-69b0-4532-bb0a-5e9a63833cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-8128411f-1cc4-44ff-9110-59188c88cd84,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-3397768b-b94d-4c6c-a359-5f3f64438b08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3726791-172.17.0.10-1595931399334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-13b0fa3b-1374-449b-962d-6fe997388c66,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-c3cb06ac-157a-4d97-8aa2-fe79abfe4afb,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-d2874bdc-7186-4fb9-9320-bc1dc38f963b,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-3c9a0013-cd19-43a7-ba74-0733c5f7551e,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a5a14df4-d9da-43a5-a7fe-43b8df0c4819,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-2b780eb9-69b0-4532-bb0a-5e9a63833cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-8128411f-1cc4-44ff-9110-59188c88cd84,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-3397768b-b94d-4c6c-a359-5f3f64438b08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320233129-172.17.0.10-1595931760699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-97ed824d-461a-4197-a2b7-d8183c2961f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-b83f6ac7-ee16-4d44-a46c-0ff64f411524,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-d977de48-3b96-4912-a58a-3621d41765f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-69607974-ed65-40da-9e0f-7fc3a0db35da,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-3663b98a-25f8-4f11-81b3-67a7c5384518,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-b0b050d2-d7f5-478a-90b6-ff0fcd062e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-c77408ed-8a2d-4f7a-8f8e-ea9957ebe2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-fe527221-3189-4b16-9e62-5eee7ba6559a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320233129-172.17.0.10-1595931760699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-97ed824d-461a-4197-a2b7-d8183c2961f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-b83f6ac7-ee16-4d44-a46c-0ff64f411524,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-d977de48-3b96-4912-a58a-3621d41765f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-69607974-ed65-40da-9e0f-7fc3a0db35da,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-3663b98a-25f8-4f11-81b3-67a7c5384518,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-b0b050d2-d7f5-478a-90b6-ff0fcd062e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-c77408ed-8a2d-4f7a-8f8e-ea9957ebe2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-fe527221-3189-4b16-9e62-5eee7ba6559a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906083516-172.17.0.10-1595932080980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-477d2bc9-7f28-4fce-b278-b1daf09980c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-44541502-d598-42ab-88d6-77b359e664f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-9f532eed-a888-45ed-84e2-b89a9a289958,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-ff848413-c63d-41e2-a85a-a9ef36a8abf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-197aabee-4524-4d61-9df6-db5ebab3f34e,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-8bfd47e3-d7ab-42f9-b1c3-c57aa6fadd91,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-c5f7c040-893a-4917-a531-7f1ccc74d15e,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-4d61847d-cd83-46b3-b14a-762b4c858e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906083516-172.17.0.10-1595932080980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-477d2bc9-7f28-4fce-b278-b1daf09980c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-44541502-d598-42ab-88d6-77b359e664f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-9f532eed-a888-45ed-84e2-b89a9a289958,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-ff848413-c63d-41e2-a85a-a9ef36a8abf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-197aabee-4524-4d61-9df6-db5ebab3f34e,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-8bfd47e3-d7ab-42f9-b1c3-c57aa6fadd91,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-c5f7c040-893a-4917-a531-7f1ccc74d15e,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-4d61847d-cd83-46b3-b14a-762b4c858e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376663454-172.17.0.10-1595932319424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-b192643d-51ee-4cfd-b4fd-b0e9b0bddf89,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-e2cae8a5-9da1-40c7-b4b9-ed0ce75171d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-533278df-ab88-40ff-9008-60904046acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-2b97f6b2-568a-454f-b3ab-8ae788ce2c47,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-7c857538-c608-4411-aafd-606f548f7f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-e1cff6cb-c440-4f98-9da2-db3900d53f50,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-15249b1a-7473-48db-9103-ed4f489c5e38,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-a8361880-8b48-4a73-9047-639243a58f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376663454-172.17.0.10-1595932319424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-b192643d-51ee-4cfd-b4fd-b0e9b0bddf89,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-e2cae8a5-9da1-40c7-b4b9-ed0ce75171d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-533278df-ab88-40ff-9008-60904046acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-2b97f6b2-568a-454f-b3ab-8ae788ce2c47,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-7c857538-c608-4411-aafd-606f548f7f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-e1cff6cb-c440-4f98-9da2-db3900d53f50,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-15249b1a-7473-48db-9103-ed4f489c5e38,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-a8361880-8b48-4a73-9047-639243a58f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134320788-172.17.0.10-1595932401054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35665,DS-4492e2a2-79b7-4d8e-a092-e3ee56616070,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-effad6a4-c886-4014-8a2f-e20dfb9f016c,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-e86c5576-7e5c-4cca-9535-e90cfb46d076,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-0d6fd704-f533-4ae1-a7b8-7e5920899963,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-f6061471-29f6-4d71-ab45-0e9f1653e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-fe1c2b85-2562-4a4f-a131-da802f151478,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-a4fcc0c3-af94-423f-b6ee-775959a752e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-a01f1cd8-09ab-42fe-8198-97fb874402ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134320788-172.17.0.10-1595932401054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35665,DS-4492e2a2-79b7-4d8e-a092-e3ee56616070,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-effad6a4-c886-4014-8a2f-e20dfb9f016c,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-e86c5576-7e5c-4cca-9535-e90cfb46d076,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-0d6fd704-f533-4ae1-a7b8-7e5920899963,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-f6061471-29f6-4d71-ab45-0e9f1653e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-fe1c2b85-2562-4a4f-a131-da802f151478,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-a4fcc0c3-af94-423f-b6ee-775959a752e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-a01f1cd8-09ab-42fe-8198-97fb874402ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469260632-172.17.0.10-1595932671850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38730,DS-e09bd8fa-ad79-4eea-bc7e-fe4a7ebca557,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-9e080ac8-2a1e-47d1-866c-8568ef813f70,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-ba5f6a70-a8f7-4bb1-81f1-e9622237a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-cf22d23e-2d4c-4c88-bc7f-57d43b39b721,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-a8c4407c-916a-459e-a638-df0c25aea8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-c14a4f1c-f9f8-4224-b161-a02324872a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-c2d451c8-dbdd-46a2-852e-a55aa3a8ef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-b7847590-18fa-4c99-b4c0-5eef64ef173f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469260632-172.17.0.10-1595932671850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38730,DS-e09bd8fa-ad79-4eea-bc7e-fe4a7ebca557,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-9e080ac8-2a1e-47d1-866c-8568ef813f70,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-ba5f6a70-a8f7-4bb1-81f1-e9622237a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-cf22d23e-2d4c-4c88-bc7f-57d43b39b721,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-a8c4407c-916a-459e-a638-df0c25aea8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-c14a4f1c-f9f8-4224-b161-a02324872a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-c2d451c8-dbdd-46a2-852e-a55aa3a8ef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-b7847590-18fa-4c99-b4c0-5eef64ef173f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592217700-172.17.0.10-1595932753835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36366,DS-17b0a762-79ee-4e34-89f6-db34407a7fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-4a37f3bc-305e-4cf4-b3cd-add3bf217744,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-a0c2762d-9dcf-4823-82e3-ce7864e0d7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-cf735a05-9c0a-448b-9968-3800519431c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-b57b59e7-a96a-4677-bf95-bf3aca2d8376,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-a6d8b1f0-5a3b-4112-91a5-4e80c81661ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-59de3229-2948-4536-b48e-a7406b41130c,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-2498e4e7-d6d3-4cc8-bee7-08ef532c7000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592217700-172.17.0.10-1595932753835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36366,DS-17b0a762-79ee-4e34-89f6-db34407a7fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-4a37f3bc-305e-4cf4-b3cd-add3bf217744,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-a0c2762d-9dcf-4823-82e3-ce7864e0d7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-cf735a05-9c0a-448b-9968-3800519431c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-b57b59e7-a96a-4677-bf95-bf3aca2d8376,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-a6d8b1f0-5a3b-4112-91a5-4e80c81661ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-59de3229-2948-4536-b48e-a7406b41130c,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-2498e4e7-d6d3-4cc8-bee7-08ef532c7000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385963837-172.17.0.10-1595933916956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34591,DS-2220349a-9636-4f59-9085-fdef61cb2a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-6b4a266e-3aa3-452b-80e8-1252b32564c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-e9720895-e177-4b15-9172-27344168cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-972bd2b6-dbcc-41d4-9907-1aa0a3372d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-66277816-f7e7-4e1b-9492-56976b89959d,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-1deb49c7-0e19-4b18-a20a-238c2ad7dcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-a33811de-1e00-4751-bbd2-7929cf1818e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-68f63d12-c971-4341-82ea-0b3908f45aef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385963837-172.17.0.10-1595933916956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34591,DS-2220349a-9636-4f59-9085-fdef61cb2a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-6b4a266e-3aa3-452b-80e8-1252b32564c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-e9720895-e177-4b15-9172-27344168cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-972bd2b6-dbcc-41d4-9907-1aa0a3372d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-66277816-f7e7-4e1b-9492-56976b89959d,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-1deb49c7-0e19-4b18-a20a-238c2ad7dcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-a33811de-1e00-4751-bbd2-7929cf1818e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-68f63d12-c971-4341-82ea-0b3908f45aef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459564181-172.17.0.10-1595934220020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-6df7f0d0-0905-457b-9d11-29aa245b30fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-96e7c74b-b92f-4738-9c90-c76ad9168f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-57720826-b61a-4627-ae78-21cc8d52f4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-3f1774ff-7a09-4bef-b44f-12e6bb26e61c,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-ab8be3f0-f59f-401e-871f-e8108f71d759,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-bdd251f3-5c89-4eac-8ea4-f3e1826a1386,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-e040f032-1da0-45b0-b905-9c65b01fee91,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-85a0305a-810b-4532-9e37-39a73f98f9ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459564181-172.17.0.10-1595934220020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-6df7f0d0-0905-457b-9d11-29aa245b30fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-96e7c74b-b92f-4738-9c90-c76ad9168f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-57720826-b61a-4627-ae78-21cc8d52f4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-3f1774ff-7a09-4bef-b44f-12e6bb26e61c,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-ab8be3f0-f59f-401e-871f-e8108f71d759,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-bdd251f3-5c89-4eac-8ea4-f3e1826a1386,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-e040f032-1da0-45b0-b905-9c65b01fee91,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-85a0305a-810b-4532-9e37-39a73f98f9ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5985
