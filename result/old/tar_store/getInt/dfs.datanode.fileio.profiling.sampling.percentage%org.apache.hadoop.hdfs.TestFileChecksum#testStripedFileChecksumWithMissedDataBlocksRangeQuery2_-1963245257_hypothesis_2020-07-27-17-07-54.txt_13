reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403197365-172.17.0.16-1595869760315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-b691c72a-26ae-426e-b568-b2bcaa7406b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-695a8eb0-2455-4909-9a1f-4f0be5f2316b,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-926ea2fd-7648-42d5-b95b-944c29f67ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-c0b33a93-c64f-4803-845c-91b994f30dba,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-5de93290-db2d-4935-af0a-0980a6bd49a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-f19fecbc-d248-4a2e-9894-b246458f6965,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-3c36bcfb-fd6e-4dd2-afb5-33ca09c1df95,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-a6a68dc9-6275-4fca-8797-7ff6b206a38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403197365-172.17.0.16-1595869760315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-b691c72a-26ae-426e-b568-b2bcaa7406b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-695a8eb0-2455-4909-9a1f-4f0be5f2316b,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-926ea2fd-7648-42d5-b95b-944c29f67ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-c0b33a93-c64f-4803-845c-91b994f30dba,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-5de93290-db2d-4935-af0a-0980a6bd49a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-f19fecbc-d248-4a2e-9894-b246458f6965,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-3c36bcfb-fd6e-4dd2-afb5-33ca09c1df95,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-a6a68dc9-6275-4fca-8797-7ff6b206a38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553251654-172.17.0.16-1595869794777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-62ba2e43-d7a7-40a5-8a6b-e19b06511f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-1f979896-014f-4fe3-b876-724a9ce0f1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-d6cab236-b70d-4e7b-a90d-4817aab487f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-2cd76a6b-d3cc-4076-baaa-9201e7048906,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-368d62f8-bfa4-40de-acf9-fcca07ef0e92,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-293e2b0f-51e0-4b96-992e-b2e0b96de93a,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-ff9a07cc-d513-4267-ba89-6c00357ecbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-457f0e19-2728-4192-90f9-94095e16aa63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553251654-172.17.0.16-1595869794777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-62ba2e43-d7a7-40a5-8a6b-e19b06511f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-1f979896-014f-4fe3-b876-724a9ce0f1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-d6cab236-b70d-4e7b-a90d-4817aab487f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-2cd76a6b-d3cc-4076-baaa-9201e7048906,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-368d62f8-bfa4-40de-acf9-fcca07ef0e92,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-293e2b0f-51e0-4b96-992e-b2e0b96de93a,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-ff9a07cc-d513-4267-ba89-6c00357ecbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-457f0e19-2728-4192-90f9-94095e16aa63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968368944-172.17.0.16-1595870027041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-953c4ff4-7980-488a-a83e-f4a30a0205e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-a05ddff1-5fa9-4bd6-9947-bfe0d7443305,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-075bc249-247d-407d-9bd3-e92cbd515eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-1c56ca4e-890b-4587-b06f-b536fd51fdca,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-95da6848-adba-4d70-8ba7-4a700cee77dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-13089357-af8d-4391-8c06-4a14f2a235ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-37aad44c-0c75-4868-a2b7-e9031ae1f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-0958372e-b428-4c5f-b476-0564cbb1ea93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968368944-172.17.0.16-1595870027041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-953c4ff4-7980-488a-a83e-f4a30a0205e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-a05ddff1-5fa9-4bd6-9947-bfe0d7443305,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-075bc249-247d-407d-9bd3-e92cbd515eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-1c56ca4e-890b-4587-b06f-b536fd51fdca,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-95da6848-adba-4d70-8ba7-4a700cee77dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-13089357-af8d-4391-8c06-4a14f2a235ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-37aad44c-0c75-4868-a2b7-e9031ae1f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-0958372e-b428-4c5f-b476-0564cbb1ea93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697018671-172.17.0.16-1595871223186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-a9452131-c3c9-4a44-8edc-cc5aef9afaac,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-5209e6c7-649f-4b23-9757-6df17dc623cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-83053f13-e8a6-437a-8998-2243d7d08103,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-b4231920-2dad-4a1e-9e4c-3d39de8c2f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-3bb34c05-f6f6-4606-867a-5c6d85b39460,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-ed87b543-68cd-4823-9a15-8001d3b009bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-9bec5ca9-159f-41cb-b977-b35da0afe8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-16447e09-03b8-4a2a-aef7-b74f69e7d762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697018671-172.17.0.16-1595871223186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-a9452131-c3c9-4a44-8edc-cc5aef9afaac,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-5209e6c7-649f-4b23-9757-6df17dc623cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-83053f13-e8a6-437a-8998-2243d7d08103,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-b4231920-2dad-4a1e-9e4c-3d39de8c2f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-3bb34c05-f6f6-4606-867a-5c6d85b39460,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-ed87b543-68cd-4823-9a15-8001d3b009bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-9bec5ca9-159f-41cb-b977-b35da0afe8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-16447e09-03b8-4a2a-aef7-b74f69e7d762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114738876-172.17.0.16-1595871412425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34616,DS-7bfaf5a6-6fe7-4665-8cfa-8daca043bd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-28f3525c-52b5-4003-aa14-67db0b1ff1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-0b2e4661-dfd6-426d-8448-cafeba82d530,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-ccb44592-bc38-493d-bc1f-dc897c174c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-122e7091-19f1-40e8-acbc-9b8b2f191481,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-90b1b600-6a9f-43a1-9078-0dc1e2ab6c05,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-c6aa82a9-601d-43f4-916c-12ba135d7811,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-a3aaeca7-24f3-49b0-bb44-d298fb9c0cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114738876-172.17.0.16-1595871412425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34616,DS-7bfaf5a6-6fe7-4665-8cfa-8daca043bd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-28f3525c-52b5-4003-aa14-67db0b1ff1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-0b2e4661-dfd6-426d-8448-cafeba82d530,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-ccb44592-bc38-493d-bc1f-dc897c174c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-122e7091-19f1-40e8-acbc-9b8b2f191481,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-90b1b600-6a9f-43a1-9078-0dc1e2ab6c05,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-c6aa82a9-601d-43f4-916c-12ba135d7811,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-a3aaeca7-24f3-49b0-bb44-d298fb9c0cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699265421-172.17.0.16-1595871516971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-2490a111-1e52-4e77-94a3-61334f6f4c37,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-27348ac8-b821-4692-8920-368378513e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-70cfbf18-897a-41e3-ab80-ba7d13848988,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-a61a54eb-22bf-4e99-9506-47b4423c1bac,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-e7f684b1-bd53-488f-9429-dee6f4c3f18e,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-0b2f4231-312f-4096-8f99-61dd7ca09ace,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-3aa05fc2-c94f-4a93-aa7d-f27ff828d83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-c304807b-42b3-4c66-9396-083d7a3f838a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699265421-172.17.0.16-1595871516971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-2490a111-1e52-4e77-94a3-61334f6f4c37,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-27348ac8-b821-4692-8920-368378513e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-70cfbf18-897a-41e3-ab80-ba7d13848988,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-a61a54eb-22bf-4e99-9506-47b4423c1bac,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-e7f684b1-bd53-488f-9429-dee6f4c3f18e,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-0b2f4231-312f-4096-8f99-61dd7ca09ace,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-3aa05fc2-c94f-4a93-aa7d-f27ff828d83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-c304807b-42b3-4c66-9396-083d7a3f838a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164896990-172.17.0.16-1595871589030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-037eb478-457d-4fb9-8e3a-f0b7e10066f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-645e25c4-1544-4cc5-ae63-3b3da3b28347,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-4f80875c-6931-43f2-9acd-b0eaf6334f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-80a5e3b6-5f2e-4221-8cf4-20ad24737201,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-c0f65b64-deff-41b8-970a-545a773db109,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-0ce1e7a4-d30e-4836-bf25-05dbb268507d,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-a95507c7-794c-4595-9679-35b43e2fd770,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-75c9c809-9db5-438b-ab0b-3c7fc4cb0a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164896990-172.17.0.16-1595871589030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-037eb478-457d-4fb9-8e3a-f0b7e10066f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-645e25c4-1544-4cc5-ae63-3b3da3b28347,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-4f80875c-6931-43f2-9acd-b0eaf6334f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-80a5e3b6-5f2e-4221-8cf4-20ad24737201,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-c0f65b64-deff-41b8-970a-545a773db109,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-0ce1e7a4-d30e-4836-bf25-05dbb268507d,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-a95507c7-794c-4595-9679-35b43e2fd770,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-75c9c809-9db5-438b-ab0b-3c7fc4cb0a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390729570-172.17.0.16-1595871850826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-336d7a8f-507f-45fa-8979-ac5e71f859b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-e28da279-056d-4cbf-b607-96f011eaa5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-33c7fcbd-02ad-4588-91b1-42b81bdcb623,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-f2f380cb-6edb-4c88-9293-b2c93ce29078,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-aaaa63bb-17f9-4fad-a143-49214b8a89d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-26113e95-69f5-4897-b6bd-f3262c15ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-507bbf69-fe3c-4ba7-bc5f-945f1c630cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-e95f7b54-4df6-4982-b16b-8d4135fff702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390729570-172.17.0.16-1595871850826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-336d7a8f-507f-45fa-8979-ac5e71f859b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-e28da279-056d-4cbf-b607-96f011eaa5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-33c7fcbd-02ad-4588-91b1-42b81bdcb623,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-f2f380cb-6edb-4c88-9293-b2c93ce29078,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-aaaa63bb-17f9-4fad-a143-49214b8a89d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-26113e95-69f5-4897-b6bd-f3262c15ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-507bbf69-fe3c-4ba7-bc5f-945f1c630cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-e95f7b54-4df6-4982-b16b-8d4135fff702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260272310-172.17.0.16-1595872065652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-d3e514e2-7ff5-42cd-a4cd-168e93f2c8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-d45fa725-fe4b-4680-a8cd-03832102edd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-82ca6d34-f2c1-4e1c-8eed-7daeb5b6704e,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-d5283779-f393-4284-8956-af9f12689e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-124b21dc-0834-4fdd-ab78-1761e4444147,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-7f3b9e2d-8e44-4008-a40f-eb689511c301,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-7a165030-01e2-4b94-98cd-3621123d2363,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-29c34c22-9c3d-4c42-9b5a-5549b25ed5b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260272310-172.17.0.16-1595872065652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-d3e514e2-7ff5-42cd-a4cd-168e93f2c8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-d45fa725-fe4b-4680-a8cd-03832102edd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-82ca6d34-f2c1-4e1c-8eed-7daeb5b6704e,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-d5283779-f393-4284-8956-af9f12689e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-124b21dc-0834-4fdd-ab78-1761e4444147,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-7f3b9e2d-8e44-4008-a40f-eb689511c301,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-7a165030-01e2-4b94-98cd-3621123d2363,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-29c34c22-9c3d-4c42-9b5a-5549b25ed5b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463987327-172.17.0.16-1595872238895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45647,DS-532c05aa-53ff-4b5a-8fdd-0334019e8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-b0acebe7-2f9c-4cd3-b230-dbdeabe2311e,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-2c41a584-f2cc-435f-821e-57030ae66b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-5256858c-e40b-42f7-8a92-fad6647c4ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-3bf864b2-603d-4a62-b155-6731cc2a6345,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-b4d499f4-84b9-4ec6-a34e-849da8c40cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-438f73f9-703a-40c7-8f75-2bc9775ef39c,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-ca036dea-4ede-48a5-a6cc-43430739a3cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463987327-172.17.0.16-1595872238895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45647,DS-532c05aa-53ff-4b5a-8fdd-0334019e8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-b0acebe7-2f9c-4cd3-b230-dbdeabe2311e,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-2c41a584-f2cc-435f-821e-57030ae66b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-5256858c-e40b-42f7-8a92-fad6647c4ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-3bf864b2-603d-4a62-b155-6731cc2a6345,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-b4d499f4-84b9-4ec6-a34e-849da8c40cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-438f73f9-703a-40c7-8f75-2bc9775ef39c,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-ca036dea-4ede-48a5-a6cc-43430739a3cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500137058-172.17.0.16-1595872775639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-745b0dc3-91d3-422e-835e-7f797707f0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-f4bbf822-2694-4719-ad30-eb71d79d5589,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-c5a9d3e9-57ca-49f6-8018-a90f3919d567,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-296311c9-5e01-41bd-aa73-b037cc867b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-3fb484d8-3663-4afa-a84d-8bdd1ec84476,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-5d37449d-bce0-4545-9770-85e0a03d72ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-f51ffc9b-1662-4997-8dc8-a31b311541f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-89d7200f-17d0-49c1-ae5e-270c95ac82ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500137058-172.17.0.16-1595872775639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-745b0dc3-91d3-422e-835e-7f797707f0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-f4bbf822-2694-4719-ad30-eb71d79d5589,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-c5a9d3e9-57ca-49f6-8018-a90f3919d567,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-296311c9-5e01-41bd-aa73-b037cc867b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-3fb484d8-3663-4afa-a84d-8bdd1ec84476,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-5d37449d-bce0-4545-9770-85e0a03d72ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-f51ffc9b-1662-4997-8dc8-a31b311541f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-89d7200f-17d0-49c1-ae5e-270c95ac82ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783772184-172.17.0.16-1595873000321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38171,DS-b219bbe4-16ad-4cc0-a1a3-ce70672a3a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-0e083cae-837b-4e34-b788-940e451fc9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-1c4a2f6f-0632-45fb-a0ea-a22b58e51993,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-32de5c38-78a5-4c63-b565-2b881a8d7133,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-fd107790-b7d5-4a44-88ea-bedabe9388fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-bca4d77a-6ab7-4faf-b9f6-5b2392d5faa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-5ea37c89-c771-4ed9-9424-494d1a5b6a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-fb4c2db1-7ffe-4171-98bd-98fc5f28c351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783772184-172.17.0.16-1595873000321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38171,DS-b219bbe4-16ad-4cc0-a1a3-ce70672a3a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-0e083cae-837b-4e34-b788-940e451fc9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-1c4a2f6f-0632-45fb-a0ea-a22b58e51993,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-32de5c38-78a5-4c63-b565-2b881a8d7133,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-fd107790-b7d5-4a44-88ea-bedabe9388fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-bca4d77a-6ab7-4faf-b9f6-5b2392d5faa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-5ea37c89-c771-4ed9-9424-494d1a5b6a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-fb4c2db1-7ffe-4171-98bd-98fc5f28c351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446586997-172.17.0.16-1595873750803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42156,DS-f0dc2341-77eb-4f19-949d-5a1e061cf2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-39698fe3-200a-4864-83d5-f832e13c430d,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-d47a2e90-f0c8-41b6-91ae-36df4ceaf0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-e79aac55-ef1d-4c66-a32f-cedb836e0cba,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-ddcfa676-504c-4f91-a15b-467a07817c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-fd1631fa-e301-4f70-bd2e-edd7a74f1197,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-5262c28c-6a7c-4e98-af18-e3a88473e937,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-dfcddb10-86a7-4275-b3e3-a126500cc31d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446586997-172.17.0.16-1595873750803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42156,DS-f0dc2341-77eb-4f19-949d-5a1e061cf2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-39698fe3-200a-4864-83d5-f832e13c430d,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-d47a2e90-f0c8-41b6-91ae-36df4ceaf0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-e79aac55-ef1d-4c66-a32f-cedb836e0cba,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-ddcfa676-504c-4f91-a15b-467a07817c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-fd1631fa-e301-4f70-bd2e-edd7a74f1197,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-5262c28c-6a7c-4e98-af18-e3a88473e937,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-dfcddb10-86a7-4275-b3e3-a126500cc31d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137617795-172.17.0.16-1595873922063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-f6f38f50-0053-428f-8264-acaf9153dafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-afbb2a28-c00d-4271-90f0-4c5e87f47ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-d10b2d99-731b-4027-906c-1d66287d1d06,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-0425759d-cae4-482a-b73a-28127183a993,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-1d906206-b872-4106-a131-7b69fa5c9bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-e8f0ecd1-2800-46b8-83ee-ca49f791f2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-e864a0cd-dafe-4533-abc7-7ed125b3a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-6b86b9f7-ab13-452a-ab7a-83ed79fd583d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137617795-172.17.0.16-1595873922063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-f6f38f50-0053-428f-8264-acaf9153dafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-afbb2a28-c00d-4271-90f0-4c5e87f47ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-d10b2d99-731b-4027-906c-1d66287d1d06,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-0425759d-cae4-482a-b73a-28127183a993,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-1d906206-b872-4106-a131-7b69fa5c9bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-e8f0ecd1-2800-46b8-83ee-ca49f791f2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-e864a0cd-dafe-4533-abc7-7ed125b3a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-6b86b9f7-ab13-452a-ab7a-83ed79fd583d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736757349-172.17.0.16-1595874285964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38665,DS-461d8276-a254-415a-a96e-37263d8fde8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-82c6bfc7-8900-486a-965e-d911e9b58cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-5c1dce64-91e8-477b-aab5-430c4134ad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-645558cb-2b9c-4222-b10c-06b55d9db157,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-899d6bd3-9a34-4cbd-93b0-d28d57c2bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-6297bd6d-2167-4a5f-8bc6-5da43a9255e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-526af67a-a465-478e-bb57-0f4388431c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-85867da0-4a84-4641-9888-50f51e714b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736757349-172.17.0.16-1595874285964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38665,DS-461d8276-a254-415a-a96e-37263d8fde8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-82c6bfc7-8900-486a-965e-d911e9b58cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-5c1dce64-91e8-477b-aab5-430c4134ad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-645558cb-2b9c-4222-b10c-06b55d9db157,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-899d6bd3-9a34-4cbd-93b0-d28d57c2bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-6297bd6d-2167-4a5f-8bc6-5da43a9255e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-526af67a-a465-478e-bb57-0f4388431c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-85867da0-4a84-4641-9888-50f51e714b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038942855-172.17.0.16-1595874575193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46251,DS-2aa0c328-a6e8-4e20-8973-797599a19fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-7e46e5a1-021a-4a2a-8707-6adf833ed394,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-daeffbde-453a-4721-a1f6-b6f7c20197af,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-057fc204-afac-4335-9bbc-73b8ee12cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-78e018aa-09cf-4636-941d-59ab3fa42be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-01519ab5-7916-4eff-90dc-69f21b6f84d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-0369fd68-2701-4219-b4f2-91f87ba43260,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-56148fd5-91e7-432d-98bf-600702f6ea70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038942855-172.17.0.16-1595874575193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46251,DS-2aa0c328-a6e8-4e20-8973-797599a19fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-7e46e5a1-021a-4a2a-8707-6adf833ed394,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-daeffbde-453a-4721-a1f6-b6f7c20197af,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-057fc204-afac-4335-9bbc-73b8ee12cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-78e018aa-09cf-4636-941d-59ab3fa42be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-01519ab5-7916-4eff-90dc-69f21b6f84d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-0369fd68-2701-4219-b4f2-91f87ba43260,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-56148fd5-91e7-432d-98bf-600702f6ea70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538846347-172.17.0.16-1595874775583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-95bfa461-79af-4979-9f86-3b667d869d64,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-2c7162a5-c77a-4cd5-af62-da6294a359db,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-5f402601-8d99-4e20-8c89-458d317bd91c,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-5a77ca17-a16e-4055-ad23-5aa8dff81f13,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-ff2b4860-130b-44f5-ac86-53b7a877085d,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-abf7c1a4-a72e-4b4f-8b65-94f5488e1575,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-aa57e1d3-7ce3-42c8-a638-dd546031fc35,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-aac80053-4de6-4c87-8561-b24b6e37a041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538846347-172.17.0.16-1595874775583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-95bfa461-79af-4979-9f86-3b667d869d64,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-2c7162a5-c77a-4cd5-af62-da6294a359db,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-5f402601-8d99-4e20-8c89-458d317bd91c,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-5a77ca17-a16e-4055-ad23-5aa8dff81f13,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-ff2b4860-130b-44f5-ac86-53b7a877085d,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-abf7c1a4-a72e-4b4f-8b65-94f5488e1575,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-aa57e1d3-7ce3-42c8-a638-dd546031fc35,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-aac80053-4de6-4c87-8561-b24b6e37a041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5337
