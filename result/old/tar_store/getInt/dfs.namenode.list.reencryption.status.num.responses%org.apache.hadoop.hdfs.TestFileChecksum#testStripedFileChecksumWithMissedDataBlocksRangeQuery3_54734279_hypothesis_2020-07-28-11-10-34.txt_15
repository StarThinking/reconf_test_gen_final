reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241261775-172.17.0.3-1595935313166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33547,DS-8de3f34b-89c7-4a3e-99a9-6c477dfd986b,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-2dd17c4a-2cf3-4b57-b582-f7d4161c02fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-8d0c4f94-c01a-46fa-8a69-bd6a546fde53,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-a3df0d37-ae2e-4ffb-97ea-442815d7864f,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-f66fcdf9-4c2c-4847-9b3e-7a7aa981122e,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-571297e0-bbcd-4d11-87c4-f66fc0c40bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-264db926-c1e1-44ad-81f2-a5257d80f247,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-2ae22292-755d-497e-aff1-c708c90a7f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241261775-172.17.0.3-1595935313166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33547,DS-8de3f34b-89c7-4a3e-99a9-6c477dfd986b,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-2dd17c4a-2cf3-4b57-b582-f7d4161c02fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-8d0c4f94-c01a-46fa-8a69-bd6a546fde53,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-a3df0d37-ae2e-4ffb-97ea-442815d7864f,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-f66fcdf9-4c2c-4847-9b3e-7a7aa981122e,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-571297e0-bbcd-4d11-87c4-f66fc0c40bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-264db926-c1e1-44ad-81f2-a5257d80f247,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-2ae22292-755d-497e-aff1-c708c90a7f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819490893-172.17.0.3-1595935530450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43521,DS-b4aea545-a4d0-44ad-bd5f-1322ef14a235,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-075e0c82-189a-45b6-8c84-f8d7a8c1f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-07fbcfb1-af11-47f6-bfe8-cd59096401fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-21f2dc6d-020f-4cde-ab96-1933966059c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-12c4a1b5-2f2a-42db-83d0-df184b37fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-c2104114-d7d3-4d33-8b98-ed35c9895a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-8f767ed4-a3b3-407e-b85f-72f140d72061,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-493634c5-5dc7-46c9-bd6f-b3cce7cd768f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819490893-172.17.0.3-1595935530450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43521,DS-b4aea545-a4d0-44ad-bd5f-1322ef14a235,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-075e0c82-189a-45b6-8c84-f8d7a8c1f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-07fbcfb1-af11-47f6-bfe8-cd59096401fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-21f2dc6d-020f-4cde-ab96-1933966059c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-12c4a1b5-2f2a-42db-83d0-df184b37fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-c2104114-d7d3-4d33-8b98-ed35c9895a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-8f767ed4-a3b3-407e-b85f-72f140d72061,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-493634c5-5dc7-46c9-bd6f-b3cce7cd768f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76887150-172.17.0.3-1595935825042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-da977eb7-eb97-44a5-8acf-b14d361f7a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-d6f2e182-ea68-4ffe-a57f-aaf5dd75323d,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-c96828cb-42d6-49a4-b4e7-bba1769f84ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-e2e7dd23-0622-416a-9cad-86370a43619f,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-528b58a8-3960-4ad9-a151-70f2180d96fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-7b126d96-d990-4b69-b6c2-f4bf4af5c10b,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-9eac1220-c17b-4db7-b9cc-a3761450e344,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-0b1ddd7a-b79c-4af2-8992-71a3d8131d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76887150-172.17.0.3-1595935825042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-da977eb7-eb97-44a5-8acf-b14d361f7a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-d6f2e182-ea68-4ffe-a57f-aaf5dd75323d,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-c96828cb-42d6-49a4-b4e7-bba1769f84ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-e2e7dd23-0622-416a-9cad-86370a43619f,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-528b58a8-3960-4ad9-a151-70f2180d96fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-7b126d96-d990-4b69-b6c2-f4bf4af5c10b,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-9eac1220-c17b-4db7-b9cc-a3761450e344,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-0b1ddd7a-b79c-4af2-8992-71a3d8131d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72429099-172.17.0.3-1595937091880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-d94dda7b-4143-4ee2-ae18-9c3ed426b5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-2f4a8653-32a9-42f5-982c-ca34f0620213,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-6f199cbd-97bd-4b79-b116-05e3c994ab71,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-6928b23b-a071-4db6-9181-91b392bd1837,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-cb90f9e3-af5e-45d4-9df0-02e8546f593f,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-8a9a23f3-0595-400d-aae6-b58572bd8592,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-e737a963-d811-4c4e-bae6-38f1fce1605b,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-9141feeb-f48c-48ac-baf1-b9d5ea9b9f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72429099-172.17.0.3-1595937091880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-d94dda7b-4143-4ee2-ae18-9c3ed426b5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-2f4a8653-32a9-42f5-982c-ca34f0620213,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-6f199cbd-97bd-4b79-b116-05e3c994ab71,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-6928b23b-a071-4db6-9181-91b392bd1837,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-cb90f9e3-af5e-45d4-9df0-02e8546f593f,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-8a9a23f3-0595-400d-aae6-b58572bd8592,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-e737a963-d811-4c4e-bae6-38f1fce1605b,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-9141feeb-f48c-48ac-baf1-b9d5ea9b9f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794306852-172.17.0.3-1595938368630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-e3a884a1-47cd-49a7-92f0-bfd50b97465c,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-3778a6e2-d674-420e-89a3-87d68413fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-43b7f75a-994c-4bbf-800e-7a4613b53e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-0850d725-1427-4705-aacf-1a125393283c,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-bf484ac2-9271-4928-bdcc-1616375cd775,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-35a2286e-7162-4417-b721-3e6b6fab0f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-c74b9169-0d88-4a74-afc2-33bab0c22eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-1418442b-14c1-47af-9f8e-af3934b3c63d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794306852-172.17.0.3-1595938368630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-e3a884a1-47cd-49a7-92f0-bfd50b97465c,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-3778a6e2-d674-420e-89a3-87d68413fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-43b7f75a-994c-4bbf-800e-7a4613b53e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-0850d725-1427-4705-aacf-1a125393283c,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-bf484ac2-9271-4928-bdcc-1616375cd775,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-35a2286e-7162-4417-b721-3e6b6fab0f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-c74b9169-0d88-4a74-afc2-33bab0c22eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-1418442b-14c1-47af-9f8e-af3934b3c63d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282991916-172.17.0.3-1595939227012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35192,DS-ebd5f330-106e-4dd7-858e-10393f4c7f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-4e6b653c-a35d-4c32-83a2-b5316d794c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-6c62c77a-af97-4941-a250-e575cfe25b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-bcf77512-4625-4ee8-b19d-aa46586180c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-59e5170d-d016-40eb-922d-d4d42a6cb638,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-5f2f0807-66cd-4e71-a5e6-15dda740e5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-88c71429-545f-43c6-8889-6b4086e13341,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-ba30b3d0-47a0-47e6-8b55-d36426edb04b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282991916-172.17.0.3-1595939227012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35192,DS-ebd5f330-106e-4dd7-858e-10393f4c7f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-4e6b653c-a35d-4c32-83a2-b5316d794c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-6c62c77a-af97-4941-a250-e575cfe25b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-bcf77512-4625-4ee8-b19d-aa46586180c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-59e5170d-d016-40eb-922d-d4d42a6cb638,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-5f2f0807-66cd-4e71-a5e6-15dda740e5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-88c71429-545f-43c6-8889-6b4086e13341,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-ba30b3d0-47a0-47e6-8b55-d36426edb04b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396188697-172.17.0.3-1595939261411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-8d144e28-c8fa-4e1f-9959-1b95f881d5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-f52476f7-6eaa-40c4-a2bc-c86e17e0a7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-2e9e598d-fbb7-4d2b-a90c-ac59f21d08e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-cc661d96-8937-4bf4-89df-1934cf253c05,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-e72cd2f3-2f90-47ca-b415-dfde99843f79,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-0204e6ef-4226-4086-8807-7116d7cf4592,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-bd39f860-dd34-48c6-b10e-21d6816336ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-a04236e7-264e-4a6a-a515-f5edeeca4d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396188697-172.17.0.3-1595939261411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-8d144e28-c8fa-4e1f-9959-1b95f881d5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-f52476f7-6eaa-40c4-a2bc-c86e17e0a7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-2e9e598d-fbb7-4d2b-a90c-ac59f21d08e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-cc661d96-8937-4bf4-89df-1934cf253c05,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-e72cd2f3-2f90-47ca-b415-dfde99843f79,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-0204e6ef-4226-4086-8807-7116d7cf4592,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-bd39f860-dd34-48c6-b10e-21d6816336ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-a04236e7-264e-4a6a-a515-f5edeeca4d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082799691-172.17.0.3-1595940117074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39577,DS-1187ff92-1f84-4063-ba8b-4aba8eae8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-454938cb-b31a-4fe1-b4b2-8a32057a0077,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-766210fb-3690-40a1-817b-aeffe250f5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-fa57f32d-f8c7-467f-99bd-c9be0672097c,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-d5f02b4f-9629-4b98-a1ac-2778c9f51bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-44b02442-79d9-42f6-b5b8-6bff6b18b651,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-a7777e88-13a2-424c-ac65-53f65960c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-7ad4125b-30b1-484f-b98e-af48971a4763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082799691-172.17.0.3-1595940117074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39577,DS-1187ff92-1f84-4063-ba8b-4aba8eae8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-454938cb-b31a-4fe1-b4b2-8a32057a0077,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-766210fb-3690-40a1-817b-aeffe250f5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-fa57f32d-f8c7-467f-99bd-c9be0672097c,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-d5f02b4f-9629-4b98-a1ac-2778c9f51bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-44b02442-79d9-42f6-b5b8-6bff6b18b651,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-a7777e88-13a2-424c-ac65-53f65960c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-7ad4125b-30b1-484f-b98e-af48971a4763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: false positive !!!
Total execution time in seconds : 5507
