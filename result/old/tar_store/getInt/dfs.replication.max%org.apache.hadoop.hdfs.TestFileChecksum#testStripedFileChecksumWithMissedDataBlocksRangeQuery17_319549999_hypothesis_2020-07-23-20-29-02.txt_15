reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147589010-172.17.0.4-1595536157466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-b01fd539-0f4b-4ed9-b4d4-e50a8b8a3025,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-33a53962-8c9e-4c98-b2f1-447afe9832cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-105ecd7a-1765-4400-8600-6b22efcf4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-2ad0746a-eb10-4d99-9839-65ba8f5c4215,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-9fc54044-a731-4658-afe8-dff74bfe1a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-5b515193-cc14-419c-8102-09c8ea1f4ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-424b9c72-1a7c-4bba-91f9-2541d38d10d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-6860a1d7-0efe-451d-b5aa-1eacbdc72d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147589010-172.17.0.4-1595536157466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-b01fd539-0f4b-4ed9-b4d4-e50a8b8a3025,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-33a53962-8c9e-4c98-b2f1-447afe9832cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-105ecd7a-1765-4400-8600-6b22efcf4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-2ad0746a-eb10-4d99-9839-65ba8f5c4215,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-9fc54044-a731-4658-afe8-dff74bfe1a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-5b515193-cc14-419c-8102-09c8ea1f4ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-424b9c72-1a7c-4bba-91f9-2541d38d10d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-6860a1d7-0efe-451d-b5aa-1eacbdc72d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299897193-172.17.0.4-1595536833252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-cee4bc32-ca2e-42dd-acbe-32731c2bc594,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-d84c1dc6-285a-43e4-b63b-f4c95a9d3d00,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-9d369baf-cb1b-464f-a442-1ebb974efeea,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-ffef64b6-f4c2-4b1f-a911-68b98435fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-73e09b33-7b6c-418a-9392-6fb3bb68ba81,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-addb35f1-d28b-4c57-9cad-c6618bc0c879,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-28498b58-eca0-4c7d-a3ac-fe4497566011,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-97de63c4-7f32-480b-bf79-a09fc108064e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299897193-172.17.0.4-1595536833252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-cee4bc32-ca2e-42dd-acbe-32731c2bc594,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-d84c1dc6-285a-43e4-b63b-f4c95a9d3d00,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-9d369baf-cb1b-464f-a442-1ebb974efeea,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-ffef64b6-f4c2-4b1f-a911-68b98435fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-73e09b33-7b6c-418a-9392-6fb3bb68ba81,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-addb35f1-d28b-4c57-9cad-c6618bc0c879,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-28498b58-eca0-4c7d-a3ac-fe4497566011,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-97de63c4-7f32-480b-bf79-a09fc108064e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117439568-172.17.0.4-1595537354882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39459,DS-4a4613e1-f56c-479e-b1af-c6f65a049b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-c3188541-9e09-44ed-bded-1b75dedd6af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-2e09eaf6-ce3c-45a7-9c59-9f877f6d8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-fb66ba0b-16e6-47b8-b8fb-fa24f5de99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-64a1a564-bffb-4b31-8878-3a5338052d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-ac2cdb1c-fc95-4cf6-b340-295990b9f345,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-2bd254d6-11ca-4df7-89e7-a4ad73ab1dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-f617b37d-16ca-421e-8a82-2bee8768a711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117439568-172.17.0.4-1595537354882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39459,DS-4a4613e1-f56c-479e-b1af-c6f65a049b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-c3188541-9e09-44ed-bded-1b75dedd6af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-2e09eaf6-ce3c-45a7-9c59-9f877f6d8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-fb66ba0b-16e6-47b8-b8fb-fa24f5de99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-64a1a564-bffb-4b31-8878-3a5338052d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-ac2cdb1c-fc95-4cf6-b340-295990b9f345,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-2bd254d6-11ca-4df7-89e7-a4ad73ab1dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-f617b37d-16ca-421e-8a82-2bee8768a711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904640279-172.17.0.4-1595537580533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45736,DS-a0e135fe-a537-4bb1-9743-1a71528d7a95,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-03c84977-6b8d-4298-97e9-c0127303a0af,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-80ab4659-d9fe-4aff-b3cd-eaf9311fde2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-c1afd917-926d-4a84-9d89-cb080559a6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-99cdb13d-5e65-4d13-b36a-8a4b5a5dee21,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-39553d7d-13c3-440a-b294-1d71a278eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-ac808a8d-b52d-480b-8705-0bc0fc505904,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-3588ff19-d36c-4530-bca0-f61b6e1ec39d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904640279-172.17.0.4-1595537580533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45736,DS-a0e135fe-a537-4bb1-9743-1a71528d7a95,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-03c84977-6b8d-4298-97e9-c0127303a0af,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-80ab4659-d9fe-4aff-b3cd-eaf9311fde2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-c1afd917-926d-4a84-9d89-cb080559a6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-99cdb13d-5e65-4d13-b36a-8a4b5a5dee21,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-39553d7d-13c3-440a-b294-1d71a278eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-ac808a8d-b52d-480b-8705-0bc0fc505904,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-3588ff19-d36c-4530-bca0-f61b6e1ec39d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066686006-172.17.0.4-1595537733282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41067,DS-400502e0-01a1-4d63-8c98-4fbd8eccba11,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-686050f2-461f-4bd7-ad0d-9e3e9871607a,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-77a639ae-a2b3-4fa1-a7a6-f1e88088ede4,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-237cd07e-e1d2-48c6-9c82-3d82b8f53aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-7af54044-b8fc-4328-9e28-c436bcb369db,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-9f7d31ef-2442-45ad-9f8e-7568d09840de,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-f0503261-6d14-4fcd-8801-10fe121d9f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-09e8e4fc-f397-4a57-9773-a7dafcb29bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066686006-172.17.0.4-1595537733282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41067,DS-400502e0-01a1-4d63-8c98-4fbd8eccba11,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-686050f2-461f-4bd7-ad0d-9e3e9871607a,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-77a639ae-a2b3-4fa1-a7a6-f1e88088ede4,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-237cd07e-e1d2-48c6-9c82-3d82b8f53aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-7af54044-b8fc-4328-9e28-c436bcb369db,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-9f7d31ef-2442-45ad-9f8e-7568d09840de,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-f0503261-6d14-4fcd-8801-10fe121d9f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-09e8e4fc-f397-4a57-9773-a7dafcb29bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708958965-172.17.0.4-1595537862831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33104,DS-0b92b698-cb87-4fa0-9ac6-06f80d375b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-0b1c3b2c-dea4-4d63-bcc8-7c3afa11d3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-590dbaca-461e-413b-9f6a-5c410f61c7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-c7a66210-5f53-4c58-8582-743d156eac56,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-c91369de-9146-43ce-952e-2da2e09130da,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-c208fbf3-a97f-4e82-9795-accd28951b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-7d4adb49-528b-4ed0-9862-a5a2ceb6c38b,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-a76f8fde-f78c-4d81-a1b7-5ff961b00cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708958965-172.17.0.4-1595537862831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33104,DS-0b92b698-cb87-4fa0-9ac6-06f80d375b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-0b1c3b2c-dea4-4d63-bcc8-7c3afa11d3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-590dbaca-461e-413b-9f6a-5c410f61c7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-c7a66210-5f53-4c58-8582-743d156eac56,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-c91369de-9146-43ce-952e-2da2e09130da,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-c208fbf3-a97f-4e82-9795-accd28951b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-7d4adb49-528b-4ed0-9862-a5a2ceb6c38b,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-a76f8fde-f78c-4d81-a1b7-5ff961b00cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489686674-172.17.0.4-1595538117086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-dd6eb676-4ab5-485b-a7a9-48db98106b51,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-a4102741-526d-432a-9c1c-aaf1f7f19a47,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-7403a79b-160c-4d2d-8b2b-fa731c261266,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-a0af0e31-9047-42f2-b9ea-b3cdff796fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-412e738d-eb54-4dcd-be8e-5d947d11fdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-3973a5df-849f-42ad-8b20-ccc42c2d060b,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-5405ab45-38c4-4f49-bdf3-3219aceaab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-29f275f5-0e66-4765-91fb-57daeeb20d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489686674-172.17.0.4-1595538117086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-dd6eb676-4ab5-485b-a7a9-48db98106b51,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-a4102741-526d-432a-9c1c-aaf1f7f19a47,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-7403a79b-160c-4d2d-8b2b-fa731c261266,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-a0af0e31-9047-42f2-b9ea-b3cdff796fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-412e738d-eb54-4dcd-be8e-5d947d11fdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-3973a5df-849f-42ad-8b20-ccc42c2d060b,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-5405ab45-38c4-4f49-bdf3-3219aceaab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-29f275f5-0e66-4765-91fb-57daeeb20d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469008853-172.17.0.4-1595539361013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-5b8eb63b-45e3-4645-be79-ba8106e181a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-e42548a7-d10c-4d18-85b4-c0f1fe375823,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-88cffe82-4302-4335-a21a-21228a3f45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-8e5003f5-05e1-4253-b824-58e20c603be1,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-663651fd-1e86-4241-ba51-4a4777ed0d88,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-e9d525a7-7718-4fe1-a098-12277f621049,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-96f2b5b2-8d76-4c52-8d55-6c1e1d5c6f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-e28102f7-8b16-4d63-a571-1af1cc612316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469008853-172.17.0.4-1595539361013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-5b8eb63b-45e3-4645-be79-ba8106e181a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-e42548a7-d10c-4d18-85b4-c0f1fe375823,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-88cffe82-4302-4335-a21a-21228a3f45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-8e5003f5-05e1-4253-b824-58e20c603be1,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-663651fd-1e86-4241-ba51-4a4777ed0d88,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-e9d525a7-7718-4fe1-a098-12277f621049,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-96f2b5b2-8d76-4c52-8d55-6c1e1d5c6f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-e28102f7-8b16-4d63-a571-1af1cc612316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1796112557-172.17.0.4-1595539393330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45262,DS-b9b40663-c706-4653-9250-f1a5e1abc260,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-f0a800bc-fc6e-481b-b538-888c73c282fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-308646cf-636e-484a-bc48-f3e000d96ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-c56932d6-0a69-4b26-8a63-a1df77861294,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-3b21b657-a729-4a5d-9652-9a2771f1b3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-63b29295-d8a8-45bb-a123-f067e53f2a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-cfc38cbf-1d0b-4fc6-8e3c-60635e8647b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-a2352cfc-6e60-47d2-bc62-82b90a5d197f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1796112557-172.17.0.4-1595539393330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45262,DS-b9b40663-c706-4653-9250-f1a5e1abc260,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-f0a800bc-fc6e-481b-b538-888c73c282fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-308646cf-636e-484a-bc48-f3e000d96ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-c56932d6-0a69-4b26-8a63-a1df77861294,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-3b21b657-a729-4a5d-9652-9a2771f1b3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-63b29295-d8a8-45bb-a123-f067e53f2a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-cfc38cbf-1d0b-4fc6-8e3c-60635e8647b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-a2352cfc-6e60-47d2-bc62-82b90a5d197f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269056446-172.17.0.4-1595540139025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41164,DS-da67b458-0e58-4d4f-afff-0b87e47cc332,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-dbbeb017-86bc-47b2-8e21-26d381f5dda1,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-d3299657-68be-4f39-86c2-e22570c26eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-caa45b75-d24f-496a-b6a6-a14bceef8e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-d58ab815-277f-46b3-a9cf-888718faf515,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-196af94e-0379-406c-be9c-5e70eb3cc151,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-e6c89875-e02c-418b-9010-37fb5cfd5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-4891ca49-1718-4de5-9f9c-ab7e299f52e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269056446-172.17.0.4-1595540139025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41164,DS-da67b458-0e58-4d4f-afff-0b87e47cc332,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-dbbeb017-86bc-47b2-8e21-26d381f5dda1,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-d3299657-68be-4f39-86c2-e22570c26eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-caa45b75-d24f-496a-b6a6-a14bceef8e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-d58ab815-277f-46b3-a9cf-888718faf515,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-196af94e-0379-406c-be9c-5e70eb3cc151,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-e6c89875-e02c-418b-9010-37fb5cfd5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-4891ca49-1718-4de5-9f9c-ab7e299f52e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056315269-172.17.0.4-1595540198070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44293,DS-e29602b2-4865-4a23-9f23-03175365d697,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-d2a33ec1-6cb6-4f27-8909-13d7bff20cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-4bfe2df6-7613-4d61-8a0b-84dcdc1791f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-1646af25-3f6f-412d-a2dd-b9004d57c61e,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-36db0c93-344b-4f67-b135-22cb84faadf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-c95b694f-5fe0-406d-a158-b32384aa08e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-4db54466-a650-4bf7-9d48-2cb97c9881f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-dbd3a37a-40e2-430a-8fce-735f0ae0ccd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056315269-172.17.0.4-1595540198070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44293,DS-e29602b2-4865-4a23-9f23-03175365d697,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-d2a33ec1-6cb6-4f27-8909-13d7bff20cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-4bfe2df6-7613-4d61-8a0b-84dcdc1791f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-1646af25-3f6f-412d-a2dd-b9004d57c61e,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-36db0c93-344b-4f67-b135-22cb84faadf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-c95b694f-5fe0-406d-a158-b32384aa08e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-4db54466-a650-4bf7-9d48-2cb97c9881f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-dbd3a37a-40e2-430a-8fce-735f0ae0ccd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940202717-172.17.0.4-1595540856549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-6d78cb46-0ba9-4231-9f97-af0aa699d622,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-1e8585d6-1970-4117-8c89-af43420ec7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-03014f29-0db4-41ff-928c-43022231f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-02efc6fc-22d0-4f99-a75b-daebb0dd2b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-18c41b0a-a686-40f9-b8bb-578b6b257315,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-265f0d89-e9a4-4b6c-a26a-75aaa11a4736,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-c2866eb5-be3d-4a77-b78a-a7cab8d2a557,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-41125ccf-abd8-4088-9589-2b65ab6ae20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940202717-172.17.0.4-1595540856549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-6d78cb46-0ba9-4231-9f97-af0aa699d622,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-1e8585d6-1970-4117-8c89-af43420ec7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-03014f29-0db4-41ff-928c-43022231f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-02efc6fc-22d0-4f99-a75b-daebb0dd2b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-18c41b0a-a686-40f9-b8bb-578b6b257315,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-265f0d89-e9a4-4b6c-a26a-75aaa11a4736,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-c2866eb5-be3d-4a77-b78a-a7cab8d2a557,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-41125ccf-abd8-4088-9589-2b65ab6ae20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634638859-172.17.0.4-1595540933556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36568,DS-66fbb883-350b-4ebc-9f86-3623cd8f2a99,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-fabd967d-ca1c-4d9a-85ba-8ca2a9c92fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-16aa3757-c9dd-4fee-9f09-aef91d15a8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-040f6a79-ad8a-4099-b3ae-5c34b49815b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-f25e57e7-a9f5-493d-9dd7-892f07a70f62,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-2f86b3f4-0d88-4992-9814-b7d2b004952b,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-6c718af4-8069-496d-9640-9cc161d51778,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-1d79ef24-dd0f-412b-a695-fcf7c0e5cf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634638859-172.17.0.4-1595540933556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36568,DS-66fbb883-350b-4ebc-9f86-3623cd8f2a99,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-fabd967d-ca1c-4d9a-85ba-8ca2a9c92fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-16aa3757-c9dd-4fee-9f09-aef91d15a8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-040f6a79-ad8a-4099-b3ae-5c34b49815b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-f25e57e7-a9f5-493d-9dd7-892f07a70f62,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-2f86b3f4-0d88-4992-9814-b7d2b004952b,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-6c718af4-8069-496d-9640-9cc161d51778,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-1d79ef24-dd0f-412b-a695-fcf7c0e5cf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 4
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396784855-172.17.0.4-1595541399464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41731,DS-f2cf7aa8-a119-4c08-858d-baa613035015,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-fa80bdf4-dabc-47d2-acae-78541c24e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-05a30a9a-5561-4be9-9abf-cac59620f011,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-d6f2d45f-608d-4e43-8f8e-1718fd6c1e35,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-b7e29d80-1717-4220-8d60-380129bcea15,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-6b99c30a-e9f5-42d2-bbfe-7b5d05bd7e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-7c9e1405-0504-4e19-9dd6-e47dd520967e,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-862c90ba-79ac-4963-98e9-21e513f15a22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396784855-172.17.0.4-1595541399464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41731,DS-f2cf7aa8-a119-4c08-858d-baa613035015,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-fa80bdf4-dabc-47d2-acae-78541c24e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-05a30a9a-5561-4be9-9abf-cac59620f011,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-d6f2d45f-608d-4e43-8f8e-1718fd6c1e35,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-b7e29d80-1717-4220-8d60-380129bcea15,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-6b99c30a-e9f5-42d2-bbfe-7b5d05bd7e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-7c9e1405-0504-4e19-9dd6-e47dd520967e,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-862c90ba-79ac-4963-98e9-21e513f15a22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5366
