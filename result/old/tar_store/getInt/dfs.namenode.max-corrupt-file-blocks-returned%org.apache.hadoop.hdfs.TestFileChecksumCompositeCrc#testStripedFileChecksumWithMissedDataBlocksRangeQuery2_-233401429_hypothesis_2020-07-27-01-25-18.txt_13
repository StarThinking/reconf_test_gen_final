reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525396340-172.17.0.17-1595813165209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35214,DS-f7c15793-79a1-40fa-b7a6-742ef21997ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-6440a25e-cd78-46fd-afdc-5f082d89d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-0328b5b1-eb7f-44d6-b3fe-fa960d70b5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-66d88345-6124-4095-8b86-6db8159d7e07,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-fed05b85-7c2d-47e1-95f4-e31d19dc24c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-db2101db-23fe-4fc4-8f63-24fc2220c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-2251187c-1a2f-4269-92e6-842ab2aacbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-7508b4d6-8e1a-4f77-8ee6-fd79cdb8390e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525396340-172.17.0.17-1595813165209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35214,DS-f7c15793-79a1-40fa-b7a6-742ef21997ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-6440a25e-cd78-46fd-afdc-5f082d89d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-0328b5b1-eb7f-44d6-b3fe-fa960d70b5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-66d88345-6124-4095-8b86-6db8159d7e07,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-fed05b85-7c2d-47e1-95f4-e31d19dc24c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-db2101db-23fe-4fc4-8f63-24fc2220c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-2251187c-1a2f-4269-92e6-842ab2aacbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-7508b4d6-8e1a-4f77-8ee6-fd79cdb8390e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250016925-172.17.0.17-1595813244500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46269,DS-3e6244e7-8e75-43f6-809c-738c90cb276c,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-1712f9c6-60d9-411e-84dc-543081e0dfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-77884854-1a63-4a2d-9249-559b3838f70d,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-5fc48ca2-6e06-4cc5-b25f-85f59b7acccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-590b48bc-bc7e-4e5a-80f0-4564e4608899,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-4c2474a8-70f5-43d2-ba8f-b7ffb840ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-4f210b8f-01c9-4d9d-922a-1483aa960369,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-041c29dd-ba68-49cf-834a-f981d5ab32f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250016925-172.17.0.17-1595813244500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46269,DS-3e6244e7-8e75-43f6-809c-738c90cb276c,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-1712f9c6-60d9-411e-84dc-543081e0dfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-77884854-1a63-4a2d-9249-559b3838f70d,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-5fc48ca2-6e06-4cc5-b25f-85f59b7acccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-590b48bc-bc7e-4e5a-80f0-4564e4608899,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-4c2474a8-70f5-43d2-ba8f-b7ffb840ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-4f210b8f-01c9-4d9d-922a-1483aa960369,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-041c29dd-ba68-49cf-834a-f981d5ab32f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681924554-172.17.0.17-1595813999592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37806,DS-3872c11c-66a0-42f6-bcf4-59a120388287,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-940a163e-6397-42aa-89ba-c88eabefac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-72ce6c0f-37d6-4ff3-9fdf-7835f8b0301d,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-e0d6dd77-5256-4eb2-bf7d-7532f38431cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-d78e8752-ca98-4b70-be85-3158db22e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-e136fd60-b323-4c0e-a334-922fc5cd5407,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-27a78914-2393-4a69-bcaf-1a3834b4383b,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-8e05cfc6-03d8-4e67-8fe2-f889cf084e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681924554-172.17.0.17-1595813999592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37806,DS-3872c11c-66a0-42f6-bcf4-59a120388287,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-940a163e-6397-42aa-89ba-c88eabefac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-72ce6c0f-37d6-4ff3-9fdf-7835f8b0301d,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-e0d6dd77-5256-4eb2-bf7d-7532f38431cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-d78e8752-ca98-4b70-be85-3158db22e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-e136fd60-b323-4c0e-a334-922fc5cd5407,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-27a78914-2393-4a69-bcaf-1a3834b4383b,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-8e05cfc6-03d8-4e67-8fe2-f889cf084e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580128596-172.17.0.17-1595814203837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-0b8c7385-507a-42d5-858f-445172ea2cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-ed502972-8fe1-4f5a-9503-3fa8bf69d05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-e9479fc5-1c07-48dc-a48b-89df11184dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-07495795-197a-4280-9b5e-36250ae8d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-1edaae7f-5110-4d99-bef7-a7d584b162e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-de303842-8cbf-4095-b9e8-ae7e20474150,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-e12b69e7-2a37-4f5d-91e8-ab0476e820b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-90776a7b-e984-410f-abbb-eea307880b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580128596-172.17.0.17-1595814203837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-0b8c7385-507a-42d5-858f-445172ea2cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-ed502972-8fe1-4f5a-9503-3fa8bf69d05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-e9479fc5-1c07-48dc-a48b-89df11184dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-07495795-197a-4280-9b5e-36250ae8d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-1edaae7f-5110-4d99-bef7-a7d584b162e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-de303842-8cbf-4095-b9e8-ae7e20474150,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-e12b69e7-2a37-4f5d-91e8-ab0476e820b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-90776a7b-e984-410f-abbb-eea307880b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186771888-172.17.0.17-1595814282845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45392,DS-55ddebfc-e17d-4030-a368-a57b98b8fdab,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-1d8685ec-4592-40d5-ab1a-af1b41838922,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-a723d1d4-15a9-4436-b19a-9322a5a9849a,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-9ae9cea6-5027-4762-8d7f-acee25e6be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-cc94298d-e81f-419f-924f-48d5a6204510,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-258550a1-eedc-4e85-a7e6-a70c06ede84f,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-b3b712b6-1162-43c5-ba77-ecc3cb85d101,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-8a8f1f28-37f4-4a72-abcd-2800f64df80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186771888-172.17.0.17-1595814282845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45392,DS-55ddebfc-e17d-4030-a368-a57b98b8fdab,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-1d8685ec-4592-40d5-ab1a-af1b41838922,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-a723d1d4-15a9-4436-b19a-9322a5a9849a,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-9ae9cea6-5027-4762-8d7f-acee25e6be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-cc94298d-e81f-419f-924f-48d5a6204510,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-258550a1-eedc-4e85-a7e6-a70c06ede84f,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-b3b712b6-1162-43c5-ba77-ecc3cb85d101,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-8a8f1f28-37f4-4a72-abcd-2800f64df80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903783037-172.17.0.17-1595814468633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43017,DS-7c5efd30-f16f-4abb-92d9-cfa551fa730a,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-b137bda6-70b5-44f4-84fd-8474e688354a,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-8cd33e74-1ffe-4828-8ed3-1ea4552a20d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-2b1af739-e56a-4583-8fef-9c8c222397a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-a8cb005d-a000-47bc-a9b2-7d8bf9dfc97e,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-e0f4b944-4002-4a36-93e0-8d51adf77521,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-1779753c-4a8e-42cf-851c-f74b6bf32d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-af07375f-bca3-4b55-a5d3-7015ea2954a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903783037-172.17.0.17-1595814468633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43017,DS-7c5efd30-f16f-4abb-92d9-cfa551fa730a,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-b137bda6-70b5-44f4-84fd-8474e688354a,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-8cd33e74-1ffe-4828-8ed3-1ea4552a20d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-2b1af739-e56a-4583-8fef-9c8c222397a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-a8cb005d-a000-47bc-a9b2-7d8bf9dfc97e,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-e0f4b944-4002-4a36-93e0-8d51adf77521,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-1779753c-4a8e-42cf-851c-f74b6bf32d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-af07375f-bca3-4b55-a5d3-7015ea2954a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568292016-172.17.0.17-1595815909582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-4dc43c7d-1572-430b-aff2-53333f8dbfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-2b52b942-2bb6-4c7d-95bf-e08d132be610,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-3ed0a587-bf86-48be-b331-3b1b0dfcc4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-c93ab8ca-82c5-4778-9917-9624484a0854,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-a37126d5-2cc6-4174-b7d8-117e16b3cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-fef57d35-8b12-473a-8727-fcd4be0e3420,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-23dc3425-62f5-4ae7-8edc-2da66e4ac28b,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-622e4e4d-18e1-492c-ba6b-70ce4adc9687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568292016-172.17.0.17-1595815909582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-4dc43c7d-1572-430b-aff2-53333f8dbfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-2b52b942-2bb6-4c7d-95bf-e08d132be610,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-3ed0a587-bf86-48be-b331-3b1b0dfcc4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-c93ab8ca-82c5-4778-9917-9624484a0854,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-a37126d5-2cc6-4174-b7d8-117e16b3cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-fef57d35-8b12-473a-8727-fcd4be0e3420,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-23dc3425-62f5-4ae7-8edc-2da66e4ac28b,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-622e4e4d-18e1-492c-ba6b-70ce4adc9687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236265618-172.17.0.17-1595816131583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38805,DS-f895aa18-8064-4499-b9e1-9ee22c681764,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-1671e169-6249-4cf9-bf29-da5c093620cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-730e504c-0947-4c78-ac2d-13525f248571,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-f373a635-82e4-4045-948a-ba4744e2781c,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-98484b6d-e8d6-4a7f-9c04-71f1d188b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-abf2f215-f902-474c-be3b-ec5f39c8f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-fe2990e9-c627-4fe0-b5f5-1b537abecf42,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-0885032f-dd8f-4f1f-b69e-4a69ccc50eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236265618-172.17.0.17-1595816131583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38805,DS-f895aa18-8064-4499-b9e1-9ee22c681764,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-1671e169-6249-4cf9-bf29-da5c093620cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-730e504c-0947-4c78-ac2d-13525f248571,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-f373a635-82e4-4045-948a-ba4744e2781c,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-98484b6d-e8d6-4a7f-9c04-71f1d188b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-abf2f215-f902-474c-be3b-ec5f39c8f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-fe2990e9-c627-4fe0-b5f5-1b537abecf42,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-0885032f-dd8f-4f1f-b69e-4a69ccc50eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131683754-172.17.0.17-1595816168058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44772,DS-c4811576-acb3-48e1-ae86-74a8c0057eef,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-7125a631-ab5f-461f-8edc-7a8b784a789e,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-a5c98352-66fe-4bd4-af75-227e1d9d8c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-ce9f96a4-ad71-4b88-aaa0-4b25ed932a72,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-98afaebb-7a8d-41e8-b4d7-f7063d882e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-44a09a15-61d9-4151-a171-54f5faf9d555,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-87192e8a-bd2b-46f8-b8c3-0519994dfd21,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-39b0fd57-b9ca-41a9-b9a3-cde4e85a735a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131683754-172.17.0.17-1595816168058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44772,DS-c4811576-acb3-48e1-ae86-74a8c0057eef,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-7125a631-ab5f-461f-8edc-7a8b784a789e,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-a5c98352-66fe-4bd4-af75-227e1d9d8c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-ce9f96a4-ad71-4b88-aaa0-4b25ed932a72,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-98afaebb-7a8d-41e8-b4d7-f7063d882e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-44a09a15-61d9-4151-a171-54f5faf9d555,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-87192e8a-bd2b-46f8-b8c3-0519994dfd21,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-39b0fd57-b9ca-41a9-b9a3-cde4e85a735a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639196718-172.17.0.17-1595816663721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35205,DS-f0bde4a4-87fc-4cf8-81b5-f3473a4d5dca,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-216c181c-d0b7-4b04-8d6c-8d321ab7177b,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-984167fb-4a27-4f5d-b2dc-0b99a6906218,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-fe54b79d-4838-4cd9-a62c-1eecad4dd6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-a38cb529-5fb7-4502-a637-fd56739b976a,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-0850d6e3-42ef-40fd-9293-1121b35d7e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-4e477f75-1566-42b4-8deb-2ad5d5915a82,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-da3b378e-ef4f-4c1c-9c6f-70cfecfd2207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639196718-172.17.0.17-1595816663721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35205,DS-f0bde4a4-87fc-4cf8-81b5-f3473a4d5dca,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-216c181c-d0b7-4b04-8d6c-8d321ab7177b,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-984167fb-4a27-4f5d-b2dc-0b99a6906218,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-fe54b79d-4838-4cd9-a62c-1eecad4dd6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-a38cb529-5fb7-4502-a637-fd56739b976a,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-0850d6e3-42ef-40fd-9293-1121b35d7e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-4e477f75-1566-42b4-8deb-2ad5d5915a82,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-da3b378e-ef4f-4c1c-9c6f-70cfecfd2207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204051709-172.17.0.17-1595816692295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34079,DS-a978246b-bba2-483e-b34c-a55dff7277d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-00e52da8-ecf9-4a18-885f-335cbed4337c,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-61dc9342-5e57-414a-bfc9-d0ca2d6a747f,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-da1c4147-d2e7-42ea-951d-03a5ebf5d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-7a49c69f-b8e4-4bef-bc9a-62cab4ac9cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-41da1799-c9ae-4c9c-87c9-fc9fbff3f5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-020a6ffc-1918-4ad4-a23d-81a0aa14d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-c2e04cba-82d5-45d3-abf9-9aac95974641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204051709-172.17.0.17-1595816692295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34079,DS-a978246b-bba2-483e-b34c-a55dff7277d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-00e52da8-ecf9-4a18-885f-335cbed4337c,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-61dc9342-5e57-414a-bfc9-d0ca2d6a747f,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-da1c4147-d2e7-42ea-951d-03a5ebf5d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-7a49c69f-b8e4-4bef-bc9a-62cab4ac9cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-41da1799-c9ae-4c9c-87c9-fc9fbff3f5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-020a6ffc-1918-4ad4-a23d-81a0aa14d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-c2e04cba-82d5-45d3-abf9-9aac95974641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905302033-172.17.0.17-1595817182313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-e0aaea27-b52a-411a-aff9-b027c64fe7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-fa1f63fd-5996-4b96-abf0-b839918e13ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-e00f4ee5-10aa-4a1e-8b22-96e1cbacec95,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-ca5eecc6-724e-460b-8922-4bce2102f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-b9172916-a098-45e7-b755-08c5131552e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-2042f6c0-e56e-4469-8f28-7512a6fc7876,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-9eccdb1e-6108-46a7-ad29-44c7ce71622c,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-c2204690-f025-4073-a5bf-713a60492cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905302033-172.17.0.17-1595817182313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-e0aaea27-b52a-411a-aff9-b027c64fe7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-fa1f63fd-5996-4b96-abf0-b839918e13ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-e00f4ee5-10aa-4a1e-8b22-96e1cbacec95,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-ca5eecc6-724e-460b-8922-4bce2102f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-b9172916-a098-45e7-b755-08c5131552e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-2042f6c0-e56e-4469-8f28-7512a6fc7876,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-9eccdb1e-6108-46a7-ad29-44c7ce71622c,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-c2204690-f025-4073-a5bf-713a60492cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677009367-172.17.0.17-1595817218012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39590,DS-93563659-d218-43a8-9927-8775dacb51f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-697bf018-6bcf-445a-8a30-c3c2e8fbcbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-9b53d923-0f85-4f27-9c32-820a61c4bb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-286f7b0a-753a-4257-864e-0ee6fe2f5282,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-cbdfbf19-8e44-441b-a905-0955182fd3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-598d4066-bbc2-44a4-b045-97280831c44c,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-fd2a63e4-04fb-413a-b542-bcc84b1949f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-698725dc-17a0-4cf3-923f-defed5bdf2f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677009367-172.17.0.17-1595817218012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39590,DS-93563659-d218-43a8-9927-8775dacb51f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-697bf018-6bcf-445a-8a30-c3c2e8fbcbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-9b53d923-0f85-4f27-9c32-820a61c4bb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-286f7b0a-753a-4257-864e-0ee6fe2f5282,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-cbdfbf19-8e44-441b-a905-0955182fd3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-598d4066-bbc2-44a4-b045-97280831c44c,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-fd2a63e4-04fb-413a-b542-bcc84b1949f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-698725dc-17a0-4cf3-923f-defed5bdf2f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579899901-172.17.0.17-1595817309657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45523,DS-94bc5dd3-1134-4720-a73f-f5bb2d96036d,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-75ab0bea-4399-4703-9729-ce0d2d3733f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-ff10468e-e95e-46ba-978e-5ff4d2ba2373,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-3c9923b6-6987-434c-8371-33df4f07b0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-bc32f8c7-aa8a-4953-b489-43336050646e,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-adbb08f6-2c48-4be6-ba49-afa1e5b1a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-e3295193-72a2-4ac8-8904-05830fe4d025,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-b68468fd-e487-47ee-8162-3c172e6a058c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579899901-172.17.0.17-1595817309657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45523,DS-94bc5dd3-1134-4720-a73f-f5bb2d96036d,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-75ab0bea-4399-4703-9729-ce0d2d3733f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-ff10468e-e95e-46ba-978e-5ff4d2ba2373,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-3c9923b6-6987-434c-8371-33df4f07b0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-bc32f8c7-aa8a-4953-b489-43336050646e,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-adbb08f6-2c48-4be6-ba49-afa1e5b1a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-e3295193-72a2-4ac8-8904-05830fe4d025,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-b68468fd-e487-47ee-8162-3c172e6a058c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936615651-172.17.0.17-1595817344483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34231,DS-e6d98d19-a424-4d58-a06d-1c6e04980317,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-2d2f1d1b-32f4-4ac8-aad1-24df8c1b18a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-3d25d5c6-bc0d-4fc0-94f0-b006f7c4310f,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-9a5d431f-13b6-45e0-a337-72aa70a8bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-241a699a-f1e2-458b-a481-5ac225c970af,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-2ab5d1b0-359f-41a0-a6b0-a9b5c59eb8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-9dae7ecd-4e1a-4fda-8e18-10537d4c0215,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-43e5095e-ad32-4bd8-b266-d6dedf34da97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936615651-172.17.0.17-1595817344483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34231,DS-e6d98d19-a424-4d58-a06d-1c6e04980317,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-2d2f1d1b-32f4-4ac8-aad1-24df8c1b18a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-3d25d5c6-bc0d-4fc0-94f0-b006f7c4310f,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-9a5d431f-13b6-45e0-a337-72aa70a8bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-241a699a-f1e2-458b-a481-5ac225c970af,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-2ab5d1b0-359f-41a0-a6b0-a9b5c59eb8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-9dae7ecd-4e1a-4fda-8e18-10537d4c0215,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-43e5095e-ad32-4bd8-b266-d6dedf34da97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289513314-172.17.0.17-1595817406855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-730e663f-52d9-4c3e-959e-c345e8021674,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-dd827f16-859e-4d74-8cac-f78d3f31719c,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-78fb780d-fb8d-49fa-a854-57a8e2b758ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-e028cbcf-6188-4615-9817-a9fda025c472,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-effafd1b-80e2-43b9-8953-e8e2a18e3336,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-36566a2e-8476-4cd2-86ee-517d209e7652,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-ed9ec31a-b884-4a55-b778-66e814b0d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-c6af6555-9983-46b0-9732-7c729acc63ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289513314-172.17.0.17-1595817406855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-730e663f-52d9-4c3e-959e-c345e8021674,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-dd827f16-859e-4d74-8cac-f78d3f31719c,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-78fb780d-fb8d-49fa-a854-57a8e2b758ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-e028cbcf-6188-4615-9817-a9fda025c472,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-effafd1b-80e2-43b9-8953-e8e2a18e3336,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-36566a2e-8476-4cd2-86ee-517d209e7652,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-ed9ec31a-b884-4a55-b778-66e814b0d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-c6af6555-9983-46b0-9732-7c729acc63ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204610577-172.17.0.17-1595818133958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-eb17508d-066e-4ce7-a9ed-d2f5aa7768fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-86faf315-cfe5-4581-b575-855acb2c61ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-c4bac863-3a57-40b1-a3e3-6da9157f22bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-ced0aa8e-813f-45eb-acad-e9e5d60b1fda,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-94a8fc42-69ca-4160-806e-95eda6ecf0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-b2c06e54-30d4-4397-b940-fade23f67bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-f8445563-69c1-47c2-af92-cd9db90c936c,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-999d9baa-9a9b-4522-9cea-092472fd0a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204610577-172.17.0.17-1595818133958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-eb17508d-066e-4ce7-a9ed-d2f5aa7768fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-86faf315-cfe5-4581-b575-855acb2c61ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-c4bac863-3a57-40b1-a3e3-6da9157f22bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-ced0aa8e-813f-45eb-acad-e9e5d60b1fda,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-94a8fc42-69ca-4160-806e-95eda6ecf0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-b2c06e54-30d4-4397-b940-fade23f67bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-f8445563-69c1-47c2-af92-cd9db90c936c,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-999d9baa-9a9b-4522-9cea-092472fd0a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931144435-172.17.0.17-1595818201538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33879,DS-5dec3ef2-d959-4f66-acf7-df3a9657fe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-7168e882-da7e-42a2-a6c7-0fbeba7a990d,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-bc05fa57-b47f-41a3-8faf-2b4ca611217f,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-e98f001d-678f-4974-84cf-ac0275e7a4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-bf49788e-a9d6-4463-9f64-00c736ad6d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-7da3f849-ed4b-4783-aa02-bdcdeda42aec,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-549be406-41a2-464e-979c-3afcc09ebc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-e85bc678-216f-4564-9293-202eda13ed6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931144435-172.17.0.17-1595818201538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33879,DS-5dec3ef2-d959-4f66-acf7-df3a9657fe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-7168e882-da7e-42a2-a6c7-0fbeba7a990d,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-bc05fa57-b47f-41a3-8faf-2b4ca611217f,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-e98f001d-678f-4974-84cf-ac0275e7a4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-bf49788e-a9d6-4463-9f64-00c736ad6d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-7da3f849-ed4b-4783-aa02-bdcdeda42aec,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-549be406-41a2-464e-979c-3afcc09ebc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-e85bc678-216f-4564-9293-202eda13ed6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5241
