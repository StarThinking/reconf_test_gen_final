reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145626536-172.17.0.10-1596025173202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36855,DS-99d412ad-2977-4f5a-9cc1-ba41a9a1b612,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-a20905a5-d72e-439b-9923-88311eb07db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-4206c6a0-a363-4984-b441-8f2f53bcb56d,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-a7f8b756-081a-497c-a40a-b3dfbe813253,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-69b261fb-9567-4b7c-9f65-cfd58f357a06,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-54b7b3f6-a54a-4003-9b1e-a0523eef9b05,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-27171100-b9aa-4348-a6c1-9b5e60aee664,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-16002627-fe38-4a4c-864c-73f37534798d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145626536-172.17.0.10-1596025173202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36855,DS-99d412ad-2977-4f5a-9cc1-ba41a9a1b612,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-a20905a5-d72e-439b-9923-88311eb07db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-4206c6a0-a363-4984-b441-8f2f53bcb56d,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-a7f8b756-081a-497c-a40a-b3dfbe813253,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-69b261fb-9567-4b7c-9f65-cfd58f357a06,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-54b7b3f6-a54a-4003-9b1e-a0523eef9b05,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-27171100-b9aa-4348-a6c1-9b5e60aee664,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-16002627-fe38-4a4c-864c-73f37534798d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962624775-172.17.0.10-1596025803884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44673,DS-58813e02-a835-4632-b7b4-bebdf604915d,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-72303d78-cfdf-407c-9874-0fa0e0578e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-625f6b57-a534-4183-8f42-a6aeacad5cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-6df3d7c7-8513-413a-8ba7-660dd76a226b,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-dfb893ac-0ca5-407b-9912-7b42072bf471,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-876bf964-e033-4c83-be2d-50d6177aeb88,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-a5608e09-8943-47a7-8e82-2dc0c7228563,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-31a2fc6f-adfa-4579-a3ed-68de34eaeb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962624775-172.17.0.10-1596025803884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44673,DS-58813e02-a835-4632-b7b4-bebdf604915d,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-72303d78-cfdf-407c-9874-0fa0e0578e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-625f6b57-a534-4183-8f42-a6aeacad5cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-6df3d7c7-8513-413a-8ba7-660dd76a226b,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-dfb893ac-0ca5-407b-9912-7b42072bf471,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-876bf964-e033-4c83-be2d-50d6177aeb88,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-a5608e09-8943-47a7-8e82-2dc0c7228563,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-31a2fc6f-adfa-4579-a3ed-68de34eaeb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962427196-172.17.0.10-1596026924623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44831,DS-df23bcdf-8a1d-4f86-8142-c12ae5086690,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-bec37bab-0b42-4817-ad6b-635442870b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-1e8e1b7d-f936-4d6a-9eab-5c2f40976001,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-da24ad1a-4e83-4540-a975-6fd457a34e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-aa1d36e6-d4e7-48b8-9b58-0ebaa6b2911a,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-343f0a31-f227-4c4a-93fd-436cc4a54167,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-51140624-39b8-47dd-9ead-4189f8574b56,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-67cf5994-f4ad-4e96-969f-5371599cf7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962427196-172.17.0.10-1596026924623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44831,DS-df23bcdf-8a1d-4f86-8142-c12ae5086690,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-bec37bab-0b42-4817-ad6b-635442870b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-1e8e1b7d-f936-4d6a-9eab-5c2f40976001,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-da24ad1a-4e83-4540-a975-6fd457a34e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-aa1d36e6-d4e7-48b8-9b58-0ebaa6b2911a,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-343f0a31-f227-4c4a-93fd-436cc4a54167,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-51140624-39b8-47dd-9ead-4189f8574b56,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-67cf5994-f4ad-4e96-969f-5371599cf7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761851085-172.17.0.10-1596027510458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-bf157555-e583-429d-80fb-835e1a9788de,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-380cf153-8c12-4950-ad43-864eed4e0542,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-b7132399-eca9-412b-abab-b12cee9ba004,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-740285cd-af2a-41cd-9f75-e1c869d3deca,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-2e57adf4-ae16-4b53-a03d-795383cef639,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-940c399d-d836-46c1-8ebf-10c29abdf191,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-bd30c932-8c1e-4aee-8ae4-b5ef3c81a5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-b62c2b58-b8d3-4b2e-8e18-012a389449ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761851085-172.17.0.10-1596027510458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-bf157555-e583-429d-80fb-835e1a9788de,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-380cf153-8c12-4950-ad43-864eed4e0542,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-b7132399-eca9-412b-abab-b12cee9ba004,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-740285cd-af2a-41cd-9f75-e1c869d3deca,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-2e57adf4-ae16-4b53-a03d-795383cef639,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-940c399d-d836-46c1-8ebf-10c29abdf191,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-bd30c932-8c1e-4aee-8ae4-b5ef3c81a5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-b62c2b58-b8d3-4b2e-8e18-012a389449ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410554310-172.17.0.10-1596027636492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38652,DS-16169d75-7422-4dad-a4a5-1eed472b822d,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-0de910e3-39d3-4d99-bc75-cbe824a73739,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-25cacab8-3431-444d-b047-19dfd07a70de,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-25684fb4-c4d7-467d-947e-23f52ceb0a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-169eae6c-210d-46e5-bebf-4bf597ebfcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-dc135234-64a1-4c89-9388-da79925c3b23,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-cb15d72a-d84c-4fff-a2e5-a2891e6f653f,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-a66abfaa-ca4f-481b-aa9e-5d5d1c288899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410554310-172.17.0.10-1596027636492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38652,DS-16169d75-7422-4dad-a4a5-1eed472b822d,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-0de910e3-39d3-4d99-bc75-cbe824a73739,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-25cacab8-3431-444d-b047-19dfd07a70de,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-25684fb4-c4d7-467d-947e-23f52ceb0a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-169eae6c-210d-46e5-bebf-4bf597ebfcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-dc135234-64a1-4c89-9388-da79925c3b23,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-cb15d72a-d84c-4fff-a2e5-a2891e6f653f,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-a66abfaa-ca4f-481b-aa9e-5d5d1c288899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133246784-172.17.0.10-1596027936460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-213b70a3-9a12-44f6-b314-09501874bbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-9efa1fdf-c4ef-4c5a-87d4-96d7c7b29d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-f6a8cf71-e63d-4dc4-bb4b-b5d9b4cb05a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-6c64f2c6-7ddd-45f5-9627-8ba647dccabd,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-c39fc4e7-a944-4bc8-b3f5-3e0aa882fe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-d1fa6857-94a0-453b-99fe-e15a17bbfc46,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-82a136cb-91ed-4d74-bdad-5687fa7cae1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-c94c25d3-c25a-4f21-aa60-7d0c615aa9f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133246784-172.17.0.10-1596027936460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-213b70a3-9a12-44f6-b314-09501874bbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-9efa1fdf-c4ef-4c5a-87d4-96d7c7b29d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-f6a8cf71-e63d-4dc4-bb4b-b5d9b4cb05a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-6c64f2c6-7ddd-45f5-9627-8ba647dccabd,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-c39fc4e7-a944-4bc8-b3f5-3e0aa882fe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-d1fa6857-94a0-453b-99fe-e15a17bbfc46,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-82a136cb-91ed-4d74-bdad-5687fa7cae1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-c94c25d3-c25a-4f21-aa60-7d0c615aa9f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099811218-172.17.0.10-1596028062471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-f2aa4242-b30b-4d40-ad88-a86bbff4e6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-8e2f4551-99f3-4158-9bcf-a1f9dd8a7784,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-1831f5e7-8bcc-4a32-8d1b-735d9f595666,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-9f50b179-1047-4135-adf9-0db200712cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-9ec7202a-2c83-4dca-a92b-98c8ea11b1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-14bd1ab2-acf5-48ed-9c10-1a9055d6cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-2501d5b4-45ca-410e-a1d5-5c5e428f96b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-f0301991-ae52-410e-b125-3eb4d1c0e2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099811218-172.17.0.10-1596028062471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-f2aa4242-b30b-4d40-ad88-a86bbff4e6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-8e2f4551-99f3-4158-9bcf-a1f9dd8a7784,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-1831f5e7-8bcc-4a32-8d1b-735d9f595666,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-9f50b179-1047-4135-adf9-0db200712cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-9ec7202a-2c83-4dca-a92b-98c8ea11b1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-14bd1ab2-acf5-48ed-9c10-1a9055d6cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-2501d5b4-45ca-410e-a1d5-5c5e428f96b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-f0301991-ae52-410e-b125-3eb4d1c0e2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938033870-172.17.0.10-1596028556958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33203,DS-f404f118-b862-409b-84b5-43b3a96bcd50,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-e71fd1f6-c3eb-4bc2-bad7-73c284b3ccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-8579e7c9-e359-4715-9c19-da81e2598bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-629e9d70-c2fa-4dbd-90b0-6c9a49a13aad,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-df596ac9-55f4-4dd8-a57f-b8ea5b8dd21e,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e9838f48-097b-4b28-ae0e-1fa698adb3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-6c45d5bf-cc53-4be9-b96e-4b986e85e058,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-4fb981ea-8ece-427b-b6a4-efa598f2c566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938033870-172.17.0.10-1596028556958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33203,DS-f404f118-b862-409b-84b5-43b3a96bcd50,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-e71fd1f6-c3eb-4bc2-bad7-73c284b3ccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-8579e7c9-e359-4715-9c19-da81e2598bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-629e9d70-c2fa-4dbd-90b0-6c9a49a13aad,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-df596ac9-55f4-4dd8-a57f-b8ea5b8dd21e,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e9838f48-097b-4b28-ae0e-1fa698adb3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-6c45d5bf-cc53-4be9-b96e-4b986e85e058,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-4fb981ea-8ece-427b-b6a4-efa598f2c566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968470600-172.17.0.10-1596028873701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-f1777711-084e-4888-a830-1bb155c121cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-5e91e71b-d30a-45b3-960c-4fd20cdcea19,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-e8a477bb-d2ea-43f6-bce1-548130f63821,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-34136434-322f-47d3-879d-9f6d5e628b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-643c366d-533e-454c-935b-1ea8e6db64e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-e208ae46-afee-4fe5-87a1-eb5b8863d679,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-70f9972d-793d-4bf1-9b56-d066f86e77a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-a1182df6-5164-4093-9421-c3030de1a533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968470600-172.17.0.10-1596028873701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-f1777711-084e-4888-a830-1bb155c121cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-5e91e71b-d30a-45b3-960c-4fd20cdcea19,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-e8a477bb-d2ea-43f6-bce1-548130f63821,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-34136434-322f-47d3-879d-9f6d5e628b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-643c366d-533e-454c-935b-1ea8e6db64e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-e208ae46-afee-4fe5-87a1-eb5b8863d679,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-70f9972d-793d-4bf1-9b56-d066f86e77a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-a1182df6-5164-4093-9421-c3030de1a533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635020697-172.17.0.10-1596030678778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41104,DS-a0dd36e8-8504-420f-89ff-e429c0f8b14d,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-8bcd14cc-3e0e-4866-8229-f9575dac9d78,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-e635d395-3a0a-46a8-8b86-3e6a8a3e5695,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-16165ef9-4aee-4d4e-9164-62c27092de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-ed39aac4-0743-4868-b0e6-b240b8961a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-600dc847-a01f-408d-8413-085edb4f2517,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-9fa4c822-9205-43b3-871b-85847693aeff,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-ca2b07af-6ffd-434f-937e-1ca20a657d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635020697-172.17.0.10-1596030678778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41104,DS-a0dd36e8-8504-420f-89ff-e429c0f8b14d,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-8bcd14cc-3e0e-4866-8229-f9575dac9d78,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-e635d395-3a0a-46a8-8b86-3e6a8a3e5695,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-16165ef9-4aee-4d4e-9164-62c27092de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-ed39aac4-0743-4868-b0e6-b240b8961a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-600dc847-a01f-408d-8413-085edb4f2517,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-9fa4c822-9205-43b3-871b-85847693aeff,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-ca2b07af-6ffd-434f-937e-1ca20a657d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157607621-172.17.0.10-1596031029194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38897,DS-e7ce9047-16b2-468c-9cc7-692b70e77730,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-0e6c737c-b87d-4027-b747-0d1d25cce3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-54c97af7-581f-4516-b688-0e7d6200b474,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-004ca8bd-4c6c-49e5-93fa-6d54b7ae98a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-653a89e3-536d-4de9-a205-d704a387a8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-4f8a746b-3148-4b00-87db-fed976fb249b,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-06b923c9-1261-414c-8ba7-1230d3b0da64,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-e91b7971-b136-433f-91e4-f8e179d78f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157607621-172.17.0.10-1596031029194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38897,DS-e7ce9047-16b2-468c-9cc7-692b70e77730,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-0e6c737c-b87d-4027-b747-0d1d25cce3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-54c97af7-581f-4516-b688-0e7d6200b474,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-004ca8bd-4c6c-49e5-93fa-6d54b7ae98a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-653a89e3-536d-4de9-a205-d704a387a8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-4f8a746b-3148-4b00-87db-fed976fb249b,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-06b923c9-1261-414c-8ba7-1230d3b0da64,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-e91b7971-b136-433f-91e4-f8e179d78f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964528854-172.17.0.10-1596031427956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-2b66f941-c604-4dab-86eb-457d36f8234a,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-aafb39c0-06f7-414d-ac3f-d00386819fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-4aa143c8-235a-46eb-b29e-997b6889c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-3de5e721-5c97-46d5-98d2-569965eaf0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-b29393a7-7d39-488f-a7f8-d7292881ab71,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-fd329d1f-a47f-40af-b3f7-d9084c02ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-6d3d3425-58ff-4783-ae00-f3f61715ed20,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-11560ee9-bf4d-4c53-82a8-35aad70ffb6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964528854-172.17.0.10-1596031427956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-2b66f941-c604-4dab-86eb-457d36f8234a,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-aafb39c0-06f7-414d-ac3f-d00386819fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-4aa143c8-235a-46eb-b29e-997b6889c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-3de5e721-5c97-46d5-98d2-569965eaf0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-b29393a7-7d39-488f-a7f8-d7292881ab71,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-fd329d1f-a47f-40af-b3f7-d9084c02ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-6d3d3425-58ff-4783-ae00-f3f61715ed20,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-11560ee9-bf4d-4c53-82a8-35aad70ffb6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6338
