reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637756839-172.17.0.10-1595934544660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33203,DS-dab21288-73da-4826-8a76-9b639fb66477,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-084df15a-ae90-4e42-b4a5-f3c6877ec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-3a680de5-8834-4737-b30e-7ed7be9e5d72,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-b6b7e871-6fa7-4613-af4f-010c13f33db3,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-55ef663c-b450-4495-8ced-dc810c05067d,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-dddded89-fd74-4888-85a4-7ba771d9b758,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-3a74c919-4f4f-472f-ae59-daf8ad710372,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-66feba87-f2f5-46dc-be38-ca486cb71d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637756839-172.17.0.10-1595934544660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33203,DS-dab21288-73da-4826-8a76-9b639fb66477,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-084df15a-ae90-4e42-b4a5-f3c6877ec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-3a680de5-8834-4737-b30e-7ed7be9e5d72,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-b6b7e871-6fa7-4613-af4f-010c13f33db3,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-55ef663c-b450-4495-8ced-dc810c05067d,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-dddded89-fd74-4888-85a4-7ba771d9b758,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-3a74c919-4f4f-472f-ae59-daf8ad710372,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-66feba87-f2f5-46dc-be38-ca486cb71d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587036868-172.17.0.10-1595935093564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39046,DS-93140f20-aefa-42c3-8f61-28bda567ba42,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-6a865815-6e3e-4310-afe6-a3b423c2554b,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-5d7303f8-9b98-48e6-bb83-10a036404033,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-fc01651e-f2b7-4fa3-a8db-7b2190ff5372,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-0696c096-87e8-43e8-9345-0d2fffb028c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-bf65fd62-dc46-4f5d-bd15-5e3f24ab2154,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-5744006f-2715-4bec-96f8-7cbd05083e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-5996549a-9d24-4667-ac2b-af5c2c82dc51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587036868-172.17.0.10-1595935093564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39046,DS-93140f20-aefa-42c3-8f61-28bda567ba42,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-6a865815-6e3e-4310-afe6-a3b423c2554b,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-5d7303f8-9b98-48e6-bb83-10a036404033,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-fc01651e-f2b7-4fa3-a8db-7b2190ff5372,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-0696c096-87e8-43e8-9345-0d2fffb028c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-bf65fd62-dc46-4f5d-bd15-5e3f24ab2154,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-5744006f-2715-4bec-96f8-7cbd05083e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-5996549a-9d24-4667-ac2b-af5c2c82dc51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701484969-172.17.0.10-1595935126301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-2339e28b-bd29-4749-93e5-8ad9b22302f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-4cf3244e-1f36-454b-9a75-03d3a6cf170f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-464dc326-0152-48fc-b67b-ce8b030c5b65,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-b435dcc0-da60-4b56-a1f5-6d7d47f0d84f,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-5d6f0ba5-9c24-4fbc-b040-fd7d8d0fb3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-2c3f3224-bee8-483d-a6ac-59ff63e45500,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-e9fa81ad-1056-4171-be18-2edfda55cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-7369a7b0-9e2e-473e-a5d9-a62b657f3f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701484969-172.17.0.10-1595935126301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-2339e28b-bd29-4749-93e5-8ad9b22302f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-4cf3244e-1f36-454b-9a75-03d3a6cf170f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-464dc326-0152-48fc-b67b-ce8b030c5b65,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-b435dcc0-da60-4b56-a1f5-6d7d47f0d84f,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-5d6f0ba5-9c24-4fbc-b040-fd7d8d0fb3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-2c3f3224-bee8-483d-a6ac-59ff63e45500,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-e9fa81ad-1056-4171-be18-2edfda55cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-7369a7b0-9e2e-473e-a5d9-a62b657f3f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725091193-172.17.0.10-1595935265051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-b62c01eb-9993-47ee-be53-8085c3f8f014,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-404f705b-8fb0-433c-b128-038c958029b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-c5b44f2f-3205-4331-b7ae-13e280e20283,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-82a6a53c-23a0-4e11-a533-fcfb14697a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-b056e5e5-5302-4545-b578-876d03dabdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-08bf6edc-1118-4aed-8303-4e769ce64c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-575eb271-1e55-49cc-8a58-11dda59e952e,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-ae64c349-7995-4c09-9f27-6c32ec6346d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725091193-172.17.0.10-1595935265051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-b62c01eb-9993-47ee-be53-8085c3f8f014,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-404f705b-8fb0-433c-b128-038c958029b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-c5b44f2f-3205-4331-b7ae-13e280e20283,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-82a6a53c-23a0-4e11-a533-fcfb14697a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-b056e5e5-5302-4545-b578-876d03dabdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-08bf6edc-1118-4aed-8303-4e769ce64c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-575eb271-1e55-49cc-8a58-11dda59e952e,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-ae64c349-7995-4c09-9f27-6c32ec6346d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159509577-172.17.0.10-1595935443341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45905,DS-24f6fb01-64c6-4f18-a6f5-4e378b7ee523,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-efad65a1-c2d7-4900-8a75-461536b873db,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-f79c3ada-fb47-45d2-9a4c-d05171074a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-11587652-982c-4972-a706-c89abbaf906e,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-41f772d1-7749-42f2-b22b-4ac631ac1b07,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-cb832c81-780a-4710-b005-25e049c25872,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-ed2b803a-e9d2-415f-91e8-1559043bdcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-56731d9b-7b4f-489a-9bbf-354293d49a47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159509577-172.17.0.10-1595935443341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45905,DS-24f6fb01-64c6-4f18-a6f5-4e378b7ee523,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-efad65a1-c2d7-4900-8a75-461536b873db,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-f79c3ada-fb47-45d2-9a4c-d05171074a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-11587652-982c-4972-a706-c89abbaf906e,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-41f772d1-7749-42f2-b22b-4ac631ac1b07,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-cb832c81-780a-4710-b005-25e049c25872,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-ed2b803a-e9d2-415f-91e8-1559043bdcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-56731d9b-7b4f-489a-9bbf-354293d49a47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971684430-172.17.0.10-1595935645333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33124,DS-7b93f6d2-de25-4921-bcc8-cd0801877b96,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-332af2f9-7796-42a9-a1aa-393e0fba2de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-d552c3df-9bf6-4e00-86a8-3469276b8462,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-dac9bac1-8126-448b-a11f-467698427f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-d5e1eec1-384c-4f35-87b6-5db06ada07a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-ee0c25b5-38cc-4451-96c6-aefc605ae747,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-ac6b957b-e25d-4c34-9886-07bdfa9335a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-bf6a5a16-5f77-4cc8-81fd-58652f0571b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971684430-172.17.0.10-1595935645333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33124,DS-7b93f6d2-de25-4921-bcc8-cd0801877b96,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-332af2f9-7796-42a9-a1aa-393e0fba2de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-d552c3df-9bf6-4e00-86a8-3469276b8462,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-dac9bac1-8126-448b-a11f-467698427f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-d5e1eec1-384c-4f35-87b6-5db06ada07a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-ee0c25b5-38cc-4451-96c6-aefc605ae747,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-ac6b957b-e25d-4c34-9886-07bdfa9335a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-bf6a5a16-5f77-4cc8-81fd-58652f0571b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371069038-172.17.0.10-1595935813492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-675b5ec3-af7f-4fc8-9dac-b005a1aa81e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-1b38e2ad-9712-4763-8693-2f4f606e5748,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-8726d629-2cb6-44d7-bb37-eecb5149c728,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-dcf031ae-a50a-4542-ba82-06f52bf6bd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-7052ab72-ea46-41b8-a902-19014616f062,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-e934efff-a524-4e1d-9d05-7da82b3a2a18,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-ab2d49f6-64bb-45c1-bb2c-fe6fb00c89fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-7a89a54a-df81-44f6-8b3d-7212b00ace2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371069038-172.17.0.10-1595935813492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-675b5ec3-af7f-4fc8-9dac-b005a1aa81e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-1b38e2ad-9712-4763-8693-2f4f606e5748,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-8726d629-2cb6-44d7-bb37-eecb5149c728,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-dcf031ae-a50a-4542-ba82-06f52bf6bd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-7052ab72-ea46-41b8-a902-19014616f062,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-e934efff-a524-4e1d-9d05-7da82b3a2a18,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-ab2d49f6-64bb-45c1-bb2c-fe6fb00c89fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-7a89a54a-df81-44f6-8b3d-7212b00ace2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489951488-172.17.0.10-1595935917860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43361,DS-af22ad0d-1f12-4ad9-bf61-90aa37b43f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-a7bb8693-af18-4228-af37-56fd232aaec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-dd5608e1-e13c-4959-a9b0-ebd27eae12c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-8413e501-3bf8-47b5-aa14-cfdd1cf9eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-d7b85f6c-6dfd-4441-8269-7c69293a772c,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-b5ac781a-5a55-455f-9e82-3e574a897d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-2b54359d-19d0-4939-9df6-019283b73cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-e6d17122-2f0b-4c9a-8584-8200233c3123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489951488-172.17.0.10-1595935917860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43361,DS-af22ad0d-1f12-4ad9-bf61-90aa37b43f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-a7bb8693-af18-4228-af37-56fd232aaec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-dd5608e1-e13c-4959-a9b0-ebd27eae12c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-8413e501-3bf8-47b5-aa14-cfdd1cf9eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-d7b85f6c-6dfd-4441-8269-7c69293a772c,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-b5ac781a-5a55-455f-9e82-3e574a897d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-2b54359d-19d0-4939-9df6-019283b73cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-e6d17122-2f0b-4c9a-8584-8200233c3123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201666227-172.17.0.10-1595936088684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42459,DS-8c8b7b16-528f-4e7f-ae81-e88d6f3cf21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-a314be5f-6eb1-4d1e-baca-03a2fadbce92,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-f71c60d0-420f-43d4-8dde-588c3d37f37a,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-3e89c08f-6b24-4089-b744-e1ca8d01fdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-aceb9afe-ce90-49dc-9aea-e1eb4c103ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-bf201049-22cd-4f85-b48b-096c369b916a,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-8a07a019-46fa-4394-82f5-45b4fbb5c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-ca7c84f0-896d-4ea0-8009-4164210d89f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201666227-172.17.0.10-1595936088684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42459,DS-8c8b7b16-528f-4e7f-ae81-e88d6f3cf21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-a314be5f-6eb1-4d1e-baca-03a2fadbce92,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-f71c60d0-420f-43d4-8dde-588c3d37f37a,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-3e89c08f-6b24-4089-b744-e1ca8d01fdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-aceb9afe-ce90-49dc-9aea-e1eb4c103ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-bf201049-22cd-4f85-b48b-096c369b916a,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-8a07a019-46fa-4394-82f5-45b4fbb5c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-ca7c84f0-896d-4ea0-8009-4164210d89f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84488217-172.17.0.10-1595937104378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-28f84064-f0cc-4fc3-853e-f9b50be5d1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-015aecbc-e7d9-44dd-b0f6-8c663d92c377,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-b1879748-ea26-416d-b14b-05093bf436b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d1d9828a-c53c-474b-af19-1da1ca19f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-9a93cd22-6e9b-4128-87c3-e13dfe7f3959,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-871057f7-90e3-4c4c-b6ec-9478c6452db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-37fa2d27-efe8-431e-8964-d0558e674ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-a00bc100-6239-4500-8001-657633261aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84488217-172.17.0.10-1595937104378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-28f84064-f0cc-4fc3-853e-f9b50be5d1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-015aecbc-e7d9-44dd-b0f6-8c663d92c377,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-b1879748-ea26-416d-b14b-05093bf436b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d1d9828a-c53c-474b-af19-1da1ca19f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-9a93cd22-6e9b-4128-87c3-e13dfe7f3959,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-871057f7-90e3-4c4c-b6ec-9478c6452db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-37fa2d27-efe8-431e-8964-d0558e674ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-a00bc100-6239-4500-8001-657633261aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399958452-172.17.0.10-1595937145921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39198,DS-38093b74-2a33-4f07-8d8f-9edb37d73a95,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-70ce1695-8932-442b-b449-ef1112c9c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-8e48a186-337f-4e61-b7c9-f605e02dec51,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-1d29cdb8-171e-42da-8d45-47f3f367f18d,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-a7947e0d-4ea4-4bb9-8b0c-14530f905261,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-bcd5b559-0e12-4b4d-a1ed-667f9f9d5dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-35d935ee-37e0-4a4b-b1b0-32a4363e19d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-87111e3e-2fa5-4c9d-b59d-84713f9f77b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399958452-172.17.0.10-1595937145921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39198,DS-38093b74-2a33-4f07-8d8f-9edb37d73a95,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-70ce1695-8932-442b-b449-ef1112c9c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-8e48a186-337f-4e61-b7c9-f605e02dec51,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-1d29cdb8-171e-42da-8d45-47f3f367f18d,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-a7947e0d-4ea4-4bb9-8b0c-14530f905261,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-bcd5b559-0e12-4b4d-a1ed-667f9f9d5dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-35d935ee-37e0-4a4b-b1b0-32a4363e19d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-87111e3e-2fa5-4c9d-b59d-84713f9f77b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833117425-172.17.0.10-1595937298920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-01bcf538-66fc-4879-85bd-87746fac1e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-875c99f0-83db-4407-97b8-25a3f2a68dac,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-81f389ab-8456-4d3d-b40a-c8b3274519e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-2ba72ebe-76b7-449d-a020-0ed0c05519f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-bc6fbb3d-dfce-4d2f-92df-853cb8a9c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-85514b3f-d62d-4f30-b7c2-d168bcdad128,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-ff6831ca-c5ea-4809-ae5a-3c6083d256a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-c8992dae-dfe9-440a-b904-7702d8cfff4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833117425-172.17.0.10-1595937298920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-01bcf538-66fc-4879-85bd-87746fac1e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-875c99f0-83db-4407-97b8-25a3f2a68dac,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-81f389ab-8456-4d3d-b40a-c8b3274519e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-2ba72ebe-76b7-449d-a020-0ed0c05519f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-bc6fbb3d-dfce-4d2f-92df-853cb8a9c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-85514b3f-d62d-4f30-b7c2-d168bcdad128,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-ff6831ca-c5ea-4809-ae5a-3c6083d256a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-c8992dae-dfe9-440a-b904-7702d8cfff4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388113331-172.17.0.10-1595938729192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-cae33ab2-c14e-4b7c-ba16-63b7b89c4eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-0f2470c2-4988-4cee-a5e1-eb369d58a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-c62ed42e-9ff9-4a6c-aa53-6ccc8702a75b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-0ad2275f-13bc-4ebe-b265-748ab80b89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-b4fd9b4f-86bb-4fe7-8fad-ed25b5f45d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-b575ed7e-ee5a-4e4d-87df-460e1f0e405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-e6cb48e6-c3a5-428d-bf19-e2f0871ea5db,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-4b309e8d-46e8-48fe-8271-f8a9cce07247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388113331-172.17.0.10-1595938729192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-cae33ab2-c14e-4b7c-ba16-63b7b89c4eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-0f2470c2-4988-4cee-a5e1-eb369d58a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-c62ed42e-9ff9-4a6c-aa53-6ccc8702a75b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-0ad2275f-13bc-4ebe-b265-748ab80b89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-b4fd9b4f-86bb-4fe7-8fad-ed25b5f45d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-b575ed7e-ee5a-4e4d-87df-460e1f0e405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-e6cb48e6-c3a5-428d-bf19-e2f0871ea5db,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-4b309e8d-46e8-48fe-8271-f8a9cce07247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921227175-172.17.0.10-1595938987008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-79fb84dd-b7ff-4dae-b8d0-50c27c418c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-8f7ce63f-037d-4abc-8e67-92690a390bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-fa9e5b3a-ea69-45fc-ab30-94e1b24bf49d,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-8cd20e61-b38f-4ca8-931f-b1bd48530e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-1ae96e73-bd6b-4c00-973c-710e9637f28a,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-8476b7d7-e191-4072-9a22-3c6f37a0fb30,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-acc398ee-f131-45b1-97d1-4799736baacf,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-add2438e-8809-4359-ba33-3f4f61721e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921227175-172.17.0.10-1595938987008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-79fb84dd-b7ff-4dae-b8d0-50c27c418c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-8f7ce63f-037d-4abc-8e67-92690a390bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-fa9e5b3a-ea69-45fc-ab30-94e1b24bf49d,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-8cd20e61-b38f-4ca8-931f-b1bd48530e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-1ae96e73-bd6b-4c00-973c-710e9637f28a,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-8476b7d7-e191-4072-9a22-3c6f37a0fb30,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-acc398ee-f131-45b1-97d1-4799736baacf,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-add2438e-8809-4359-ba33-3f4f61721e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022719667-172.17.0.10-1595939385675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39504,DS-681072c5-848d-4f31-911b-20d097b75a04,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-eb307b75-7694-4d12-8c47-8b351f202fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-2d5b2c0a-c856-4b16-8987-36f4ee3d378e,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-653ae15d-bba8-4293-b0fa-a003296c5230,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-1eed843b-e0cb-4a8d-88a6-0b7bacf008f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-ac5bd662-9b31-4971-ba85-f57e7a50812d,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-53d42cb9-946c-4dc1-aff1-41693e47e1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-263d9979-6056-40fa-bc72-e42076829d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022719667-172.17.0.10-1595939385675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39504,DS-681072c5-848d-4f31-911b-20d097b75a04,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-eb307b75-7694-4d12-8c47-8b351f202fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-2d5b2c0a-c856-4b16-8987-36f4ee3d378e,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-653ae15d-bba8-4293-b0fa-a003296c5230,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-1eed843b-e0cb-4a8d-88a6-0b7bacf008f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-ac5bd662-9b31-4971-ba85-f57e7a50812d,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-53d42cb9-946c-4dc1-aff1-41693e47e1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-263d9979-6056-40fa-bc72-e42076829d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5307
