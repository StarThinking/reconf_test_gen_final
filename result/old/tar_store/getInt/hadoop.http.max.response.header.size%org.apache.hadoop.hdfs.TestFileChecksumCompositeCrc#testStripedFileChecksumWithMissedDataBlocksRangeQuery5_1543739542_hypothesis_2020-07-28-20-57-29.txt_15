reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529925285-172.17.0.16-1595969974419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-2142a974-59f8-42aa-bdba-554be2721059,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-71c13063-5d12-4871-8afe-d58d279b8e58,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-6c880c14-72c7-4c69-96b0-e522c70c44fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-e88733ff-8cc2-4a42-af38-acccfcdc3a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-58522064-2ddc-486b-86fc-9ac47cc18a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-542aab17-2318-4d5c-bb95-5c1abde584d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-cec7f84e-2ebb-451d-89a4-bb57d414bc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-c1721195-ee19-4179-918e-bddd82def24e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529925285-172.17.0.16-1595969974419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-2142a974-59f8-42aa-bdba-554be2721059,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-71c13063-5d12-4871-8afe-d58d279b8e58,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-6c880c14-72c7-4c69-96b0-e522c70c44fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-e88733ff-8cc2-4a42-af38-acccfcdc3a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-58522064-2ddc-486b-86fc-9ac47cc18a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-542aab17-2318-4d5c-bb95-5c1abde584d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-cec7f84e-2ebb-451d-89a4-bb57d414bc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-c1721195-ee19-4179-918e-bddd82def24e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964590083-172.17.0.16-1595970611954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41065,DS-8cc35401-630a-42dc-af24-b1c4b791fdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-80809d86-5c32-48eb-a42b-5e2faf29e02f,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-a3f1cfee-e6a3-49e3-99ae-3d52431c575e,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-23282870-9993-4c27-b88a-c17f7be9ae71,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-de89c198-9c6c-42fb-b36e-6f1c835dbeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-4fa47656-1eb0-4ae4-a438-2312e45cc8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-5cf44618-bde9-4a8b-bd07-ebcf319f46ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-105588fe-e811-4aa2-92b8-4cbe8bdc5fd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964590083-172.17.0.16-1595970611954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41065,DS-8cc35401-630a-42dc-af24-b1c4b791fdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-80809d86-5c32-48eb-a42b-5e2faf29e02f,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-a3f1cfee-e6a3-49e3-99ae-3d52431c575e,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-23282870-9993-4c27-b88a-c17f7be9ae71,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-de89c198-9c6c-42fb-b36e-6f1c835dbeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-4fa47656-1eb0-4ae4-a438-2312e45cc8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-5cf44618-bde9-4a8b-bd07-ebcf319f46ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-105588fe-e811-4aa2-92b8-4cbe8bdc5fd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631421422-172.17.0.16-1595971878255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45632,DS-850f7551-749f-4f1b-899d-5715de49a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-cb2bdad5-52cc-41db-8c24-cccc08702e97,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-35cc2be1-1831-4b84-85b8-0c659e5e76d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-9009a8a6-ed2c-426b-a47c-22faa6c857db,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-4df6c7f1-f794-49e0-ae3f-6fa446946250,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-53ea74e4-a5af-4639-a0ee-370f9afb7377,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-c2023b32-3fa5-4cd2-985d-33f09382c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-0f78a28d-e87f-4227-a986-81de8e1b32e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631421422-172.17.0.16-1595971878255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45632,DS-850f7551-749f-4f1b-899d-5715de49a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-cb2bdad5-52cc-41db-8c24-cccc08702e97,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-35cc2be1-1831-4b84-85b8-0c659e5e76d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-9009a8a6-ed2c-426b-a47c-22faa6c857db,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-4df6c7f1-f794-49e0-ae3f-6fa446946250,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-53ea74e4-a5af-4639-a0ee-370f9afb7377,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-c2023b32-3fa5-4cd2-985d-33f09382c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-0f78a28d-e87f-4227-a986-81de8e1b32e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579875542-172.17.0.16-1595971992930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38059,DS-2ac11acb-32ad-429b-9c6f-b65917779c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-fe056f06-9588-4734-b5fd-848ffb13d201,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-56a899a4-31f8-4f2e-824e-4aa5a8ffe3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-de2f30bb-d1ae-4b47-8421-a65fa3a7ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-1801cd1d-7a69-413a-82f6-9df7ce53cb34,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-771b7615-5435-42e1-92b2-b468e9adad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-26e12d70-085b-4cda-bcb0-2c8b9536e3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-cad787ba-3c8e-4378-846c-0291a51fbb69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579875542-172.17.0.16-1595971992930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38059,DS-2ac11acb-32ad-429b-9c6f-b65917779c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-fe056f06-9588-4734-b5fd-848ffb13d201,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-56a899a4-31f8-4f2e-824e-4aa5a8ffe3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-de2f30bb-d1ae-4b47-8421-a65fa3a7ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-1801cd1d-7a69-413a-82f6-9df7ce53cb34,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-771b7615-5435-42e1-92b2-b468e9adad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-26e12d70-085b-4cda-bcb0-2c8b9536e3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-cad787ba-3c8e-4378-846c-0291a51fbb69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584466573-172.17.0.16-1595972283442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-6dd99cf4-3737-40c1-8ba7-613bbd210ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-a63ab7a7-65d8-4002-8d23-d83086ca3919,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-64bf983c-1ed1-4a8b-b6de-e8991b51ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-b23c5ede-a720-4a1c-a0cd-6bba431d15cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-ddc4765c-958a-4d6b-bd0a-43664bc2a611,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-d5507093-7d70-4187-94fa-a12527de7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-e182b596-d0b1-4388-bc56-7ebd969d0e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-831db667-1091-4246-bb3f-bb71e927aeca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584466573-172.17.0.16-1595972283442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-6dd99cf4-3737-40c1-8ba7-613bbd210ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-a63ab7a7-65d8-4002-8d23-d83086ca3919,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-64bf983c-1ed1-4a8b-b6de-e8991b51ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-b23c5ede-a720-4a1c-a0cd-6bba431d15cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-ddc4765c-958a-4d6b-bd0a-43664bc2a611,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-d5507093-7d70-4187-94fa-a12527de7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-e182b596-d0b1-4388-bc56-7ebd969d0e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-831db667-1091-4246-bb3f-bb71e927aeca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162418916-172.17.0.16-1595972324841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-fde7e13c-9d81-47a9-a942-ca5a3e6e5cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-af4660c7-8ba9-4f3f-b282-adac695d04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-da92c81d-b0d3-46b0-b3a1-804780e84ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-0766f2dc-77b9-4a76-a17c-ecf39c9ff0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-d6f805c7-bec1-4921-b802-6be5d277a05c,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-4c84b429-5aea-495b-a6cc-c8e87481cdee,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-f29b3ca2-f715-48ce-b5b0-d68efe2c637c,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-88e87e23-10ab-48ab-8edb-516f993ddf30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162418916-172.17.0.16-1595972324841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-fde7e13c-9d81-47a9-a942-ca5a3e6e5cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-af4660c7-8ba9-4f3f-b282-adac695d04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-da92c81d-b0d3-46b0-b3a1-804780e84ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-0766f2dc-77b9-4a76-a17c-ecf39c9ff0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-d6f805c7-bec1-4921-b802-6be5d277a05c,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-4c84b429-5aea-495b-a6cc-c8e87481cdee,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-f29b3ca2-f715-48ce-b5b0-d68efe2c637c,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-88e87e23-10ab-48ab-8edb-516f993ddf30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986272552-172.17.0.16-1595972507866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44464,DS-b618afcd-584c-49c1-aa02-d9eacb66ce0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-c486c7e8-88f2-44a8-bb55-306e4616d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-8347be22-b8b3-417f-8ee9-6ed2cda57231,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-efdfe577-6df1-417f-9d7d-198bc0e4c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-42ebe66e-62a4-49f9-8cf1-1309765a1b94,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-edb2132d-03ae-4d07-a20d-6329e0b3038b,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-8cd7e81a-4fa3-48d8-a03d-bf91636e13dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-1f038ad8-d66f-4604-a7ee-838d6679f57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986272552-172.17.0.16-1595972507866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44464,DS-b618afcd-584c-49c1-aa02-d9eacb66ce0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-c486c7e8-88f2-44a8-bb55-306e4616d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-8347be22-b8b3-417f-8ee9-6ed2cda57231,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-efdfe577-6df1-417f-9d7d-198bc0e4c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-42ebe66e-62a4-49f9-8cf1-1309765a1b94,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-edb2132d-03ae-4d07-a20d-6329e0b3038b,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-8cd7e81a-4fa3-48d8-a03d-bf91636e13dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-1f038ad8-d66f-4604-a7ee-838d6679f57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863887269-172.17.0.16-1595972647862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-34c667df-411f-4def-98ce-5d0e37f990d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-f249cf2d-2d5e-4a3b-bcc3-b2545f9a8cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-24e1b625-e4fc-45e0-9379-ee60dfb8d180,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-5b009b0a-05a2-4f55-bc79-e5dd63cb0db0,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-505e7b95-913d-4c35-a7c9-931279e22430,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-5d0d63c9-2b8c-4d6d-80dc-8e16df55c7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-a5cc7071-cbc8-4d25-8fb7-e93ba19e24b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-13805121-b7a3-4d21-b327-f0f912c352ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863887269-172.17.0.16-1595972647862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-34c667df-411f-4def-98ce-5d0e37f990d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-f249cf2d-2d5e-4a3b-bcc3-b2545f9a8cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-24e1b625-e4fc-45e0-9379-ee60dfb8d180,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-5b009b0a-05a2-4f55-bc79-e5dd63cb0db0,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-505e7b95-913d-4c35-a7c9-931279e22430,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-5d0d63c9-2b8c-4d6d-80dc-8e16df55c7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-a5cc7071-cbc8-4d25-8fb7-e93ba19e24b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-13805121-b7a3-4d21-b327-f0f912c352ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870834411-172.17.0.16-1595972724326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-ac27d18e-3b91-41c1-8a2e-7d651acfb5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-ef473a63-ec44-49dd-bc05-5ac2e43a68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-a919c650-0dce-4976-9049-60ababfe3f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-9a0681cc-ac3d-4619-9aae-b559d1891291,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-f01fcf3c-df9f-438d-8977-31377c9dc944,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-a11c6e9c-7705-4226-899d-2c0bde6fd4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-1bbcb205-cf19-4c67-aebe-f14a291c4c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-f38dade0-1d18-4d39-9b9a-8c3914c9e674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870834411-172.17.0.16-1595972724326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-ac27d18e-3b91-41c1-8a2e-7d651acfb5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-ef473a63-ec44-49dd-bc05-5ac2e43a68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-a919c650-0dce-4976-9049-60ababfe3f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-9a0681cc-ac3d-4619-9aae-b559d1891291,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-f01fcf3c-df9f-438d-8977-31377c9dc944,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-a11c6e9c-7705-4226-899d-2c0bde6fd4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-1bbcb205-cf19-4c67-aebe-f14a291c4c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-f38dade0-1d18-4d39-9b9a-8c3914c9e674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819919968-172.17.0.16-1595973654970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37704,DS-86630668-dc11-4a03-b40c-df50f826e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-e82a2291-c504-4c8a-8c31-ebed9c0d91ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-f2c364c2-ee22-47c0-978f-08d86a77f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-3df7ad12-c043-4765-ae50-d0485b373aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-5fa3e4fc-3fd5-4617-80bd-4c04d170d317,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-db0564a8-ba17-48fe-9162-3e1e8f6d16c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-125da687-8522-4052-8bca-3c54d6ec6cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-8217a134-5192-41c5-b304-97830afa7968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819919968-172.17.0.16-1595973654970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37704,DS-86630668-dc11-4a03-b40c-df50f826e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-e82a2291-c504-4c8a-8c31-ebed9c0d91ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-f2c364c2-ee22-47c0-978f-08d86a77f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-3df7ad12-c043-4765-ae50-d0485b373aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-5fa3e4fc-3fd5-4617-80bd-4c04d170d317,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-db0564a8-ba17-48fe-9162-3e1e8f6d16c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-125da687-8522-4052-8bca-3c54d6ec6cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-8217a134-5192-41c5-b304-97830afa7968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366134135-172.17.0.16-1595973834951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-f4acec92-8275-41a0-a460-ccb10c01c44a,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-e176c83c-c147-4d89-9ff6-8b5be41867f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-72b50222-599c-433d-a94f-ddab0760a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-3e1ba5b7-a806-4cb5-8aa7-66ff1591cfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-6b94ba1d-ea1c-41d4-b968-703f98ca4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-46d18382-ea5e-4879-98ab-9f409e0f7a20,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-97e7d7db-ea7d-40d7-a7e2-7dc45c07b494,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-09a4d373-a42e-4a97-a3f9-f5017e0a41e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366134135-172.17.0.16-1595973834951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-f4acec92-8275-41a0-a460-ccb10c01c44a,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-e176c83c-c147-4d89-9ff6-8b5be41867f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-72b50222-599c-433d-a94f-ddab0760a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-3e1ba5b7-a806-4cb5-8aa7-66ff1591cfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-6b94ba1d-ea1c-41d4-b968-703f98ca4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-46d18382-ea5e-4879-98ab-9f409e0f7a20,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-97e7d7db-ea7d-40d7-a7e2-7dc45c07b494,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-09a4d373-a42e-4a97-a3f9-f5017e0a41e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441785325-172.17.0.16-1595973906727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-ff95e07b-ed61-46bc-957b-9228947a9934,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-7e1f3d66-18c3-451c-a643-c5e636ec9af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-e1508f19-b13b-41c4-8b0b-2f9f3ca3c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-ed3d8394-f40f-4813-a46d-9cfa198677b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-200144b9-d26e-4478-9307-4d1de55a0a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-69ed560f-78e7-491f-942a-28e0433affde,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-0b45a0dc-4c8d-410e-9606-101c12f0cb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-aa8e4a12-7c40-4194-8762-1ac3eca45a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441785325-172.17.0.16-1595973906727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-ff95e07b-ed61-46bc-957b-9228947a9934,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-7e1f3d66-18c3-451c-a643-c5e636ec9af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-e1508f19-b13b-41c4-8b0b-2f9f3ca3c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-ed3d8394-f40f-4813-a46d-9cfa198677b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-200144b9-d26e-4478-9307-4d1de55a0a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-69ed560f-78e7-491f-942a-28e0433affde,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-0b45a0dc-4c8d-410e-9606-101c12f0cb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-aa8e4a12-7c40-4194-8762-1ac3eca45a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735791108-172.17.0.16-1595974197352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-c7160075-b087-443b-8ade-7c0452339404,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-7bad94f0-81f1-462d-b40b-9d8d0aef76c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-26d0bbbf-7b19-4308-a978-58eb1dc14d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-062b74d7-df69-4408-93d4-78eb1777fe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-cace4592-ac6a-4024-a5ae-04ea3a4f0f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-3d86e856-3a15-4184-8d6a-0a4ac7fe394e,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-ef485c9a-a213-4f93-b371-21d5bad0ea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-e58c6959-678a-4fe8-a383-718c72428e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735791108-172.17.0.16-1595974197352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-c7160075-b087-443b-8ade-7c0452339404,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-7bad94f0-81f1-462d-b40b-9d8d0aef76c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-26d0bbbf-7b19-4308-a978-58eb1dc14d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-062b74d7-df69-4408-93d4-78eb1777fe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-cace4592-ac6a-4024-a5ae-04ea3a4f0f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-3d86e856-3a15-4184-8d6a-0a4ac7fe394e,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-ef485c9a-a213-4f93-b371-21d5bad0ea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-e58c6959-678a-4fe8-a383-718c72428e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366678886-172.17.0.16-1595974812449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-613c1929-b71f-4281-9dd3-832539429bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-ca38359c-5a59-4626-a7c7-9ae498aa70a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-d192f323-3c9a-4562-aa6a-63457731b423,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-0fd0fe8a-e0a9-481c-8f83-564da1130841,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-9089f2f7-b03c-4c65-ad9b-b6ce87204135,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-316e056f-cc4b-4b85-95c0-24576a2b2299,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-f9c3c000-f999-4d96-98b5-eb647e35456f,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-7289173c-eb83-46ec-97cf-0aa5d6920025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366678886-172.17.0.16-1595974812449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-613c1929-b71f-4281-9dd3-832539429bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-ca38359c-5a59-4626-a7c7-9ae498aa70a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-d192f323-3c9a-4562-aa6a-63457731b423,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-0fd0fe8a-e0a9-481c-8f83-564da1130841,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-9089f2f7-b03c-4c65-ad9b-b6ce87204135,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-316e056f-cc4b-4b85-95c0-24576a2b2299,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-f9c3c000-f999-4d96-98b5-eb647e35456f,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-7289173c-eb83-46ec-97cf-0aa5d6920025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342572149-172.17.0.16-1595974994585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-9b1cc23e-f6bc-4269-8c77-03e7177b8995,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-2b02e2ca-6d70-4c74-a9a6-3f40a440d527,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-bb1a20a9-82db-4662-8651-5c14f4aa7cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-b3d56c03-3236-4db9-b92e-4c717389c50c,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-966f95a6-505e-4eb8-8429-132bd14866f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-6a7a4b88-5fac-4f07-968a-22bd7fdb6f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-4da6c63b-5955-4fce-b4dc-0c6b176f2680,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-c0f6dd80-61fe-42e2-8ead-117e45bf127a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342572149-172.17.0.16-1595974994585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-9b1cc23e-f6bc-4269-8c77-03e7177b8995,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-2b02e2ca-6d70-4c74-a9a6-3f40a440d527,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-bb1a20a9-82db-4662-8651-5c14f4aa7cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-b3d56c03-3236-4db9-b92e-4c717389c50c,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-966f95a6-505e-4eb8-8429-132bd14866f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-6a7a4b88-5fac-4f07-968a-22bd7fdb6f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-4da6c63b-5955-4fce-b4dc-0c6b176f2680,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-c0f6dd80-61fe-42e2-8ead-117e45bf127a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5630
