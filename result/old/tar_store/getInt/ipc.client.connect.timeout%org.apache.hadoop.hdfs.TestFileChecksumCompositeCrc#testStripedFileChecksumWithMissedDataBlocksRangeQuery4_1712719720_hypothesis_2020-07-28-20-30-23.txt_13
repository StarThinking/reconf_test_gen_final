reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188977612-172.17.0.4-1595968586645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37039,DS-32a52f0b-52fe-4d88-a7a3-6eb1b5e65fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-75eaa35e-cd85-49a3-adda-4cf29d672d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-1a331409-4c9c-4edb-9a59-dbb238fc79d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-7b935008-5c46-433f-9611-da66ac79ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-6db7a2fb-1bee-4199-ad27-436c9a968a72,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-8ac9ece8-7e22-4e49-9ee4-eea931b26d45,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-b283e1b1-a238-4fec-bf4e-01f0375dd4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-58e4e3f4-bb70-484d-8666-837c4944ba70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188977612-172.17.0.4-1595968586645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37039,DS-32a52f0b-52fe-4d88-a7a3-6eb1b5e65fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-75eaa35e-cd85-49a3-adda-4cf29d672d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-1a331409-4c9c-4edb-9a59-dbb238fc79d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-7b935008-5c46-433f-9611-da66ac79ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-6db7a2fb-1bee-4199-ad27-436c9a968a72,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-8ac9ece8-7e22-4e49-9ee4-eea931b26d45,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-b283e1b1-a238-4fec-bf4e-01f0375dd4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-58e4e3f4-bb70-484d-8666-837c4944ba70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722059409-172.17.0.4-1595969109735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45395,DS-4af25073-8d1f-4fab-8737-8d658ec60f84,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-c34de0ba-c7e7-4c9a-aa01-fde57dcfef69,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-b6d09a70-2833-494a-9d56-154dc3975624,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-4c99ab9f-9060-4860-b188-cd1fbe42e602,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-d54ffa43-fd9f-4270-8f4f-2dac308ff349,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-be773fa0-5f61-476e-a13d-ae18f9c85eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-be6aa82f-9239-4618-ac61-d9f72e28655c,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-bc606827-f6ed-42aa-aa0a-dd394a0a7a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722059409-172.17.0.4-1595969109735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45395,DS-4af25073-8d1f-4fab-8737-8d658ec60f84,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-c34de0ba-c7e7-4c9a-aa01-fde57dcfef69,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-b6d09a70-2833-494a-9d56-154dc3975624,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-4c99ab9f-9060-4860-b188-cd1fbe42e602,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-d54ffa43-fd9f-4270-8f4f-2dac308ff349,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-be773fa0-5f61-476e-a13d-ae18f9c85eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-be6aa82f-9239-4618-ac61-d9f72e28655c,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-bc606827-f6ed-42aa-aa0a-dd394a0a7a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758380936-172.17.0.4-1595969700705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-bab8a787-4a3e-4743-8711-c8d503923a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-888b2874-6c6c-4bb9-a382-65841254898f,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-c69d540f-9c40-4c52-b6e4-39f41e0b6688,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-f274f667-17a5-483d-9408-fc85941dca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-20167c54-bc31-4926-962e-913221df5b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-c5c7f198-6d66-429f-80a3-aca827fbd263,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-f1710a08-3383-4a9d-a057-3c40f0312372,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-488d6f1d-f4a8-47c1-9372-32eb67a4185d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758380936-172.17.0.4-1595969700705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-bab8a787-4a3e-4743-8711-c8d503923a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-888b2874-6c6c-4bb9-a382-65841254898f,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-c69d540f-9c40-4c52-b6e4-39f41e0b6688,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-f274f667-17a5-483d-9408-fc85941dca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-20167c54-bc31-4926-962e-913221df5b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-c5c7f198-6d66-429f-80a3-aca827fbd263,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-f1710a08-3383-4a9d-a057-3c40f0312372,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-488d6f1d-f4a8-47c1-9372-32eb67a4185d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560898383-172.17.0.4-1595969766547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33850,DS-eebfff0d-219a-4df8-80a3-2a63cb81dca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-b75255e9-c033-41ba-b1d4-f953d8a1b5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-e19b1c1f-6616-48c7-b0dc-e71cfec42429,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-b14d3fea-a75a-4338-a711-158f5c9c1911,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cf7d13b0-076d-44e3-b63c-c0cc1f785e89,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-ca67e52d-4b8e-462e-a327-07cebdd10dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-829578fc-6d69-49f1-97e2-1bd316bd4fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-357333e9-dbbe-454d-ad14-aaec67f6f167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560898383-172.17.0.4-1595969766547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33850,DS-eebfff0d-219a-4df8-80a3-2a63cb81dca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-b75255e9-c033-41ba-b1d4-f953d8a1b5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-e19b1c1f-6616-48c7-b0dc-e71cfec42429,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-b14d3fea-a75a-4338-a711-158f5c9c1911,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cf7d13b0-076d-44e3-b63c-c0cc1f785e89,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-ca67e52d-4b8e-462e-a327-07cebdd10dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-829578fc-6d69-49f1-97e2-1bd316bd4fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-357333e9-dbbe-454d-ad14-aaec67f6f167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331017780-172.17.0.4-1595969879320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-f52e6940-d4c2-4b70-9f97-68bdf25edf35,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-c495e734-4987-4318-a83a-9a721cde3ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-3e65ac26-7afe-4687-9b5d-c136c53836f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-247eaf0a-b5de-465d-be84-bda16494012e,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-b7c6043e-6e44-440f-8af4-c02939b80d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-e28b1c7e-d1e8-40f2-9d2b-1741689a9091,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-e8e66491-253a-435e-a201-0a384e91941a,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-bd06a273-3c77-4eae-93d6-03e5ed75549b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331017780-172.17.0.4-1595969879320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-f52e6940-d4c2-4b70-9f97-68bdf25edf35,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-c495e734-4987-4318-a83a-9a721cde3ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-3e65ac26-7afe-4687-9b5d-c136c53836f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-247eaf0a-b5de-465d-be84-bda16494012e,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-b7c6043e-6e44-440f-8af4-c02939b80d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-e28b1c7e-d1e8-40f2-9d2b-1741689a9091,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-e8e66491-253a-435e-a201-0a384e91941a,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-bd06a273-3c77-4eae-93d6-03e5ed75549b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700350613-172.17.0.4-1595970243277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-9941c70d-3bd4-4106-aa2a-1909b5f69d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-d4ed1e26-8a4e-4bd9-aef7-4782ed5a5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-b5b7c626-2dd9-44ce-8e7b-3c1a2f22042a,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-32d4868a-84d9-41e1-abca-d7e4bb38cb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-5e8d2039-bc1e-4f80-98dd-0e1718ffdc15,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-7ab307c4-f98a-4b3e-b674-a2fafc5bae38,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-bcdf988f-0ab5-45c2-8446-908a72a54aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-def4aaf3-cbfb-49b3-9dc5-9bcd09b8f116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700350613-172.17.0.4-1595970243277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-9941c70d-3bd4-4106-aa2a-1909b5f69d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-d4ed1e26-8a4e-4bd9-aef7-4782ed5a5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-b5b7c626-2dd9-44ce-8e7b-3c1a2f22042a,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-32d4868a-84d9-41e1-abca-d7e4bb38cb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-5e8d2039-bc1e-4f80-98dd-0e1718ffdc15,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-7ab307c4-f98a-4b3e-b674-a2fafc5bae38,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-bcdf988f-0ab5-45c2-8446-908a72a54aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-def4aaf3-cbfb-49b3-9dc5-9bcd09b8f116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930326335-172.17.0.4-1595970277501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-0a1e3659-fa24-45f9-9bcb-44d072726ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-1907f180-e168-4c69-a36e-9a38474983e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-ad96ffd7-c579-46bb-8d15-118c3eede421,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-940c542e-f211-4c45-922c-839d9b3b78ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-c48778cf-ca06-4b25-97da-734ca3863287,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-f1589005-868b-4b2c-b087-5ef8ca87caf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-5fb40db0-fef4-4382-857d-211d4744c06d,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-4ad7c87a-9d96-4d68-b010-1d28e743cffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930326335-172.17.0.4-1595970277501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-0a1e3659-fa24-45f9-9bcb-44d072726ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-1907f180-e168-4c69-a36e-9a38474983e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-ad96ffd7-c579-46bb-8d15-118c3eede421,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-940c542e-f211-4c45-922c-839d9b3b78ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-c48778cf-ca06-4b25-97da-734ca3863287,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-f1589005-868b-4b2c-b087-5ef8ca87caf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-5fb40db0-fef4-4382-857d-211d4744c06d,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-4ad7c87a-9d96-4d68-b010-1d28e743cffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669144711-172.17.0.4-1595970626225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-047f043f-4c96-4539-b278-ec61f5f8787f,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-ef1af032-17ff-4f42-a849-5ace121a2c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-bbf28a1a-9214-4897-834a-0339ff9b2dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-70e9a100-1a4f-405e-8f55-ad517070570a,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-977fca1e-e8ee-401f-b0df-a463c5ba3071,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-f1c00e02-9893-465e-99ff-60fb4a954008,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-44e2ecbe-f119-4dbc-ae15-538c3a27325d,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-965eb7aa-425a-49f1-b4f5-e0459c3ca0c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669144711-172.17.0.4-1595970626225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-047f043f-4c96-4539-b278-ec61f5f8787f,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-ef1af032-17ff-4f42-a849-5ace121a2c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-bbf28a1a-9214-4897-834a-0339ff9b2dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-70e9a100-1a4f-405e-8f55-ad517070570a,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-977fca1e-e8ee-401f-b0df-a463c5ba3071,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-f1c00e02-9893-465e-99ff-60fb4a954008,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-44e2ecbe-f119-4dbc-ae15-538c3a27325d,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-965eb7aa-425a-49f1-b4f5-e0459c3ca0c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72444985-172.17.0.4-1595970812571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-43060aa9-ea26-4f49-a80a-2d3d31bcc37b,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-b1daee02-5fd9-4cc1-9f1a-ec416d334ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-e27629cc-ea90-4949-b421-d28e869aaeba,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-ac410f8c-38b5-478c-957c-c9b1df725b98,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-95227ef8-5c75-4ce5-a24b-f462fc6ffb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-aff8e95b-6076-44ae-a5a8-7142a9a93a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-43b51594-d7df-460c-a23e-dae2bcd2c0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-b2a16978-72fc-408a-99a4-136ac6d1f68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72444985-172.17.0.4-1595970812571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-43060aa9-ea26-4f49-a80a-2d3d31bcc37b,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-b1daee02-5fd9-4cc1-9f1a-ec416d334ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-e27629cc-ea90-4949-b421-d28e869aaeba,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-ac410f8c-38b5-478c-957c-c9b1df725b98,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-95227ef8-5c75-4ce5-a24b-f462fc6ffb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-aff8e95b-6076-44ae-a5a8-7142a9a93a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-43b51594-d7df-460c-a23e-dae2bcd2c0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-b2a16978-72fc-408a-99a4-136ac6d1f68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836415796-172.17.0.4-1595971115807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42712,DS-7af2a47d-34c8-4cdf-93e3-1cbce8cd994b,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-6b7408ac-4aa8-4140-911b-2b746ad576ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-42af762d-0cd1-4706-955f-df9b376ed9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-3dc37fe8-f07e-406a-baf0-8953c86639d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-98ec3c89-1729-4745-91a6-bd9aae159606,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-38864a84-6799-43d1-8ca2-2958d4ca66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-3046fb5c-8b88-437d-a815-14c5fd16dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-0af4169d-027c-4f04-8d51-5ca435497d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836415796-172.17.0.4-1595971115807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42712,DS-7af2a47d-34c8-4cdf-93e3-1cbce8cd994b,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-6b7408ac-4aa8-4140-911b-2b746ad576ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-42af762d-0cd1-4706-955f-df9b376ed9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-3dc37fe8-f07e-406a-baf0-8953c86639d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-98ec3c89-1729-4745-91a6-bd9aae159606,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-38864a84-6799-43d1-8ca2-2958d4ca66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-3046fb5c-8b88-437d-a815-14c5fd16dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-0af4169d-027c-4f04-8d51-5ca435497d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788542545-172.17.0.4-1595971219243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41160,DS-2a816ab1-31fa-490a-a400-2c1e57d0079a,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-a00e6cbc-c6e7-4a0d-b49e-eb4f89297c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-ea65e25a-3105-496d-8b02-920aa7d7654f,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-771fe9f6-123c-4342-bb44-9ee13a96d5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-8aa8739f-d1ea-4bc7-895e-90aab8515e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-dda85a15-d053-45eb-8b7c-6c54f406676e,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-dce05a34-74ce-4d10-a299-1c86d0a2f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-a7db49b6-4fcc-4be5-ab53-819c52ba0b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788542545-172.17.0.4-1595971219243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41160,DS-2a816ab1-31fa-490a-a400-2c1e57d0079a,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-a00e6cbc-c6e7-4a0d-b49e-eb4f89297c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-ea65e25a-3105-496d-8b02-920aa7d7654f,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-771fe9f6-123c-4342-bb44-9ee13a96d5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-8aa8739f-d1ea-4bc7-895e-90aab8515e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-dda85a15-d053-45eb-8b7c-6c54f406676e,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-dce05a34-74ce-4d10-a299-1c86d0a2f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-a7db49b6-4fcc-4be5-ab53-819c52ba0b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136142495-172.17.0.4-1595971376588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40666,DS-12ce77aa-e9c6-4baa-b401-a71888f25184,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-ad42e581-12f7-4eb0-b089-39cd4e6593fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-0c24d966-a126-4eaf-81e3-14db9dcaa0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-c1506a5f-6042-439c-9f56-cc9afba0d343,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-4ac21ba6-9a8f-4315-9e77-1fbd61619fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-ca9c48ef-015d-4e07-b5c8-bdedb16dd0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-132dfafe-58ad-44ba-9cc2-6e41aee5d80a,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-08d9c846-f609-413d-a156-27ef60fd81cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136142495-172.17.0.4-1595971376588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40666,DS-12ce77aa-e9c6-4baa-b401-a71888f25184,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-ad42e581-12f7-4eb0-b089-39cd4e6593fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-0c24d966-a126-4eaf-81e3-14db9dcaa0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-c1506a5f-6042-439c-9f56-cc9afba0d343,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-4ac21ba6-9a8f-4315-9e77-1fbd61619fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-ca9c48ef-015d-4e07-b5c8-bdedb16dd0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-132dfafe-58ad-44ba-9cc2-6e41aee5d80a,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-08d9c846-f609-413d-a156-27ef60fd81cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531060171-172.17.0.4-1595971537616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-ef667c1d-8360-4efd-b475-089bee5d7555,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-51133800-ae3f-4e38-abfd-d0120292f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-7fed065f-c50a-48ea-b719-a83d633816ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-306d2ced-62f0-4090-8b1b-c87baccee453,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-2655255f-1f60-4885-ac96-e551510affe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-9ba7eb88-f104-4e66-a7a4-d3e1fb39dec3,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-2ed756b1-8232-439e-8fe9-b04ed5b9c411,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-ab7b57eb-347d-4452-afd8-9dd6e1a96eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531060171-172.17.0.4-1595971537616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-ef667c1d-8360-4efd-b475-089bee5d7555,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-51133800-ae3f-4e38-abfd-d0120292f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-7fed065f-c50a-48ea-b719-a83d633816ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-306d2ced-62f0-4090-8b1b-c87baccee453,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-2655255f-1f60-4885-ac96-e551510affe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-9ba7eb88-f104-4e66-a7a4-d3e1fb39dec3,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-2ed756b1-8232-439e-8fe9-b04ed5b9c411,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-ab7b57eb-347d-4452-afd8-9dd6e1a96eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525752363-172.17.0.4-1595972855149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-4f3075df-4599-467f-b3fe-8fa3210e492c,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-2261c6ca-c384-4479-9c2f-66b329366b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-1ff46c3d-0489-449b-aa6c-86ace03cc944,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-ab051cb2-ebee-4edd-8cd4-6b2e5fabebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-de0fed9b-0dff-4abf-b7f7-94a5ff1cda10,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-eea31f23-0517-4b00-ac9f-d7d47e74f914,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-f80171eb-b726-491c-b2ca-65f4c4d1a8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-a98ed9c0-cf36-4325-9e2d-cfad283e08dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525752363-172.17.0.4-1595972855149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-4f3075df-4599-467f-b3fe-8fa3210e492c,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-2261c6ca-c384-4479-9c2f-66b329366b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-1ff46c3d-0489-449b-aa6c-86ace03cc944,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-ab051cb2-ebee-4edd-8cd4-6b2e5fabebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-de0fed9b-0dff-4abf-b7f7-94a5ff1cda10,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-eea31f23-0517-4b00-ac9f-d7d47e74f914,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-f80171eb-b726-491c-b2ca-65f4c4d1a8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-a98ed9c0-cf36-4325-9e2d-cfad283e08dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394834782-172.17.0.4-1595972974472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-e91351a4-1761-488e-8fc2-dfc78a234e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-4536ac34-5844-47f3-8226-014fe13685ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-0f6629fd-881b-4775-a748-080812d4a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-2bafd153-7df6-4a64-9008-cfd3e76d469e,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-1ac869e5-4ac1-49e4-8726-0cee3035d7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-631a4947-9ba6-4b1a-86cb-0aa6f1bbf025,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-ccd9e34e-446d-4953-805f-a3e52d8280b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-8ecf8467-7e41-464a-b790-ed1cd6196527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394834782-172.17.0.4-1595972974472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-e91351a4-1761-488e-8fc2-dfc78a234e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-4536ac34-5844-47f3-8226-014fe13685ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-0f6629fd-881b-4775-a748-080812d4a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-2bafd153-7df6-4a64-9008-cfd3e76d469e,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-1ac869e5-4ac1-49e4-8726-0cee3035d7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-631a4947-9ba6-4b1a-86cb-0aa6f1bbf025,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-ccd9e34e-446d-4953-805f-a3e52d8280b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-8ecf8467-7e41-464a-b790-ed1cd6196527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788182841-172.17.0.4-1595973087165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-7aeeeeaa-f613-4f07-ac35-bae6ddf5992d,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-14db0e65-85e2-48ab-82f3-1a7f79851c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-c15bd86a-255e-4c7e-bc74-289cd2222aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-6db4b131-8dd0-4278-b2b5-5162c67331f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-b1ba3f1a-21a2-476e-9273-41ea662a59ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-10cccf8c-add8-431e-b1e1-413310004be4,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-529a9002-f431-438c-9359-1799fd3615c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-e0218948-043c-46e0-aad7-6a52c22b338e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788182841-172.17.0.4-1595973087165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-7aeeeeaa-f613-4f07-ac35-bae6ddf5992d,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-14db0e65-85e2-48ab-82f3-1a7f79851c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-c15bd86a-255e-4c7e-bc74-289cd2222aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-6db4b131-8dd0-4278-b2b5-5162c67331f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-b1ba3f1a-21a2-476e-9273-41ea662a59ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-10cccf8c-add8-431e-b1e1-413310004be4,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-529a9002-f431-438c-9359-1799fd3615c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-e0218948-043c-46e0-aad7-6a52c22b338e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026981603-172.17.0.4-1595973119360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-af218eee-bb23-47b8-8c14-9758abf2975c,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-1a798119-5d3a-493a-82ce-57eb08d5029d,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-8946a3cb-4169-442d-bb9d-6b9b18602515,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-bb6c3978-3075-4513-89a4-077bba1250f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-ce7c20c6-10b4-4470-aeef-2f04e58c69b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-b77608b6-2067-4515-8e34-78be614349d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-df9559fe-8d0e-4bcf-8a5f-f134658dacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-4f5636de-f929-4fcc-a55c-b16142413be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026981603-172.17.0.4-1595973119360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-af218eee-bb23-47b8-8c14-9758abf2975c,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-1a798119-5d3a-493a-82ce-57eb08d5029d,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-8946a3cb-4169-442d-bb9d-6b9b18602515,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-bb6c3978-3075-4513-89a4-077bba1250f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-ce7c20c6-10b4-4470-aeef-2f04e58c69b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-b77608b6-2067-4515-8e34-78be614349d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-df9559fe-8d0e-4bcf-8a5f-f134658dacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-4f5636de-f929-4fcc-a55c-b16142413be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235863286-172.17.0.4-1595973151839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-ace6c02e-04e0-4d46-8d39-ce8f83da9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-16d1d82b-e362-4967-8c00-306703fc5173,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-32406d4c-ea20-4f69-ba31-d030e98e9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-d2a52525-dc20-47ff-9807-be8f26b41340,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-e29c3e8e-736e-4c7b-b834-9bea6fcc7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-2544576d-f47a-4a17-ab88-13a1710ff070,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-458f75de-d21a-492f-b912-38199c02325c,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-ff51ad4f-be79-4be8-a982-159d2ab65625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235863286-172.17.0.4-1595973151839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-ace6c02e-04e0-4d46-8d39-ce8f83da9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-16d1d82b-e362-4967-8c00-306703fc5173,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-32406d4c-ea20-4f69-ba31-d030e98e9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-d2a52525-dc20-47ff-9807-be8f26b41340,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-e29c3e8e-736e-4c7b-b834-9bea6fcc7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-2544576d-f47a-4a17-ab88-13a1710ff070,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-458f75de-d21a-492f-b912-38199c02325c,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-ff51ad4f-be79-4be8-a982-159d2ab65625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 2000000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008575062-172.17.0.4-1595973261684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43328,DS-30a6278b-3ede-4835-95c9-fd5279d6889b,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-241040e4-cc56-4027-a109-10f7ef3ec46b,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-ebd51578-ea35-40f1-9288-59ae444c8996,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-90d79eff-6434-435d-bba6-34fc20644e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-011861e8-fef5-4290-a698-38900ad934c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-0fafa4bf-8f32-43a1-aad6-420e706f1eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-093234ac-c874-4bc4-9d49-c42173ebe551,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-e04d8589-bf8a-4359-a5cb-0e670218c4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008575062-172.17.0.4-1595973261684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43328,DS-30a6278b-3ede-4835-95c9-fd5279d6889b,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-241040e4-cc56-4027-a109-10f7ef3ec46b,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-ebd51578-ea35-40f1-9288-59ae444c8996,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-90d79eff-6434-435d-bba6-34fc20644e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-011861e8-fef5-4290-a698-38900ad934c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-0fafa4bf-8f32-43a1-aad6-420e706f1eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-093234ac-c874-4bc4-9d49-c42173ebe551,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-e04d8589-bf8a-4359-a5cb-0e670218c4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5270
