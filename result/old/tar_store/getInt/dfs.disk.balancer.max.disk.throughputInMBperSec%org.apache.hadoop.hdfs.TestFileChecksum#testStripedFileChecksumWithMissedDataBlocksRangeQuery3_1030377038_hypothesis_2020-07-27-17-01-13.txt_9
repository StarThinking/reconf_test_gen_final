reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95813065-172.17.0.12-1595870077654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-fc810746-b3fa-4391-9715-b084a6783598,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-d4609ef7-3d9a-45ba-8533-ae9912efc8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-3e70d0e5-5338-499f-9209-9523f93ceb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-8635108f-5d72-440f-b804-dab5d5ba782c,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-464c1fe1-c84d-4a07-8d13-b327cf1c5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-5de46655-8960-4c54-86b1-aab0a110875b,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-4ddb97bf-b0af-44c2-82e8-ad2ef26019cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-dcb5408a-bd66-4a61-b05d-118fdcedbf9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95813065-172.17.0.12-1595870077654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-fc810746-b3fa-4391-9715-b084a6783598,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-d4609ef7-3d9a-45ba-8533-ae9912efc8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-3e70d0e5-5338-499f-9209-9523f93ceb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-8635108f-5d72-440f-b804-dab5d5ba782c,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-464c1fe1-c84d-4a07-8d13-b327cf1c5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-5de46655-8960-4c54-86b1-aab0a110875b,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-4ddb97bf-b0af-44c2-82e8-ad2ef26019cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-dcb5408a-bd66-4a61-b05d-118fdcedbf9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528503814-172.17.0.12-1595870236440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-ede5dd23-e11b-4d31-b41b-dd46b21b4910,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-8ac844e5-e516-48f6-a5f4-f0eced20263f,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-199e808e-504b-439e-b3e5-ce9cc55c606d,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-cc98753d-b9d3-4f81-ac5f-9403f3cc9006,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-98dfae9c-cca0-4814-a15e-fca2469b9fea,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-681a0fea-e445-4a8a-8908-f23b764d560c,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-4c296a1d-d562-44bc-aeb1-176b5775f447,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-f6dc7def-d188-4882-977b-8545cb63013f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528503814-172.17.0.12-1595870236440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-ede5dd23-e11b-4d31-b41b-dd46b21b4910,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-8ac844e5-e516-48f6-a5f4-f0eced20263f,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-199e808e-504b-439e-b3e5-ce9cc55c606d,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-cc98753d-b9d3-4f81-ac5f-9403f3cc9006,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-98dfae9c-cca0-4814-a15e-fca2469b9fea,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-681a0fea-e445-4a8a-8908-f23b764d560c,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-4c296a1d-d562-44bc-aeb1-176b5775f447,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-f6dc7def-d188-4882-977b-8545cb63013f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073491811-172.17.0.12-1595870489180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41872,DS-9c21b189-6193-4d01-8879-ec3b3e8d6264,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-b3bca740-d65f-42e1-a1d0-d015af05ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-821bba43-4ca2-479c-b7bd-2cab7a31092d,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-e3d0534d-249c-4bcf-b3ed-9b473af89bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-fc2e97ba-ae39-4e1f-b9aa-304ed63d380c,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-4228f70a-498c-4c48-9af7-f1ebfeba486e,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-77369916-10ed-4841-bc26-cefe556c9283,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-719c90c0-8e80-4a4f-bab4-ed592f5458d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073491811-172.17.0.12-1595870489180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41872,DS-9c21b189-6193-4d01-8879-ec3b3e8d6264,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-b3bca740-d65f-42e1-a1d0-d015af05ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-821bba43-4ca2-479c-b7bd-2cab7a31092d,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-e3d0534d-249c-4bcf-b3ed-9b473af89bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-fc2e97ba-ae39-4e1f-b9aa-304ed63d380c,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-4228f70a-498c-4c48-9af7-f1ebfeba486e,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-77369916-10ed-4841-bc26-cefe556c9283,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-719c90c0-8e80-4a4f-bab4-ed592f5458d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29515879-172.17.0.12-1595870652634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-ec7ec143-31bb-4185-84c1-9fba352e2d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-5a6ff4ef-de40-42dd-a3b0-9718b41c7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-57c359ce-9470-48b8-ad7d-ec97eeb67d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-66136bf6-5908-41b7-89e8-9da31ab01ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-14639ec0-4a06-41d9-9034-e882032e16a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-b95100e1-810c-4f56-8b9e-78a20837b4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-1812654c-111a-46a4-be54-2da5231cb860,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-c14cecb5-9bb0-4b49-a182-588bed056ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29515879-172.17.0.12-1595870652634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-ec7ec143-31bb-4185-84c1-9fba352e2d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-5a6ff4ef-de40-42dd-a3b0-9718b41c7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-57c359ce-9470-48b8-ad7d-ec97eeb67d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-66136bf6-5908-41b7-89e8-9da31ab01ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-14639ec0-4a06-41d9-9034-e882032e16a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-b95100e1-810c-4f56-8b9e-78a20837b4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-1812654c-111a-46a4-be54-2da5231cb860,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-c14cecb5-9bb0-4b49-a182-588bed056ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392723123-172.17.0.12-1595870928976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40893,DS-b0194821-fc5c-4cce-91ee-8993c17b90d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-370eeb39-6702-4193-b5a6-ae601cdebaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-c023eaeb-597c-4b96-8142-0864b2cb9c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-e4c11ccb-83ee-4a43-a857-b3c8ceb54595,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-806480bc-70a9-46dc-9a6e-733a43511e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-cd729b4f-1dba-4a56-a351-362f08134546,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-00e56b4c-d0a3-4883-af6e-7da2f32e22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-d3abc027-1d74-4a37-85ea-59de38506d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392723123-172.17.0.12-1595870928976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40893,DS-b0194821-fc5c-4cce-91ee-8993c17b90d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-370eeb39-6702-4193-b5a6-ae601cdebaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-c023eaeb-597c-4b96-8142-0864b2cb9c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-e4c11ccb-83ee-4a43-a857-b3c8ceb54595,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-806480bc-70a9-46dc-9a6e-733a43511e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-cd729b4f-1dba-4a56-a351-362f08134546,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-00e56b4c-d0a3-4883-af6e-7da2f32e22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-d3abc027-1d74-4a37-85ea-59de38506d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495975705-172.17.0.12-1595871120267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-4024336e-494c-4c6b-bf8d-93c01a84fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-8548a9b1-0c16-4b39-8b9d-4c5036dd0903,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-98a40a83-9c4f-42a2-94ee-d182da88433c,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-de629d0a-7392-4b77-bffb-adc61efeeaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-6947443c-de1d-4a05-816c-18bdaaae5603,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-500fd2ee-65dd-4e87-8c52-f3530d939b75,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-4550f7c6-7e9f-48da-80ad-2c0c9527146e,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-a00ea588-436b-46a2-ba51-545c8db479b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495975705-172.17.0.12-1595871120267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-4024336e-494c-4c6b-bf8d-93c01a84fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-8548a9b1-0c16-4b39-8b9d-4c5036dd0903,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-98a40a83-9c4f-42a2-94ee-d182da88433c,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-de629d0a-7392-4b77-bffb-adc61efeeaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-6947443c-de1d-4a05-816c-18bdaaae5603,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-500fd2ee-65dd-4e87-8c52-f3530d939b75,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-4550f7c6-7e9f-48da-80ad-2c0c9527146e,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-a00ea588-436b-46a2-ba51-545c8db479b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441412870-172.17.0.12-1595871299439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46867,DS-e0d44aa0-3e4e-4c6d-92c4-d75b78f5c363,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-299aba58-09f5-45cc-a469-4636388b91a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-4711d127-eb2b-4cf6-b9a1-03be01eb78cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-0e30c3c4-a9a3-415c-906a-063fa6b085cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-9acdfb17-90db-4521-a139-e1257a7038d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-ffbd07e0-3285-40ff-beb6-8cb3169e701d,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-afa33e58-e0f0-4ea0-b7bf-7ee54ee88b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-2f4f6be7-541a-411f-acc0-87ef3e46522c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441412870-172.17.0.12-1595871299439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46867,DS-e0d44aa0-3e4e-4c6d-92c4-d75b78f5c363,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-299aba58-09f5-45cc-a469-4636388b91a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-4711d127-eb2b-4cf6-b9a1-03be01eb78cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-0e30c3c4-a9a3-415c-906a-063fa6b085cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-9acdfb17-90db-4521-a139-e1257a7038d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-ffbd07e0-3285-40ff-beb6-8cb3169e701d,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-afa33e58-e0f0-4ea0-b7bf-7ee54ee88b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-2f4f6be7-541a-411f-acc0-87ef3e46522c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020196827-172.17.0.12-1595872069024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42025,DS-6f0e6c62-8d00-4b40-a5a4-3bda2aac5291,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-cea83164-c1c2-463b-a931-1d225fcea9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-74afb412-374c-408d-aed1-2bb39f68a03e,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-73de3f5e-2268-4899-ad40-2d2d009833c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-913f1af4-4ecf-41df-9d61-dbe699a9e2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-2d184748-3a73-46e7-b381-f412a449b20b,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-b39fb855-0f3e-427a-bd44-41a46d51b125,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-3cabb12b-089a-40cb-9f33-ef384d471977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020196827-172.17.0.12-1595872069024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42025,DS-6f0e6c62-8d00-4b40-a5a4-3bda2aac5291,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-cea83164-c1c2-463b-a931-1d225fcea9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-74afb412-374c-408d-aed1-2bb39f68a03e,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-73de3f5e-2268-4899-ad40-2d2d009833c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-913f1af4-4ecf-41df-9d61-dbe699a9e2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-2d184748-3a73-46e7-b381-f412a449b20b,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-b39fb855-0f3e-427a-bd44-41a46d51b125,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-3cabb12b-089a-40cb-9f33-ef384d471977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894167623-172.17.0.12-1595872111392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36429,DS-71074c32-57bb-4b60-a293-11f9a6a2791d,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-a78be9fd-e1e2-47aa-96d9-96b118110806,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-c3cb6c54-68df-4deb-9900-dbc82fb9ea18,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-d7afe0bb-d321-441c-83e7-5e8bf8e26b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-ec940f09-d941-454a-9456-f4d14aab5d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-e6d4b27b-ac1b-44b5-9278-4dbfb7f4936c,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-292094d3-8ed1-4f0d-9647-27766f55d7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-71d0d02e-fe32-4403-897f-ef9b0b4b0090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894167623-172.17.0.12-1595872111392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36429,DS-71074c32-57bb-4b60-a293-11f9a6a2791d,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-a78be9fd-e1e2-47aa-96d9-96b118110806,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-c3cb6c54-68df-4deb-9900-dbc82fb9ea18,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-d7afe0bb-d321-441c-83e7-5e8bf8e26b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-ec940f09-d941-454a-9456-f4d14aab5d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-e6d4b27b-ac1b-44b5-9278-4dbfb7f4936c,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-292094d3-8ed1-4f0d-9647-27766f55d7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-71d0d02e-fe32-4403-897f-ef9b0b4b0090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075159993-172.17.0.12-1595872675524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43490,DS-cde04bbb-93fc-47cd-a70f-e6c5ede0a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-1054ff64-85e6-40bc-af22-1d3e65d0f276,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-4c9012c3-752b-485c-93de-19f3a4337f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-e2c89861-be2f-4360-84e3-6220489af4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-a76a5f4f-1a8c-4fd1-943c-e6a1c58e71ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-b2689977-0c1a-4169-9c92-c1ac3c50b84b,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-67eac0b7-7df7-4c92-93b6-7cc413a616b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-0569e6e1-a901-4924-a781-f2a0d363562b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075159993-172.17.0.12-1595872675524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43490,DS-cde04bbb-93fc-47cd-a70f-e6c5ede0a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-1054ff64-85e6-40bc-af22-1d3e65d0f276,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-4c9012c3-752b-485c-93de-19f3a4337f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-e2c89861-be2f-4360-84e3-6220489af4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-a76a5f4f-1a8c-4fd1-943c-e6a1c58e71ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-b2689977-0c1a-4169-9c92-c1ac3c50b84b,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-67eac0b7-7df7-4c92-93b6-7cc413a616b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-0569e6e1-a901-4924-a781-f2a0d363562b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952993803-172.17.0.12-1595872854185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44560,DS-14d896ec-9346-4801-8e5d-3c8d6ee4a315,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-c7f74e39-aef6-460e-8c03-080d83b21bef,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-3d87701c-b185-4c1c-8566-e9683a620eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-b89f1a17-285e-4f6e-8b4e-4cef18829ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-da449ffd-3274-401a-b6d4-c4143d40c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-78f85a73-6408-45c8-9e3b-3610d707efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-e885abb8-d11d-4ed3-ada9-a841ae9c247b,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-722bbdca-e72b-419f-8b57-faeff8b4a71b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952993803-172.17.0.12-1595872854185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44560,DS-14d896ec-9346-4801-8e5d-3c8d6ee4a315,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-c7f74e39-aef6-460e-8c03-080d83b21bef,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-3d87701c-b185-4c1c-8566-e9683a620eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-b89f1a17-285e-4f6e-8b4e-4cef18829ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-da449ffd-3274-401a-b6d4-c4143d40c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-78f85a73-6408-45c8-9e3b-3610d707efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-e885abb8-d11d-4ed3-ada9-a841ae9c247b,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-722bbdca-e72b-419f-8b57-faeff8b4a71b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297228790-172.17.0.12-1595872998695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33884,DS-d6c78f3c-da30-4593-9e10-e055275312e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-0a86837e-1179-4c61-bc8f-27c6b2266813,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-87ee01ce-09f6-4f1d-9588-bb4e4044e149,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-8a3fb7df-4dae-47df-a64e-36ee0e7d4812,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-fa7aa3c6-41ab-4188-9e7e-6a382f4cb54b,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-e290d8d3-4746-48dc-9673-c2cc04d9c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-38af6667-6212-463c-bbe9-355b054f24d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-588d7d71-64d2-4da7-8b81-cda4bf41de9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297228790-172.17.0.12-1595872998695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33884,DS-d6c78f3c-da30-4593-9e10-e055275312e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-0a86837e-1179-4c61-bc8f-27c6b2266813,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-87ee01ce-09f6-4f1d-9588-bb4e4044e149,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-8a3fb7df-4dae-47df-a64e-36ee0e7d4812,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-fa7aa3c6-41ab-4188-9e7e-6a382f4cb54b,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-e290d8d3-4746-48dc-9673-c2cc04d9c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-38af6667-6212-463c-bbe9-355b054f24d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-588d7d71-64d2-4da7-8b81-cda4bf41de9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980658772-172.17.0.12-1595873529488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46407,DS-e3092e96-ea4b-44c8-a284-3ed23320ad6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-e3a991eb-c200-4b2b-828d-c6b71c2df646,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-afe1dfa8-7592-4111-b65c-589f88386ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-760b2e25-7f5a-402e-ae9d-3fe806e3fa10,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-34d7aab4-c333-48e4-a04a-922f87fff397,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-720377a4-d583-4416-9ac2-015f4e4a89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-6313a6d6-69cc-44cc-b7c9-ac1cd7550c19,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-8cf04268-d067-4743-af7e-699da74b1d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980658772-172.17.0.12-1595873529488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46407,DS-e3092e96-ea4b-44c8-a284-3ed23320ad6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-e3a991eb-c200-4b2b-828d-c6b71c2df646,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-afe1dfa8-7592-4111-b65c-589f88386ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-760b2e25-7f5a-402e-ae9d-3fe806e3fa10,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-34d7aab4-c333-48e4-a04a-922f87fff397,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-720377a4-d583-4416-9ac2-015f4e4a89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-6313a6d6-69cc-44cc-b7c9-ac1cd7550c19,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-8cf04268-d067-4743-af7e-699da74b1d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182086170-172.17.0.12-1595873847977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34627,DS-b53cc0c0-c3a2-43b3-9124-573fededadf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-8c0d87ee-3e4e-417b-aebe-321e64693fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-6a74d4b4-124d-48ee-8e5c-bbc732bd0981,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-fdb7ce68-c544-4ca5-9919-b0518f4c1a91,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-1243c971-cfb8-4d61-8317-49d794f2e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-ea37e4ae-5705-4e26-8a4f-cd54f0c112f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-794a21a1-612d-43b4-b48a-54f45d973c41,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-4c0ecdf3-e9d3-4c28-ad6e-53e5a1405cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182086170-172.17.0.12-1595873847977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34627,DS-b53cc0c0-c3a2-43b3-9124-573fededadf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-8c0d87ee-3e4e-417b-aebe-321e64693fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-6a74d4b4-124d-48ee-8e5c-bbc732bd0981,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-fdb7ce68-c544-4ca5-9919-b0518f4c1a91,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-1243c971-cfb8-4d61-8317-49d794f2e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-ea37e4ae-5705-4e26-8a4f-cd54f0c112f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-794a21a1-612d-43b4-b48a-54f45d973c41,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-4c0ecdf3-e9d3-4c28-ad6e-53e5a1405cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726827005-172.17.0.12-1595873889313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40752,DS-ee342e83-aeba-48e4-a8f1-065a27253954,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-1f1df891-ed81-47b8-9380-91066450b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-11664d48-5f48-4622-992f-9b2a73a1e863,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-f4e8101b-00f1-49be-9787-ad7ac5b437a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-703e6bfc-34df-40bd-9dbf-32cf46ab125a,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-c4c9b28a-695f-4d33-a9ce-d03d6c04420d,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-f020eac4-1309-44c1-97c5-c29ab5efc1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-ec5d7b14-db48-44b2-a5f4-b6a1a1a0caf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726827005-172.17.0.12-1595873889313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40752,DS-ee342e83-aeba-48e4-a8f1-065a27253954,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-1f1df891-ed81-47b8-9380-91066450b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-11664d48-5f48-4622-992f-9b2a73a1e863,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-f4e8101b-00f1-49be-9787-ad7ac5b437a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-703e6bfc-34df-40bd-9dbf-32cf46ab125a,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-c4c9b28a-695f-4d33-a9ce-d03d6c04420d,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-f020eac4-1309-44c1-97c5-c29ab5efc1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-ec5d7b14-db48-44b2-a5f4-b6a1a1a0caf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745821922-172.17.0.12-1595874001146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41430,DS-91168e23-8db9-4a25-b964-912b016158b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-77b80124-2780-4ac6-a9ce-23680d6fe023,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-27b7ba96-64ae-4314-b6c5-8071b5956c11,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-6323e7e5-6f62-4527-8631-c929d0a0dfee,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-93590aff-6222-47fb-9ec9-d83be3dbdd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-67adfe30-4101-4518-8ab9-ce3e0e4e12cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-d87c7161-ad2c-4d68-b2cc-ed8eb9e8e81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-bfb7adba-b5a7-4462-9a00-3789f88fa6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745821922-172.17.0.12-1595874001146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41430,DS-91168e23-8db9-4a25-b964-912b016158b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-77b80124-2780-4ac6-a9ce-23680d6fe023,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-27b7ba96-64ae-4314-b6c5-8071b5956c11,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-6323e7e5-6f62-4527-8631-c929d0a0dfee,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-93590aff-6222-47fb-9ec9-d83be3dbdd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-67adfe30-4101-4518-8ab9-ce3e0e4e12cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-d87c7161-ad2c-4d68-b2cc-ed8eb9e8e81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-bfb7adba-b5a7-4462-9a00-3789f88fa6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387516901-172.17.0.12-1595874146649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37962,DS-93260673-4e74-4e47-828d-031f254b6933,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-60fc06b2-c557-4a9b-92e8-8dec9fd1eeec,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-238c643c-508e-4d00-adc1-a7f16e198a58,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-94c9063c-75b1-4f14-80d8-a71568726fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-519dd1c6-83bb-4363-b811-f7a3569729c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-82d8b7f8-ece4-45da-ba64-7295b604039b,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-02b0618d-906f-4370-a2ff-80346ad8feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-08a148fd-e09b-4d58-81a0-fd1e364369ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387516901-172.17.0.12-1595874146649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37962,DS-93260673-4e74-4e47-828d-031f254b6933,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-60fc06b2-c557-4a9b-92e8-8dec9fd1eeec,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-238c643c-508e-4d00-adc1-a7f16e198a58,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-94c9063c-75b1-4f14-80d8-a71568726fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-519dd1c6-83bb-4363-b811-f7a3569729c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-82d8b7f8-ece4-45da-ba64-7295b604039b,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-02b0618d-906f-4370-a2ff-80346ad8feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-08a148fd-e09b-4d58-81a0-fd1e364369ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136346950-172.17.0.12-1595874253693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45394,DS-38c98a3c-06c0-4d3c-a9d6-73c59ca1e405,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-4bcc4239-5c82-4afc-add6-28f2d69b039f,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-fb6e9b77-dbc5-4bd7-9688-9c977e017002,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-e4a3fe4c-56b3-4ab4-a206-a006294a8178,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-7331eb8a-50a1-4156-8462-258342b10b63,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-316e4f4a-530f-4704-a51a-d04797a420f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-4f53e580-e435-41ae-993b-73154438422c,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-226454c7-579c-499a-99e4-29e9fc3f4f18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136346950-172.17.0.12-1595874253693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45394,DS-38c98a3c-06c0-4d3c-a9d6-73c59ca1e405,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-4bcc4239-5c82-4afc-add6-28f2d69b039f,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-fb6e9b77-dbc5-4bd7-9688-9c977e017002,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-e4a3fe4c-56b3-4ab4-a206-a006294a8178,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-7331eb8a-50a1-4156-8462-258342b10b63,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-316e4f4a-530f-4704-a51a-d04797a420f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-4f53e580-e435-41ae-993b-73154438422c,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-226454c7-579c-499a-99e4-29e9fc3f4f18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5541
