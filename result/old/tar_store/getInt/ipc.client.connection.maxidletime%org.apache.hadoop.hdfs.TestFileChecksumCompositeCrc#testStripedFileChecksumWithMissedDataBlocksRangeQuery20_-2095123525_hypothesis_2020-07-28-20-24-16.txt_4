reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647046234-172.17.0.19-1595967945977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-bdac6f46-f669-44b9-84b8-5bf972ce5746,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-98b2ca1b-df68-4891-a2f6-65c49e5dd770,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-c29c3354-bfd3-4271-9a3f-7a8d4d39a809,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-6923c4d3-d365-4ec1-ab6b-c402e8edd979,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-32bd17ae-95d0-4efc-ae7e-ae4dc632fdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-3c238464-c3c3-4519-849d-8eb9551caaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-0f1ef506-705c-4adf-af26-1da222c2fe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-a9726aa4-4bcc-4b0e-a18d-d7016ecb876f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647046234-172.17.0.19-1595967945977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-bdac6f46-f669-44b9-84b8-5bf972ce5746,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-98b2ca1b-df68-4891-a2f6-65c49e5dd770,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-c29c3354-bfd3-4271-9a3f-7a8d4d39a809,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-6923c4d3-d365-4ec1-ab6b-c402e8edd979,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-32bd17ae-95d0-4efc-ae7e-ae4dc632fdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-3c238464-c3c3-4519-849d-8eb9551caaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-0f1ef506-705c-4adf-af26-1da222c2fe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-a9726aa4-4bcc-4b0e-a18d-d7016ecb876f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555030134-172.17.0.19-1595968011896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-924be547-f4d4-404f-8477-3fffee76cf79,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-16b5568b-121d-46a5-af4e-7e4507409cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-7f0da4ec-a70c-4d58-a665-e449ebba2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-8ff5f154-581d-4c6b-9652-1c29123c6c37,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-795edf14-165f-4def-b8d1-5d62ce4c39b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-548896b7-87d2-4d94-ad03-e2c2c7668cde,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-e726085c-e016-477e-8489-287edb1f45ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-8be8e6bf-4043-485e-9a00-94cf981b453b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555030134-172.17.0.19-1595968011896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-924be547-f4d4-404f-8477-3fffee76cf79,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-16b5568b-121d-46a5-af4e-7e4507409cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-7f0da4ec-a70c-4d58-a665-e449ebba2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-8ff5f154-581d-4c6b-9652-1c29123c6c37,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-795edf14-165f-4def-b8d1-5d62ce4c39b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-548896b7-87d2-4d94-ad03-e2c2c7668cde,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-e726085c-e016-477e-8489-287edb1f45ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-8be8e6bf-4043-485e-9a00-94cf981b453b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475699858-172.17.0.19-1595968140810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36688,DS-eeed71e5-51fa-4a4d-b049-cdc52342e69c,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-377044af-3012-4163-b6ef-66d2769480ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-433ab206-9b39-4aab-b72f-f1648c44180e,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-322bc8a4-b0a7-42af-a1e2-7ac4afc3e398,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-580e0605-eb5a-443f-85b6-67e4e2a219a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-8fac1156-a431-4c7b-b05c-26027139b838,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-d3b06973-34b4-41a8-90c1-729877abccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-4bd6167f-088f-4d32-97a6-55d3105d549c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475699858-172.17.0.19-1595968140810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36688,DS-eeed71e5-51fa-4a4d-b049-cdc52342e69c,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-377044af-3012-4163-b6ef-66d2769480ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-433ab206-9b39-4aab-b72f-f1648c44180e,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-322bc8a4-b0a7-42af-a1e2-7ac4afc3e398,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-580e0605-eb5a-443f-85b6-67e4e2a219a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-8fac1156-a431-4c7b-b05c-26027139b838,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-d3b06973-34b4-41a8-90c1-729877abccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-4bd6167f-088f-4d32-97a6-55d3105d549c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998113433-172.17.0.19-1595968176634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41559,DS-0f96be2e-d0f6-499e-9454-b58fd1c32fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-1cac751e-57d0-4b8f-a457-8530da1c7563,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-68553d3f-a83f-4bb0-b2ea-4215aacc093d,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-84e1c7da-48cf-42e1-ac8d-fcac3da5e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-a6a1248c-feb7-47a4-879f-fe45663ebda2,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-3d48f2b4-d253-48ad-90a6-93b44ec2bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-98fb2dd5-3f40-411f-87c2-2a4b1754ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-f00b2da4-d5f4-42fc-9a67-082faeff25e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998113433-172.17.0.19-1595968176634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41559,DS-0f96be2e-d0f6-499e-9454-b58fd1c32fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-1cac751e-57d0-4b8f-a457-8530da1c7563,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-68553d3f-a83f-4bb0-b2ea-4215aacc093d,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-84e1c7da-48cf-42e1-ac8d-fcac3da5e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-a6a1248c-feb7-47a4-879f-fe45663ebda2,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-3d48f2b4-d253-48ad-90a6-93b44ec2bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-98fb2dd5-3f40-411f-87c2-2a4b1754ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-f00b2da4-d5f4-42fc-9a67-082faeff25e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681832111-172.17.0.19-1595968286755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-4a8d34a9-46d3-43cb-8ea7-bbb1be07fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-7fe85853-5f0f-45b1-b77e-482a1876fe56,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-cafeeb1e-afbf-4977-9f5a-83b460ffcd15,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-c6c564ee-89f9-4271-8b55-36610b45314c,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-742d8687-46ec-4697-a442-ea6310895df6,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-1384641e-fc4e-4ab1-b5e2-dd999608fd68,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-15875879-d84f-479a-9afc-6aa5642aa0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-42ebfe36-2bab-4c42-a2f1-2db5e53c416e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681832111-172.17.0.19-1595968286755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-4a8d34a9-46d3-43cb-8ea7-bbb1be07fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-7fe85853-5f0f-45b1-b77e-482a1876fe56,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-cafeeb1e-afbf-4977-9f5a-83b460ffcd15,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-c6c564ee-89f9-4271-8b55-36610b45314c,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-742d8687-46ec-4697-a442-ea6310895df6,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-1384641e-fc4e-4ab1-b5e2-dd999608fd68,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-15875879-d84f-479a-9afc-6aa5642aa0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-42ebfe36-2bab-4c42-a2f1-2db5e53c416e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713521814-172.17.0.19-1595969159169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44813,DS-a0d5c758-1c38-47a0-8c78-6907edb89c75,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-3e525048-2058-4f8c-9a4e-9ece06f2c016,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-c129019f-cbb8-44ef-94b4-58b90ea17829,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-91455359-4408-4689-83e9-d996cdd0f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-969ee798-89ea-40f4-9d9b-f64185151f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-e66e3d96-d174-469d-aa1d-cdb09ef413a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-534136d3-4152-4984-9308-0ede542e24b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-a98401cd-11e2-4e56-8b92-be620e54a338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713521814-172.17.0.19-1595969159169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44813,DS-a0d5c758-1c38-47a0-8c78-6907edb89c75,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-3e525048-2058-4f8c-9a4e-9ece06f2c016,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-c129019f-cbb8-44ef-94b4-58b90ea17829,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-91455359-4408-4689-83e9-d996cdd0f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-969ee798-89ea-40f4-9d9b-f64185151f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-e66e3d96-d174-469d-aa1d-cdb09ef413a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-534136d3-4152-4984-9308-0ede542e24b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-a98401cd-11e2-4e56-8b92-be620e54a338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822804014-172.17.0.19-1595969564031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33016,DS-c409f9c5-5d87-4ea0-9d56-2fa26e8b7ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-3742e7fa-117f-4e88-8ec1-ae7fac9e2bec,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-50f7d7e3-342f-4246-a681-3aee55a9a039,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-e9b229a0-3fe1-4f74-a47f-d9276f1f5db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-de3f9156-9dc9-4e13-bbaf-56dae15e68eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-ef67160e-77e2-4442-8646-a273f947b89d,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-28c4eae5-e1a1-432f-95a7-2f9790e98db1,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-33ee3652-86e4-49fb-8632-ddda3f87b338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822804014-172.17.0.19-1595969564031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33016,DS-c409f9c5-5d87-4ea0-9d56-2fa26e8b7ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-3742e7fa-117f-4e88-8ec1-ae7fac9e2bec,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-50f7d7e3-342f-4246-a681-3aee55a9a039,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-e9b229a0-3fe1-4f74-a47f-d9276f1f5db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-de3f9156-9dc9-4e13-bbaf-56dae15e68eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-ef67160e-77e2-4442-8646-a273f947b89d,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-28c4eae5-e1a1-432f-95a7-2f9790e98db1,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-33ee3652-86e4-49fb-8632-ddda3f87b338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099066086-172.17.0.19-1595969831110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-93fe8ff9-2927-4722-9b20-0ab528a1c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-1037b082-a47c-45c7-ac6d-0701b0e896e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-bbe7a6f7-e3fd-4296-88c3-3607ddfa00bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-4c67437a-474f-48aa-8189-4ee44c6e53fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-6ce35504-be75-4a43-8fcf-962c19fe3b22,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-770b37ca-1458-4c60-b74a-cf9ebe3152ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-64692992-81a3-465f-878f-e1e39d9f1d67,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-146c71cc-3cff-4a38-bfe5-4188f245566c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099066086-172.17.0.19-1595969831110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-93fe8ff9-2927-4722-9b20-0ab528a1c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-1037b082-a47c-45c7-ac6d-0701b0e896e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-bbe7a6f7-e3fd-4296-88c3-3607ddfa00bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-4c67437a-474f-48aa-8189-4ee44c6e53fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-6ce35504-be75-4a43-8fcf-962c19fe3b22,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-770b37ca-1458-4c60-b74a-cf9ebe3152ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-64692992-81a3-465f-878f-e1e39d9f1d67,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-146c71cc-3cff-4a38-bfe5-4188f245566c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-389282240-172.17.0.19-1595969985433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36165,DS-eddd175c-c18f-4e5c-894a-e5b2cbad4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-49c35272-38a2-4cb2-a536-6c06dcb9088e,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-e6a9de15-ba98-42bc-b3ef-44ef5f8b492f,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-641a5880-db6d-426a-ab97-d0e997bbe35a,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-27bf5234-217f-4fb3-ba90-84c267086183,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-daa79506-af77-44f9-9442-f6539cd065a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-b529764a-8dff-4e47-99d1-2feba264e0af,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-a82e9fbf-d5d4-4698-8d66-a472f489c14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-389282240-172.17.0.19-1595969985433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36165,DS-eddd175c-c18f-4e5c-894a-e5b2cbad4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-49c35272-38a2-4cb2-a536-6c06dcb9088e,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-e6a9de15-ba98-42bc-b3ef-44ef5f8b492f,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-641a5880-db6d-426a-ab97-d0e997bbe35a,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-27bf5234-217f-4fb3-ba90-84c267086183,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-daa79506-af77-44f9-9442-f6539cd065a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-b529764a-8dff-4e47-99d1-2feba264e0af,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-a82e9fbf-d5d4-4698-8d66-a472f489c14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815823463-172.17.0.19-1595970450405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44180,DS-a91a70ea-cbbe-4308-af16-f678364d8583,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-c4c358a4-7ac3-4dda-a0de-7b46bbdf98a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-4ea8b3be-63e5-49c3-bbea-eca8d32fcdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-e2cf73f7-5486-47db-9148-5dfa75d84bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-03309d2c-2697-4c17-aa57-2ba9e878c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-39b82d40-1a8c-4a24-b5a3-00efb0e62882,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-73411ff6-eeec-4f8b-9a85-63418d7b3135,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-23dc0591-cfda-4c15-b862-8089f219e9a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815823463-172.17.0.19-1595970450405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44180,DS-a91a70ea-cbbe-4308-af16-f678364d8583,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-c4c358a4-7ac3-4dda-a0de-7b46bbdf98a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-4ea8b3be-63e5-49c3-bbea-eca8d32fcdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-e2cf73f7-5486-47db-9148-5dfa75d84bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-03309d2c-2697-4c17-aa57-2ba9e878c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-39b82d40-1a8c-4a24-b5a3-00efb0e62882,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-73411ff6-eeec-4f8b-9a85-63418d7b3135,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-23dc0591-cfda-4c15-b862-8089f219e9a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608366124-172.17.0.19-1595970488253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-c294bca1-b036-4c9f-9fc1-ff4b6febf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-cd652e81-3c11-4950-8b67-c6e40ec08a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-27414421-aca3-48d3-9336-6a493c257cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-45a5195d-d005-457c-8528-f83ea47aac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-8e720561-eba7-4988-9a0a-030d145605f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-c85f7619-9cdf-47d7-9cfe-1fb60a12333d,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-a08488bd-341a-440f-8810-f83d9d7d5287,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-ccf2262a-d894-44c6-bc42-56aac3f1371f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608366124-172.17.0.19-1595970488253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-c294bca1-b036-4c9f-9fc1-ff4b6febf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-cd652e81-3c11-4950-8b67-c6e40ec08a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-27414421-aca3-48d3-9336-6a493c257cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-45a5195d-d005-457c-8528-f83ea47aac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-8e720561-eba7-4988-9a0a-030d145605f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-c85f7619-9cdf-47d7-9cfe-1fb60a12333d,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-a08488bd-341a-440f-8810-f83d9d7d5287,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-ccf2262a-d894-44c6-bc42-56aac3f1371f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969996107-172.17.0.19-1595970524440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37929,DS-9f4e259c-3738-4f60-ab7f-878e90fdf699,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-7993777f-0d6c-4f30-886c-518fcab05880,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-91622b5f-5953-4adb-8e43-ed3d9616392f,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-c20e7a5f-137b-44c6-8630-bf3bf6d121c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-bd942ea4-75e9-4e56-af62-ecbd18c2a41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-87cb75d8-339e-450c-b9a1-27d039e46c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-a7944143-4346-4558-995e-f3b0d458d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-107dada3-1efd-42a2-abdd-0492d97ffd58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969996107-172.17.0.19-1595970524440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37929,DS-9f4e259c-3738-4f60-ab7f-878e90fdf699,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-7993777f-0d6c-4f30-886c-518fcab05880,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-91622b5f-5953-4adb-8e43-ed3d9616392f,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-c20e7a5f-137b-44c6-8630-bf3bf6d121c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-bd942ea4-75e9-4e56-af62-ecbd18c2a41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-87cb75d8-339e-450c-b9a1-27d039e46c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-a7944143-4346-4558-995e-f3b0d458d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-107dada3-1efd-42a2-abdd-0492d97ffd58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835109268-172.17.0.19-1595970564076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42005,DS-7250b803-2213-420f-81a5-25bd1d04839e,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-e23f105d-f34a-489b-bf99-48aed8ec6074,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-8d6f4417-c396-48f8-a522-66ed9a0809bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-076dd6cd-3383-437b-906e-c7367ffeeb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cc65ab31-af5e-49ef-8ec1-24d56eeac51c,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-ccf81f73-066e-4baf-bc8c-758aa4ebed46,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-eb8f5722-8b28-436c-979b-1c793e9ae9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-1390322a-5b45-4e13-97c6-0fa8b5acf0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835109268-172.17.0.19-1595970564076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42005,DS-7250b803-2213-420f-81a5-25bd1d04839e,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-e23f105d-f34a-489b-bf99-48aed8ec6074,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-8d6f4417-c396-48f8-a522-66ed9a0809bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-076dd6cd-3383-437b-906e-c7367ffeeb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cc65ab31-af5e-49ef-8ec1-24d56eeac51c,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-ccf81f73-066e-4baf-bc8c-758aa4ebed46,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-eb8f5722-8b28-436c-979b-1c793e9ae9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-1390322a-5b45-4e13-97c6-0fa8b5acf0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234617991-172.17.0.19-1595970861351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41927,DS-7935e297-d9b5-4f6e-b1ac-5c9798af502c,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-2566e49d-dd52-4a66-9f05-e2eedf14edfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-60df476c-bd09-4656-b06b-9168b569de44,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-32f7213f-9dad-48ff-aa2b-d2af4bd36489,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-e75cf402-9976-40bd-9f86-923d3416c388,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-d7f69f80-06d1-4eed-aaaa-09eb5cf2ff41,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-37a872fc-f4c7-4ecf-979c-b055e30b1842,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-f947d7ab-1e8c-48ee-b6f5-63c0d3d5ab8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234617991-172.17.0.19-1595970861351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41927,DS-7935e297-d9b5-4f6e-b1ac-5c9798af502c,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-2566e49d-dd52-4a66-9f05-e2eedf14edfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-60df476c-bd09-4656-b06b-9168b569de44,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-32f7213f-9dad-48ff-aa2b-d2af4bd36489,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-e75cf402-9976-40bd-9f86-923d3416c388,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-d7f69f80-06d1-4eed-aaaa-09eb5cf2ff41,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-37a872fc-f4c7-4ecf-979c-b055e30b1842,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-f947d7ab-1e8c-48ee-b6f5-63c0d3d5ab8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472526230-172.17.0.19-1595971027079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36037,DS-733c22d7-6796-4494-93c3-ddd280c4b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-20882835-2ffd-4e6e-ba40-e3fde6d8a851,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-eaa1c981-9e7a-4e07-bde6-99968cda6963,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-9cbb33b0-1114-44ab-b7e4-05b94920a6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-12f19fc2-d7c0-46b9-aad0-4396322ab6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-80850b5f-fb27-4f0e-b75a-d87f4ab32946,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-89574f3f-297e-4cc9-9571-3be866235b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-045ebd24-d0e1-4f31-aa70-79543d95268f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472526230-172.17.0.19-1595971027079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36037,DS-733c22d7-6796-4494-93c3-ddd280c4b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-20882835-2ffd-4e6e-ba40-e3fde6d8a851,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-eaa1c981-9e7a-4e07-bde6-99968cda6963,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-9cbb33b0-1114-44ab-b7e4-05b94920a6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-12f19fc2-d7c0-46b9-aad0-4396322ab6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-80850b5f-fb27-4f0e-b75a-d87f4ab32946,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-89574f3f-297e-4cc9-9571-3be866235b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-045ebd24-d0e1-4f31-aa70-79543d95268f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162916376-172.17.0.19-1595971088236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-95c6a51a-07e8-4a28-b759-7f24064aea18,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-1e48f05d-92d9-43a4-9427-6edf2525dff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-ce45ee64-425f-407b-a76c-dab07f4396d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-cd03e6e1-a525-4c93-8cce-91fae7491ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-8631e66d-0131-4321-b7e4-d5f7c92792e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-c0c15a63-0eae-4721-881c-76a8715c8fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-a87f0e3b-2b64-4fb1-ae4f-b9e3947eb5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-19540e0f-923f-4707-8b3a-deb3c94ec25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162916376-172.17.0.19-1595971088236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-95c6a51a-07e8-4a28-b759-7f24064aea18,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-1e48f05d-92d9-43a4-9427-6edf2525dff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-ce45ee64-425f-407b-a76c-dab07f4396d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-cd03e6e1-a525-4c93-8cce-91fae7491ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-8631e66d-0131-4321-b7e4-d5f7c92792e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-c0c15a63-0eae-4721-881c-76a8715c8fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-a87f0e3b-2b64-4fb1-ae4f-b9e3947eb5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-19540e0f-923f-4707-8b3a-deb3c94ec25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144798565-172.17.0.19-1595971396579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-6ea9e3eb-fd85-4a48-b0dc-df05a5282503,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-40987d4a-83ef-48b8-bfe7-1d8759ac3082,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-b5488aa7-3a05-4d90-9587-76a5a85ef9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-b0156202-7dcf-4e1d-beb7-e67230638304,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-68b28462-d303-407e-afea-bb9eb2d1da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-4f5d0cf5-24a3-487d-90ae-10fc8f058b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-4625ad90-c740-4b02-aa95-bbadeed2c389,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-c3cca793-82d5-4c03-9494-a241c28cb835,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144798565-172.17.0.19-1595971396579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-6ea9e3eb-fd85-4a48-b0dc-df05a5282503,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-40987d4a-83ef-48b8-bfe7-1d8759ac3082,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-b5488aa7-3a05-4d90-9587-76a5a85ef9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-b0156202-7dcf-4e1d-beb7-e67230638304,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-68b28462-d303-407e-afea-bb9eb2d1da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-4f5d0cf5-24a3-487d-90ae-10fc8f058b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-4625ad90-c740-4b02-aa95-bbadeed2c389,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-c3cca793-82d5-4c03-9494-a241c28cb835,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783623544-172.17.0.19-1595971744538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-667df6f5-527e-477a-b8b8-47f5c5b60a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-d05a63e9-f4ce-45a7-b353-33de8590d026,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-c6585007-58b6-4e68-8a3d-24996595b7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-b2b4f556-db7c-4c00-a648-36a38b7574a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-e45775bd-19b9-4ab3-be99-79929746514f,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-4baccdf3-8d90-4a6e-81c0-e7326bce6398,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-47c22f15-044c-44f2-b8e8-9dc0f49e1fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-ca2f65f5-b74e-4401-bde3-96e7ef714050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783623544-172.17.0.19-1595971744538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-667df6f5-527e-477a-b8b8-47f5c5b60a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-d05a63e9-f4ce-45a7-b353-33de8590d026,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-c6585007-58b6-4e68-8a3d-24996595b7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-b2b4f556-db7c-4c00-a648-36a38b7574a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-e45775bd-19b9-4ab3-be99-79929746514f,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-4baccdf3-8d90-4a6e-81c0-e7326bce6398,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-47c22f15-044c-44f2-b8e8-9dc0f49e1fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-ca2f65f5-b74e-4401-bde3-96e7ef714050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450162821-172.17.0.19-1595972157511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-bc048089-dd5c-4371-a271-61915437b517,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-0b38af4f-a699-4057-888b-75c084cdcd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-bda58c63-0c1f-449f-adc2-726ba38c429a,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-71b7a7bb-6434-4206-af12-81d02638643d,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-22254a6a-4f77-4a5b-9592-8621bd9a85a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-517b96f7-9a84-46d0-bc98-f9ec43438e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-8ee329d9-8276-4935-b3ea-4053ab92a515,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-a179f249-fd86-4124-9c52-73b7cb096ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450162821-172.17.0.19-1595972157511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-bc048089-dd5c-4371-a271-61915437b517,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-0b38af4f-a699-4057-888b-75c084cdcd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-bda58c63-0c1f-449f-adc2-726ba38c429a,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-71b7a7bb-6434-4206-af12-81d02638643d,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-22254a6a-4f77-4a5b-9592-8621bd9a85a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-517b96f7-9a84-46d0-bc98-f9ec43438e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-8ee329d9-8276-4935-b3ea-4053ab92a515,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-a179f249-fd86-4124-9c52-73b7cb096ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025528863-172.17.0.19-1595972379566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-893109d0-b56f-4bc8-a6f2-3cb18f21d9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-b0a9e5d7-b0f2-4ac2-a5a1-57c0be4ca2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-117d414c-6518-4162-be99-413eec00784e,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-888cac50-0e98-407f-8c37-3997fcc46640,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-0f8b2a85-6433-41e1-be06-2722318796ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-01ad3f27-6c18-4632-a265-5e39359b7826,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-92aafd74-1bed-4696-bd08-8d944287d91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-0a5a6054-9833-4790-9d66-84c8132427de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025528863-172.17.0.19-1595972379566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-893109d0-b56f-4bc8-a6f2-3cb18f21d9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-b0a9e5d7-b0f2-4ac2-a5a1-57c0be4ca2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-117d414c-6518-4162-be99-413eec00784e,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-888cac50-0e98-407f-8c37-3997fcc46640,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-0f8b2a85-6433-41e1-be06-2722318796ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-01ad3f27-6c18-4632-a265-5e39359b7826,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-92aafd74-1bed-4696-bd08-8d944287d91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-0a5a6054-9833-4790-9d66-84c8132427de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690702440-172.17.0.19-1595972815793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38391,DS-e35b90a1-947a-42cb-b6c7-41abea78084b,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-fd2acef0-0d1d-4df4-9f33-63294dea18f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-ba89ac3b-5b50-42da-acfa-1f55d6cd93c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-7071044d-b963-435c-b075-18beb44b87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-aa7c2db6-0a28-4f9f-b999-21b96fad67aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-afb99d5e-f815-49fd-94b1-aeca383d6bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-422dcb16-ff58-4d2f-82b6-8a92bcc42e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-d8a1f636-0797-45c5-bdd4-4f79e1265792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690702440-172.17.0.19-1595972815793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38391,DS-e35b90a1-947a-42cb-b6c7-41abea78084b,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-fd2acef0-0d1d-4df4-9f33-63294dea18f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-ba89ac3b-5b50-42da-acfa-1f55d6cd93c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-7071044d-b963-435c-b075-18beb44b87ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-aa7c2db6-0a28-4f9f-b999-21b96fad67aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-afb99d5e-f815-49fd-94b1-aeca383d6bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-422dcb16-ff58-4d2f-82b6-8a92bcc42e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-d8a1f636-0797-45c5-bdd4-4f79e1265792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268571322-172.17.0.19-1595973070416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42105,DS-c9c4c864-feb1-4fbf-9329-60bbf9a625c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-cb384f86-03a4-472b-9364-e28f6e6e25b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-55218f30-77d8-497c-bfee-ee42b12dc906,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-1a95b64c-95eb-4271-8e29-afe1a43173e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-e3ec6a6d-7bde-4fa0-b5b5-5776e11e3d32,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-be443937-32b6-44eb-9eca-8f192fae2387,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-8e10981d-7f27-46d4-9686-b66d5135fa75,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-3e928d72-f6ed-411b-bd32-10a79d8a754d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268571322-172.17.0.19-1595973070416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42105,DS-c9c4c864-feb1-4fbf-9329-60bbf9a625c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-cb384f86-03a4-472b-9364-e28f6e6e25b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-55218f30-77d8-497c-bfee-ee42b12dc906,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-1a95b64c-95eb-4271-8e29-afe1a43173e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-e3ec6a6d-7bde-4fa0-b5b5-5776e11e3d32,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-be443937-32b6-44eb-9eca-8f192fae2387,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-8e10981d-7f27-46d4-9686-b66d5135fa75,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-3e928d72-f6ed-411b-bd32-10a79d8a754d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5239
