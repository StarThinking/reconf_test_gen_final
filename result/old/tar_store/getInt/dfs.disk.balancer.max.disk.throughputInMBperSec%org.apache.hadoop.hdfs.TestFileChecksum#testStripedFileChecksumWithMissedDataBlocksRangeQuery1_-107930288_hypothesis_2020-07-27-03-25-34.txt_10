reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127562230-172.17.0.17-1595820730703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-ca0ec7b1-666a-481a-acf6-9b1cec2a8194,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-18f36089-8839-4bea-9942-c0002e120436,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-2c00361f-b5dc-44be-8fa2-c86218c27519,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-c7290a74-6026-46bf-94ba-28acc6a92b71,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-d760bbc7-0278-472e-b0cb-ae1b3c1eaffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-75486e0a-8e58-4071-9848-a3fe34aa9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-813d067f-4e19-4150-b9c2-c684b99344c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-a41663df-26b3-47a2-9431-3cbd65e35ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127562230-172.17.0.17-1595820730703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-ca0ec7b1-666a-481a-acf6-9b1cec2a8194,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-18f36089-8839-4bea-9942-c0002e120436,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-2c00361f-b5dc-44be-8fa2-c86218c27519,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-c7290a74-6026-46bf-94ba-28acc6a92b71,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-d760bbc7-0278-472e-b0cb-ae1b3c1eaffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-75486e0a-8e58-4071-9848-a3fe34aa9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-813d067f-4e19-4150-b9c2-c684b99344c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-a41663df-26b3-47a2-9431-3cbd65e35ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662625671-172.17.0.17-1595820808865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-73f5df8c-bcf3-4de4-a5e2-1393c1d32a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-2e66b739-18d5-4895-8eab-e56b855c53a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-3ed5f9ff-0567-4187-b49e-561108753387,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-c708dd38-e852-45c0-877d-724d041e0fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-be2fec13-bcc8-487b-983a-3245b27507c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-ee9cf4f6-3285-489b-8cd8-6454776d22bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-3ab78848-323f-4881-8899-53817fc85284,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-8d0b5537-1b4c-4574-b8a2-45da6ac7607e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662625671-172.17.0.17-1595820808865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-73f5df8c-bcf3-4de4-a5e2-1393c1d32a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-2e66b739-18d5-4895-8eab-e56b855c53a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-3ed5f9ff-0567-4187-b49e-561108753387,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-c708dd38-e852-45c0-877d-724d041e0fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-be2fec13-bcc8-487b-983a-3245b27507c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-ee9cf4f6-3285-489b-8cd8-6454776d22bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-3ab78848-323f-4881-8899-53817fc85284,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-8d0b5537-1b4c-4574-b8a2-45da6ac7607e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935931877-172.17.0.17-1595821216569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41717,DS-0a029a26-2cbd-4d0e-98e6-b53e06590800,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-e2c3a55a-04f0-4367-bf6d-7a9db35ac88e,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-867cbf01-1643-42d7-bdf4-b1b033d84024,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-21c71372-7589-4a38-b637-71e9fad27765,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-1409f118-f2f5-4512-83b9-295cdb781ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ba4efaa3-fb83-4f65-b705-21f1ffc1fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-bdf858e7-cef8-4820-86a6-9cdcf269da27,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-d9080028-0f16-4438-bd8f-e676188d2dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935931877-172.17.0.17-1595821216569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41717,DS-0a029a26-2cbd-4d0e-98e6-b53e06590800,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-e2c3a55a-04f0-4367-bf6d-7a9db35ac88e,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-867cbf01-1643-42d7-bdf4-b1b033d84024,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-21c71372-7589-4a38-b637-71e9fad27765,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-1409f118-f2f5-4512-83b9-295cdb781ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ba4efaa3-fb83-4f65-b705-21f1ffc1fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-bdf858e7-cef8-4820-86a6-9cdcf269da27,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-d9080028-0f16-4438-bd8f-e676188d2dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710047092-172.17.0.17-1595821498205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33692,DS-a636bc11-2b3a-4dc4-a1fc-9e4e2a89265c,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-67dccf92-d6a3-467a-90b3-cd5bd9c83678,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-f34db8ba-4a2d-46c8-9c63-c460d3a21e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-3fe2b330-6b82-446b-ab42-6cc0e24746d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-cdda29a0-d426-4840-8164-963a918d4f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-56a6a067-48b7-4366-a496-2ef9e29c10ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-455cca42-c76d-42e4-b26e-7f7a9a8ea526,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-0abf6f80-b31a-4dfc-923d-42d38408f093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710047092-172.17.0.17-1595821498205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33692,DS-a636bc11-2b3a-4dc4-a1fc-9e4e2a89265c,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-67dccf92-d6a3-467a-90b3-cd5bd9c83678,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-f34db8ba-4a2d-46c8-9c63-c460d3a21e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-3fe2b330-6b82-446b-ab42-6cc0e24746d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-cdda29a0-d426-4840-8164-963a918d4f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-56a6a067-48b7-4366-a496-2ef9e29c10ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-455cca42-c76d-42e4-b26e-7f7a9a8ea526,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-0abf6f80-b31a-4dfc-923d-42d38408f093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014257521-172.17.0.17-1595821788910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38240,DS-97b2da72-36ec-443c-bdc9-ce10b5e42790,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-a302177e-1cb1-409b-beb6-fc3a32504efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-5ef72d10-6856-48b7-a7e9-ba90091a6c37,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-425e48e0-3ce2-4b49-9a77-a9bae212e372,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-31b0234a-e685-40af-aebd-306f5deadc83,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-10d16dd1-fed6-4dde-859c-ebd8ae6df8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-e12d8094-e21b-4ecd-a8bf-9da69e019c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-a45dffd1-1b9c-4d5c-bc59-4a7040d3e26b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014257521-172.17.0.17-1595821788910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38240,DS-97b2da72-36ec-443c-bdc9-ce10b5e42790,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-a302177e-1cb1-409b-beb6-fc3a32504efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-5ef72d10-6856-48b7-a7e9-ba90091a6c37,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-425e48e0-3ce2-4b49-9a77-a9bae212e372,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-31b0234a-e685-40af-aebd-306f5deadc83,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-10d16dd1-fed6-4dde-859c-ebd8ae6df8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-e12d8094-e21b-4ecd-a8bf-9da69e019c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-a45dffd1-1b9c-4d5c-bc59-4a7040d3e26b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784227559-172.17.0.17-1595822164110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34219,DS-fce48697-b543-45f2-8ceb-b97ba069f3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-7e1b1ffc-f1dd-443f-8699-172385e9a1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-4766c6ec-222a-4a7b-97e6-fe8173c898f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-cbf52f7c-9c1f-45a4-80b5-a3c8ceacd117,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-75dae482-cb65-4583-88f0-a2fcdf7cca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-97a30599-d78e-403f-8cbf-e54d0368a324,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-295c6ede-0c58-410b-af00-c506f155317c,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-6f6505d6-7f43-4258-8ec2-782bcad644e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784227559-172.17.0.17-1595822164110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34219,DS-fce48697-b543-45f2-8ceb-b97ba069f3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-7e1b1ffc-f1dd-443f-8699-172385e9a1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-4766c6ec-222a-4a7b-97e6-fe8173c898f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-cbf52f7c-9c1f-45a4-80b5-a3c8ceacd117,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-75dae482-cb65-4583-88f0-a2fcdf7cca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-97a30599-d78e-403f-8cbf-e54d0368a324,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-295c6ede-0c58-410b-af00-c506f155317c,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-6f6505d6-7f43-4258-8ec2-782bcad644e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363496749-172.17.0.17-1595822246568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-2e82cd07-fff4-49d4-9c25-60845cf51fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-1996353f-c81a-4f23-99c9-c79956ba9928,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-2bf82706-edb9-4a57-bbc4-bbc3764d3289,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-79385e58-c62b-493f-a717-9f1d62587642,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-e330cff4-fc92-4a2e-9d32-e31f7f31add3,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-546accfa-9f89-400b-9aa8-0f1586ab789d,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-702c97a9-4b9e-4624-88af-3c34a515c873,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-90d449b6-5ea3-4a7b-b609-9ff8ce7273c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363496749-172.17.0.17-1595822246568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-2e82cd07-fff4-49d4-9c25-60845cf51fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-1996353f-c81a-4f23-99c9-c79956ba9928,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-2bf82706-edb9-4a57-bbc4-bbc3764d3289,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-79385e58-c62b-493f-a717-9f1d62587642,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-e330cff4-fc92-4a2e-9d32-e31f7f31add3,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-546accfa-9f89-400b-9aa8-0f1586ab789d,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-702c97a9-4b9e-4624-88af-3c34a515c873,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-90d449b6-5ea3-4a7b-b609-9ff8ce7273c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26794371-172.17.0.17-1595822558009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-b5d62337-5687-4d61-81f4-405d64720114,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-81f74364-ffa6-45f8-806d-59afcc61a659,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-f9fa64a1-7ba1-4d3f-836f-917de92e264b,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-fa750a84-da33-4809-8195-533d4c216afb,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-c2d6b822-e7d8-4946-93ec-e0bf31a32ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-fba6cd74-547b-45e7-8edb-3b573d5af65f,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-7e415599-3ca4-4946-b574-5729f47ffbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-03070b8c-2f36-4100-a7fe-00597bb99c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26794371-172.17.0.17-1595822558009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-b5d62337-5687-4d61-81f4-405d64720114,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-81f74364-ffa6-45f8-806d-59afcc61a659,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-f9fa64a1-7ba1-4d3f-836f-917de92e264b,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-fa750a84-da33-4809-8195-533d4c216afb,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-c2d6b822-e7d8-4946-93ec-e0bf31a32ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-fba6cd74-547b-45e7-8edb-3b573d5af65f,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-7e415599-3ca4-4946-b574-5729f47ffbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-03070b8c-2f36-4100-a7fe-00597bb99c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895244727-172.17.0.17-1595822794854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42788,DS-e873401c-cb18-47a2-9272-6e9df253a225,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-aa4f68ae-bae0-480f-9419-435db9747204,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-7829df7b-4100-47ee-bae1-31ac2bd59284,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-02e60976-b62a-41e0-9df7-ed7518148ada,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-7b3330df-1ea3-45b8-878c-3e6daf0e4383,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-183616f3-de28-4129-9a57-ae144e5ae18d,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-8960bed5-d0bf-412a-93e6-bf6de535b352,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-d38ee949-ac46-4632-b0e9-e5534fe36777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895244727-172.17.0.17-1595822794854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42788,DS-e873401c-cb18-47a2-9272-6e9df253a225,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-aa4f68ae-bae0-480f-9419-435db9747204,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-7829df7b-4100-47ee-bae1-31ac2bd59284,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-02e60976-b62a-41e0-9df7-ed7518148ada,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-7b3330df-1ea3-45b8-878c-3e6daf0e4383,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-183616f3-de28-4129-9a57-ae144e5ae18d,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-8960bed5-d0bf-412a-93e6-bf6de535b352,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-d38ee949-ac46-4632-b0e9-e5534fe36777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214370228-172.17.0.17-1595823460806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-7ab749b3-db0f-439f-899b-30919ebeeb74,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-a3d741d4-2512-4085-b320-60686eeee3af,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-38548b80-c4e5-48a9-8f5c-331255b5cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-149afdf7-bc97-49c2-a556-d3b9dd4bb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-4858168b-6756-4bab-8458-c80feaf79895,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-b440b936-21ea-497d-91fd-38c7cf72f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-c006a899-ae4d-48ee-afe4-85cc15d4cbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-ecc5eff3-ef3c-4e2d-96b9-03beae0d6ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214370228-172.17.0.17-1595823460806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-7ab749b3-db0f-439f-899b-30919ebeeb74,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-a3d741d4-2512-4085-b320-60686eeee3af,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-38548b80-c4e5-48a9-8f5c-331255b5cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-149afdf7-bc97-49c2-a556-d3b9dd4bb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-4858168b-6756-4bab-8458-c80feaf79895,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-b440b936-21ea-497d-91fd-38c7cf72f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-c006a899-ae4d-48ee-afe4-85cc15d4cbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-ecc5eff3-ef3c-4e2d-96b9-03beae0d6ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441513243-172.17.0.17-1595824324804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-a0dce84c-bf84-4f0f-bc07-8736b64f6365,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-648e482d-1053-4d7c-8a42-9d68247cb42c,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-5112520e-0da4-4de8-8abb-c79f2821caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-f83cca33-6090-4333-be5b-3cf3b9de4e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-c354c2f8-4f62-4dbc-9131-9120c58cc53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-16c7fcb0-bf79-435d-9cba-ee7a51762d49,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-3363599d-c465-4400-8e3d-0f3aebe699cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-bd5bd44d-075d-44ae-a3f5-b061361b2bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441513243-172.17.0.17-1595824324804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-a0dce84c-bf84-4f0f-bc07-8736b64f6365,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-648e482d-1053-4d7c-8a42-9d68247cb42c,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-5112520e-0da4-4de8-8abb-c79f2821caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-f83cca33-6090-4333-be5b-3cf3b9de4e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-c354c2f8-4f62-4dbc-9131-9120c58cc53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-16c7fcb0-bf79-435d-9cba-ee7a51762d49,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-3363599d-c465-4400-8e3d-0f3aebe699cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-bd5bd44d-075d-44ae-a3f5-b061361b2bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553137410-172.17.0.17-1595824359640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46847,DS-ce074fa7-4954-4b14-bbfe-37ee16194b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-8c23bbda-e944-4b2e-8e7d-967c8bdaf9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-aef4ee53-882b-4f74-86c0-fbe6a90ebd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-6c95a80c-352c-4401-b66d-2fd0c70d5a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-cc8c4a7f-8e69-4aea-9dbf-4a7dd0cc4568,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-362802e4-9550-45f7-b3ab-5c7376e4817d,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-f7c1ac8d-651d-4c50-94b4-87af0fe49e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-c2d5ec49-f662-4364-8d38-291fe4297d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553137410-172.17.0.17-1595824359640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46847,DS-ce074fa7-4954-4b14-bbfe-37ee16194b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-8c23bbda-e944-4b2e-8e7d-967c8bdaf9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-aef4ee53-882b-4f74-86c0-fbe6a90ebd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-6c95a80c-352c-4401-b66d-2fd0c70d5a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-cc8c4a7f-8e69-4aea-9dbf-4a7dd0cc4568,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-362802e4-9550-45f7-b3ab-5c7376e4817d,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-f7c1ac8d-651d-4c50-94b4-87af0fe49e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-c2d5ec49-f662-4364-8d38-291fe4297d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601254233-172.17.0.17-1595824628877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46745,DS-dd158b80-1001-45c9-a256-a2aa781bc532,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-40ae65ce-f651-418f-aebe-d51e9b41359f,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-3c4cca95-7efc-48d9-b09e-1695c6aa79a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-988da30d-bcd2-4303-8bf0-1b805091182e,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-3656c347-f554-4778-848b-db8cbbc8febc,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-a6d9cd52-c94a-42fa-a2fd-eef49d591aef,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-12c6d3fe-b180-46bf-b570-50d037674a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-967bb2ec-d0dc-4e18-ac08-26ba4f82ad90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601254233-172.17.0.17-1595824628877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46745,DS-dd158b80-1001-45c9-a256-a2aa781bc532,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-40ae65ce-f651-418f-aebe-d51e9b41359f,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-3c4cca95-7efc-48d9-b09e-1695c6aa79a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-988da30d-bcd2-4303-8bf0-1b805091182e,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-3656c347-f554-4778-848b-db8cbbc8febc,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-a6d9cd52-c94a-42fa-a2fd-eef49d591aef,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-12c6d3fe-b180-46bf-b570-50d037674a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-967bb2ec-d0dc-4e18-ac08-26ba4f82ad90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584069350-172.17.0.17-1595824697761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-eaebb057-dca8-445a-aecc-dace5a7e04de,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-6718537c-032c-4a74-b8e4-e2a46ba77cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-a53fc32e-2729-4fbc-9389-9b99a894109a,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-940a9fac-a67d-400e-8142-270a03dbf259,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-9cb5e76a-3a41-4ff5-8e52-5e620f19fe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-f2fb6d3f-85b6-4595-917f-48f2dca1310a,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-8544cd26-6339-4cad-9278-0bba8d431ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-3cd432e1-fcd2-406f-a6ed-df84cb851bac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584069350-172.17.0.17-1595824697761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-eaebb057-dca8-445a-aecc-dace5a7e04de,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-6718537c-032c-4a74-b8e4-e2a46ba77cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-a53fc32e-2729-4fbc-9389-9b99a894109a,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-940a9fac-a67d-400e-8142-270a03dbf259,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-9cb5e76a-3a41-4ff5-8e52-5e620f19fe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-f2fb6d3f-85b6-4595-917f-48f2dca1310a,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-8544cd26-6339-4cad-9278-0bba8d431ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-3cd432e1-fcd2-406f-a6ed-df84cb851bac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63145652-172.17.0.17-1595825302318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-75a671c7-c9c8-431f-93bf-bc3b318fd774,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-2db60ea1-ebf7-4849-97ab-32b416bfaead,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-bb6148b4-041b-46c8-b316-89cdc576abce,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-7644cac8-6b6d-46b2-a791-8be482b2a58e,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-662fad32-4e47-4ad6-ac6c-e956a36a6579,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-4330c3df-be07-475b-8f96-895df83774a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-15a8626a-2c01-40a5-acf9-e096932c6e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-aa027075-6569-40b6-ae77-b0f02b37d2df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63145652-172.17.0.17-1595825302318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-75a671c7-c9c8-431f-93bf-bc3b318fd774,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-2db60ea1-ebf7-4849-97ab-32b416bfaead,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-bb6148b4-041b-46c8-b316-89cdc576abce,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-7644cac8-6b6d-46b2-a791-8be482b2a58e,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-662fad32-4e47-4ad6-ac6c-e956a36a6579,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-4330c3df-be07-475b-8f96-895df83774a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-15a8626a-2c01-40a5-acf9-e096932c6e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-aa027075-6569-40b6-ae77-b0f02b37d2df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865720708-172.17.0.17-1595825414948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33627,DS-b7a04999-a537-4740-a793-f883d11ce456,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-5fe7b849-6e74-4649-866a-8ed41e203c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-ac110b05-fd84-4c20-a74e-307375b943fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-46345d69-db50-4462-9796-ef8dc7da2b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-daa6b7da-c961-41d6-8112-86fe10b4caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-6dcf3d80-efc2-42d8-a13f-224a3d206d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-4c7e07b2-a3c7-4692-b24e-1da3ad815ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-98276895-7702-431d-b48f-291f6c05b431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865720708-172.17.0.17-1595825414948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33627,DS-b7a04999-a537-4740-a793-f883d11ce456,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-5fe7b849-6e74-4649-866a-8ed41e203c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-ac110b05-fd84-4c20-a74e-307375b943fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-46345d69-db50-4462-9796-ef8dc7da2b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-daa6b7da-c961-41d6-8112-86fe10b4caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-6dcf3d80-efc2-42d8-a13f-224a3d206d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-4c7e07b2-a3c7-4692-b24e-1da3ad815ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-98276895-7702-431d-b48f-291f6c05b431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836805764-172.17.0.17-1595825559765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-f639d0e6-54c7-4395-b7f8-fb4900b12472,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-ee584bbe-dc66-4a3f-88ed-64130ac49b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-2afd628e-72c8-4b0a-a140-27b45e8754e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-bf602dbf-b01d-4b89-bfaf-dc51f22894dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-f3f57afe-7b8e-4cc2-99f7-49ce3ef7eac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-365255bc-e864-414d-a847-3feff22bf56e,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-0cab290f-861f-4169-8245-863a686449f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-54c12ad4-dd3e-4d0d-8dd1-07c62d3b8277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836805764-172.17.0.17-1595825559765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-f639d0e6-54c7-4395-b7f8-fb4900b12472,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-ee584bbe-dc66-4a3f-88ed-64130ac49b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-2afd628e-72c8-4b0a-a140-27b45e8754e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-bf602dbf-b01d-4b89-bfaf-dc51f22894dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-f3f57afe-7b8e-4cc2-99f7-49ce3ef7eac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-365255bc-e864-414d-a847-3feff22bf56e,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-0cab290f-861f-4169-8245-863a686449f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-54c12ad4-dd3e-4d0d-8dd1-07c62d3b8277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211743484-172.17.0.17-1595825790838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33644,DS-2589984b-03ba-4d0c-87c2-7d3ff4b0f78a,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-731b7faf-c06d-4919-b569-352a44d61167,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-7444a2ea-c509-4380-a9f7-9bfa10623c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-60c39671-52b0-4a0f-9388-ac7c754082db,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-52ef92c8-f73b-4981-99fe-ab1e8f46b76a,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-c5075912-4a5a-4050-89cd-068098cef327,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-add758e1-845c-416c-8a35-75a3397bd203,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-c3003e39-3680-4e83-87a5-ae12790ac457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211743484-172.17.0.17-1595825790838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33644,DS-2589984b-03ba-4d0c-87c2-7d3ff4b0f78a,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-731b7faf-c06d-4919-b569-352a44d61167,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-7444a2ea-c509-4380-a9f7-9bfa10623c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-60c39671-52b0-4a0f-9388-ac7c754082db,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-52ef92c8-f73b-4981-99fe-ab1e8f46b76a,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-c5075912-4a5a-4050-89cd-068098cef327,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-add758e1-845c-416c-8a35-75a3397bd203,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-c3003e39-3680-4e83-87a5-ae12790ac457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5731
