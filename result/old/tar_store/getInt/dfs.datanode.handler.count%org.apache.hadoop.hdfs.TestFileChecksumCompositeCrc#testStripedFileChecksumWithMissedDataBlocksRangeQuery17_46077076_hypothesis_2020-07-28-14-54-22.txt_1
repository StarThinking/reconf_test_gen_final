reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157465262-172.17.0.16-1595948469421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-de0748ee-9ee4-4128-ba81-5ecf425e0101,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-e5344b4d-55a8-40aa-b2d2-95c122a0aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-34bb3484-5429-4ce3-924d-e8e618cc40d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-2e44c216-10d1-41e1-acf2-38f14a0f6e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-e7d9c8b4-eb9c-434e-b38e-919aa2e182ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-a1c88869-cbdd-4184-8a15-12e4f526c421,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-e0f55482-e89a-4f5f-bba0-2aea6bf15420,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-c4ffa4ab-f530-49b9-9c3d-63b7d703fbdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157465262-172.17.0.16-1595948469421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-de0748ee-9ee4-4128-ba81-5ecf425e0101,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-e5344b4d-55a8-40aa-b2d2-95c122a0aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-34bb3484-5429-4ce3-924d-e8e618cc40d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-2e44c216-10d1-41e1-acf2-38f14a0f6e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-e7d9c8b4-eb9c-434e-b38e-919aa2e182ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-a1c88869-cbdd-4184-8a15-12e4f526c421,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-e0f55482-e89a-4f5f-bba0-2aea6bf15420,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-c4ffa4ab-f530-49b9-9c3d-63b7d703fbdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440782396-172.17.0.16-1595948654621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-c22cf1be-9a19-40e1-8d2e-e59cfe258404,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-e12903a7-b5ed-47c4-99dc-367c478cbce9,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-3615a859-c8ac-4f97-a939-bd89b76a8f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-41758da0-dba3-401d-b519-d346d49a5721,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-9ae84a93-1754-46e1-a399-47a39741397a,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-002d00a4-518b-4709-91e5-e3a60db23554,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-ffa7abb4-09f7-46b8-8fb9-e4264835071e,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-5b3f93c8-a0e2-4584-b7a9-91d2f7a49b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440782396-172.17.0.16-1595948654621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-c22cf1be-9a19-40e1-8d2e-e59cfe258404,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-e12903a7-b5ed-47c4-99dc-367c478cbce9,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-3615a859-c8ac-4f97-a939-bd89b76a8f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-41758da0-dba3-401d-b519-d346d49a5721,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-9ae84a93-1754-46e1-a399-47a39741397a,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-002d00a4-518b-4709-91e5-e3a60db23554,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-ffa7abb4-09f7-46b8-8fb9-e4264835071e,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-5b3f93c8-a0e2-4584-b7a9-91d2f7a49b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478809619-172.17.0.16-1595948687039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-267d151b-d665-46a2-982f-2d1e450b49dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-e30faecf-6138-4b99-ae4a-63301438f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-66a7a3e7-6623-4fb4-8003-5aa50eeba994,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-e51760b7-d6c5-4cff-9228-3dde8919ab09,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-ec49681a-b035-42f9-a1d0-4a1ac0e5f45d,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-c6a5025d-d056-41c1-8a1a-a3d86c2b3907,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-b10e9aae-fdb7-44cb-aafc-d5382a96f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-6e1cbb77-0a5a-4269-a286-d46fb3ff663c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478809619-172.17.0.16-1595948687039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-267d151b-d665-46a2-982f-2d1e450b49dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-e30faecf-6138-4b99-ae4a-63301438f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-66a7a3e7-6623-4fb4-8003-5aa50eeba994,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-e51760b7-d6c5-4cff-9228-3dde8919ab09,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-ec49681a-b035-42f9-a1d0-4a1ac0e5f45d,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-c6a5025d-d056-41c1-8a1a-a3d86c2b3907,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-b10e9aae-fdb7-44cb-aafc-d5382a96f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-6e1cbb77-0a5a-4269-a286-d46fb3ff663c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859995057-172.17.0.16-1595948725131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-06f5bdd6-eb07-40af-9543-761d49e73137,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-2c3c4c6e-cc98-4562-8d1f-5ce99301114b,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-8f17b21f-eaf1-40e8-814b-4a9758fa9983,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-bde96742-da5b-42c4-bf67-23dd440d96e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-fd712b5d-8fb9-4e55-87dd-cc1afa77d44c,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-6ba344ab-467d-4841-ab66-2bff1582a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-758e5654-7e59-4338-97e6-64f174d2a51f,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-2e12a4c3-6eb4-4fb1-9967-b4cbc93142b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859995057-172.17.0.16-1595948725131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-06f5bdd6-eb07-40af-9543-761d49e73137,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-2c3c4c6e-cc98-4562-8d1f-5ce99301114b,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-8f17b21f-eaf1-40e8-814b-4a9758fa9983,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-bde96742-da5b-42c4-bf67-23dd440d96e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-fd712b5d-8fb9-4e55-87dd-cc1afa77d44c,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-6ba344ab-467d-4841-ab66-2bff1582a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-758e5654-7e59-4338-97e6-64f174d2a51f,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-2e12a4c3-6eb4-4fb1-9967-b4cbc93142b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349499003-172.17.0.16-1595949665381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42044,DS-8b4e3aa9-a379-4af8-a170-5b218a39bc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-61e41b31-3e46-4b49-b44c-f3f99d409df0,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-2dfef7aa-6a03-45f6-953f-5d04d4d8b28b,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-0433678e-9861-428e-9f10-37fab393a0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-a86395a4-7af6-4b6b-a17a-822b72ce2022,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-e06ef0b8-cb32-4071-95ea-8fa90393ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-5804163e-b98d-418f-8358-ecc01d7f0524,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-f6be0ce8-1f02-48d7-99be-0271bf492e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349499003-172.17.0.16-1595949665381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42044,DS-8b4e3aa9-a379-4af8-a170-5b218a39bc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-61e41b31-3e46-4b49-b44c-f3f99d409df0,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-2dfef7aa-6a03-45f6-953f-5d04d4d8b28b,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-0433678e-9861-428e-9f10-37fab393a0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-a86395a4-7af6-4b6b-a17a-822b72ce2022,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-e06ef0b8-cb32-4071-95ea-8fa90393ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-5804163e-b98d-418f-8358-ecc01d7f0524,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-f6be0ce8-1f02-48d7-99be-0271bf492e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27619037-172.17.0.16-1595949772018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39202,DS-de535702-c2f3-437c-8f64-f85b4a0ad308,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-e0665e0d-3101-426b-9a30-03cca840b36d,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-ce44abd3-1d24-42da-baa6-447a3580b5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-3b0318a4-8533-43f5-9b62-1328a87742c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-eed91a49-1433-442e-b750-99fe73c5112c,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-abb9a907-22db-428b-8b66-146f51d1fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-5d19db58-3c59-4ba1-a2b1-e549bb1cf9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-bfe9d906-9c14-495f-ad1b-6e7f140b28ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27619037-172.17.0.16-1595949772018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39202,DS-de535702-c2f3-437c-8f64-f85b4a0ad308,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-e0665e0d-3101-426b-9a30-03cca840b36d,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-ce44abd3-1d24-42da-baa6-447a3580b5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-3b0318a4-8533-43f5-9b62-1328a87742c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-eed91a49-1433-442e-b750-99fe73c5112c,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-abb9a907-22db-428b-8b66-146f51d1fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-5d19db58-3c59-4ba1-a2b1-e549bb1cf9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-bfe9d906-9c14-495f-ad1b-6e7f140b28ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132125562-172.17.0.16-1595950799128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-cd49e22d-2f77-424b-9b6f-d362f4bc8d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-fadfef4e-f8c3-48b3-9036-cfc2779b1674,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-c69ba26e-142f-4558-ab4b-0b8c85922932,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-bc250482-b1fe-4a13-a93e-998872aa8603,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-c60b7588-c19a-40ae-96e1-b2ef6447b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-bfbbb385-7d4b-4b7f-b16a-4afd43dedd89,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-bc607110-385e-4090-bafc-398ca09b581b,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-7d7e2c15-37a6-4cd0-8f3a-15077eb364eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132125562-172.17.0.16-1595950799128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-cd49e22d-2f77-424b-9b6f-d362f4bc8d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-fadfef4e-f8c3-48b3-9036-cfc2779b1674,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-c69ba26e-142f-4558-ab4b-0b8c85922932,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-bc250482-b1fe-4a13-a93e-998872aa8603,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-c60b7588-c19a-40ae-96e1-b2ef6447b7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-bfbbb385-7d4b-4b7f-b16a-4afd43dedd89,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-bc607110-385e-4090-bafc-398ca09b581b,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-7d7e2c15-37a6-4cd0-8f3a-15077eb364eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452521549-172.17.0.16-1595950937504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-e0ec951c-18b4-4ab4-8bb2-ff4db108fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-23455010-d605-4fc6-b3ee-6b22ece7ac05,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-147908fc-4984-41c5-a9d2-a3e15883d3df,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-218483bb-0ab4-4b0a-833b-72c226c8e759,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-9adec8a2-a79d-445d-83e1-cc154aa0756b,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-5a50799f-6ac8-4796-9cdd-2f8fda47115b,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-1bfda259-f112-45fb-b946-ad69d203b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-cbcd4d9f-950d-4188-bee1-f73049b64dcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452521549-172.17.0.16-1595950937504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-e0ec951c-18b4-4ab4-8bb2-ff4db108fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-23455010-d605-4fc6-b3ee-6b22ece7ac05,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-147908fc-4984-41c5-a9d2-a3e15883d3df,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-218483bb-0ab4-4b0a-833b-72c226c8e759,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-9adec8a2-a79d-445d-83e1-cc154aa0756b,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-5a50799f-6ac8-4796-9cdd-2f8fda47115b,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-1bfda259-f112-45fb-b946-ad69d203b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-cbcd4d9f-950d-4188-bee1-f73049b64dcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566420914-172.17.0.16-1595952188078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-ab7039ed-7407-484c-8225-02ff0b29c802,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-0ddd302d-1073-446f-a7ba-e62945c1ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-cc66291a-25d1-4f6f-9873-dfc02ac1f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-4af974e9-ff47-4f32-bf65-72102217d886,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-72c250e5-f29e-4261-8c30-ff300b3ad1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-0a12a397-bd1f-40b4-91c7-c60fc6769a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-59a0ce20-b427-419f-816e-652a92489ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-feb8b0fa-350f-43a9-a1e1-9d6d05e611c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566420914-172.17.0.16-1595952188078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-ab7039ed-7407-484c-8225-02ff0b29c802,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-0ddd302d-1073-446f-a7ba-e62945c1ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-cc66291a-25d1-4f6f-9873-dfc02ac1f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-4af974e9-ff47-4f32-bf65-72102217d886,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-72c250e5-f29e-4261-8c30-ff300b3ad1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-0a12a397-bd1f-40b4-91c7-c60fc6769a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-59a0ce20-b427-419f-816e-652a92489ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-feb8b0fa-350f-43a9-a1e1-9d6d05e611c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-228352162-172.17.0.16-1595952414562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-21d70bd6-1d25-406e-8843-4faa5c247fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-7798218c-5274-44dd-83e5-009e1b255990,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-26ec5bc2-ca83-4e52-91eb-fbc2d7ba650c,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-dac6abc8-b511-4776-9f6f-140945a19ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-9863865c-23d5-4cfd-9851-8ff101bf62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-30ac8db3-c533-4f8e-8db0-d952709cbe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-48c56077-5fec-4ed3-87b7-e7630c351c01,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-aedd2008-5b6c-4118-a37c-13ddabd83fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-228352162-172.17.0.16-1595952414562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-21d70bd6-1d25-406e-8843-4faa5c247fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-7798218c-5274-44dd-83e5-009e1b255990,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-26ec5bc2-ca83-4e52-91eb-fbc2d7ba650c,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-dac6abc8-b511-4776-9f6f-140945a19ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-9863865c-23d5-4cfd-9851-8ff101bf62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-30ac8db3-c533-4f8e-8db0-d952709cbe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-48c56077-5fec-4ed3-87b7-e7630c351c01,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-aedd2008-5b6c-4118-a37c-13ddabd83fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424444742-172.17.0.16-1595952631045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44469,DS-8c8cd865-109e-45ab-86f4-5b9471dca751,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-b5f46c98-6afa-4583-b9f2-1f5f76542b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-6e931bfc-7899-4d74-8603-16c2062af0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-8a4e132a-e87c-4100-8148-1d2c94f0e320,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-771afd71-2e13-4ec2-b540-e9daa1c8345b,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-6537a90e-2fe5-47d1-a15d-f91821337bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-1b7899b2-7249-474f-bddc-3307ea955b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-9bdc642a-ef21-4e1b-9a05-e43ea7331cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424444742-172.17.0.16-1595952631045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44469,DS-8c8cd865-109e-45ab-86f4-5b9471dca751,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-b5f46c98-6afa-4583-b9f2-1f5f76542b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-6e931bfc-7899-4d74-8603-16c2062af0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-8a4e132a-e87c-4100-8148-1d2c94f0e320,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-771afd71-2e13-4ec2-b540-e9daa1c8345b,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-6537a90e-2fe5-47d1-a15d-f91821337bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-1b7899b2-7249-474f-bddc-3307ea955b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-9bdc642a-ef21-4e1b-9a05-e43ea7331cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598060909-172.17.0.16-1595952734597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35067,DS-7942349d-82ec-4b9f-9359-57696780fc01,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-80df247e-2e1f-4576-bea3-a42d33c0e11c,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-c1596c69-b1a5-4d98-92c8-05daeea7b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-2976feac-ac94-4ef3-86c4-844ca8c6a102,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-d2184141-d697-4106-8e35-0ec2ee194284,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-f0832940-7352-4b29-b47c-6e8a6c4406bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-2b612317-3f24-4da1-990f-ea0e74237c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-2a7b9024-1aac-463a-9379-38a52937e102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598060909-172.17.0.16-1595952734597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35067,DS-7942349d-82ec-4b9f-9359-57696780fc01,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-80df247e-2e1f-4576-bea3-a42d33c0e11c,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-c1596c69-b1a5-4d98-92c8-05daeea7b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-2976feac-ac94-4ef3-86c4-844ca8c6a102,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-d2184141-d697-4106-8e35-0ec2ee194284,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-f0832940-7352-4b29-b47c-6e8a6c4406bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-2b612317-3f24-4da1-990f-ea0e74237c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-2a7b9024-1aac-463a-9379-38a52937e102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278985731-172.17.0.16-1595953226515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40605,DS-303b4d98-4111-4de7-8314-9137aa99bd59,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-a048b2f4-283d-4321-8e54-ac17609db026,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-8e0d1767-0534-4c5e-9c68-1ac277ee4ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-38950249-72f9-463d-9347-7d5f6e7d272f,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-7abe124d-1aaa-4c74-882b-5e4e81c65b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-eede33da-514f-4963-b796-97af6c2c630e,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-e15ef85e-9458-4eb8-b039-ebf57e16e570,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-bd454717-07db-47f7-95de-166d48b1d1f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278985731-172.17.0.16-1595953226515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40605,DS-303b4d98-4111-4de7-8314-9137aa99bd59,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-a048b2f4-283d-4321-8e54-ac17609db026,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-8e0d1767-0534-4c5e-9c68-1ac277ee4ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-38950249-72f9-463d-9347-7d5f6e7d272f,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-7abe124d-1aaa-4c74-882b-5e4e81c65b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-eede33da-514f-4963-b796-97af6c2c630e,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-e15ef85e-9458-4eb8-b039-ebf57e16e570,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-bd454717-07db-47f7-95de-166d48b1d1f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5398
