reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387401879-172.17.0.20-1595961453802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45156,DS-3bebd80d-b025-4c8c-89ea-2554980e27d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-e6ca1561-bca2-452c-9878-30eb2ceff717,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-33565904-d5f0-4bfa-9d04-f4869152324d,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-129aa118-1f24-4df7-b7d4-6353a3ada1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-36a5115f-a0cf-41c1-9aa6-c5b5ed222a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1e3476a2-1c51-4ff4-b102-84e956c05d16,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-5d85c39c-8480-4ae9-aabc-23bdde76d323,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-12b32760-d8bf-4692-8829-ad48777aefd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387401879-172.17.0.20-1595961453802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45156,DS-3bebd80d-b025-4c8c-89ea-2554980e27d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-e6ca1561-bca2-452c-9878-30eb2ceff717,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-33565904-d5f0-4bfa-9d04-f4869152324d,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-129aa118-1f24-4df7-b7d4-6353a3ada1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-36a5115f-a0cf-41c1-9aa6-c5b5ed222a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1e3476a2-1c51-4ff4-b102-84e956c05d16,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-5d85c39c-8480-4ae9-aabc-23bdde76d323,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-12b32760-d8bf-4692-8829-ad48777aefd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167008970-172.17.0.20-1595962390211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33467,DS-bfe5b38d-c72f-4075-b4ce-98c5a7f71c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-d2bcdf93-dd08-4cda-a8ae-bd16d4ab5fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-029631a0-e8e7-4f98-ba14-15e310bdf515,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-b81b67f9-68de-4de0-9cd5-5cf219ed567c,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-31c8fa12-4e70-44d7-ac4a-624262fa0924,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-70510a24-4a86-417b-95d9-0dceec87b089,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-22b9e1bd-2d14-4a2c-adcd-ebcb1fd5fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-314b481b-5c6e-47e9-8a58-af4663d8b6fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167008970-172.17.0.20-1595962390211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33467,DS-bfe5b38d-c72f-4075-b4ce-98c5a7f71c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-d2bcdf93-dd08-4cda-a8ae-bd16d4ab5fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-029631a0-e8e7-4f98-ba14-15e310bdf515,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-b81b67f9-68de-4de0-9cd5-5cf219ed567c,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-31c8fa12-4e70-44d7-ac4a-624262fa0924,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-70510a24-4a86-417b-95d9-0dceec87b089,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-22b9e1bd-2d14-4a2c-adcd-ebcb1fd5fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-314b481b-5c6e-47e9-8a58-af4663d8b6fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688189109-172.17.0.20-1595962422024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46201,DS-71976643-063b-400d-90e4-fdaed11a8d38,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-b755bc23-20aa-430d-9ba9-865645c4be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-628a2623-2839-43c7-b615-e59b20087fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-c067ea96-ad5a-43b0-898f-cba96e16bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-e6aa07b3-09cc-4553-ba76-da903e14124a,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-418cf21c-b3ea-4903-b2d4-8760acdd4398,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-5e382b90-8b12-4d3b-99b3-6db3d25d18b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-1265a42b-2b47-4c9d-92dd-3704c1c19bef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688189109-172.17.0.20-1595962422024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46201,DS-71976643-063b-400d-90e4-fdaed11a8d38,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-b755bc23-20aa-430d-9ba9-865645c4be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-628a2623-2839-43c7-b615-e59b20087fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-c067ea96-ad5a-43b0-898f-cba96e16bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-e6aa07b3-09cc-4553-ba76-da903e14124a,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-418cf21c-b3ea-4903-b2d4-8760acdd4398,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-5e382b90-8b12-4d3b-99b3-6db3d25d18b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-1265a42b-2b47-4c9d-92dd-3704c1c19bef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433036524-172.17.0.20-1595963093960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37785,DS-a3310ccc-1fa1-48a2-95b2-430ef2014a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-1d883d75-5adc-4967-99a2-9a67dde2fd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-d66e4b8f-4f73-49f2-9cd5-67a475411a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-34bb71b0-96e3-48f3-bb38-5eec2dc6994b,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-acd90490-c90b-4247-a507-f341e15959e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-50fb4252-dc4c-4b04-a7d2-a7ab4935759d,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-64ef9de8-a435-4be8-891f-7d3b117dd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-0cd9ada0-bbfe-455d-99f1-bd3ae3c3c33b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433036524-172.17.0.20-1595963093960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37785,DS-a3310ccc-1fa1-48a2-95b2-430ef2014a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-1d883d75-5adc-4967-99a2-9a67dde2fd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-d66e4b8f-4f73-49f2-9cd5-67a475411a47,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-34bb71b0-96e3-48f3-bb38-5eec2dc6994b,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-acd90490-c90b-4247-a507-f341e15959e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-50fb4252-dc4c-4b04-a7d2-a7ab4935759d,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-64ef9de8-a435-4be8-891f-7d3b117dd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-0cd9ada0-bbfe-455d-99f1-bd3ae3c3c33b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190266048-172.17.0.20-1595963394384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42819,DS-3e8f66d9-2cc4-4ef2-a52d-dfe80d214975,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-74d7d510-711c-4312-819e-c15df9f3efd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-d141e79f-7bc1-4cdf-abea-c74e7edf665a,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-401faca3-bc34-4c63-b479-4170def2e855,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-5b6421d7-2ba4-4db3-9bee-c7b3c13f5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-c8965a97-bd84-4c84-a47e-ac7177dd1963,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-de93aefa-e63b-4ac1-9936-236fd525ea14,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-a9603b13-bb4b-448a-be02-97113ca9d716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190266048-172.17.0.20-1595963394384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42819,DS-3e8f66d9-2cc4-4ef2-a52d-dfe80d214975,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-74d7d510-711c-4312-819e-c15df9f3efd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-d141e79f-7bc1-4cdf-abea-c74e7edf665a,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-401faca3-bc34-4c63-b479-4170def2e855,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-5b6421d7-2ba4-4db3-9bee-c7b3c13f5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-c8965a97-bd84-4c84-a47e-ac7177dd1963,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-de93aefa-e63b-4ac1-9936-236fd525ea14,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-a9603b13-bb4b-448a-be02-97113ca9d716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515669903-172.17.0.20-1595963432916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36315,DS-5e3ebf22-2585-4d49-baab-fa09608282a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-67712dda-f8b4-4d09-b437-902d386c0560,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-9f8f2205-324c-4b41-bec0-9ce910dbdb55,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-f4d106bb-b6bd-4d9c-84ce-191009e0b0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-24aa0086-a5c9-4f68-9ba6-5190fb974704,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-c654fa92-030d-4f03-a71f-63ecd384fbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-30e6b3d5-5612-4f46-88c9-6af5f846b33d,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-61daf830-3b80-44da-998f-ae51289e6550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515669903-172.17.0.20-1595963432916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36315,DS-5e3ebf22-2585-4d49-baab-fa09608282a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-67712dda-f8b4-4d09-b437-902d386c0560,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-9f8f2205-324c-4b41-bec0-9ce910dbdb55,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-f4d106bb-b6bd-4d9c-84ce-191009e0b0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-24aa0086-a5c9-4f68-9ba6-5190fb974704,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-c654fa92-030d-4f03-a71f-63ecd384fbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-30e6b3d5-5612-4f46-88c9-6af5f846b33d,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-61daf830-3b80-44da-998f-ae51289e6550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025702952-172.17.0.20-1595963575947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40602,DS-f9bc5d39-8732-4d35-8746-72470bae6811,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-aa881f0e-b52c-4a0a-8fa0-a5603a3db5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-2405edb7-413e-45c7-b63b-d9d0d4fb46a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-6849a9f9-5ab2-4fc1-bcc8-6b028089df10,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-ea919569-bc65-4d3f-b65f-1baa5d67d1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-6eb13522-1b85-4586-a354-4f4aaa949514,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-f06542f2-a1a6-4157-846d-0899da1aea79,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-963e4d52-4ac2-40ba-bc07-77f0736d0ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025702952-172.17.0.20-1595963575947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40602,DS-f9bc5d39-8732-4d35-8746-72470bae6811,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-aa881f0e-b52c-4a0a-8fa0-a5603a3db5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-2405edb7-413e-45c7-b63b-d9d0d4fb46a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-6849a9f9-5ab2-4fc1-bcc8-6b028089df10,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-ea919569-bc65-4d3f-b65f-1baa5d67d1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-6eb13522-1b85-4586-a354-4f4aaa949514,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-f06542f2-a1a6-4157-846d-0899da1aea79,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-963e4d52-4ac2-40ba-bc07-77f0736d0ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316412086-172.17.0.20-1595963726919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44996,DS-66a96677-f1eb-4642-876e-b0c25e5e3b90,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-cf0ca336-a158-47b4-bfbe-121937b42bad,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-67ee759a-6abf-452b-b3e2-7e34a930aa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-c8fbb73c-7b7d-47e9-b8fd-01e466ea5eec,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-0ae5a965-0973-4930-8b7e-4af59bdd3ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-bc7e44df-b480-4c31-b8a8-c1a5a5b2e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-36bf670e-7edf-4f58-9ab8-0877c0300a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-b433d11c-42d6-407c-a28d-9b85ac651f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316412086-172.17.0.20-1595963726919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44996,DS-66a96677-f1eb-4642-876e-b0c25e5e3b90,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-cf0ca336-a158-47b4-bfbe-121937b42bad,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-67ee759a-6abf-452b-b3e2-7e34a930aa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-c8fbb73c-7b7d-47e9-b8fd-01e466ea5eec,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-0ae5a965-0973-4930-8b7e-4af59bdd3ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-bc7e44df-b480-4c31-b8a8-c1a5a5b2e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-36bf670e-7edf-4f58-9ab8-0877c0300a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-b433d11c-42d6-407c-a28d-9b85ac651f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517351716-172.17.0.20-1595963803698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36216,DS-62401e2b-62b4-4083-b8b9-54547e3f2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-1921f300-b622-4bbf-8a83-b8167b13fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-5572ccc8-875c-401e-a7cf-ec4641f9303d,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-50df9266-0f7a-423f-ac95-ca640dcdfee7,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-f4983448-7c4f-4063-8de3-9946466aecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-dd48554c-3dee-4057-846c-8b05d30ea3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-95799d8b-ec6f-4836-b6a7-e66e489ac2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-be3b415b-963f-4d9e-88bf-a8d70d6b4495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517351716-172.17.0.20-1595963803698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36216,DS-62401e2b-62b4-4083-b8b9-54547e3f2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-1921f300-b622-4bbf-8a83-b8167b13fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-5572ccc8-875c-401e-a7cf-ec4641f9303d,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-50df9266-0f7a-423f-ac95-ca640dcdfee7,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-f4983448-7c4f-4063-8de3-9946466aecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-dd48554c-3dee-4057-846c-8b05d30ea3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-95799d8b-ec6f-4836-b6a7-e66e489ac2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-be3b415b-963f-4d9e-88bf-a8d70d6b4495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92108000-172.17.0.20-1595964361251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35841,DS-682c7fb3-65f4-41de-a4ed-0afbc61457f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-e950f122-5522-4a06-a974-0ce1db01ba81,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-3f209a61-69c9-476a-9c94-ca2ade88bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-7de224b2-ea00-49de-addd-a1573859d9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-7897bf7e-6876-47fa-91f9-ba36f05b5540,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-73e72fa9-7a73-4c33-8007-e0d0e780d3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-d6f95424-f672-4ea5-8432-7c4dd02c9d57,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-1527a20b-3c7b-4f70-8e7d-f513bdd95c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92108000-172.17.0.20-1595964361251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35841,DS-682c7fb3-65f4-41de-a4ed-0afbc61457f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-e950f122-5522-4a06-a974-0ce1db01ba81,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-3f209a61-69c9-476a-9c94-ca2ade88bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-7de224b2-ea00-49de-addd-a1573859d9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-7897bf7e-6876-47fa-91f9-ba36f05b5540,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-73e72fa9-7a73-4c33-8007-e0d0e780d3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-d6f95424-f672-4ea5-8432-7c4dd02c9d57,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-1527a20b-3c7b-4f70-8e7d-f513bdd95c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644123975-172.17.0.20-1595964436845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40258,DS-282b2e35-2551-48ee-8efc-baa3d1de9f68,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-819fe774-0bc1-45cf-baff-832942b35fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-f346c1dd-d617-44ff-bedf-0ca873503896,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-80649ae2-d0d9-4c78-9a1a-3b6d2360d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-d5f75b74-42c4-44e1-8652-e433a7de929a,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-681fcfe2-9af8-45ec-9024-7f4ff0946acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-4eb2e1aa-0a80-444a-907f-72ba7c488652,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-af909564-dc07-45eb-a256-4cb1af54b40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644123975-172.17.0.20-1595964436845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40258,DS-282b2e35-2551-48ee-8efc-baa3d1de9f68,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-819fe774-0bc1-45cf-baff-832942b35fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-f346c1dd-d617-44ff-bedf-0ca873503896,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-80649ae2-d0d9-4c78-9a1a-3b6d2360d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-d5f75b74-42c4-44e1-8652-e433a7de929a,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-681fcfe2-9af8-45ec-9024-7f4ff0946acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-4eb2e1aa-0a80-444a-907f-72ba7c488652,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-af909564-dc07-45eb-a256-4cb1af54b40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805991182-172.17.0.20-1595964625382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-b7666969-e02b-495c-81f2-818a965309b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-39feaede-61e4-475f-a45a-8595ee78db0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-2e6e5418-fdba-4a9b-acdb-398c79d153a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-61186740-51a3-41b0-8b95-41167c3402a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-198807e3-381a-4a30-891f-3f41b09ac58e,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-985c9942-87f7-4519-be86-ff64293f2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-359e1c13-f4c7-4f0d-b5c3-bd36db2cdb68,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-2f94e3fc-f7ea-4b99-8f13-8ce9174869e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805991182-172.17.0.20-1595964625382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-b7666969-e02b-495c-81f2-818a965309b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-39feaede-61e4-475f-a45a-8595ee78db0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-2e6e5418-fdba-4a9b-acdb-398c79d153a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-61186740-51a3-41b0-8b95-41167c3402a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-198807e3-381a-4a30-891f-3f41b09ac58e,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-985c9942-87f7-4519-be86-ff64293f2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-359e1c13-f4c7-4f0d-b5c3-bd36db2cdb68,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-2f94e3fc-f7ea-4b99-8f13-8ce9174869e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388379949-172.17.0.20-1595964697529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42775,DS-e3223d41-7f6b-4b05-b4a6-2f30b35b3244,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-39d85d25-7682-4cf3-95a4-a4f7716a4a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-e4785a67-b5bd-4c44-a707-9981eb9d19d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-4cbd7003-923a-4eee-afd3-1c5d7daf5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-6692b404-d6eb-4673-90da-b02659f17f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-3d79f2aa-64ca-4668-8f90-48a34f9207b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-bd1f0c65-92aa-4cd1-96f1-a69cf49795e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-24309027-c563-452d-b284-95efc3ab8c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388379949-172.17.0.20-1595964697529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42775,DS-e3223d41-7f6b-4b05-b4a6-2f30b35b3244,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-39d85d25-7682-4cf3-95a4-a4f7716a4a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-e4785a67-b5bd-4c44-a707-9981eb9d19d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-4cbd7003-923a-4eee-afd3-1c5d7daf5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-6692b404-d6eb-4673-90da-b02659f17f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-3d79f2aa-64ca-4668-8f90-48a34f9207b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-bd1f0c65-92aa-4cd1-96f1-a69cf49795e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-24309027-c563-452d-b284-95efc3ab8c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427032080-172.17.0.20-1595964832417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37159,DS-a57d066b-d554-477f-a0c4-e30542cf89b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-47ea1a64-34fa-48b6-8d93-56ed7f95c19d,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-8f364495-4c75-40cc-952d-c61e0593bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-403d1f3c-e9a7-40d5-abe6-cf214275494b,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-4426e52e-c4be-4457-8b3c-a5eeb1c368a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-403a284f-ddd9-47c3-8e13-56c13491cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-c305dd4a-fb84-402f-a732-7a819da9cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-e4e1d76c-a471-4b4d-bfb7-a902a1451345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427032080-172.17.0.20-1595964832417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37159,DS-a57d066b-d554-477f-a0c4-e30542cf89b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-47ea1a64-34fa-48b6-8d93-56ed7f95c19d,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-8f364495-4c75-40cc-952d-c61e0593bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-403d1f3c-e9a7-40d5-abe6-cf214275494b,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-4426e52e-c4be-4457-8b3c-a5eeb1c368a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-403a284f-ddd9-47c3-8e13-56c13491cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-c305dd4a-fb84-402f-a732-7a819da9cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-e4e1d76c-a471-4b4d-bfb7-a902a1451345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386831371-172.17.0.20-1595965015835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42247,DS-ade03a88-40eb-491a-8ea8-b0b6b499b3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-8c796212-fe78-45d1-acfa-c725b1697d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-d4afd052-81a3-48f8-9ec3-4cee6bf0c421,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-85e7792a-a7b9-4bfd-b800-78015d092790,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-58894aab-553b-40f6-9b46-8c3efd711241,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-34425bb0-37e7-485d-ae88-1e5c05f487f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-b183baf9-4daf-4036-96a9-6d069dee51f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-cfb4a37d-efb7-4a71-a806-a0d96b9d39cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386831371-172.17.0.20-1595965015835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42247,DS-ade03a88-40eb-491a-8ea8-b0b6b499b3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-8c796212-fe78-45d1-acfa-c725b1697d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-d4afd052-81a3-48f8-9ec3-4cee6bf0c421,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-85e7792a-a7b9-4bfd-b800-78015d092790,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-58894aab-553b-40f6-9b46-8c3efd711241,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-34425bb0-37e7-485d-ae88-1e5c05f487f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-b183baf9-4daf-4036-96a9-6d069dee51f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-cfb4a37d-efb7-4a71-a806-a0d96b9d39cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869957854-172.17.0.20-1595965221604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-d831bff1-2f19-46d6-843d-e211433f12a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-65796316-315e-4ef9-a06e-48bd550d2b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-994b76f7-2031-4893-8daa-02f5d1829328,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-7ad96740-d432-4539-bb18-d9ea76b2b461,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-3509709d-1765-4811-9349-0a57d29e4e24,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-7dfb19f1-f3f5-4b61-b51e-fa06a42159b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-367bc636-3a66-4145-a650-da81973a17b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-a78b31a1-67cc-4f19-8791-b26780b09722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869957854-172.17.0.20-1595965221604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-d831bff1-2f19-46d6-843d-e211433f12a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-65796316-315e-4ef9-a06e-48bd550d2b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-994b76f7-2031-4893-8daa-02f5d1829328,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-7ad96740-d432-4539-bb18-d9ea76b2b461,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-3509709d-1765-4811-9349-0a57d29e4e24,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-7dfb19f1-f3f5-4b61-b51e-fa06a42159b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-367bc636-3a66-4145-a650-da81973a17b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-a78b31a1-67cc-4f19-8791-b26780b09722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523788583-172.17.0.20-1595965530151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37137,DS-36f6806d-6bbb-4f44-82ba-14a95a186b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-7ea7d216-6f65-4184-b131-095a30100152,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-1d918884-9165-448a-9818-a40fd959f3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-4d716859-bc1d-487e-9026-522dc50dac2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-72fa96dc-c63b-4c3b-aff8-24befddc59c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-46754303-6469-4bc1-a3cc-b8add003db56,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-ca44c4fd-e28b-4b0c-a9f1-1e63aa07e31f,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-76c590f9-ee63-47ba-9f45-51a728d9e1d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523788583-172.17.0.20-1595965530151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37137,DS-36f6806d-6bbb-4f44-82ba-14a95a186b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-7ea7d216-6f65-4184-b131-095a30100152,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-1d918884-9165-448a-9818-a40fd959f3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-4d716859-bc1d-487e-9026-522dc50dac2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-72fa96dc-c63b-4c3b-aff8-24befddc59c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-46754303-6469-4bc1-a3cc-b8add003db56,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-ca44c4fd-e28b-4b0c-a9f1-1e63aa07e31f,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-76c590f9-ee63-47ba-9f45-51a728d9e1d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222071394-172.17.0.20-1595966104004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43160,DS-3017fbef-05b0-453e-b8dc-5eb8ee413261,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-31aff1cf-f6bc-47df-8200-b375a37bf0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-d6490ed8-cab3-49d4-b121-2a6846af0be1,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-7270fa0a-39c2-480f-a089-2c4767c021e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-0301af80-1cda-4f2d-a030-cc840dbf4cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-726318c9-2f8d-45ff-875d-3afa04999a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-4f57ef2d-dcd9-4a5a-b14e-144752649d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-9d52ed0a-3aff-4a4d-b9ae-e3f54ad95f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222071394-172.17.0.20-1595966104004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43160,DS-3017fbef-05b0-453e-b8dc-5eb8ee413261,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-31aff1cf-f6bc-47df-8200-b375a37bf0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-d6490ed8-cab3-49d4-b121-2a6846af0be1,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-7270fa0a-39c2-480f-a089-2c4767c021e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-0301af80-1cda-4f2d-a030-cc840dbf4cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-726318c9-2f8d-45ff-875d-3afa04999a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-4f57ef2d-dcd9-4a5a-b14e-144752649d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-9d52ed0a-3aff-4a4d-b9ae-e3f54ad95f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 127
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230367873-172.17.0.20-1595966137942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-e164d5ea-8925-4f92-a0cd-3dd515f37a70,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-9abab492-604a-4584-94dd-2bc27440b286,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-74bdaf06-c529-48c6-8982-0fa8da7f7961,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-7f38c6cf-09bd-4f21-9bf6-0d36b080f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-0b40b872-d365-4736-a2bf-5b98e153781f,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-d3fd7a06-9687-45f1-acd7-dd93eb0a0dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-8e804e4a-1d12-45d3-8704-dea18cc505a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-15917564-fcdd-489f-b8b7-b2194e5358cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230367873-172.17.0.20-1595966137942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-e164d5ea-8925-4f92-a0cd-3dd515f37a70,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-9abab492-604a-4584-94dd-2bc27440b286,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-74bdaf06-c529-48c6-8982-0fa8da7f7961,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-7f38c6cf-09bd-4f21-9bf6-0d36b080f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-0b40b872-d365-4736-a2bf-5b98e153781f,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-d3fd7a06-9687-45f1-acd7-dd93eb0a0dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-8e804e4a-1d12-45d3-8704-dea18cc505a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-15917564-fcdd-489f-b8b7-b2194e5358cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5094
